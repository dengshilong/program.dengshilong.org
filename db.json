{"meta":{"version":1,"warehouse":"1.0.3"},"models":{"Asset":[{"_id":"themes/jacman/source/js/totop.js","path":"js/totop.js","modified":0},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","path":"js/jquery.qrcode-0.12.0.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0},{"_id":"themes/jacman/source/js/gallery.js","path":"js/gallery.js","modified":0},{"_id":"themes/jacman/source/img/scrollup.png","path":"img/scrollup.png","modified":0},{"_id":"themes/jacman/source/img/logo.svg","path":"img/logo.svg","modified":0},{"_id":"themes/jacman/source/img/logo.png","path":"img/logo.png","modified":0},{"_id":"themes/jacman/source/img/jacman.jpg","path":"img/jacman.jpg","modified":0},{"_id":"themes/jacman/source/img/cc-zero.svg","path":"img/cc-zero.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by.svg","path":"img/cc-by.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-sa.svg","path":"img/cc-by-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nd.svg","path":"img/cc-by-nd.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc.svg","path":"img/cc-by-nc.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","path":"img/cc-by-nc-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","path":"img/cc-by-nc-nd.svg","modified":0},{"_id":"themes/jacman/source/img/banner.jpg","path":"img/banner.jpg","modified":0},{"_id":"themes/jacman/source/img/author.jpg.bak","path":"img/author.jpg.bak","modified":0},{"_id":"themes/jacman/source/img/author.jpg","path":"img/author.jpg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.woff","path":"font/fontdiao.woff","modified":0},{"_id":"themes/jacman/source/font/fontdiao.ttf","path":"font/fontdiao.ttf","modified":0},{"_id":"themes/jacman/source/font/fontdiao.svg","path":"font/fontdiao.svg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.eot","path":"font/fontdiao.eot","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","path":"font/fontawesome-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","path":"font/fontawesome-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","path":"font/fontawesome-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","path":"font/fontawesome-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","path":"font/coveredbyyourgrace-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","path":"font/coveredbyyourgrace-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","path":"font/coveredbyyourgrace-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","path":"font/coveredbyyourgrace-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/FontAwesome.otf","path":"font/FontAwesome.otf","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0},{"_id":"themes/jacman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0},{"_id":"themes/jacman/source/css/style.styl","path":"css/style.styl","modified":0}],"Cache":[{"_id":"source/_posts/Django后台添加markdown编辑器.md","shasum":"24534e19f7025d4c4920ce93f2becb848802501e","modified":1451781531000},{"_id":"source/_posts/13球问题.md","shasum":"3023e1bd6392bd4481e278b2132251385488477b","modified":1451781531000},{"_id":"source/_posts/Django1-9-1使用django-pagination分页.md","shasum":"7440825d1bdc4335968d7200c1df66ea4a6990ee","modified":1461413042000},{"_id":"source/_drafts/寻找极小值.md","shasum":"8b0a84c702895f17cfc7331f34c6fa742bcd80f6","modified":1451781531000},{"_id":"source/_posts/Elasticsearch中ik添加同义词.md","shasum":"d8724df9f0932444c7517ea8977de6449c7eb2fa","modified":1459944972000},{"_id":"source/_posts/Elasticsearch从MySQL导数据.md","shasum":"58b7978ab75c37fb7eac6b65e6ee983abf207e66","modified":1460279125000},{"_id":"source/_posts/Django生产环境静态资源配置.md","shasum":"0a7491043d1d9c9f66bdcbe41ef362e4c23e4254","modified":1451781531000},{"_id":"source/_posts/Django添加markdown.md","shasum":"6d2c8001c4eb26f29e2137846cab1202a2b52483","modified":1457231546000},{"_id":"source/_posts/HDU2222-Keywords-Search.md","shasum":"bc4d8611bfd283ec9b1d8592487f2d8d668ad2e3","modified":1451781531000},{"_id":"source/_posts/Elasticsearch源码分析-启动.md","shasum":"18bfcf14f7ebf79c187b34073fe17ed17788b016","modified":1460726274000},{"_id":"source/_posts/Elasticsearch源码分析-查询.md","shasum":"bfe058788db7d8c8172117846632e044fb11e7d3","modified":1460795757000},{"_id":"source/_posts/Elasticsearch修改版本号和日志.md","shasum":"e855180079b637b8fd3ee654dbc6c7a74d275965","modified":1460811159000},{"_id":"source/_posts/Lucene中扩展codec功能.md","shasum":"3d37405dca2839c0dee19aff8a707ff536e363a5","modified":1451781531000},{"_id":"source/_posts/Linux挂载U盘.md","shasum":"f3f15d55ac239ef03fbb45855bda74eae732e6f5","modified":1451781531000},{"_id":"source/_posts/Java创建线程.md","shasum":"a5db951f9c46d7dbb5bdfc66b7348707fca4d84f","modified":1451781531000},{"_id":"source/_posts/Lucene入门例子.md","shasum":"be41bd8616a16c4980050d035c5b995cf4e297ee","modified":1451781531000},{"_id":"source/_posts/Lucene编写Analyzer.md","shasum":"7e4a9bc3fe2d209db788f67187fe31ef4c35f15c","modified":1451781531000},{"_id":"source/_posts/MMSEG分词.md","shasum":"1ae5801c2113ddb13d283591e4d2a9e48c08071e","modified":1451781531000},{"_id":"source/_posts/MySQL的timestamp类型.md","shasum":"621201b0de461ef4c6036ba927f3bef5476349cb","modified":1451781531000},{"_id":"source/_posts/N后问题递归解.md","shasum":"4d430a8a91543373d0456648144a03d92f11eeed","modified":1451781531000},{"_id":"source/_posts/Octave中的for循环.md","shasum":"7818d7e3aab6029fd7755ad6c82fb5c4568d1b65","modified":1451781531000},{"_id":"source/_posts/POJ2001-Shortest-Prefixes.md","shasum":"13dc4d140d1a97702026abb01e20e650facbf16f","modified":1451781531000},{"_id":"source/_posts/Lucene索引文件格式.md","shasum":"917942f52325a987194f7d1ae41c55aabf7e80d9","modified":1451781531000},{"_id":"source/_posts/POJ2524-Ubiquitous-Religions.md","shasum":"df93aeedcfa56c6ca8ccae9b5a451b5d14412a36","modified":1451781531000},{"_id":"source/_posts/Screen-会话管理工具.md","shasum":"bb48c096fa6c31df14349e78a906ca8e4f708de8","modified":1451781531000},{"_id":"source/_posts/PyCharm安装vim插件.md","shasum":"2add327584f92898b5d9b76ed2ee8ca82d1e0273","modified":1460687046000},{"_id":"source/_posts/Python筛法求素数的优化.md","shasum":"760c77f9ccbf1b8d782aade4de1603bacc8e46d4","modified":1451781531000},{"_id":"source/_posts/Solr-in-Action笔记一.md","shasum":"62f0ca121eb45bb4c612daafab685f164f9e86c2","modified":1451781531000},{"_id":"source/_posts/Solr-in-Action笔记三.md","shasum":"b4ccdb65dc834b611d7cd654e8974514622b39a7","modified":1451781531000},{"_id":"source/_posts/SlopeOne算法.md","shasum":"f17e7cea140fb46afffcd4a0b3f6ca70fb50265d","modified":1462453184000},{"_id":"source/_posts/Solr-in-Action笔记二.md","shasum":"9cda2d0588ac4a4e6f73ca1036ba459c6b507d53","modified":1451781531000},{"_id":"source/_posts/Solr从MySQL导数据.md","shasum":"147868e9fd6f615c439334f8894c5254ca8a30f7","modified":1459750125000},{"_id":"source/_posts/Solr分布式请求stage理解.md","shasum":"44a928deb2cee6b21bb1c3ffe6286e48728509df","modified":1451781531000},{"_id":"source/_posts/Solr分布式group查询过程.md","shasum":"c244a30ff3306a6df3f61730cf221161553e7b3e","modified":1451781531000},{"_id":"source/_posts/Solr查询词提取.md","shasum":"eebb48835a4cc2b817146812edcfb0f3929e7be2","modified":1451781531000},{"_id":"source/_posts/Solr权限控制.md","shasum":"b08bba5d7141bb58f6d89314d932182d1cceeb71","modified":1451781531000},{"_id":"source/_posts/Solr索引升级错误.md","shasum":"f9ae1d0c967b3d4c140416a1807fecdf7ba695f9","modified":1451781531000},{"_id":"source/_posts/Solr索引升级.md","shasum":"2d8108a1d945c4924791a82554d92a4a15fa1208","modified":1451781531000},{"_id":"source/_posts/Solr权限控制solrj认证.md","shasum":"a437809f7a6504ba74b9ce1595f593cf7e6c0942","modified":1451781531000},{"_id":"source/_posts/Sphinx-for-Chinese的分词细粒度问题.md","shasum":"2c6f3bb8f194132b93378133274435775486f45e","modified":1451781531000},{"_id":"source/_posts/Spark初体验.md","shasum":"5eb4c7bf5bf43d02dca732ff768bd640fa504cf5","modified":1461680278000},{"_id":"source/_posts/Sphinx使用一元分词.md","shasum":"2d2f365e22ced9624ba1455d9ff28356472a5623","modified":1451781531000},{"_id":"source/_posts/Sphinx-for-Chinese的分词细粒度问题解决代码.md","shasum":"d848ff5b41843cd40fca0fe1fdd98af03ef9a78f","modified":1451781531000},{"_id":"source/_posts/TCP建立连接时的三次握手.md","shasum":"1ae6c9803e5f44333032fdfe48e79dd84f041f3f","modified":1451781531000},{"_id":"source/_posts/Sphinx更新属性无法为负值.md","shasum":"e24f7da83fd4f9b8d766aa4f98fbbb3827026049","modified":1451781531000},{"_id":"source/_posts/Wordpress迁移到Hexo遇到的问题.md","shasum":"75e365bbae6db3e1552ddbc2860297444ba0b5bd","modified":1451781531000},{"_id":"source/_posts/Ubuntu中打开PDF文件.md","shasum":"8238866c5935095fb2a531c80212d8cbdf1e6d95","modified":1451781531000},{"_id":"source/_posts/Sphinx-for-Chinese的分词细粒度问题(续).md","shasum":"06f72cc1ec438fb6c44cef753232a40a0eb9aaac","modified":1451781531000},{"_id":"source/_posts/cannot-import-name-detail-route错误.md","shasum":"a7af76fffe5263d531581b49a15a3a837756c158","modified":1460636715000},{"_id":"source/_posts/find查找目录下的所有shell脚本.md","shasum":"b71a70a78f4f4c9b3072e25e0784556bf2fb4db9","modified":1451781531000},{"_id":"source/_posts/junit找不到方法.md","shasum":"bf887859fc3819b18118b073ed7bdc26ebe73184","modified":1451781531000},{"_id":"source/_posts/int,double等转化成byte数组.md","shasum":"9b16752117ec88320ea15c746df5eb58a3b1e09c","modified":1451781531000},{"_id":"source/_posts/sed替换文件内容.md","shasum":"5a3a5d88d7034c2b1707c1042c9b10bf46e55534","modified":1451781531000},{"_id":"source/_posts/mysqli_fetch_all函数.md","shasum":"c8855a8b7356a33a675422c730128337218ce1aa","modified":1451781531000},{"_id":"source/_posts/smarty使用的注意点.md","shasum":"346eeae6b664661365d41d4f91fab5dc13b9bfc0","modified":1451781531000},{"_id":"source/_posts/shell的一些特殊变量.md","shasum":"86a0ae6388eba514880c3723adda4f64d661758a","modified":1451781531000},{"_id":"source/_posts/solr非存储字段变成存储字段.md","shasum":"4982ccd7ca6f07ce6cfe60e3604cd0bda4554b03","modified":1451781531000},{"_id":"source/_posts/solr分布式搜索时设置分页的一个错误.md","shasum":"7868273e9fdc491b63ecf564445bfeb9e5a5fa51","modified":1451781531000},{"_id":"source/_posts/solr非存储字段变成存储字段解决代码.md","shasum":"834971988aaad3e6b97e74a311a848d9ed70b391","modified":1451781531000},{"_id":"source/_posts/crontab定时运行脚本.md","shasum":"3142347032025df5b7db698f9f9ce3f248c4ea82","modified":1451781531000},{"_id":"source/_posts/产生Gray码.md","shasum":"dd22fa70d68ae83d245a8a6d014e2bbdee81765f","modified":1451781531000},{"_id":"source/_posts/两数组最短距离.md","shasum":"034472192b5afb58aa59048c9e21d3f835657596","modified":1451781531000},{"_id":"source/_posts/产生所有排列--字典顺序(非递归解).md","shasum":"f0ccc1fb3fdaf31b4ee170ac64f1d2c36cf41ba7","modified":1451781531000},{"_id":"source/_posts/vps上部署Hexo.md","shasum":"d55f229ab3467e0ce9d8567830e8fa16fecf62e1","modified":1459736795000},{"_id":"source/_posts/产生匹配括号的字符串.md","shasum":"0ea0952b9502dff3fc6452139db9f1a8011c1de9","modified":1451781531000},{"_id":"source/_posts/Hadoop-Yarn安装.md","shasum":"ca4a248f0a629fc4bb698f577216222d6ddea411","modified":1461143691000},{"_id":"source/_posts/产生所有排列--字典顺序.md","shasum":"b4f2b2204e158bf43db5f3039edd1fc1e7ac10b0","modified":1451781531000},{"_id":"source/_posts/关于Sphinx引擎的一些想法.md","shasum":"76f69b8a717ef02cdaa235a62761d462e43f069d","modified":1451781531000},{"_id":"source/_posts/几道数学笔试题.md","shasum":"d21005b0048020c4791dfce772c6c5763bf4ffd1","modified":1451781531000},{"_id":"source/_posts/使用virtualenvwrapper隔离Python环境.md","shasum":"8e038ec8394e868930fd530fbd3301dc8a9e3f4d","modified":1461240773000},{"_id":"source/_posts/取石子游戏.md","shasum":"ef38cb5196dfa1c76910a925a8d441a5f5e5fd5c","modified":1451781531000},{"_id":"source/_posts/在C++的sort排序中永远让比较函数对相等的值返回false.md","shasum":"354e51d090a150119bc1f50fa51f6a17fada7f90","modified":1451781531000},{"_id":"source/_posts/堆排序.md","shasum":"9ad01db006b606c23500a8334f2b7321852d8661","modified":1451781531000},{"_id":"source/_posts/填方格问题.md","shasum":"83822c968e37b850e20c9cd4fd169073407a19f2","modified":1451781531000},{"_id":"source/_posts/在Intellij中启动ElasticSearch.md","shasum":"ebd66605e3c2d5d83e3c24b493fc974b640eaaf6","modified":1460096194000},{"_id":"source/_posts/安装Maven.md","shasum":"b816522abfa850a9c352927784c2416beb9d756f","modified":1451781531000},{"_id":"source/_posts/如何判断一个数是否是素数.md","shasum":"4592212fa705c271841e2f014bfe817c210d274d","modified":1451781531000},{"_id":"source/_posts/如何实现site查询.md","shasum":"9b1ff3e33363f7d6ac43deb4493fc3f731a6d272","modified":1451781531000},{"_id":"source/_posts/常用正则备忘.md","shasum":"01937e20eaf1f7f18a50b3f9aade71a4e7b0b6cd","modified":1451781531000},{"_id":"source/_posts/寻找极小值.md","shasum":"b4c39526b70fb212133eab006509a079cbf56e28","modified":1451781531000},{"_id":"source/_posts/提取雪球搜索页面主要内容.md","shasum":"c1f87b1ba2fc063ea28cccb802e26bc754fe449f","modified":1451781531000},{"_id":"source/_posts/扔蛋问题.md","shasum":"1be1e23eadc35416dcda557e6a82e02a4b10dd73","modified":1451781531000},{"_id":"source/_posts/安装jdk源码.md","shasum":"982be8daa02de1c30baf4b3945300d9d33f21a8d","modified":1451781531000},{"_id":"source/_posts/搭建Sphinx-for-chinese引擎时遇到的问题.md","shasum":"0841ac07681e6020af93019353127ab2d3c112ff","modified":1451781531000},{"_id":"source/_posts/支配值数目.md","shasum":"da77799ba50cb41c515f1a3cfef5d86493fcfe2f","modified":1451781531000},{"_id":"source/_posts/搜索第二页实现.md","shasum":"97369b3f2f7c1f4931f8c4a2772d27fa02fa04d5","modified":1458122523000},{"_id":"source/_posts/整数划分.md","shasum":"72dad106b1adbd9c9ae710c972cd5fae49dc57fd","modified":1451781531000},{"_id":"source/_posts/数字漩涡.md","shasum":"5601b0b872731b98f1e5f09c5cdc48e68a52ec57","modified":1451781531000},{"_id":"source/_posts/无解的难题.md","shasum":"7839ddce30fb42fa100954c1165bc2c6bfe2c628","modified":1451781531000},{"_id":"source/_posts/最大子矩阵.md","shasum":"4e4f537b0c6444b499fa40796df16a775e388d47","modified":1451781531000},{"_id":"source/_posts/收到金融学结业证书.md","shasum":"68d0702badce863e1df4b14af8d5a5e71d94b800","modified":1451781531000},{"_id":"source/_posts/最大连续元素和.md","shasum":"02ef112f418877d2f0e847cd59ecacdf86bf9664","modified":1451781531000},{"_id":"source/_posts/最大连续子序列.md","shasum":"8e0a5f86b6e2218eb0f66676c19fcbdecb02d416","modified":1451781531000},{"_id":"source/_posts/最小的K个数.md","shasum":"a7095ebd25f8bca9ce8f8d2e4ce1c6b11c284325","modified":1451781531000},{"_id":"source/_posts/最短编辑距离.md","shasum":"ddebe43422ce3833cd3a136d6bc8ad6309b72150","modified":1451781531000},{"_id":"source/_posts/最长平台.md","shasum":"2d590bbe9741ed2c389919e3556cc2d2b886b0bd","modified":1451781531000},{"_id":"source/_posts/查找矩阵.md","shasum":"8eda93931a20194f6b4cea482ecfdd02076eba23","modified":1451781531000},{"_id":"source/_posts/查看端口是否被占用.md","shasum":"4536988b1250ec9bfcbc062493d74cfe1917e4fc","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题1.md","shasum":"a5704dc54fc19eb73fedc840ef01babe41c02913","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题10.md","shasum":"d1efbe354572ca7b48efdaec38efbfa770f5913e","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题11.md","shasum":"f154434998443f52a3c4bad9c5d0a8c5d03d66b2","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题12.md","shasum":"18f90d1e0b57b5a9cb406a135552a90eab55ebc4","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题13.md","shasum":"bf386a3fdfbb3d71bd3194a0fb0f18b2adce95d0","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题14.md","shasum":"025ec8edf4a43fbb5108759c2f6347b7aee4eb0b","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题16.md","shasum":"382a89d478fd3db20aea6895c0e0e5ebadc5d4ca","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题17.md","shasum":"748521c16826c64125aba5fc8f5c010be5cc112a","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题15.md","shasum":"02209fc3f8fc4467d25e92342f9e6f6cec531a6d","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题19.md","shasum":"112c199dd87fc4debf62adcc763489f14d3b4881","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题2.md","shasum":"bd918e3c93e6f78a87c966edfb87d3d239c135e2","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题18.md","shasum":"751ff06830167749f75fdbe6d32410c4ef09fc0c","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题20.md","shasum":"cf50184e5dc4a41a324268e70cb5ed13a962be58","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题21.md","shasum":"a6b8a5d4a09d96875351c56bc8d98c8521e97613","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题22.md","shasum":"575cfd67dd4ce1cd0bf8100b6a777045a7c787f4","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题23.md","shasum":"b45d446bea5c7b9f74b7d9714f56ee46059e0714","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题25.md","shasum":"982476ea528e49f5ac32d1c685ecde43999ae38b","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题24.md","shasum":"869cdaca16d0b2c646e4fcd5036a7875e885fac9","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题26.md","shasum":"a0a82f38e6ec39a05a82f76c04513e947b5b9f02","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题27.md","shasum":"f24843dc0e9713cb2b8083fd07553e70727996e5","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题28.md","shasum":"03c8e1d10acf6302576352149461e277c3988d88","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题29.md","shasum":"d2e78e67648e39d1928c777ed9c498376c0827b9","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题30.md","shasum":"cd5e4ce4ce590eae6f0ac480a1093a95dfb99e44","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题31.md","shasum":"a230c250445d5d6740be6c993c1afbe53d135f12","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题3.md","shasum":"3b466c04526ed4b3cc2c86cbf2c4b5fea545d589","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题32.md","shasum":"defde3a2dc3434426f3b4c7eace79ef7c52427f3","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题34.md","shasum":"e075fdb31ba7817d6765937fd2c0ccb1729f738b","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题33.md","shasum":"e5f5cc3f13237718f748896e785861d965f3c061","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题35.md","shasum":"44f88a870a25959760cc43cbc9ffc3e126542ee6","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题36.md","shasum":"2f2a245c9827dbf750f4f7f435b841e09168644a","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题37.md","shasum":"9f476bd0e40a96c0e5ec17ff06216bf72eba1a88","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题38.md","shasum":"6fe8ae3156d097b3fd324c9fd13cab86b861a177","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题39.md","shasum":"e6ec94599e6257e418812cf077925a2966a8d62c","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题4.md","shasum":"3ffc5223c03b1dbcc8d65d170b41a6d8fe9ab20f","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题40.md","shasum":"165695304d2eb6aea75651aaa14f1c70fa00d3b1","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题41.md","shasum":"3d6f13390c025f05e3fa4d96806e2484561c37ba","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题43.md","shasum":"f49854b39c39b061c5137fd0364131e39d967240","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题44.md","shasum":"7ac58ffb841d050bed007707f9b9dd75c4963c8c","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题42.md","shasum":"7c45016e2f5019c8a0f01b777cdae046e81cb8fb","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题45.md","shasum":"fe876e5eec27b7871284574490752e168bdf71ad","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题46.md","shasum":"41c8dfedb6b5e82c7c41bfc9550423f7671ab3a8","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题47.md","shasum":"9923eace4975a4735a44811f504925419c7bbe23","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题49.md","shasum":"f0d8c5554efa4c228e86f889382893d911771625","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题5.md","shasum":"296423ebdbabec81bde68112b083edb0dfc4421d","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题48.md","shasum":"94b9aaa3ea1fb3a82340a7dfb7c6ed3984f8d743","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题52.md","shasum":"fabbab68526b8677c5a65ca1273e4041f74154b0","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题50.md","shasum":"2b43e4db7c21b61617b7259e97c8e334720d4d16","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题53.md","shasum":"925c3d5a845b060b0076898dffca4b9e96005be8","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题51.md","shasum":"bbd59eca4ba0f6ac4ff7dc06f62bc323de76d399","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题56.md","shasum":"e830b6f6416303130b9c82ed6ec091944fd4ac87","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题55.md","shasum":"7158b3f84f22c643903a88e3dc10b4ff24abe3a9","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题54.md","shasum":"9d21eacfad70a851ba4c97772d1065aaac95cc89","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题57.md","shasum":"174e8bbfcfeb8bc5f7cef07ed5ac5398b9a940f9","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题59.md","shasum":"d1ec15f6a4674f4f13af46ca12b7f247cfd43ce0","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题58.md","shasum":"01c5e8904d722c4ef36067871f581bfad1abd010","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题7.md","shasum":"15a51a697be43a8c89fb403e7950836242f998a1","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题60.md","shasum":"18ed1511a362a6c03b17ea31a178a4b17a7ad784","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题6.md","shasum":"7a1ad9ad1c9a9e1d4913cedb8104ea87e5619f26","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题8.md","shasum":"8522621f362729413f74972b1edc643f781597ea","modified":1451781531000},{"_id":"source/_posts/欧拉工程-问题9.md","shasum":"0378031f3409ad1883f519512d7a3d9adecb5381","modified":1451781531000},{"_id":"source/_posts/求一个数的质因子分解.md","shasum":"24fd075de8b5f4a2cc4068424d68159dcc4a8c17","modified":1451781531000},{"_id":"source/_posts/用Sphinx建立main+delta索引(下篇).md","shasum":"7dd1873aa056c32ab5482c24671f8cc1ee5ceeb7","modified":1451781531000},{"_id":"source/_posts/用Sphinx建立main+delta索引(上篇).md","shasum":"11384a0ac8671e2621db6c4faf59070d632f1cd1","modified":1451781531000},{"_id":"source/_posts/用Sphinx建立只有主索引的引擎.md","shasum":"1ef1e5958d21788b749bc093ae085dfcc47b1c72","modified":1451781531000},{"_id":"source/_posts/用Sphinx提供的klist处理文章更新和删除.md","shasum":"b150d2aedf5d8813638eccafa0a1c3f0eab3c317","modified":1451781531000},{"_id":"source/_posts/用epoll提供telnet服务的代码(续).md","shasum":"50955f07167b7843f02b6fe871cd4ab45fa28edb","modified":1451781531000},{"_id":"source/_posts/用select实现精确定时器.md","shasum":"9f51c686dfccf1688cf112d50898a44253a80e2b","modified":1451781531000},{"_id":"source/_posts/用epoll提供telnet服务的代码.md","shasum":"1d60ef704428cc70325696172d71e63ad1d41727","modified":1451781531000},{"_id":"source/_posts/等值数目.md","shasum":"75362f8caed7461c88b25bef7633820e44cf676f","modified":1451781531000},{"_id":"source/_posts/登陆框获取焦点.md","shasum":"b27a03fa871eba536069f8e08fc6a57c6f1863ff","modified":1451781531000},{"_id":"source/_posts/筛法得到素数.md","shasum":"b7f756cdba3513e5eef847d1593a92cfa7208a63","modified":1451781531000},{"_id":"source/_posts/给sphinxclient.c增加flush索引到硬盘功能.md","shasum":"c1a99b5c486227bd106f9ed0ae92570b5edae3c9","modified":1451781531000},{"_id":"source/_posts/等值首尾和.md","shasum":"8ab4c4613adbf5e0bbc8b8e1620d3a80ed51a908","modified":1451781531000},{"_id":"source/_posts/自动脚本登录服务器.md","shasum":"ec1e6f85ddd8c6778d4f19efbea32ea2ebeb1323","modified":1451781531000},{"_id":"source/_posts/语言特性还是有必要学习的.md","shasum":"4e43e1f6b3c0bd1a25cdc1283eb457be8b1f918d","modified":1451781531000},{"_id":"source/_posts/软连接和硬连接.md","shasum":"b6e21eca23e464a090a3a6b88ef958f8a8bbdbc4","modified":1451781531000},{"_id":"source/_posts/追踪query-too-complex-not-enough-stack错误.md","shasum":"7a089092abcd8cd3403d8294717d4e09f893aa1f","modified":1451781531000},{"_id":"source/_posts/解决Error:-searchd-error:-offset-out-of-bounds问题.md","shasum":"534107b7f02ac81953a8d6331ada49db70af5786","modified":1451781531000},{"_id":"source/_posts/选择排序中的交换次数.md","shasum":"cc89d2b18cea3698ee87acf76960acb61f0f6832","modified":1451781531000},{"_id":"source/_posts/重温manufactoria.md","shasum":"6c9f3ba3ea9d989d01e1b8a8d4afa7844f0007d9","modified":1451781531000},{"_id":"source/_posts/金融学公开课结业.md","shasum":"cb7c72559a5d22b7580a9b29d00b7f56c3bf992d","modified":1451781531000},{"_id":"source/about-me/index.md","shasum":"e9225f91d89ea05b09962b6a49f2cb3ff038c5fe","modified":1451781531000},{"_id":"source/about/index.md","shasum":"72555d74633fb0f802fd60a65fd0d30cf10b86d4","modified":1460722607000},{"_id":"themes/jacman/README_zh.md","shasum":"0854e4c96f53005f3a47e21af3f8aee361719ce4","modified":1451781531000},{"_id":"themes/jacman/README.md","shasum":"79be8a49927c8666f1804d7ccd08af8d3268062a","modified":1451781531000},{"_id":"themes/jacman/_config.yml","shasum":"193167ca2685023f694bb66c891ad22c8a298046","modified":1451781531000},{"_id":"themes/jacman/LICENSE","shasum":"931516aa36c53eb7843c83d82662eb50cc3c4367","modified":1451781531000},{"_id":"themes/jacman/languages/zh-CN.yml","shasum":"1f3b9d00dd4322352b0c9c82a76dc9865a616d41","modified":1451781531000},{"_id":"themes/jacman/languages/default.yml","shasum":"eea72d6138497287c0b3f4bd93e4f6f62b7aff37","modified":1451781531000},{"_id":"themes/jacman/languages/zh-TW.yml","shasum":"61a02ba818d641579a86fcd7f5926ab1e6ab5f70","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/after_footer.ejs","shasum":"806dc4349387eec9179000ad7c9fef4023a72aab","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/analytics.ejs","shasum":"697601996220fe0a0f9cd628be67dec3c86ae2aa","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/article_row.ejs","shasum":"4cb855d91ece7f67b2ca0992fffa55472d0b9c93","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/archive.ejs","shasum":"2c7395e7563fe016521712a645c28a13f952d52a","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/categories.ejs","shasum":"8a52d0344d5bce1925cf586ed73c11192925209b","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/article.ejs","shasum":"261ecacb8456f4cb972632b6a9103860fa63b9a3","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/header.ejs","shasum":"b62087514c28016685f035bd3c5ad83557b4b5ad","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/footer.ejs","shasum":"32db7e7c8171530d29c3878f387c4438d6057508","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/mathjax.ejs","shasum":"d42994ac696f52ba99c1cbac382cd76d5b04a3e8","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/pagination.ejs","shasum":"6146ac37dfb4f8613090bc52b3fc8cfa911a186a","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/head.ejs","shasum":"734797203f17f7d0239a33e796e9e96fabfc44a8","modified":1457231587000},{"_id":"themes/jacman/layout/_partial/post/catetags.ejs","shasum":"0e37bababc8f4659f5b59a552a946b46d89e4158","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/article.ejs","shasum":"4ba7b60a19bccfca96839138f84c67c18eb1982d","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/comment.ejs","shasum":"c88bc8f5805173920a5fdd7e9234a850e3d8e151","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/footer.ejs","shasum":"b12ec08a5845a3d8c01257614f1dfead879c87d2","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/header.ejs","shasum":"36a705942b691abe0d643ea8afa339981b32f6f2","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/jiathis.ejs","shasum":"d7f5960039ac74924559ab6ba03c64457b8f0966","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/pagination.ejs","shasum":"7de9c07a4c968429a8088c31a28b7f3a993ded1b","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/search.ejs","shasum":"1083824a6c6c3df02767f2f3b727aee78ebb76ec","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/sidebar.ejs","shasum":"c4f527fff0070fbe65919053a16224412317f40d","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/tags.ejs","shasum":"b33b2b5d08f1d53a8de25a95f660f7f1cea7b3cb","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/tinysou_search.ejs","shasum":"06ecddc8a9d40b480fe2e958af1dab857a9d5441","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/post/gallery.ejs","shasum":"fafc2501d7e65983b0f5c2b58151ca12e57c0574","modified":1451781531000},{"_id":"themes/jacman/layout/_partial/totop.ejs","shasum":"bea5bb7cb9350b8af7d97a8d223af63a5b30ab78","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/archive.ejs","shasum":"39ea6b7888406fbd1b4cf236ebd718e881493374","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/category.ejs","shasum":"c1fae96b5053da021bcc04ab2ce5c2c8d30de8a2","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/douban.ejs","shasum":"e3820c36169e88663e6c9177666b2904c1ce47e6","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/github-card.ejs","shasum":"5c759b6ea214bac56a393247de27e67ce73fb33f","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/rss.ejs","shasum":"0a4b5f2a2e36a1d504fe2e7c6c8372cbb4628aab","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/links.ejs","shasum":"e49868063439c2092cdf9a8ec82cc295b0e42f66","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/tagcloud.ejs","shasum":"10a1001189d5c28ce6d42494563b9637c302b454","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/tag.ejs","shasum":"7e82ad9c916b9ce871b2f65ce8f283c5ba47947b","modified":1451781531000},{"_id":"themes/jacman/layout/archive.ejs","shasum":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1451781531000},{"_id":"themes/jacman/layout/category.ejs","shasum":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1451781531000},{"_id":"themes/jacman/layout/_widget/weibo.ejs","shasum":"a31c2b223d0feb2a227e203cac9e5d13b7d328a8","modified":1451781531000},{"_id":"themes/jacman/layout/index.ejs","shasum":"75cef2172c286994af412e11ab7f4f5a0daaf1f5","modified":1451781531000},{"_id":"themes/jacman/layout/layout.ejs","shasum":"5b4289a4526899809b9c2facea535367ff51ba2b","modified":1451781531000},{"_id":"themes/jacman/scripts/fancybox.js","shasum":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1451781531000},{"_id":"themes/jacman/layout/post.ejs","shasum":"3114134775bdde5a83cf14feb019606fa2b2b2be","modified":1451781531000},{"_id":"themes/jacman/layout/page.ejs","shasum":"bd6bbf2ea8e183bd835867ff617dc6366b56748c","modified":1451781531000},{"_id":"themes/jacman/layout/tag.ejs","shasum":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1451781531000},{"_id":"themes/jacman/source/css/_base/font.styl","shasum":"c8a0faf43b08e37ad07a5669db76d595da966159","modified":1451781531000},{"_id":"themes/jacman/source/css/_base/public.styl","shasum":"f016180726019927b9a835ed01e04d153f27a149","modified":1451781531000},{"_id":"themes/jacman/source/css/_base/highlight/highlight.styl","shasum":"91b62bfc58390b0d5db782a75be6965ee3665eb3","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/article.styl","shasum":"239608edd92175a948f2a0dc7cc0837d9156ad04","modified":1451781531000},{"_id":"themes/jacman/source/css/_base/highlight/theme.styl","shasum":"e3a59bd427ba37a54ead9eeba9a5356b3f720a48","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/aside.styl","shasum":"506fde1d67ce750452cbe84bee01a19c7d027c5e","modified":1451781531000},{"_id":"themes/jacman/source/css/_base/variable.styl","shasum":"cb652eb83c28a208743fabab92de896f8b7cbf7b","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/footer.styl","shasum":"1911613a19b605a58f801c21b03b5d4c83b90f9c","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/gallery.styl","shasum":"7246809f4ce3166ec1b259bf475cae1a48e29aad","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/index.styl","shasum":"a72ff14effd276015264f870f47ed8f8413bf5d3","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/duoshuo.styl","shasum":"e85f1192283f043115c272a9deb3cb6ced793990","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/header.styl","shasum":"5121ceb712be3f2dde98b8b6e589b546e19eab8f","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/helper.styl","shasum":"1136600932b97534b88465bf05ef313630b2de3d","modified":1451781531000},{"_id":"themes/jacman/source/css/_partial/totop.styl","shasum":"96363d7c5aaed5f649667fc0752a62620a67e872","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1451781531000},{"_id":"themes/jacman/source/css/style.styl","shasum":"a0a45af186a72ae68979bf26f2a5d0d2303189ca","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1451781531000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1451781531000},{"_id":"themes/jacman/source/font/FontAwesome.otf","shasum":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1451781531000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","shasum":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1451781531000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","shasum":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1451781531000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","shasum":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1451781531000},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1451781531000},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","shasum":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1451781531000},{"_id":"themes/jacman/source/font/fontdiao.eot","shasum":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1451781531000},{"_id":"themes/jacman/source/font/fontdiao.woff","shasum":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1451781531000},{"_id":"themes/jacman/source/font/fontdiao.ttf","shasum":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1451781531000},{"_id":"themes/jacman/source/img/author.jpg","shasum":"15d37d00c1ac7f049c5329836e42d3ffb8d4b425","modified":1451781531000},{"_id":"themes/jacman/source/img/author.jpg.bak","shasum":"2a292e681b4c6c975eec9c8c356d99647a465542","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1451781531000},{"_id":"themes/jacman/source/img/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1451781531000},{"_id":"themes/jacman/source/img/jacman.jpg","shasum":"0ba14a4a5e3be012826fc713c33479912126d34e","modified":1451781531000},{"_id":"themes/jacman/source/img/logo.svg","shasum":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1451781531000},{"_id":"themes/jacman/source/img/scrollup.png","shasum":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1451781531000},{"_id":"themes/jacman/source/js/gallery.js","shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1451781531000},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1451781531000},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","shasum":"57c3987166a26415a71292162690e82c21e315ad","modified":1451781531000},{"_id":"themes/jacman/source/js/totop.js","shasum":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb","modified":1451781531000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","shasum":"eabdb262d8e246865dfb56031f01ff6e8d2f9d53","modified":1451781531000},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1451781531000},{"_id":"themes/jacman/source/font/fontdiao.svg","shasum":"334a94e6a66a8b089be7315d876bec93efe38d2b","modified":1451781531000},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","shasum":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d","modified":1451781531000},{"_id":"themes/jacman/source/img/logo.png","shasum":"fd08d12d1fa147cf894e8f8327e38f1758de32ed","modified":1451781531000},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","shasum":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1451781531000},{"_id":"themes/jacman/source/img/banner.jpg","shasum":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1451781531000}],"Category":[{"name":"算法","_id":"cinuar4a9000126s68a9ofmwp"},{"name":"未分类","_id":"cinuar4ay000826s6pccbpctk"},{"name":"编程","_id":"cinuar4b1000f26s6ug7ootoz"},{"name":"搜索引擎","_id":"cinuar4b6000o26s6ymffjcdv"},{"name":"shell","_id":"cinuar4ba000z26s661xuwf2o"},{"name":"Python","_id":"cinuar4be001626s692sqcylh"},{"name":"Javascript","_id":"cinuar4bz002926s6j89rvr8s"},{"name":"欧拉工程","_id":"cinuar4cv004c26s6ct1k6k76"},{"name":"数学","_id":"cinuar4kj00eb26s6ni5yxglw"},{"name":"Java","_id":"cinuar4l100fa26s6o8wp2cgr"},{"name":"软件安装","_id":"cinuar4ld00fx26s6jvrnkd95"},{"name":"数据结构","_id":"cinuar4lp00gg26s6z7qll19l"},{"name":"PHP","_id":"cinuar4n500ir26s6irntv0vk"},{"name":"网络编程","_id":"cinuar4of00ki26s67reod77g"},{"name":"大数据","_id":"cinuar4oz00lp26s64c4p8c0x"},{"name":"机器学习","_id":"cinuar4qn00o826s6kj3115ql"},{"name":"数据库","_id":"cinuar4qs00og26s6l79cdwpf"},{"name":"Lucene","_id":"cinuar4qz00ov26s62185ka6b"}],"Data":[],"Page":[{"title":"关于我","id":2,"date":"2013-04-10T23:59:12.000Z","_content":"\n一只小小鸟，相信兼济天下则达，独善其身则穷。所以在此记录学习过程中遇到的一些问题以及解决办法。\n更详细的关于我请移步至[http://www.dengshilong.org/about-me](http://www.dengshilong.org/about-me)\n\n邮箱邮箱：long470884130#163.com 自行将#改为@","source":"about-me/index.md","raw":"title: 关于我\nid: 2\ndate: 2013-04-11 07:59:12\n---\n\n一只小小鸟，相信兼济天下则达，独善其身则穷。所以在此记录学习过程中遇到的一些问题以及解决办法。\n更详细的关于我请移步至[http://www.dengshilong.org/about-me](http://www.dengshilong.org/about-me)\n\n邮箱邮箱：long470884130#163.com 自行将#改为@","updated":"2016-01-03T00:38:51.000Z","path":"about-me/index.html","comments":1,"layout":"page","_id":"cinuar4ak000526s63sd70lqb"},{"title":"关于我","id":2,"date":"2013-04-10T23:59:12.000Z","_content":"\n一只小小鸟，相信兼济天下则达，独善其身则穷。所以在此记录学习过程中遇到的一些问题以及解决办法。\n更详细的关于我请移步至[http://www.dengshilong.org/about-me](http://www.dengshilong.org/about-me)\n\n邮箱：dengshilong1988@gmail.com 自行将#改为@\n[github](https://github.com/dengshilong)\n","source":"about/index.md","raw":"title: 关于我\nid: 2\ndate: 2013-04-11 07:59:12\n---\n\n一只小小鸟，相信兼济天下则达，独善其身则穷。所以在此记录学习过程中遇到的一些问题以及解决办法。\n更详细的关于我请移步至[http://www.dengshilong.org/about-me](http://www.dengshilong.org/about-me)\n\n邮箱：dengshilong1988@gmail.com 自行将#改为@\n[github](https://github.com/dengshilong)\n","updated":"2016-04-15T12:16:47.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cinuar4au000626s63tqp6qrq"}],"Post":[{"title":"寻找极小值","id":"1112","_content":"\n一个数组是以循环顺序排列的，也就是说在数组中有某个元素i，从x[i]开始有这样的关系，即x[0] < x[1] < x[2] < ... < x[i - 1]，x[i] < x[i + 1] < ... < x[n] < x[0]。例如8，10，14，15，2，6这7个元素就是循环顺序排列的，因为从2开始为递增，到了最后一个元素就转化为第1个元素，再一次顺序递增。换句话说，如果把x[i]，x[i + 1]，...，x[n]取出，并且接到数组开头，于是就是一个从小到大的顺序(这不是个旋转的工作吗？)。编写一个程序，接收一个以循环顺序排列的数组，把它的极小值找出来，以上面的数据为例，程序应该会输出2.\n\n说明：\n因为从x[0]起顺序是递增的，一直到极小值出现，马上就会出现相反的顺序，于是很多人马上就会想出这个做法：\nfor (i = 1; i < n && x[i] >= x[i - 1]; i++)\n一旦这个循环停下来了，如果i等于n那就表示每一个元素都大于在它前面的哪一个，因而极小值为x[0]；但若i < n，且x[i] < x[i - 1]，因此极小值为x[i]。\n这是个正确的做法，但效率却不够高，因为在最坏的情况下可能要做n - 1次的比较。不过，这个数组严格说还是有顺序性的，根据这一特性应该可以找出更好、更快的方法，不妨试试看。\n\n解决的办法是用二分查找。也许会质疑这个数组并没有完全依顺序排列，所以不能用二分查找法。其实只要能够把问题分成两部分，而有办法判断解答在其中一部分的话，这就是个二分查找。\n\n现在处理x[L]与x[R]之间的元素(包含两个端点)，去中间元素x[M], M = (R - L) / 2 + L，会出现以下两中情况\n(1) x[M] < x[R]，因为从左到右是递增的，直到极小值开始才下降，之后又开始递增。而第一个递增部分的任意一个元素大于第二个递增部分的任意元素。所以极小值一定不会在M的右边。所以下一个R=M。 (2) x[M] >= x[R]，会出现这种情况，说明M在第一个递增部分，R在第二个递增部分，所以极小值一定在M的右边。所以下一个L=M + 1。\n\n就这样一直反复下去，等到L=R的时候， x[L]就是极小值。\n写成代码如下：\n\n``` java\npublic class MinimumInRotatedSortedArray {\n\tpublic static int findMin(int[] nums) {\n\t\tint left = 0;\n\t\tint right = nums.length - 1;\n\t\tint mid = 0;\n\t\twhile (left < right) {\n\t\t\tmid = (right - left) / 2 + left;\n\t\t\tif (nums[mid] < nums[right]) {\n\t\t\t\tright = mid;\n\t\t\t} else {\n\t\t\t\tleft = mid + 1;\n\t\t\t}\n\t\t}\nreturn nums[left];\n}\n\n\tpublic static void main(String[] args) {\n\t\tint[] temp = {6, 7, 1, 2, 3, 4};\n\t\tSystem.out.println(findMin(temp));\n\t}\n}\n```","source":"_drafts/寻找极小值.md","raw":"title: 寻找极小值\ntags:\n  - C名题百则\nid: 1112\ncategories:\n  - 算法\n---\n\n一个数组是以循环顺序排列的，也就是说在数组中有某个元素i，从x[i]开始有这样的关系，即x[0] < x[1] < x[2] < ... < x[i - 1]，x[i] < x[i + 1] < ... < x[n] < x[0]。例如8，10，14，15，2，6这7个元素就是循环顺序排列的，因为从2开始为递增，到了最后一个元素就转化为第1个元素，再一次顺序递增。换句话说，如果把x[i]，x[i + 1]，...，x[n]取出，并且接到数组开头，于是就是一个从小到大的顺序(这不是个旋转的工作吗？)。编写一个程序，接收一个以循环顺序排列的数组，把它的极小值找出来，以上面的数据为例，程序应该会输出2.\n\n说明：\n因为从x[0]起顺序是递增的，一直到极小值出现，马上就会出现相反的顺序，于是很多人马上就会想出这个做法：\nfor (i = 1; i < n && x[i] >= x[i - 1]; i++)\n一旦这个循环停下来了，如果i等于n那就表示每一个元素都大于在它前面的哪一个，因而极小值为x[0]；但若i < n，且x[i] < x[i - 1]，因此极小值为x[i]。\n这是个正确的做法，但效率却不够高，因为在最坏的情况下可能要做n - 1次的比较。不过，这个数组严格说还是有顺序性的，根据这一特性应该可以找出更好、更快的方法，不妨试试看。\n\n解决的办法是用二分查找。也许会质疑这个数组并没有完全依顺序排列，所以不能用二分查找法。其实只要能够把问题分成两部分，而有办法判断解答在其中一部分的话，这就是个二分查找。\n\n现在处理x[L]与x[R]之间的元素(包含两个端点)，去中间元素x[M], M = (R - L) / 2 + L，会出现以下两中情况\n(1) x[M] < x[R]，因为从左到右是递增的，直到极小值开始才下降，之后又开始递增。而第一个递增部分的任意一个元素大于第二个递增部分的任意元素。所以极小值一定不会在M的右边。所以下一个R=M。 (2) x[M] >= x[R]，会出现这种情况，说明M在第一个递增部分，R在第二个递增部分，所以极小值一定在M的右边。所以下一个L=M + 1。\n\n就这样一直反复下去，等到L=R的时候， x[L]就是极小值。\n写成代码如下：\n\n``` java\npublic class MinimumInRotatedSortedArray {\n\tpublic static int findMin(int[] nums) {\n\t\tint left = 0;\n\t\tint right = nums.length - 1;\n\t\tint mid = 0;\n\t\twhile (left < right) {\n\t\t\tmid = (right - left) / 2 + left;\n\t\t\tif (nums[mid] < nums[right]) {\n\t\t\t\tright = mid;\n\t\t\t} else {\n\t\t\t\tleft = mid + 1;\n\t\t\t}\n\t\t}\nreturn nums[left];\n}\n\n\tpublic static void main(String[] args) {\n\t\tint[] temp = {6, 7, 1, 2, 3, 4};\n\t\tSystem.out.println(findMin(temp));\n\t}\n}\n```","slug":"寻找极小值","published":0,"date":"2016-01-03T00:38:51.000Z","updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4a2000026s65fz5hpip"},{"title":"金融学公开课结业","id":"719","date":"2014-05-11T10:12:34.000Z","_content":"\n经过三个月的时间，金融学公开课终于告一个段落了。两年之前就选修过这门课，可是当时由于时间问题，还是未能完成，一直心有不甘。现在工作之后，腾出周末的时间选修了这门课，所以想好好学完这门课。\n\n这门课整体来说难度不大，只有到了统计部分才发现有点难度，这时也才知道以前学的数理统计还是有用的，可是我已经忘的差不多了。幸亏Gautam Kaul教导有方，对这部分总算有个了解。\n\n我的感悟是，学习的过程最重要还是要做笔记和练习，否则太容易忘记了，即便是当时已经弄懂了，过了很久之后，还是会忘记当初的想法，就像现在，即使已经学完了，很多内容又忘的差不多了，真是可恶。可是有一点还是不能忘记的，那就是价值的创造是来自于伟大的想法，而金融运作并不创造价值。\n\n下面是自己用Python写的一些函数，还是很实用的。\n\n``` python\ndef pv(rate,nper,pmt,fv=0):\n     v = pmt * (( 1 + rate) ** nper - 1) / rate / ( (1 + rate) ** nper)\n     v += fv / ((1 + rate) ** nper)\n     return v\ndef pmt(rate,nper,pv,fv=0):\n     p = pv * ((1 + rate) ** nper ) * rate / ((1 + rate) ** nper - 1)\n     p += fv * rate / ((1 + rate) ** nper - 1)\n     return p\ndef fv(rate,nper,pmt,pv=0):\n    v = pmt * ((1 + rate) ** nper - 1) / rate\n    v += pv / ((1 + rate) ** nper)\n    return v\ndef paf(r,n,g):\n    return 1.0 / (r - g) * (1 - (1 + g) ** n / (1 + r) **n)\n```","source":"_posts/金融学公开课结业.md","raw":"title: 金融学公开课结业\ntags:\n  - 公开课\n  - 金融学\nid: 719\ncategories:\n  - 未分类\ndate: 2014-05-11 18:12:34\n---\n\n经过三个月的时间，金融学公开课终于告一个段落了。两年之前就选修过这门课，可是当时由于时间问题，还是未能完成，一直心有不甘。现在工作之后，腾出周末的时间选修了这门课，所以想好好学完这门课。\n\n这门课整体来说难度不大，只有到了统计部分才发现有点难度，这时也才知道以前学的数理统计还是有用的，可是我已经忘的差不多了。幸亏Gautam Kaul教导有方，对这部分总算有个了解。\n\n我的感悟是，学习的过程最重要还是要做笔记和练习，否则太容易忘记了，即便是当时已经弄懂了，过了很久之后，还是会忘记当初的想法，就像现在，即使已经学完了，很多内容又忘的差不多了，真是可恶。可是有一点还是不能忘记的，那就是价值的创造是来自于伟大的想法，而金融运作并不创造价值。\n\n下面是自己用Python写的一些函数，还是很实用的。\n\n``` python\ndef pv(rate,nper,pmt,fv=0):\n     v = pmt * (( 1 + rate) ** nper - 1) / rate / ( (1 + rate) ** nper)\n     v += fv / ((1 + rate) ** nper)\n     return v\ndef pmt(rate,nper,pv,fv=0):\n     p = pv * ((1 + rate) ** nper ) * rate / ((1 + rate) ** nper - 1)\n     p += fv * rate / ((1 + rate) ** nper - 1)\n     return p\ndef fv(rate,nper,pmt,pv=0):\n    v = pmt * ((1 + rate) ** nper - 1) / rate\n    v += pv / ((1 + rate) ** nper)\n    return v\ndef paf(r,n,g):\n    return 1.0 / (r - g) * (1 - (1 + g) ** n / (1 + r) **n)\n```","slug":"金融学公开课结业","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ax000726s6cpantzr8"},{"title":"重温manufactoria","id":"855","date":"2014-08-13T02:26:17.000Z","_content":"\n最近又玩了一遍manufactoria,发现有些关卡都快忘记怎么过的，这次还是写下来好了。\n关卡按照从左到右，从上到下计数。\n1\\. Move robots from the entrance(top) to the exit (bottom)! 将机器从入口(顶部)移到出口(底部)!\n简单，不多说\n2\\.  If a robot's string starts with blue, accept. Otherwise, reject!  如果机器以蓝色字符开头，则接受。否则，丢弃。\n3\\.  ACCEPT:if there are three or more blues! 如果有三个或三个以上的蓝色的，则接受\n4\\. ACCEPT: if a robot contains NO red! 如果机器不包含红色的，则接受。\n5\\. OUTPUT:The input,but with the first symbol at the end!  对于输入的字符，将第一个字符移到末尾作为输出\n6\\. ACCEPT: if the tape has only alternating colors! 如果只存在交替字符，则接受。\n意思就是字符如果是交替出现的则接受，如蓝红蓝红蓝，红蓝红蓝等等，而蓝蓝红，红蓝蓝等出现连续相同的字符，所以不接受\n7\\. OUTPUT：Replace blue with green, and red with yellow! 输出：将蓝色换成绿色，将红色换成黄色。\n8\\. ACCEPT: if the tape ends with two blues!  如果末尾是两个蓝色，则接受。\n9\\. OUTPUT： Put a green at the begining,  and a yellow at the end! 输出： 对于输入的字符，在开头中添加一个绿色字符，在末尾中添加一个黄色字符。\n10\\. ACCEPT: Strings that begin and end with the same color! 如果开始字符和结束字符时相同，则接受。\n11\\. ACCEPT: With blue as 1 and red as 0, accept odd binary string! 把蓝色当做1，红色当做0， 接受奇数二进制数。\n其实就是接受蓝色结尾的字符。\n12\\. ACCEPT: Some number of blue, then the same number of red! 接受： 一些蓝色的，然后相同数量的红色的。\n也就是接受诸如蓝蓝红红，蓝蓝蓝红红红等，当然空字符也要接受，因为空字符代表0个蓝色，0个红色。\n解决办法是每次除去一个蓝色和红色\n13.OUTPUT: Swap blue for red, and red for blue! 输出： 将蓝色换成红色，红色换成蓝色。\n也就是将字符串中的颜色互换。\n14\\. OUTPUT: All of the blue, but none of the red! 输出字符串中的所有蓝色字符，不输出红色字符。\n也就是将字符串中的所有红色字符去掉，留下蓝色的。\n15\\. OUTPUT： The input, but with the last symbol moved to the front! 输出： 对于输入的字符，将最后一个字符移动最前面。\n在末尾添加一个绿色，用来标示最后一个字符\n16\\. OUTPUT: With blue as 1 and red as 0, multiply by 8! 输出：把蓝色当做1，红色当做0，将二进制字符串乘以8.\n其实也就是在字符串末尾添加3个0，也就是添加三个红色\n17.ACCEPT: With blue as 1 and red as 0, accept binary strings > 15! 接受：把蓝色当做1，红色当做0，接受大于15的字符串。\n18\\. An equal number of blue and red, in any order! 只要字符串中包含相同个数的蓝色和红色，则接受。\n使用与12相同的办法\n19.OUTPUT：Put a yellow in the middle of the (even-lenght) string! 输出： 在字符串（偶数个字符串）的中间放置一个黄色字符。\n在头尾都添加黄色，之后每个循环，头部的向前移一步，尾部的向后移一步。\n20.ACCEPT: X blue, then X red, then X more blue, for any X! 接受： X个蓝色，然后X个红色，接着X个蓝色，对于X没有限制。\n也就是接受蓝红蓝，蓝蓝红红蓝蓝等字符串，对于空字符也接受，因为它代表0个蓝色，然后0个红色，接着0个蓝色。\n使用与12题相同的办法\n21.OUTPUT: The input, but with all blues moved to the front! 输出：对于输入，将字符串中所有的蓝色移到前面。\n逆向思维，将红色字符移到后面\n22.OUTPUT: With blue as 1 and red as 0, add 1 to the binary string! 输出： 将蓝色当做1，红色当做0，将二进制字符串加上1.\n在末尾添加一个黄色，每个循环，如果黄色左边的是蓝色，则蓝色变成红色，并且黄色左后退一个字符，\n如果黄色左边的红色，则将红色变成蓝色，程序结束。\n23\\. ACCEPT: With blue as 1 and red as 0,  accept natural powers of four! 接受：把蓝色当做1，红色当做0，接受四的开方\n24.ACCEPT: (Even-length) strings that repeat midway through! 接受：(偶数长度)接受从中间开始重复的字符串\n意思就是接受的字符串是偶数长度，前半段和后半段是一样的，如蓝红红蓝红红，\n25\\. ACCEPT: If there are exactly twice as many blues as red! 接受：如果蓝色的个数是红色个数的两倍，则接受。\n每个循环，除去两个蓝色和一个红色\n26\\. OUTPUT: Reverse the input string! 输出：将输入的字符串逆转输出\n27.OUTPUT: Subtract 1 from the binary string!(Input >= 1) 输出：从二进制字符串中减去1(输入字符串>=1)\n在末尾添加一个黄色，每个循环，如果黄色左边的是红色，则红色变成蓝色，并且黄色左后退一个字符，\n如果黄色左边的蓝色，则将蓝色变成红色，程序结束。\n28.ACCEPT: Perfectly symmetrical strings! 接受：完美对称字符串！\n意思就是回文串，也就是从左读到右和从右读到左是一样的。\n每个循环，头尾消去的字符是一样的。\n29.ACCEPT: Two identical strings, separated by a green! 接受：两个相同的字符串，由绿色隔开。\n30\\. ACCEPT: Read the tape as two numbers, A and B, split by a green: accept if A > B! 接受：读入的字符串当做两个二进制数，A和B，由一个绿色隔开，如果A>B则接受。\n每次比较A和B的字符，分四种情况\n蓝蓝，继续比较A和B剩余的字符\n红红，继续比较A和B剩余的字符\n蓝红，这种情况下，有个小技巧，将B的字符再消去一个，这时A剩余的字符比B剩余的字符长，则A>B\n红蓝,A剩余的字符比B剩余的字符长，则A>B\n31\\. OUTPUT: Read the tape as two numbers, A and B, split by a green: output A + B! 输出：读入的字符串当做两个二进制数，A和B，由一个绿色隔开，输出A+B的和！\n将A和B都转成黄色字符，之后再将黄色字符转成二进制。","source":"_posts/重温manufactoria.md","raw":"title: 重温manufactoria\ntags:\n  - manufactoria\nid: 855\ncategories:\n  - 编程\ndate: 2014-08-13 10:26:17\n---\n\n最近又玩了一遍manufactoria,发现有些关卡都快忘记怎么过的，这次还是写下来好了。\n关卡按照从左到右，从上到下计数。\n1\\. Move robots from the entrance(top) to the exit (bottom)! 将机器从入口(顶部)移到出口(底部)!\n简单，不多说\n2\\.  If a robot's string starts with blue, accept. Otherwise, reject!  如果机器以蓝色字符开头，则接受。否则，丢弃。\n3\\.  ACCEPT:if there are three or more blues! 如果有三个或三个以上的蓝色的，则接受\n4\\. ACCEPT: if a robot contains NO red! 如果机器不包含红色的，则接受。\n5\\. OUTPUT:The input,but with the first symbol at the end!  对于输入的字符，将第一个字符移到末尾作为输出\n6\\. ACCEPT: if the tape has only alternating colors! 如果只存在交替字符，则接受。\n意思就是字符如果是交替出现的则接受，如蓝红蓝红蓝，红蓝红蓝等等，而蓝蓝红，红蓝蓝等出现连续相同的字符，所以不接受\n7\\. OUTPUT：Replace blue with green, and red with yellow! 输出：将蓝色换成绿色，将红色换成黄色。\n8\\. ACCEPT: if the tape ends with two blues!  如果末尾是两个蓝色，则接受。\n9\\. OUTPUT： Put a green at the begining,  and a yellow at the end! 输出： 对于输入的字符，在开头中添加一个绿色字符，在末尾中添加一个黄色字符。\n10\\. ACCEPT: Strings that begin and end with the same color! 如果开始字符和结束字符时相同，则接受。\n11\\. ACCEPT: With blue as 1 and red as 0, accept odd binary string! 把蓝色当做1，红色当做0， 接受奇数二进制数。\n其实就是接受蓝色结尾的字符。\n12\\. ACCEPT: Some number of blue, then the same number of red! 接受： 一些蓝色的，然后相同数量的红色的。\n也就是接受诸如蓝蓝红红，蓝蓝蓝红红红等，当然空字符也要接受，因为空字符代表0个蓝色，0个红色。\n解决办法是每次除去一个蓝色和红色\n13.OUTPUT: Swap blue for red, and red for blue! 输出： 将蓝色换成红色，红色换成蓝色。\n也就是将字符串中的颜色互换。\n14\\. OUTPUT: All of the blue, but none of the red! 输出字符串中的所有蓝色字符，不输出红色字符。\n也就是将字符串中的所有红色字符去掉，留下蓝色的。\n15\\. OUTPUT： The input, but with the last symbol moved to the front! 输出： 对于输入的字符，将最后一个字符移动最前面。\n在末尾添加一个绿色，用来标示最后一个字符\n16\\. OUTPUT: With blue as 1 and red as 0, multiply by 8! 输出：把蓝色当做1，红色当做0，将二进制字符串乘以8.\n其实也就是在字符串末尾添加3个0，也就是添加三个红色\n17.ACCEPT: With blue as 1 and red as 0, accept binary strings > 15! 接受：把蓝色当做1，红色当做0，接受大于15的字符串。\n18\\. An equal number of blue and red, in any order! 只要字符串中包含相同个数的蓝色和红色，则接受。\n使用与12相同的办法\n19.OUTPUT：Put a yellow in the middle of the (even-lenght) string! 输出： 在字符串（偶数个字符串）的中间放置一个黄色字符。\n在头尾都添加黄色，之后每个循环，头部的向前移一步，尾部的向后移一步。\n20.ACCEPT: X blue, then X red, then X more blue, for any X! 接受： X个蓝色，然后X个红色，接着X个蓝色，对于X没有限制。\n也就是接受蓝红蓝，蓝蓝红红蓝蓝等字符串，对于空字符也接受，因为它代表0个蓝色，然后0个红色，接着0个蓝色。\n使用与12题相同的办法\n21.OUTPUT: The input, but with all blues moved to the front! 输出：对于输入，将字符串中所有的蓝色移到前面。\n逆向思维，将红色字符移到后面\n22.OUTPUT: With blue as 1 and red as 0, add 1 to the binary string! 输出： 将蓝色当做1，红色当做0，将二进制字符串加上1.\n在末尾添加一个黄色，每个循环，如果黄色左边的是蓝色，则蓝色变成红色，并且黄色左后退一个字符，\n如果黄色左边的红色，则将红色变成蓝色，程序结束。\n23\\. ACCEPT: With blue as 1 and red as 0,  accept natural powers of four! 接受：把蓝色当做1，红色当做0，接受四的开方\n24.ACCEPT: (Even-length) strings that repeat midway through! 接受：(偶数长度)接受从中间开始重复的字符串\n意思就是接受的字符串是偶数长度，前半段和后半段是一样的，如蓝红红蓝红红，\n25\\. ACCEPT: If there are exactly twice as many blues as red! 接受：如果蓝色的个数是红色个数的两倍，则接受。\n每个循环，除去两个蓝色和一个红色\n26\\. OUTPUT: Reverse the input string! 输出：将输入的字符串逆转输出\n27.OUTPUT: Subtract 1 from the binary string!(Input >= 1) 输出：从二进制字符串中减去1(输入字符串>=1)\n在末尾添加一个黄色，每个循环，如果黄色左边的是红色，则红色变成蓝色，并且黄色左后退一个字符，\n如果黄色左边的蓝色，则将蓝色变成红色，程序结束。\n28.ACCEPT: Perfectly symmetrical strings! 接受：完美对称字符串！\n意思就是回文串，也就是从左读到右和从右读到左是一样的。\n每个循环，头尾消去的字符是一样的。\n29.ACCEPT: Two identical strings, separated by a green! 接受：两个相同的字符串，由绿色隔开。\n30\\. ACCEPT: Read the tape as two numbers, A and B, split by a green: accept if A > B! 接受：读入的字符串当做两个二进制数，A和B，由一个绿色隔开，如果A>B则接受。\n每次比较A和B的字符，分四种情况\n蓝蓝，继续比较A和B剩余的字符\n红红，继续比较A和B剩余的字符\n蓝红，这种情况下，有个小技巧，将B的字符再消去一个，这时A剩余的字符比B剩余的字符长，则A>B\n红蓝,A剩余的字符比B剩余的字符长，则A>B\n31\\. OUTPUT: Read the tape as two numbers, A and B, split by a green: output A + B! 输出：读入的字符串当做两个二进制数，A和B，由一个绿色隔开，输出A+B的和！\n将A和B都转成黄色字符，之后再将黄色字符转成二进制。","slug":"重温manufactoria","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4b0000e26s6a3e7od57"},{"title":"选择排序中的交换次数","id":"826","date":"2014-07-14T23:43:16.000Z","_content":"\n给你一个list L, 如 L=[2,8,3,50], 对L进行选择排序并输出交换次数,\n如样例L的结果为1\n\n对于这题，无非就是写一个选择排序，在排序过程中记下交换的次数。很意外的是Pythontip上竟然会有那么多人写错，\n按照选择排序的定义，写一个应该是分分钟的事。或许这帮人都没看书。\n``` python\nL=[2,8,3,50]\nlength = len(L)\ncount = 0\nfor i in xrange(length):\n    minum = L[i]\n    index = i\n    for j in xrange(i + 1, length):\n        if L[j] < minum:\n            minum = L[j]\n            index = j\n    if index != i:\n        L[i],L[index] = L[index],L[i]\n        count += 1\nprint count\n```","source":"_posts/选择排序中的交换次数.md","raw":"title: 选择排序中的交换次数\ntags:\n  - 选择排序\nid: 826\ncategories:\n  - 算法\ndate: 2014-07-15 07:43:16\n---\n\n给你一个list L, 如 L=[2,8,3,50], 对L进行选择排序并输出交换次数,\n如样例L的结果为1\n\n对于这题，无非就是写一个选择排序，在排序过程中记下交换的次数。很意外的是Pythontip上竟然会有那么多人写错，\n按照选择排序的定义，写一个应该是分分钟的事。或许这帮人都没看书。\n``` python\nL=[2,8,3,50]\nlength = len(L)\ncount = 0\nfor i in xrange(length):\n    minum = L[i]\n    index = i\n    for j in xrange(i + 1, length):\n        if L[j] < minum:\n            minum = L[j]\n            index = j\n    if index != i:\n        L[i],L[index] = L[index],L[i]\n        count += 1\nprint count\n```","slug":"选择排序中的交换次数","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4b2000j26s6am7ue4pp"},{"title":"追踪query too complex not enough stack错误","id":"702","date":"2014-04-24T13:37:21.000Z","_content":"\n很早之前，在使用Sphinx搭建搜索服务时，遇到这个问题，到Sphinx for Chinese的群里请教，没有得到满意的答案，于是将sql_query_info 这个选项注释掉，就没有报错了。今天正好有时间，于是着手找到这个问题的症结，也算是为Sphinx做点贡献。\n\n打开源代码，才发现用的是匈牙利命名法，看得不爽。也许因为没有Lucene那么出名，只有两个人在维护这个项目，代码里到处充斥这Fix Me,还好结构还算精良，要不然真不知道从和看起。本来想用GDB调试的，还不太熟练，于是就只好用最原始的printf输出。经过缩小范围，找到了一些蛛丝马迹，\n在search.cpp中  的第331附近，主要的查询工作就在这里完成的，跳转过去之后\n if ( !pIndex->MultiQuery ( &tQuery, pResult, 1, &pTop, NULL ) )\n锁定了到下面这个函数\n在sphinx.cpp中 17301 if ( !sphCheckQueryHeight ( tParsed.m_pRoot, pResult->m_sError ) )\n继续跳转，到了下面这行\n在sphinx.cpp中 16404 int64_t iQueryStack = sphGetStackUsed() + iHeight*SPH_EXTNODE_STACK_SIZE;\n输出之后，发现问题出在sphGetStackUsed这个函数里\n在sphinxstd.cpp 中  1218行 int64_t sphGetStackUsed()\n继续跳转，\nsphinxstd.cpp 中  1221行\nBYTE cStack;\n BYTE * pStackTop = (BYTE*)sphMyStack();\n线程栈的使用大小就是上面两个值的差，继续查找\n在sphinxstd.cpp return sphThreadGet ( g_tMyThreadStack );\n\n这里用到了线程私有数据，看到私有数据的设置还是很正常，所以依然不知道哪里出了问题。于是索性将\nint64_t iQueryStack = sphGetStackUsed() + iHeight*SPH_EXTNODE_STACK_SIZE;\n这行改成\nint64_t iQueryStack =  iHeight*SPH_EXTNODE_STACK_SIZE;\n这样sql_query_info就可以使用了，也不会再报query too complex not enough stack错误。\n可是这个自己查询得到的中文显示出来都是乱码，我认为是没有设置SET NAMES utf8的原因，但又无法在sql_query_info这里添加这句。虽然在sql_query_pre = SET NAMES utf8已经设置了，但是因为不是同一个查询连接，所以无效。\n\n所以最终我得到解决这个错误的结论，那就是注释掉sql_query_info这个选项。最坑人的是，官方的示例中是开启这个选项的。","source":"_posts/追踪query-too-complex-not-enough-stack错误.md","raw":"title: 追踪query too complex not enough stack错误\ntags:\n  - Sphinx\n  - Sphinx-for-chinese\n  - sql_query_info\n  - 匈牙利\nid: 702\ncategories:\n  - 搜索引擎\ndate: 2014-04-24 21:37:21\n---\n\n很早之前，在使用Sphinx搭建搜索服务时，遇到这个问题，到Sphinx for Chinese的群里请教，没有得到满意的答案，于是将sql_query_info 这个选项注释掉，就没有报错了。今天正好有时间，于是着手找到这个问题的症结，也算是为Sphinx做点贡献。\n\n打开源代码，才发现用的是匈牙利命名法，看得不爽。也许因为没有Lucene那么出名，只有两个人在维护这个项目，代码里到处充斥这Fix Me,还好结构还算精良，要不然真不知道从和看起。本来想用GDB调试的，还不太熟练，于是就只好用最原始的printf输出。经过缩小范围，找到了一些蛛丝马迹，\n在search.cpp中  的第331附近，主要的查询工作就在这里完成的，跳转过去之后\n if ( !pIndex->MultiQuery ( &tQuery, pResult, 1, &pTop, NULL ) )\n锁定了到下面这个函数\n在sphinx.cpp中 17301 if ( !sphCheckQueryHeight ( tParsed.m_pRoot, pResult->m_sError ) )\n继续跳转，到了下面这行\n在sphinx.cpp中 16404 int64_t iQueryStack = sphGetStackUsed() + iHeight*SPH_EXTNODE_STACK_SIZE;\n输出之后，发现问题出在sphGetStackUsed这个函数里\n在sphinxstd.cpp 中  1218行 int64_t sphGetStackUsed()\n继续跳转，\nsphinxstd.cpp 中  1221行\nBYTE cStack;\n BYTE * pStackTop = (BYTE*)sphMyStack();\n线程栈的使用大小就是上面两个值的差，继续查找\n在sphinxstd.cpp return sphThreadGet ( g_tMyThreadStack );\n\n这里用到了线程私有数据，看到私有数据的设置还是很正常，所以依然不知道哪里出了问题。于是索性将\nint64_t iQueryStack = sphGetStackUsed() + iHeight*SPH_EXTNODE_STACK_SIZE;\n这行改成\nint64_t iQueryStack =  iHeight*SPH_EXTNODE_STACK_SIZE;\n这样sql_query_info就可以使用了，也不会再报query too complex not enough stack错误。\n可是这个自己查询得到的中文显示出来都是乱码，我认为是没有设置SET NAMES utf8的原因，但又无法在sql_query_info这里添加这句。虽然在sql_query_pre = SET NAMES utf8已经设置了，但是因为不是同一个查询连接，所以无效。\n\n所以最终我得到解决这个错误的结论，那就是注释掉sql_query_info这个选项。最坑人的是，官方的示例中是开启这个选项的。","slug":"追踪query-too-complex-not-enough-stack错误","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4b5000n26s6j3ggx44m"},{"title":"软连接和硬连接","id":"982","date":"2014-12-27T02:10:54.000Z","_content":"\n软连接和硬链接是Linux中经常用到的，详细介绍可以参考https://www.ibm.com/developerworks/cn/linux/l-cn-hardandsymb-links/\n\n要知道软连接和硬链接的区别，必须知道了解Linux的文件系统设计，这其中就有inode这个概念。一个文件被分为用户数据和元数据，其中用户数据是数据存储的地方，而元数据中的inode则是指向这个地方，而文件名只是便于人们记忆而已。对于inode号，可以使用stat或者ls -i查看.\n\n一个inode号可以对应多个文件名，这种情况下就是硬链接。因此创建硬链接并不需要拷贝用户数据，也就是不像cp命令那样,新创建一个inode号，所以创建硬链接速度非常快。只是硬链接有一个局限的地方就是只能对文件创建硬链接，并且不能跨越文件系统。需要注意的一个问题是，修改硬连接，原文件的内容也会修改。而修改原文件，也会修改硬连接。\n\n而创建软连接则会创建新的inode号，只是这个inode号指向的用户数据很特殊，它指向创建软连接的文件。对于软连接，则没有硬链接的那些限制，它可以跨越文件系统，可以对目录创建软链接。只是当把原文件删除后，软连接就变成了死链接了。","source":"_posts/软连接和硬连接.md","raw":"title: 软连接和硬连接\ntags:\n  - 硬链接\n  - 软链接\nid: 982\ncategories:\n  - shell\ndate: 2014-12-27 10:10:54\n---\n\n软连接和硬链接是Linux中经常用到的，详细介绍可以参考https://www.ibm.com/developerworks/cn/linux/l-cn-hardandsymb-links/\n\n要知道软连接和硬链接的区别，必须知道了解Linux的文件系统设计，这其中就有inode这个概念。一个文件被分为用户数据和元数据，其中用户数据是数据存储的地方，而元数据中的inode则是指向这个地方，而文件名只是便于人们记忆而已。对于inode号，可以使用stat或者ls -i查看.\n\n一个inode号可以对应多个文件名，这种情况下就是硬链接。因此创建硬链接并不需要拷贝用户数据，也就是不像cp命令那样,新创建一个inode号，所以创建硬链接速度非常快。只是硬链接有一个局限的地方就是只能对文件创建硬链接，并且不能跨越文件系统。需要注意的一个问题是，修改硬连接，原文件的内容也会修改。而修改原文件，也会修改硬连接。\n\n而创建软连接则会创建新的inode号，只是这个inode号指向的用户数据很特殊，它指向创建软连接的文件。对于软连接，则没有硬链接的那些限制，它可以跨越文件系统，可以对目录创建软链接。只是当把原文件删除后，软连接就变成了死链接了。","slug":"软连接和硬连接","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4b8000y26s6klz9g1cs"},{"title":"语言特性还是有必要学习的","id":"970","date":"2014-12-04T13:08:44.000Z","_content":"\n最近一个项目需要用脚本生成汉字拼音时来排序，组里同事说以前有同事写过一个，于是拿过来用，看了一下代码，发现有些地方还是可以优化的，\n\n如以下代码：\n``` python\nself.polyphone = {}\nfor line in open(polyphone_path):\n    k, context, pron, other = line.split(' ', 3)\n    item = collections.defaultdict(dict)\n    key = \"%X\" % ord(unicode(k, 'utf8'))\n    item[key]['context'] = unicode(context, 'utf8')\n\n    item[key]['pron'] = pron\n    if self.polyphone.has_key(key):\n        self.polyphone[key].append(item)\n    else:\n        self.polyphone[key] = []\n        self.polyphone[key].append(item)  \n```     \n这一段代码里需要判断字典里有没有包含key,如果没有，则要先声明value为空的list,之后再添加值,这种情况下collections中的defaultdict就派上用场了。\n``` python\nself.polyphone = defaultdict(list)\nfor line in open(polyphone_path):\n    k, context, pron, other = line.split(' ', 3)\n    item = defaultdict(dict)\n    key = \"%X\" % ord(unicode(k, 'utf8'))\n    item[key]['context'] = unicode(context, 'utf8')\n    item[key]['pron'] = pron\n    self.polyphone[key].append(item)  \n``` \ndefaultdict可以给定一个默认值，这样省去了判断key是否已经在字典里存在。\n\n还见到如下代码：\n``` python\npolyphone = False\nfor item in self.polyphone[key]:\n    if chars.find(item[key]['context']) != -1: \n        result.append(item[key]['pron'].strip()[:-1].lower())\n        polyphone = True\n        break\n\nif not polyphone:\n    result.append(self.dict[key].split(\",\")[0].strip()[:-1].lower())\n```\n这段代码里，if not polyphonse判断里的句子只有在上面的for没有被break时才执行，也就是for循环执行时才执行，这种情况在编程中经常遇到，而python提供了for else循环语句，于是可以修改成：\n``` python\nfor item in self.polyphone[key]:\n    if chars.find(item[key]['context']) != -1: \n        result.append(item[key]['pron'].strip()[:-1].lower())\n        break\nelse :\n    result.append(self.dict[key].split(\",\")[0].strip()[:-1].lower())\n```\n是不是瞬间简洁很多？所以说，语言特性还是有必要学习的，虽然算法和数据结构依然是核心，可是代码易维护，易懂也是非常重要的","source":"_posts/语言特性还是有必要学习的.md","raw":"title: 语言特性还是有必要学习的\ntags:\n  - defaultdict\n  - 简洁\nid: 970\ncategories:\n  - Python\ndate: 2014-12-04 21:08:44\n---\n\n最近一个项目需要用脚本生成汉字拼音时来排序，组里同事说以前有同事写过一个，于是拿过来用，看了一下代码，发现有些地方还是可以优化的，\n\n如以下代码：\n``` python\nself.polyphone = {}\nfor line in open(polyphone_path):\n    k, context, pron, other = line.split(' ', 3)\n    item = collections.defaultdict(dict)\n    key = \"%X\" % ord(unicode(k, 'utf8'))\n    item[key]['context'] = unicode(context, 'utf8')\n\n    item[key]['pron'] = pron\n    if self.polyphone.has_key(key):\n        self.polyphone[key].append(item)\n    else:\n        self.polyphone[key] = []\n        self.polyphone[key].append(item)  \n```     \n这一段代码里需要判断字典里有没有包含key,如果没有，则要先声明value为空的list,之后再添加值,这种情况下collections中的defaultdict就派上用场了。\n``` python\nself.polyphone = defaultdict(list)\nfor line in open(polyphone_path):\n    k, context, pron, other = line.split(' ', 3)\n    item = defaultdict(dict)\n    key = \"%X\" % ord(unicode(k, 'utf8'))\n    item[key]['context'] = unicode(context, 'utf8')\n    item[key]['pron'] = pron\n    self.polyphone[key].append(item)  \n``` \ndefaultdict可以给定一个默认值，这样省去了判断key是否已经在字典里存在。\n\n还见到如下代码：\n``` python\npolyphone = False\nfor item in self.polyphone[key]:\n    if chars.find(item[key]['context']) != -1: \n        result.append(item[key]['pron'].strip()[:-1].lower())\n        polyphone = True\n        break\n\nif not polyphone:\n    result.append(self.dict[key].split(\",\")[0].strip()[:-1].lower())\n```\n这段代码里，if not polyphonse判断里的句子只有在上面的for没有被break时才执行，也就是for循环执行时才执行，这种情况在编程中经常遇到，而python提供了for else循环语句，于是可以修改成：\n``` python\nfor item in self.polyphone[key]:\n    if chars.find(item[key]['context']) != -1: \n        result.append(item[key]['pron'].strip()[:-1].lower())\n        break\nelse :\n    result.append(self.dict[key].split(\",\")[0].strip()[:-1].lower())\n```\n是不是瞬间简洁很多？所以说，语言特性还是有必要学习的，虽然算法和数据结构依然是核心，可是代码易维护，易懂也是非常重要的","slug":"语言特性还是有必要学习的","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bd001526s6nla88zgy"},{"title":"解决Error: searchd error: offset out of bounds问题","id":"716","date":"2014-05-06T11:42:39.000Z","_content":"\n因为项目需要用到分页功能，所以需要用到SetLimits函数，结果就出现了Error: searchd error: offset out of bounds (offset=9500, max_matches=1000)\n\n于是找原因，发现配置文件中有max_matches这个选项，于是将它改为10000,可是依然出现Error: searchd error: offset out of bounds (offset=9500, max_matches=1000)错误，真是莫名其妙的错误，仔细看了SetLimits的函数说明以及SphinxClient.java,才知道使用SetLimits这个函数时，如果没有提供max_matches这个参数的值，则max_matches默认为1000,而9500超过了1000,所以溢出了。\n\n现在终于明白原因，也就是说使用Sphinx一共可以在两个地方设置max_matches,一个是在searchd,也就是引擎端，提供给searchd的配置文件中进行设置；而在SphinxClient中,也就是客户端，如果在SetLimits函数中没有设置max_matches,则默认使用1000.这里有一点需要注意的是，客户端的max_matches一定要小于服务器端，否则会报错。而offset也一定要小于客户端的max_matches,这样offset才不会溢出。","source":"_posts/解决Error:-searchd-error:-offset-out-of-bounds问题.md","raw":"title: '解决Error: searchd error: offset out of bounds问题'\ntags:\n  - max_matches\n  - SetLimits\n  - Sphinx\nid: 716\ncategories:\n  - 搜索引擎\ndate: 2014-05-06 19:42:39\n---\n\n因为项目需要用到分页功能，所以需要用到SetLimits函数，结果就出现了Error: searchd error: offset out of bounds (offset=9500, max_matches=1000)\n\n于是找原因，发现配置文件中有max_matches这个选项，于是将它改为10000,可是依然出现Error: searchd error: offset out of bounds (offset=9500, max_matches=1000)错误，真是莫名其妙的错误，仔细看了SetLimits的函数说明以及SphinxClient.java,才知道使用SetLimits这个函数时，如果没有提供max_matches这个参数的值，则max_matches默认为1000,而9500超过了1000,所以溢出了。\n\n现在终于明白原因，也就是说使用Sphinx一共可以在两个地方设置max_matches,一个是在searchd,也就是引擎端，提供给searchd的配置文件中进行设置；而在SphinxClient中,也就是客户端，如果在SetLimits函数中没有设置max_matches,则默认使用1000.这里有一点需要注意的是，客户端的max_matches一定要小于服务器端，否则会报错。而offset也一定要小于客户端的max_matches,这样offset才不会溢出。","slug":"解决Error:-searchd-error:-offset-out-of-bounds问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bg001c26s6qqqin1bu"},{"title":"自动脚本登录服务器","id":"986","date":"2014-12-27T02:59:49.000Z","_content":"\n我们几乎每天都做这样的操作，输入账号和密码登陆跳转机，从跳转机输入帐号和密码登陆目标机器。当然输入账号和密码登陆跳转机可以在SecureCRT这些客户端中建立登录会话解决，可是后面这一步呢？事实上，后面这一步可以写一个脚本解决。\n\n例如现在需要登录192.168.1.1这台机器,登录用户名和密码都为test，而要登录192.168.1.1，需要先登录到跳板机172.168.1.1,则我们可以新建会话链接192.168.1.1，在其中的会话选项中，ssh2中填上登录172.168.1.1需要的用户名和密码，在登录动作中，我们可以引用一个登录脚本。这里的登录动作指的是登录机器后需要进行的后续操作，在我们这里指的是登录跳板机后需要进行的操作，这当然是登录我们的目标主机了，于是可以写脚本，脚本的内容如下。\n```\n#$language = \"VBScript\"\n\n#$interface = \"1.0\"\nSub main\n  ' turn on synchronous mode so we don't miss any data\n  crt.Screen.Synchronous = True\n  crt.Screen.Send \"ssh test@192.168.1.1\" & VbCr\n  ' Wait for a tring that looks like \"password: \" or \"Password: \"\n  crt.Screen.WaitForString \"assword:\"\n  ' Send your password followed by a carriage return\n  crt.Screen.Send \"test\" & VbCr\n  ' turn off synchronous mode to restore normal input processing\n  crt.Screen.Synchronous = False\nEnd Sub\n```\n如此，我们只需要在SecureCRT中点击一下这个会话，就可以登录到192.168.1.1这台服务器了，是不是很方便？\n","source":"_posts/自动脚本登录服务器.md","raw":"title: 自动脚本登录服务器\nid: 986\ncategories:\n  - shell\ndate: 2014-12-27 10:59:49\ntags:\n---\n\n我们几乎每天都做这样的操作，输入账号和密码登陆跳转机，从跳转机输入帐号和密码登陆目标机器。当然输入账号和密码登陆跳转机可以在SecureCRT这些客户端中建立登录会话解决，可是后面这一步呢？事实上，后面这一步可以写一个脚本解决。\n\n例如现在需要登录192.168.1.1这台机器,登录用户名和密码都为test，而要登录192.168.1.1，需要先登录到跳板机172.168.1.1,则我们可以新建会话链接192.168.1.1，在其中的会话选项中，ssh2中填上登录172.168.1.1需要的用户名和密码，在登录动作中，我们可以引用一个登录脚本。这里的登录动作指的是登录机器后需要进行的后续操作，在我们这里指的是登录跳板机后需要进行的操作，这当然是登录我们的目标主机了，于是可以写脚本，脚本的内容如下。\n```\n#$language = \"VBScript\"\n\n#$interface = \"1.0\"\nSub main\n  ' turn on synchronous mode so we don't miss any data\n  crt.Screen.Synchronous = True\n  crt.Screen.Send \"ssh test@192.168.1.1\" & VbCr\n  ' Wait for a tring that looks like \"password: \" or \"Password: \"\n  crt.Screen.WaitForString \"assword:\"\n  ' Send your password followed by a carriage return\n  crt.Screen.Send \"test\" & VbCr\n  ' turn off synchronous mode to restore normal input processing\n  crt.Screen.Synchronous = False\nEnd Sub\n```\n如此，我们只需要在SecureCRT中点击一下这个会话，就可以登录到192.168.1.1这台服务器了，是不是很方便？\n","slug":"自动脚本登录服务器","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bk001j26s65kzk2z4r"},{"title":"给sphinxclient.c增加flush索引到硬盘功能","id":"799","date":"2014-07-11T03:35:02.000Z","_content":"\n在Sphinx中，如果你调用的是C的api，并使用更新属性的功能，而此时，你想将更新后的索引冲刷到硬盘，你就会发现C的api中没有提供这个功能。而在Java,PHP,Python中，都提供了FlushAttributes这个接口来完成这个功能，于是你不得不另外在写一个程序来调用这个接口。\n\n仔细想想，Sphinx都是用C++写的，而C的API中竟然没有提供这个接口，反倒是其它语言有提供，真是匪夷所思。所幸，代码都是开源的，想要自己有这个接口，自己动手写一个就好了，也许这就是开源的好处。\n\n代码如下：\n``` c\nint sphinx_flush_attributes(sphinx_client * client) {\n\tchar *buf, *req, *p;\n\tint req_len = 0;\n\tif (!client) {\n\t\tprintf(\"not valid client\\n\");\n\t\treturn -1;\n\t}\n\tbuf = malloc ( 12 + req_len ); // request body length plus 12 header bytes\n\tif ( !buf ) {\n\t\tset_error ( client, \"malloc() failed (bytes=%d)\", req_len );\n\t\treturn -1;\n\t}\n\n\treq = buf;\n\n\tsend_word ( &req, SEARCHD_COMMAND_FLUSHATTRS );\n\tsend_word ( &req, VER_COMMAND_FLUSHATTRS );\n\tsend_int ( &req, req_len );\n\n\t// send query, get response\n\tif ( !net_simple_query ( client, buf, req_len ) )\n\t\treturn -1;\n\n\t// parse response\n\tif ( client->response_len < 4 ) {\n\t\tset_error ( client, \"incomplete reply\" );\n\t\treturn -1;\n\t}\n\n\tp = client->response_start;\n\treturn unpack_int ( &p );\n}\n```\n之后还要添加\nSEARCHD_COMMAND_FLUSHATTRS  = 7，\nVER_COMMAND_FLUSHATTRS  = 0x100，\n以及在头文件中添加int sphinx_flush_attributes(sphinx_client * client)；即可。","source":"_posts/给sphinxclient.c增加flush索引到硬盘功能.md","raw":"title: 给sphinxclient.c增加flush索引到硬盘功能\ntags:\n  - flush\n  - Sphinx\n  - sphinxclient\n  - 开源\n  - 索引\nid: 799\ncategories:\n  - 搜索引擎\ndate: 2014-07-11 11:35:02\n---\n\n在Sphinx中，如果你调用的是C的api，并使用更新属性的功能，而此时，你想将更新后的索引冲刷到硬盘，你就会发现C的api中没有提供这个功能。而在Java,PHP,Python中，都提供了FlushAttributes这个接口来完成这个功能，于是你不得不另外在写一个程序来调用这个接口。\n\n仔细想想，Sphinx都是用C++写的，而C的API中竟然没有提供这个接口，反倒是其它语言有提供，真是匪夷所思。所幸，代码都是开源的，想要自己有这个接口，自己动手写一个就好了，也许这就是开源的好处。\n\n代码如下：\n``` c\nint sphinx_flush_attributes(sphinx_client * client) {\n\tchar *buf, *req, *p;\n\tint req_len = 0;\n\tif (!client) {\n\t\tprintf(\"not valid client\\n\");\n\t\treturn -1;\n\t}\n\tbuf = malloc ( 12 + req_len ); // request body length plus 12 header bytes\n\tif ( !buf ) {\n\t\tset_error ( client, \"malloc() failed (bytes=%d)\", req_len );\n\t\treturn -1;\n\t}\n\n\treq = buf;\n\n\tsend_word ( &req, SEARCHD_COMMAND_FLUSHATTRS );\n\tsend_word ( &req, VER_COMMAND_FLUSHATTRS );\n\tsend_int ( &req, req_len );\n\n\t// send query, get response\n\tif ( !net_simple_query ( client, buf, req_len ) )\n\t\treturn -1;\n\n\t// parse response\n\tif ( client->response_len < 4 ) {\n\t\tset_error ( client, \"incomplete reply\" );\n\t\treturn -1;\n\t}\n\n\tp = client->response_start;\n\treturn unpack_int ( &p );\n}\n```\n之后还要添加\nSEARCHD_COMMAND_FLUSHATTRS  = 7，\nVER_COMMAND_FLUSHATTRS  = 0x100，\n以及在头文件中添加int sphinx_flush_attributes(sphinx_client * client)；即可。","slug":"给sphinxclient.c增加flush索引到硬盘功能","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bm001l26s6fn6n8xh9"},{"title":"筛法得到素数","id":"831","date":"2014-07-15T01:25:07.000Z","_content":"\n在欧拉工程中，很多时候都需要用到素数，而得到素数比较好就是用筛法生成。筛法还是很容易理解的，随便找一本教科书的可以找到。\n\n有了这个函数后，要得到100以内的素数就非常容易了。\n\n``` python\ndef getPrimes(n):\n    primes = [True for i in xrange(n + 1)]\n    primes[0] = primes[1] = False\n    for x in xrange(2, n + 1):\n        if not primes[x]:\n            continue\n        m = x * x\n        while m <= n:\n            primes[m] = False\n            m += x\n    return [i for i in xrange(n + 1) if primes[i]]\n\nprint get_primes(100)\n```\n2014年8月16日更新：\n才发现这个函数的速度还不理想，于是改成\n``` python\ndef getPrimes(n):\n    primes = [True] * (n + 1)\n    primes[0] = primes[1] = False\n    i = 2\n    while i * i <= n:\n        if primes[i]:\n            primes[i * i:n + 1:i] = [False] * ((n - i * i) / i + 1)\n        i += 1\n    return [i for i in xrange(n + 1) if primes[i]]\n```\n之所以这么改，可参看[Python筛法求素数的优化](http://program.dengshilong.org/2014/08/16/python%E7%AD%9B%E6%B3%95%E6%B1%82%E7%B4%A0%E6%95%B0%E7%9A%84%E4%BC%98%E5%8C%96/)","source":"_posts/筛法得到素数.md","raw":"title: 筛法得到素数\ntags:\n  - 筛法\n  - 素数\nid: 831\ncategories:\n  - 算法\ndate: 2014-07-15 09:25:07\n---\n\n在欧拉工程中，很多时候都需要用到素数，而得到素数比较好就是用筛法生成。筛法还是很容易理解的，随便找一本教科书的可以找到。\n\n有了这个函数后，要得到100以内的素数就非常容易了。\n\n``` python\ndef getPrimes(n):\n    primes = [True for i in xrange(n + 1)]\n    primes[0] = primes[1] = False\n    for x in xrange(2, n + 1):\n        if not primes[x]:\n            continue\n        m = x * x\n        while m <= n:\n            primes[m] = False\n            m += x\n    return [i for i in xrange(n + 1) if primes[i]]\n\nprint get_primes(100)\n```\n2014年8月16日更新：\n才发现这个函数的速度还不理想，于是改成\n``` python\ndef getPrimes(n):\n    primes = [True] * (n + 1)\n    primes[0] = primes[1] = False\n    i = 2\n    while i * i <= n:\n        if primes[i]:\n            primes[i * i:n + 1:i] = [False] * ((n - i * i) / i + 1)\n        i += 1\n    return [i for i in xrange(n + 1) if primes[i]]\n```\n之所以这么改，可参看[Python筛法求素数的优化](http://program.dengshilong.org/2014/08/16/python%E7%AD%9B%E6%B3%95%E6%B1%82%E7%B4%A0%E6%95%B0%E7%9A%84%E4%BC%98%E5%8C%96/)","slug":"筛法得到素数","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4br001w26s65watgidi"},{"title":"等值首尾和","id":"1039","date":"2015-10-22T08:16:54.000Z","_content":"\n假设有一个数组x[ ], 它有n个元素，每一个都大于零，称x[0] + x[1] + ... + x[i]为前置和(Prefix Sum),而 x[j] + x[j + 1] + ... + x[n - 1]为后置和(Suffix Sum)。试编写一个程序，求出x[ ] 中有多少组相同的前置和与后置和。\n\n说明\n如果x[ ] 的元素是3，6，2，1，4，5，2，则x[ ]的前置和有一下7个，即3，9，11，12，16，21，23；后置和则是2，7，11，12，14，20，23；于是11，12，与23这3对就是值相同的前置和与后置和，因为：\n11 = 3 + 6 + 2(前置和) = 2 + 5 + 4 (后置和)\n12 = 3 + 6 + 2 + 1(前置和) = 2 + 5 + 4 + 1 (后置和)\n因为23是整个数组元素的和，因此前置和与后置和一定相同。\n\n可以用变量prefix来表示前置和，用suffix来表示后置和，用i表示前置和累加元素的位置，i从前往后加，用j表示后置和累加元素的位置, j从后往前加。当prefix > suffix时，累加后置和，也就是j向前走；当prefix < suffix时，累加前置和，也就是i往后走；当prefix == suffix时，同时累加前置和与后置和，也就是i往后走，j往前走\n\n``` java\n public class HeadTail {\n\tpublic static int headTail(int[] nums) {\n\t\tint i = 0;\n\t\tint j = nums.length - 1;\n\t\tint prefix = 0;\n\t\tint suffix = 0;\n\t\tint result = 0;\n\t\twhile (i < nums.length && j >= 0) {\n\t\t\tSystem.out.println(prefix + \" \" + suffix + \" \" + i + \" \" + j);\n\t\t\tif (prefix == suffix) {\t\t\n\t\t\t\tprefix += nums[i++];\n\t\t\t\tsuffix += nums[j--];\n\t\t\t\tresult++;\n\t\t\t} else if (prefix > suffix) {\n\t\t\t\tsuffix += nums[j--];\n\t\t\t} else {\t\t\t\n\t\t\t\tprefix += nums[i++];\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {3, 6, 2, 1, 4, 5, 2};\n\t\tSystem.out.println(headTail(nums));\n\t}\n}\n```","source":"_posts/等值首尾和.md","raw":"title: 等值首尾和\ntags:\n  - C名题百则\nid: 1039\ncategories:\n  - 算法\ndate: 2015-10-22 16:16:54\n---\n\n假设有一个数组x[ ], 它有n个元素，每一个都大于零，称x[0] + x[1] + ... + x[i]为前置和(Prefix Sum),而 x[j] + x[j + 1] + ... + x[n - 1]为后置和(Suffix Sum)。试编写一个程序，求出x[ ] 中有多少组相同的前置和与后置和。\n\n说明\n如果x[ ] 的元素是3，6，2，1，4，5，2，则x[ ]的前置和有一下7个，即3，9，11，12，16，21，23；后置和则是2，7，11，12，14，20，23；于是11，12，与23这3对就是值相同的前置和与后置和，因为：\n11 = 3 + 6 + 2(前置和) = 2 + 5 + 4 (后置和)\n12 = 3 + 6 + 2 + 1(前置和) = 2 + 5 + 4 + 1 (后置和)\n因为23是整个数组元素的和，因此前置和与后置和一定相同。\n\n可以用变量prefix来表示前置和，用suffix来表示后置和，用i表示前置和累加元素的位置，i从前往后加，用j表示后置和累加元素的位置, j从后往前加。当prefix > suffix时，累加后置和，也就是j向前走；当prefix < suffix时，累加前置和，也就是i往后走；当prefix == suffix时，同时累加前置和与后置和，也就是i往后走，j往前走\n\n``` java\n public class HeadTail {\n\tpublic static int headTail(int[] nums) {\n\t\tint i = 0;\n\t\tint j = nums.length - 1;\n\t\tint prefix = 0;\n\t\tint suffix = 0;\n\t\tint result = 0;\n\t\twhile (i < nums.length && j >= 0) {\n\t\t\tSystem.out.println(prefix + \" \" + suffix + \" \" + i + \" \" + j);\n\t\t\tif (prefix == suffix) {\t\t\n\t\t\t\tprefix += nums[i++];\n\t\t\t\tsuffix += nums[j--];\n\t\t\t\tresult++;\n\t\t\t} else if (prefix > suffix) {\n\t\t\t\tsuffix += nums[j--];\n\t\t\t} else {\t\t\t\n\t\t\t\tprefix += nums[i++];\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {3, 6, 2, 1, 4, 5, 2};\n\t\tSystem.out.println(headTail(nums));\n\t}\n}\n```","slug":"等值首尾和","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bt002226s6u2ibwkgi"},{"title":"等值数目","id":"1035","date":"2015-10-22T07:31:31.000Z","_content":"\n已知两个整数数组f[]与g[]，它们的元素都已经从小到大排列好，而且两个数组中的元素都各不相同。例如，f[]中有1,3,4,7,9,而g[]中有3,5,7,8,10。试编写程序算出这两个数组之间有多少组相同的元素。\n\n就上例而言，f[2]和g[1]为3是一组​；f[3]与g[2]为7是第二组\n\n依然是利用已经排好序的这个特性。\n``` java\npublic class EQCount {\n\tpublic static int eqCount(int[] f, int[] g) {\n\t\tint i = 0;\n\t\tint j = 0;\n\t\tint result = 0;\n\t\twhile (i < f.length && j < g.length) {\n\t\t\tif (f[i] == g[j]) {\n\t\t\t\ti++;\n\t\t\t\tj++;\n\t\t\t\tresult++;\n\t\t\t} else if (f[i] > g[j]) {\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] f = {1, 3, 4, 7, 9};\n\t\tint[] g = {3, 5, 7, 8, 10};\n\t\tSystem.out.println(eqCount(f, g));\n\t}\n}\n```","source":"_posts/等值数目.md","raw":"title: 等值数目\ntags:\n  - C名题百则\nid: 1035\ncategories:\n  - 算法\ndate: 2015-10-22 15:31:31\n---\n\n已知两个整数数组f[]与g[]，它们的元素都已经从小到大排列好，而且两个数组中的元素都各不相同。例如，f[]中有1,3,4,7,9,而g[]中有3,5,7,8,10。试编写程序算出这两个数组之间有多少组相同的元素。\n\n就上例而言，f[2]和g[1]为3是一组​；f[3]与g[2]为7是第二组\n\n依然是利用已经排好序的这个特性。\n``` java\npublic class EQCount {\n\tpublic static int eqCount(int[] f, int[] g) {\n\t\tint i = 0;\n\t\tint j = 0;\n\t\tint result = 0;\n\t\twhile (i < f.length && j < g.length) {\n\t\t\tif (f[i] == g[j]) {\n\t\t\t\ti++;\n\t\t\t\tj++;\n\t\t\t\tresult++;\n\t\t\t} else if (f[i] > g[j]) {\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] f = {1, 3, 4, 7, 9};\n\t\tint[] g = {3, 5, 7, 8, 10};\n\t\tSystem.out.println(eqCount(f, g));\n\t}\n}\n```","slug":"等值数目","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4bw002526s6ii64o8cw"},{"title":"登陆框获取焦点","id":"738","date":"2014-05-25T16:46:19.000Z","_content":"\n在登陆后台的时候，要输入用户名和密码，此时希望打开页面，焦点就直接停留在用户名输入框，这样就可以省去移动鼠标的麻烦。\n\n如以下一个登陆表单。\n```\n<form action=\"login.php\" method=\"post\" name=\"login\">\n    用户名：<input name=\"username\" type=\"text\" value=\"\" />\n    密码：<input name=\"password\" type=\"password\" />\n    <input type=\"submit\" value=\"登陆\" />\n</form>\n```\n此时可以编写如下javascript:\n```\nwindow.onload = function() {\n    if (document.forms.login.username.value == \"\") {\n        document.forms.login.username.focus();\n    } else {\n        document.forms.login.password.focus();\n    }\n}\n```\n","source":"_posts/登陆框获取焦点.md","raw":"title: 登陆框获取焦点\ntags:\n  - html\n  - javascript\n  - 焦点\nid: 738\ncategories:\n  - Javascript\ndate: 2014-05-26 00:46:19\n---\n\n在登陆后台的时候，要输入用户名和密码，此时希望打开页面，焦点就直接停留在用户名输入框，这样就可以省去移动鼠标的麻烦。\n\n如以下一个登陆表单。\n```\n<form action=\"login.php\" method=\"post\" name=\"login\">\n    用户名：<input name=\"username\" type=\"text\" value=\"\" />\n    密码：<input name=\"password\" type=\"password\" />\n    <input type=\"submit\" value=\"登陆\" />\n</form>\n```\n此时可以编写如下javascript:\n```\nwindow.onload = function() {\n    if (document.forms.login.username.value == \"\") {\n        document.forms.login.username.focus();\n    } else {\n        document.forms.login.password.focus();\n    }\n}\n```\n","slug":"登陆框获取焦点","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4by002826s6ih30ml2w"},{"title":"用select实现精确定时器","id":"587","date":"2013-12-26T13:37:40.000Z","_content":"\n之前为了找出Sphinx中index 'test1': search error: query too complex, not enough stack (thread_stack=1217498K or higher required)这个bug,大致看了一下Sphinx的源码，发现问题的原因是在计算线程使用的空间时出错，具体原因依然没有找到，还在努力当中。在这个过程中，看到以下这段程序\n``` c\nvoid sphSleepMsec ( int iMsec )\n{\n    if ( iMsec<0 )\n        return;\n\n#if USE_WINDOWS\n    Sleep ( iMsec );\n\n#else\n    struct timeval tvTimeout;\n    tvTimeout.tv_sec = iMsec / 1000; // full seconds\n    tvTimeout.tv_usec = ( iMsec % 1000 ) * 1000; // remainder is msec, so *1000 for usec\n\n    select ( 0, NULL, NULL, NULL, &tvTimeout ); // FIXME? could handle EINTR\n#endif\n}\n```\n其实就是一个毫秒定时器，《UNIX环境编程》第14章的习题就要求实现一个这样的函数。看这段程序，又是令人恶心的匈牙利命名，把它改为正常点的比较好。程序中的注释\"//FIXME?could handle EINR\"说的是select会被SIGINT信号中断，那么这个定时器也会因为这个原因而被中断信号中断，看看能否提供不被中断的方法。立刻就想到了忽略中断信号，试了一下，其实还是挺容易的。难道这种直接忽略中断信号还是存在问题？\n``` c\n#include <sys/select.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <signal.h>\nvoid sleep_ms(int msec) {//睡眠msec毫秒\n    if (msec < 0)\n        return;\n    signal(SIGINT, SIG_IGN);\n    struct timeval tv; \n    tv.tv_sec = msec / 1000;//除以1000，得到秒数\n    tv.tv_usec = (msec % 1000) * 1000;//得到剩余的毫秒数，之后乘以1000得到微秒数\n    select(0, NULL, NULL, NULL, &tv);\n}\nint main() {\n    printf(\"start sleeping\\n\");\n    sleep_ms(4000);\n    printf(\"finish sleeping\\n\");\n    return 0;\n}\n```\n","source":"_posts/用select实现精确定时器.md","raw":"title: 用select实现精确定时器\ntags:\n  - select\n  - SIGINT\n  - sleep\n  - 中断\n  - 定时器\n  - 忽略\nid: 587\ncategories:\n  - 编程\ndate: 2013-12-26 21:37:40\n---\n\n之前为了找出Sphinx中index 'test1': search error: query too complex, not enough stack (thread_stack=1217498K or higher required)这个bug,大致看了一下Sphinx的源码，发现问题的原因是在计算线程使用的空间时出错，具体原因依然没有找到，还在努力当中。在这个过程中，看到以下这段程序\n``` c\nvoid sphSleepMsec ( int iMsec )\n{\n    if ( iMsec<0 )\n        return;\n\n#if USE_WINDOWS\n    Sleep ( iMsec );\n\n#else\n    struct timeval tvTimeout;\n    tvTimeout.tv_sec = iMsec / 1000; // full seconds\n    tvTimeout.tv_usec = ( iMsec % 1000 ) * 1000; // remainder is msec, so *1000 for usec\n\n    select ( 0, NULL, NULL, NULL, &tvTimeout ); // FIXME? could handle EINTR\n#endif\n}\n```\n其实就是一个毫秒定时器，《UNIX环境编程》第14章的习题就要求实现一个这样的函数。看这段程序，又是令人恶心的匈牙利命名，把它改为正常点的比较好。程序中的注释\"//FIXME?could handle EINR\"说的是select会被SIGINT信号中断，那么这个定时器也会因为这个原因而被中断信号中断，看看能否提供不被中断的方法。立刻就想到了忽略中断信号，试了一下，其实还是挺容易的。难道这种直接忽略中断信号还是存在问题？\n``` c\n#include <sys/select.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <signal.h>\nvoid sleep_ms(int msec) {//睡眠msec毫秒\n    if (msec < 0)\n        return;\n    signal(SIGINT, SIG_IGN);\n    struct timeval tv; \n    tv.tv_sec = msec / 1000;//除以1000，得到秒数\n    tv.tv_usec = (msec % 1000) * 1000;//得到剩余的毫秒数，之后乘以1000得到微秒数\n    select(0, NULL, NULL, NULL, &tv);\n}\nint main() {\n    printf(\"start sleeping\\n\");\n    sleep_ms(4000);\n    printf(\"finish sleeping\\n\");\n    return 0;\n}\n```\n","slug":"用select实现精确定时器","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4c2002h26s6g4yf56de"},{"title":"用epoll提供telnet服务的代码","id":"572","date":"2013-12-25T14:03:54.000Z","_content":"\n这是之前写的用epoll提供telnet服务的代码。\n\n``` c\n#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <errno.h>\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <fcntl.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include <stdlib.h>\n#include <netinet/tcp.h> \n#include <ctype.h>\n#include <assert.h>\n#define MAX_EVENTS 10\n#define PORT 9999\n//从buf中得到命令\nvoid _get_command(char *buf, char *cmd) {\n\tint i = 0;\n\tint j = 0;\n\twhile (!isalpha(buf[i]))\n\t\ti++;\n\twhile (buf[i] != '\\0' && buf[i] != ' ' && buf[i] != '\\r' && buf[i] != '\\n') {\n\t\tcmd[j++] = buf[i];\n\t\ti++;\n\t}\n\tcmd[j] = '\\0';\n}\n// 返回成功发送的字节数\nint Send(int sock, void *buffer, int size)\n{\n\tint nsend = 0, total = 0;\n\tint err;\n\tif(NULL == buffer || 0 == size) {\n\t\treturn 0;\n\t}\n\twhile(size > 0) {\n\t\tnsend = write(sock, (char*)buffer + total, size);\n\t\tif(nsend == -1) {\n\t\t\terr = errno;\n\t\t\tif(EINTR == err) {\n\t\t\t\tprintf(\"send data to socket[%d], error is %s[%d]\\n\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t} else {\n\t\t\t\tprintf(\"Fail to send data to socket[%d], error is %s[%d]\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t\treturn -1;\t\n\t\t\t}\n\t\t} else {\n\t\t\ttotal += nsend;\n\t\t\tsize -= nsend;\n\t\t}\n\t}\n\treturn total;\n}\n//处理重置命令\nvoid process_reset(int sock){\n\tchar mess[] = \"reset successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n//处理错误命令\nvoid process_error(int sock) {\n\tchar error[] = \"ERROR\\r\\n\";\n\tSend(sock, error, strlen(error));\n\treturn;\n}\nvoid process_stats(int sock){\n\tchar mess[] = \"stats successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n\n//处理退出命令\nvoid process_quit(int sock) {\n\tclose(sock);\n}\n\nint process_command(int sock, char *buf) {\n\tassert(buf != NULL);\n\n\t/*char cmd[BUFSIZ];\n\t_get_command(buf, cmd);\t\n\tprintf(\"command: %s\\n\", cmd);\n\n\tif (strcmp(\"stats\",cmd) == 0) {\n\t\tprocess_stats(sock);\n\t} else if (strcmp(\"reset\", cmd) == 0) {\n\t\tprocess_reset(sock);\n\t} else if (strcmp(\"quit\", cmd) == 0){\n\t\tprocess_quit(sock);\n\t} else {\n\t\tprocess_error(sock);\n\t}*/\n\tSend(sock, buf, strlen(buf));\n\n\treturn 0;\n}\n\n//设置socket为非阻塞\nvoid setnonblocking(int sockfd) {\n\tint opts;\n\topts = fcntl(sockfd, F_GETFL);\n\tif (opts < 0) {\n\t\tperror(\"fcntl(F_GETFL)\\n\");\n\t\texit(1);\n\t}\n\topts = (opts | O_NONBLOCK);\n\tif (fcntl(sockfd, F_SETFL, opts) < 0) {\n\t\tperror(\"fcntl(F_SETFL)\\n\");\n\t\texit(1);\n\t}\n}\nint main() {\n\tint listenfd, conn_sock, epfd;\n\tchar buf[BUFSIZ];\n\tsocklen_t clilen;\n\tstruct sockaddr_in cliaddr, servaddr;\n\tstruct epoll_event ev, events[MAX_EVENTS];\n\tlistenfd = socket(AF_INET, SOCK_STREAM, 0);\n\tif (listenfd < 0) {\n\t\tprintf(\"create socket error\\n\");\n\t\treturn -1;\n\t}\n\tint on = 1;\n\tsetsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));\n\tsetnonblocking(listenfd);\n    struct linger {\n        int l_onoff; /* 0 = off, nozero = on */\n        int l_linger; /* linger time */\n    }lin;\n    lin.l_onoff = 1;\n    lin.l_linger = 0;\n    setsockopt(listenfd, SOL_SOCKET, SO_LINGER, (char*)&lin, sizeof(lin));\n\tbzero(&servaddr, sizeof(servaddr));\n\tservaddr.sin_family = AF_INET;\n\tservaddr.sin_addr.s_addr = htonl(INADDR_ANY);\n\tservaddr.sin_port = htons(PORT);\n\n\tif(bind(listenfd,(struct sockaddr*)&servaddr,sizeof(struct sockaddr))<0){\n\t\tprintf(\"bind error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\n\tif(listen(listenfd, 5) < 0) {\n\t\tprintf(\"listen error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1; \n\t}\n\tepfd = epoll_create(MAX_EVENTS); //生成epoll专用的文件描述符\n\tif (epfd == -1) {\n\t\tprintf(\"epoll_create\\n\");\n\t\treturn -1;\n\t}\n\tev.events = EPOLLIN | EPOLLET; //设置处理的事件类型,设置为边沿触发\n\tev.data.fd = listenfd;\n\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, &ev) == -1) {\n\t\tprintf(\"epoll_ctl add listen_sock fail\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\twhile (1) {\n\t\tint timeout = 1000; \n\t\tint nfds = epoll_wait(epfd, events, MAX_EVENTS, timeout);\n\t\tif (nfds == -1) {\n\t\t\tprintf(\"epoll_wait\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tfor (int i = 0;i < nfds; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == listenfd) { //监听事件\n\t\t\t\twhile ((conn_sock = accept(listenfd, NULL, NULL)) > 0) {//循环处理accept,这样可以处理多个连接在就绪队列中的情况\n\t\t\t\t\tprintf(\"accept %d\\n\", conn_sock);\n\t\t\t\t\tsetnonblocking(conn_sock);\n\t\t\t\t\tev.events = EPOLLIN | EPOLLET; //设置为边沿触发\n\t\t\t\t\tev.data.fd = conn_sock;\n\t\t\t\t\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, conn_sock, &ev) == -1) {\n\t\t\t\t\t\tprintf(\"epoll_ctl: add fail\\n\");\n\t\t\t\t\t\tclose(conn_sock);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLIN) {//读事件，说明有数据从客户端发来\n\t\t\t\tint n = 0;\n\t\t\t\tint nread = 0;\n\t\t\t\twhile ((nread = read(fd, buf + n, BUFSIZ - n)) > 0) {\n\t\t\t\t\tn += nread;\n\t\t\t\t}\n\t\t\t\tif (nread == -1 && errno != EAGAIN) {//读数据错误,关闭描述符\n\t\t\t\t\tprintf(\"read error\\n\");\n\t\t\t\t\tclose(fd); //关闭一个描述符，它会从epoll描述符集合中自动删除\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(nread == 0) { //客户端关闭连接，关闭相应的描述符\n\t\t\t\t\tclose(fd);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif( n > 0) {\n\t\t\t\t\tprocess_command(fd, buf);\n\t\t\t\t\tmemset(buf, 0, sizeof(buf));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```\n","source":"_posts/用epoll提供telnet服务的代码.md","raw":"title: 用epoll提供telnet服务的代码\ntags:\n  - epoll\n  - telnet\nid: 572\ncategories:\n  - 编程\ndate: 2013-12-25 22:03:54\n---\n\n这是之前写的用epoll提供telnet服务的代码。\n\n``` c\n#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <errno.h>\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <fcntl.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include <stdlib.h>\n#include <netinet/tcp.h> \n#include <ctype.h>\n#include <assert.h>\n#define MAX_EVENTS 10\n#define PORT 9999\n//从buf中得到命令\nvoid _get_command(char *buf, char *cmd) {\n\tint i = 0;\n\tint j = 0;\n\twhile (!isalpha(buf[i]))\n\t\ti++;\n\twhile (buf[i] != '\\0' && buf[i] != ' ' && buf[i] != '\\r' && buf[i] != '\\n') {\n\t\tcmd[j++] = buf[i];\n\t\ti++;\n\t}\n\tcmd[j] = '\\0';\n}\n// 返回成功发送的字节数\nint Send(int sock, void *buffer, int size)\n{\n\tint nsend = 0, total = 0;\n\tint err;\n\tif(NULL == buffer || 0 == size) {\n\t\treturn 0;\n\t}\n\twhile(size > 0) {\n\t\tnsend = write(sock, (char*)buffer + total, size);\n\t\tif(nsend == -1) {\n\t\t\terr = errno;\n\t\t\tif(EINTR == err) {\n\t\t\t\tprintf(\"send data to socket[%d], error is %s[%d]\\n\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t} else {\n\t\t\t\tprintf(\"Fail to send data to socket[%d], error is %s[%d]\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t\treturn -1;\t\n\t\t\t}\n\t\t} else {\n\t\t\ttotal += nsend;\n\t\t\tsize -= nsend;\n\t\t}\n\t}\n\treturn total;\n}\n//处理重置命令\nvoid process_reset(int sock){\n\tchar mess[] = \"reset successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n//处理错误命令\nvoid process_error(int sock) {\n\tchar error[] = \"ERROR\\r\\n\";\n\tSend(sock, error, strlen(error));\n\treturn;\n}\nvoid process_stats(int sock){\n\tchar mess[] = \"stats successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n\n//处理退出命令\nvoid process_quit(int sock) {\n\tclose(sock);\n}\n\nint process_command(int sock, char *buf) {\n\tassert(buf != NULL);\n\n\t/*char cmd[BUFSIZ];\n\t_get_command(buf, cmd);\t\n\tprintf(\"command: %s\\n\", cmd);\n\n\tif (strcmp(\"stats\",cmd) == 0) {\n\t\tprocess_stats(sock);\n\t} else if (strcmp(\"reset\", cmd) == 0) {\n\t\tprocess_reset(sock);\n\t} else if (strcmp(\"quit\", cmd) == 0){\n\t\tprocess_quit(sock);\n\t} else {\n\t\tprocess_error(sock);\n\t}*/\n\tSend(sock, buf, strlen(buf));\n\n\treturn 0;\n}\n\n//设置socket为非阻塞\nvoid setnonblocking(int sockfd) {\n\tint opts;\n\topts = fcntl(sockfd, F_GETFL);\n\tif (opts < 0) {\n\t\tperror(\"fcntl(F_GETFL)\\n\");\n\t\texit(1);\n\t}\n\topts = (opts | O_NONBLOCK);\n\tif (fcntl(sockfd, F_SETFL, opts) < 0) {\n\t\tperror(\"fcntl(F_SETFL)\\n\");\n\t\texit(1);\n\t}\n}\nint main() {\n\tint listenfd, conn_sock, epfd;\n\tchar buf[BUFSIZ];\n\tsocklen_t clilen;\n\tstruct sockaddr_in cliaddr, servaddr;\n\tstruct epoll_event ev, events[MAX_EVENTS];\n\tlistenfd = socket(AF_INET, SOCK_STREAM, 0);\n\tif (listenfd < 0) {\n\t\tprintf(\"create socket error\\n\");\n\t\treturn -1;\n\t}\n\tint on = 1;\n\tsetsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));\n\tsetnonblocking(listenfd);\n    struct linger {\n        int l_onoff; /* 0 = off, nozero = on */\n        int l_linger; /* linger time */\n    }lin;\n    lin.l_onoff = 1;\n    lin.l_linger = 0;\n    setsockopt(listenfd, SOL_SOCKET, SO_LINGER, (char*)&lin, sizeof(lin));\n\tbzero(&servaddr, sizeof(servaddr));\n\tservaddr.sin_family = AF_INET;\n\tservaddr.sin_addr.s_addr = htonl(INADDR_ANY);\n\tservaddr.sin_port = htons(PORT);\n\n\tif(bind(listenfd,(struct sockaddr*)&servaddr,sizeof(struct sockaddr))<0){\n\t\tprintf(\"bind error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\n\tif(listen(listenfd, 5) < 0) {\n\t\tprintf(\"listen error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1; \n\t}\n\tepfd = epoll_create(MAX_EVENTS); //生成epoll专用的文件描述符\n\tif (epfd == -1) {\n\t\tprintf(\"epoll_create\\n\");\n\t\treturn -1;\n\t}\n\tev.events = EPOLLIN | EPOLLET; //设置处理的事件类型,设置为边沿触发\n\tev.data.fd = listenfd;\n\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, &ev) == -1) {\n\t\tprintf(\"epoll_ctl add listen_sock fail\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\twhile (1) {\n\t\tint timeout = 1000; \n\t\tint nfds = epoll_wait(epfd, events, MAX_EVENTS, timeout);\n\t\tif (nfds == -1) {\n\t\t\tprintf(\"epoll_wait\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tfor (int i = 0;i < nfds; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == listenfd) { //监听事件\n\t\t\t\twhile ((conn_sock = accept(listenfd, NULL, NULL)) > 0) {//循环处理accept,这样可以处理多个连接在就绪队列中的情况\n\t\t\t\t\tprintf(\"accept %d\\n\", conn_sock);\n\t\t\t\t\tsetnonblocking(conn_sock);\n\t\t\t\t\tev.events = EPOLLIN | EPOLLET; //设置为边沿触发\n\t\t\t\t\tev.data.fd = conn_sock;\n\t\t\t\t\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, conn_sock, &ev) == -1) {\n\t\t\t\t\t\tprintf(\"epoll_ctl: add fail\\n\");\n\t\t\t\t\t\tclose(conn_sock);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLIN) {//读事件，说明有数据从客户端发来\n\t\t\t\tint n = 0;\n\t\t\t\tint nread = 0;\n\t\t\t\twhile ((nread = read(fd, buf + n, BUFSIZ - n)) > 0) {\n\t\t\t\t\tn += nread;\n\t\t\t\t}\n\t\t\t\tif (nread == -1 && errno != EAGAIN) {//读数据错误,关闭描述符\n\t\t\t\t\tprintf(\"read error\\n\");\n\t\t\t\t\tclose(fd); //关闭一个描述符，它会从epoll描述符集合中自动删除\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(nread == 0) { //客户端关闭连接，关闭相应的描述符\n\t\t\t\t\tclose(fd);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif( n > 0) {\n\t\t\t\t\tprocess_command(fd, buf);\n\t\t\t\t\tmemset(buf, 0, sizeof(buf));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```\n","slug":"用epoll提供telnet服务的代码","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4c7002v26s64tgl3nxi"},{"title":"用epoll提供telnet服务的代码(续)","id":"578","date":"2013-12-26T11:39:35.000Z","_content":"\n最终的代码如下，这里修正了对nc命令无法处理的问题\n\n``` c\n#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <errno.h>\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <fcntl.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include <stdlib.h>\n#include <netinet/tcp.h> \n#include <ctype.h>\n#include <assert.h>\n#define MAX_EVENTS 10\n#define PORT 9999\n//从buf中得到命令\nvoid _get_command(char *buf, char *cmd) {\n\tint i = 0;\n\tint j = 0;\n\twhile (!isalpha(buf[i]))\n\t\ti++;\n\twhile (buf[i] != '\\0' && buf[i] != ' ' && buf[i] != '\\r' && buf[i] != '\\n') {\n\t\tcmd[j++] = buf[i];\n\t\ti++;\n\t}\n\tcmd[j] = '\\0';\n}\n// 返回成功发送的字节数\nint Send(int sock, void *buffer, int size)\n{\n\tint nsend = 0, total = 0;\n\tint err;\n\tif(NULL == buffer || 0 == size) {\n\t\treturn 0;\n\t}\n\twhile(size > 0) {\n\t\tnsend = write(sock, (char*)buffer + total, size);\n\t\tif(nsend == -1) {\n\t\t\terr = errno;\n\t\t\tif(EINTR == err) {\n\t\t\t\tprintf(\"send data to socket[%d], error is %s[%d]\\n\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t} else {\n\t\t\t\tprintf(\"Fail to send data to socket[%d], error is %s[%d]\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t\treturn -1;\t\n\t\t\t}\n\t\t} else {\n\t\t\ttotal += nsend;\n\t\t\tsize -= nsend;\n\t\t}\n\t}\n\treturn total;\n}\n//处理重置命令\nvoid process_reset(int sock){\n\tchar mess[] = \"reset successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n//处理错误命令\nvoid process_error(int sock) {\n\tchar error[] = \"ERROR\\r\\n\";\n\tSend(sock, error, strlen(error));\n\treturn;\n}\nvoid process_stats(int sock){\n\tchar mess[] = \"stats successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n\n//处理退出命令\nvoid process_quit(int sock) {\n\tclose(sock);\n}\n\nint process_command(int sock, char *buf) {\n\tassert(buf != NULL);\n\n\t/*char cmd[BUFSIZ];\n\t_get_command(buf, cmd);\t\n\tprintf(\"command: %s\\n\", cmd);\n\n\tif (strcmp(\"stats\",cmd) == 0) {\n\t\tprocess_stats(sock);\n\t} else if (strcmp(\"reset\", cmd) == 0) {\n\t\tprocess_reset(sock);\n\t} else if (strcmp(\"quit\", cmd) == 0){\n\t\tprocess_quit(sock);\n\t} else {\n\t\tprocess_error(sock);\n\t}*/\n\tSend(sock, buf, strlen(buf));\n\n\treturn 0;\n}\n\n//设置socket为非阻塞\nvoid setnonblocking(int sockfd) {\n\tint opts;\n\topts = fcntl(sockfd, F_GETFL);\n\tif (opts < 0) {\n\t\tperror(\"fcntl(F_GETFL)\\n\");\n\t\texit(1);\n\t}\n\topts = (opts | O_NONBLOCK);\n\tif (fcntl(sockfd, F_SETFL, opts) < 0) {\n\t\tperror(\"fcntl(F_SETFL)\\n\");\n\t\texit(1);\n\t}\n}\nint main() {\n\tint listenfd, conn_sock, epfd;\n\tchar buf[BUFSIZ];\n\tsocklen_t clilen;\n\tstruct sockaddr_in cliaddr, servaddr;\n\tstruct epoll_event ev, events[MAX_EVENTS];\n\tlistenfd = socket(AF_INET, SOCK_STREAM, 0);\n\tif (listenfd < 0) {\n\t\tprintf(\"create socket error\\n\");\n\t\treturn -1;\n\t}\n\tint on = 1;\n\tsetsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));\n\tsetnonblocking(listenfd);\n\tbzero(&servaddr, sizeof(servaddr));\n\tservaddr.sin_family = AF_INET;\n\tservaddr.sin_addr.s_addr = htonl(INADDR_ANY);\n\tservaddr.sin_port = htons(PORT);\n\n\tif(bind(listenfd,(struct sockaddr*)&servaddr,sizeof(struct sockaddr))<0){\n\t\tprintf(\"bind error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\n\tif(listen(listenfd, 5) < 0) {\n\t\tprintf(\"listen error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1; \n\t}\n\tepfd = epoll_create(MAX_EVENTS); //生成epoll专用的文件描述符\n\tif (epfd == -1) {\n\t\tprintf(\"epoll_create\\n\");\n\t\treturn -1;\n\t}\n\tev.events = EPOLLIN | EPOLLET; //设置处理的事件类型,设置为边沿触发\n\tev.data.fd = listenfd;\n\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, &ev) == -1) {\n\t\tprintf(\"epoll_ctl add listen_sock fail\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\twhile (1) {\n\t\tint timeout = 1000; \n\t\tint nfds = epoll_wait(epfd, events, MAX_EVENTS, timeout);\n\t\tif (nfds == -1) {\n\t\t\tprintf(\"epoll_wait\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tfor (int i = 0;i < nfds; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == listenfd) { //监听事件\n\t\t\t\twhile ((conn_sock = accept(listenfd, NULL, NULL)) > 0) {//循环处理accept,这样可以处理多个连接在就绪队列中的情况\n\t\t\t\t\tprintf(\"accept %d\\n\", conn_sock);\n\t\t\t\t\tsetnonblocking(conn_sock);\n\t\t\t\t\tev.events = EPOLLIN | EPOLLET; //设置为边沿触发\n\t\t\t\t\tev.data.fd = conn_sock;\n\t\t\t\t\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, conn_sock, &ev) == -1) {\n\t\t\t\t\t\tprintf(\"epoll_ctl: add fail\\n\");\n\t\t\t\t\t\tclose(conn_sock);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLIN) {//读事件，说明有数据从客户端发来\n\t\t\t\tint n = 0;\n\t\t\t\tint nread = 0;\n\t\t\t\twhile ((nread = read(fd, buf + n, BUFSIZ - n)) > 0) {\n\t\t\t\t\tn += nread;\n\t\t\t\t}\n\t\t\t\t//printf(\"n %d nread %d\\n\", n, nread);\n\t\t\t\tif (nread == -1 && errno != EAGAIN) {//读数据错误,关闭描述符\n\t\t\t\t\tprintf(\"read error\\n\");\n\t\t\t\t\tclose(fd); //关闭一个描述符，它会从epoll描述符集合中自动删除\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif( n > 0) {\n\t\t\t\t\tprocess_command(fd, buf);\n\t\t\t\t\tmemset(buf, 0, sizeof(buf));\n\t\t\t\t}\n\t\t\t\tif(nread == 0) { //客户端关闭连接，关闭相应的描述符\n\t\t\t\t\tclose(fd);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```","source":"_posts/用epoll提供telnet服务的代码(续).md","raw":"title: 用epoll提供telnet服务的代码(续)\ntags:\n  - epoll\n  - telnet\nid: 578\ncategories:\n  - 编程\ndate: 2013-12-26 19:39:35\n---\n\n最终的代码如下，这里修正了对nc命令无法处理的问题\n\n``` c\n#include <stdio.h>\n#include <unistd.h>\n#include <string.h>\n#include <errno.h>\n#include <sys/socket.h>\n#include <sys/types.h>\n#include <fcntl.h>\n#include <arpa/inet.h>\n#include <sys/epoll.h>\n#include <stdlib.h>\n#include <netinet/tcp.h> \n#include <ctype.h>\n#include <assert.h>\n#define MAX_EVENTS 10\n#define PORT 9999\n//从buf中得到命令\nvoid _get_command(char *buf, char *cmd) {\n\tint i = 0;\n\tint j = 0;\n\twhile (!isalpha(buf[i]))\n\t\ti++;\n\twhile (buf[i] != '\\0' && buf[i] != ' ' && buf[i] != '\\r' && buf[i] != '\\n') {\n\t\tcmd[j++] = buf[i];\n\t\ti++;\n\t}\n\tcmd[j] = '\\0';\n}\n// 返回成功发送的字节数\nint Send(int sock, void *buffer, int size)\n{\n\tint nsend = 0, total = 0;\n\tint err;\n\tif(NULL == buffer || 0 == size) {\n\t\treturn 0;\n\t}\n\twhile(size > 0) {\n\t\tnsend = write(sock, (char*)buffer + total, size);\n\t\tif(nsend == -1) {\n\t\t\terr = errno;\n\t\t\tif(EINTR == err) {\n\t\t\t\tprintf(\"send data to socket[%d], error is %s[%d]\\n\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t} else {\n\t\t\t\tprintf(\"Fail to send data to socket[%d], error is %s[%d]\", \n\t\t\t\t\t\t\tsock, strerror(err), err);\n\t\t\t\treturn -1;\t\n\t\t\t}\n\t\t} else {\n\t\t\ttotal += nsend;\n\t\t\tsize -= nsend;\n\t\t}\n\t}\n\treturn total;\n}\n//处理重置命令\nvoid process_reset(int sock){\n\tchar mess[] = \"reset successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n//处理错误命令\nvoid process_error(int sock) {\n\tchar error[] = \"ERROR\\r\\n\";\n\tSend(sock, error, strlen(error));\n\treturn;\n}\nvoid process_stats(int sock){\n\tchar mess[] = \"stats successful\\r\\n\";\n\tSend(sock, mess, strlen(mess));\n\treturn;\n}\n\n//处理退出命令\nvoid process_quit(int sock) {\n\tclose(sock);\n}\n\nint process_command(int sock, char *buf) {\n\tassert(buf != NULL);\n\n\t/*char cmd[BUFSIZ];\n\t_get_command(buf, cmd);\t\n\tprintf(\"command: %s\\n\", cmd);\n\n\tif (strcmp(\"stats\",cmd) == 0) {\n\t\tprocess_stats(sock);\n\t} else if (strcmp(\"reset\", cmd) == 0) {\n\t\tprocess_reset(sock);\n\t} else if (strcmp(\"quit\", cmd) == 0){\n\t\tprocess_quit(sock);\n\t} else {\n\t\tprocess_error(sock);\n\t}*/\n\tSend(sock, buf, strlen(buf));\n\n\treturn 0;\n}\n\n//设置socket为非阻塞\nvoid setnonblocking(int sockfd) {\n\tint opts;\n\topts = fcntl(sockfd, F_GETFL);\n\tif (opts < 0) {\n\t\tperror(\"fcntl(F_GETFL)\\n\");\n\t\texit(1);\n\t}\n\topts = (opts | O_NONBLOCK);\n\tif (fcntl(sockfd, F_SETFL, opts) < 0) {\n\t\tperror(\"fcntl(F_SETFL)\\n\");\n\t\texit(1);\n\t}\n}\nint main() {\n\tint listenfd, conn_sock, epfd;\n\tchar buf[BUFSIZ];\n\tsocklen_t clilen;\n\tstruct sockaddr_in cliaddr, servaddr;\n\tstruct epoll_event ev, events[MAX_EVENTS];\n\tlistenfd = socket(AF_INET, SOCK_STREAM, 0);\n\tif (listenfd < 0) {\n\t\tprintf(\"create socket error\\n\");\n\t\treturn -1;\n\t}\n\tint on = 1;\n\tsetsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));\n\tsetnonblocking(listenfd);\n\tbzero(&servaddr, sizeof(servaddr));\n\tservaddr.sin_family = AF_INET;\n\tservaddr.sin_addr.s_addr = htonl(INADDR_ANY);\n\tservaddr.sin_port = htons(PORT);\n\n\tif(bind(listenfd,(struct sockaddr*)&servaddr,sizeof(struct sockaddr))<0){\n\t\tprintf(\"bind error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\n\tif(listen(listenfd, 5) < 0) {\n\t\tprintf(\"listen error\\n\");\n\t\tclose(listenfd);\n\t\treturn -1; \n\t}\n\tepfd = epoll_create(MAX_EVENTS); //生成epoll专用的文件描述符\n\tif (epfd == -1) {\n\t\tprintf(\"epoll_create\\n\");\n\t\treturn -1;\n\t}\n\tev.events = EPOLLIN | EPOLLET; //设置处理的事件类型,设置为边沿触发\n\tev.data.fd = listenfd;\n\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, &ev) == -1) {\n\t\tprintf(\"epoll_ctl add listen_sock fail\\n\");\n\t\tclose(listenfd);\n\t\treturn -1;\n\t}\n\twhile (1) {\n\t\tint timeout = 1000; \n\t\tint nfds = epoll_wait(epfd, events, MAX_EVENTS, timeout);\n\t\tif (nfds == -1) {\n\t\t\tprintf(\"epoll_wait\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tfor (int i = 0;i < nfds; ++i) {\n\t\t\tint fd = events[i].data.fd;\n\t\t\tif (fd == listenfd) { //监听事件\n\t\t\t\twhile ((conn_sock = accept(listenfd, NULL, NULL)) > 0) {//循环处理accept,这样可以处理多个连接在就绪队列中的情况\n\t\t\t\t\tprintf(\"accept %d\\n\", conn_sock);\n\t\t\t\t\tsetnonblocking(conn_sock);\n\t\t\t\t\tev.events = EPOLLIN | EPOLLET; //设置为边沿触发\n\t\t\t\t\tev.data.fd = conn_sock;\n\t\t\t\t\tif (epoll_ctl(epfd, EPOLL_CTL_ADD, conn_sock, &ev) == -1) {\n\t\t\t\t\t\tprintf(\"epoll_ctl: add fail\\n\");\n\t\t\t\t\t\tclose(conn_sock);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (events[i].events & EPOLLIN) {//读事件，说明有数据从客户端发来\n\t\t\t\tint n = 0;\n\t\t\t\tint nread = 0;\n\t\t\t\twhile ((nread = read(fd, buf + n, BUFSIZ - n)) > 0) {\n\t\t\t\t\tn += nread;\n\t\t\t\t}\n\t\t\t\t//printf(\"n %d nread %d\\n\", n, nread);\n\t\t\t\tif (nread == -1 && errno != EAGAIN) {//读数据错误,关闭描述符\n\t\t\t\t\tprintf(\"read error\\n\");\n\t\t\t\t\tclose(fd); //关闭一个描述符，它会从epoll描述符集合中自动删除\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif( n > 0) {\n\t\t\t\t\tprocess_command(fd, buf);\n\t\t\t\t\tmemset(buf, 0, sizeof(buf));\n\t\t\t\t}\n\t\t\t\tif(nread == 0) { //客户端关闭连接，关闭相应的描述符\n\t\t\t\t\tclose(fd);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```","slug":"用epoll提供telnet服务的代码(续)","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ca003126s6xvzwhfa4"},{"title":"用Sphinx提供的klist处理文章更新和删除","id":"691","date":"2014-04-14T05:18:16.000Z","_content":"\n在前面的介绍中，都没有处理更新和删除问题，这里有必要说说。在[关于sphinx引擎的一些想法](http://program.dengshilong.org/2014/04/11/关于sphinx引擎的一些想法/)中说过公司所用的引擎中，处理更新和删除的办法是在索引中增加一个属性来标志这条记录是否失效，每次做增量时，就要去主索引和增量索引中更改相应id的属性值，这确实可以解决问题。不过并不是一个很好的解决办法，Sphinx的作者也说过这种方法既麻烦又容易出错。既然有更新和删除这个需求，必然会提供解决的办法，这个办法就是kilst。所谓的klist，就是kill list,按照字面理解，就是删除列表。我们只需要在增量索引中保存一个id列表，搜索时，如果在主索引中搜到相关文档，而文档的id存在于增量索引的id列表中，则这个文档将被丢弃。\n\n这里有一个需要注意的是，当文章被删除时，仅仅通过增量抓取，在增量索引中并不能知道主索引中哪一个文档被删除了，所以这就必须在表中文档被删除时，能够记录下被删除的id，这就需要用到触发器，也需要建立一个辅助表来保存这些id。辅助表的建立如下：\n```\ncreate table sphinxklist(\n        id integer not null,\n        ts timestamp not null\n);\n```\n触发器的建立如下：\n```\nDELIMITER //\nCREATE TRIGGER sphinx_kill\nAFTER DELETE ON wp_posts\nFOR EACH ROW\nBEGIN\n        INSERT INTO sphinxklist VALUES (OLD.ID, NOW());\nEND\n//\n```\n有了这些准备工作后，我们就可以使用klist了，事实上在之前的配置文件的基础上，只需要修改一点点内容就好了。首先修改主索引\n```\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = UPDATE sphinx_helper SET main_tmp_maxts=NOW() WHERE appid='blog_search';\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < (SELECT main_tmp_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_query_post_index = UPDATE sphinx_helper SET main_maxts=main_tmp_maxts WHERE appid='blog_search';\n        sql_query_post_index = DELETE FROM sphinxklist WHERE ts < (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n}\n```\n可以看到，相对于之前的配置，这里只添加了一行\n```\nsql_query_post_index = DELETE FROM sphinxklist WHERE ts < (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search');\n```\n添加这行是为了防止之前运行引擎时留下的id再次被使用。\n之后修改临时索引：\n```\nsource srcdelta_temp : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_killlist = SELECT ID FROM wp_posts WHERE post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE \\\n                appid='blog_search') AND post_modified < @maxtsdelta UNION SELECT id FROM sphinxklist;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\n```\n也只是添加了一行，也就是将这次抓取的id与sphinxlist中的id合并。\n之后还需要修改Shell脚本\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/blog_search.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        #./indexer -c $conf --merge-klists --rotate --merge delta deltaTemp\n        ./indexer -c $conf  --merge-klists --rotate --merge delta delta_temp\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta_temp\n        fi\n        sleep 60\ndone\n```\n这个脚本相对于原来的只增加了--merge-klists这个参数，这个参数的意义是，将delta_temp合并到delta时，并不会删除delta的klist,而是将delta_temp的klist和delta的klist合并，这正是我们想要的。经过这样的变化，一个可以处理更新和删除的main+delta索引就建好了。\n\n感谢Sphinx团队，感谢Sphinx-for-chinese团队，给我们提供了一个这么好用的开源引擎。\n","source":"_posts/用Sphinx提供的klist处理文章更新和删除.md","raw":"title: 用Sphinx提供的klist处理文章更新和删除\ntags:\n  - Klist\n  - Klists\n  - Sphinx\n  - Sphinx-for-chinese\n  - 删除\n  - 更新\nid: 691\ncategories:\n  - 搜索引擎\ndate: 2014-04-14 13:18:16\n---\n\n在前面的介绍中，都没有处理更新和删除问题，这里有必要说说。在[关于sphinx引擎的一些想法](http://program.dengshilong.org/2014/04/11/关于sphinx引擎的一些想法/)中说过公司所用的引擎中，处理更新和删除的办法是在索引中增加一个属性来标志这条记录是否失效，每次做增量时，就要去主索引和增量索引中更改相应id的属性值，这确实可以解决问题。不过并不是一个很好的解决办法，Sphinx的作者也说过这种方法既麻烦又容易出错。既然有更新和删除这个需求，必然会提供解决的办法，这个办法就是kilst。所谓的klist，就是kill list,按照字面理解，就是删除列表。我们只需要在增量索引中保存一个id列表，搜索时，如果在主索引中搜到相关文档，而文档的id存在于增量索引的id列表中，则这个文档将被丢弃。\n\n这里有一个需要注意的是，当文章被删除时，仅仅通过增量抓取，在增量索引中并不能知道主索引中哪一个文档被删除了，所以这就必须在表中文档被删除时，能够记录下被删除的id，这就需要用到触发器，也需要建立一个辅助表来保存这些id。辅助表的建立如下：\n```\ncreate table sphinxklist(\n        id integer not null,\n        ts timestamp not null\n);\n```\n触发器的建立如下：\n```\nDELIMITER //\nCREATE TRIGGER sphinx_kill\nAFTER DELETE ON wp_posts\nFOR EACH ROW\nBEGIN\n        INSERT INTO sphinxklist VALUES (OLD.ID, NOW());\nEND\n//\n```\n有了这些准备工作后，我们就可以使用klist了，事实上在之前的配置文件的基础上，只需要修改一点点内容就好了。首先修改主索引\n```\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = UPDATE sphinx_helper SET main_tmp_maxts=NOW() WHERE appid='blog_search';\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < (SELECT main_tmp_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_query_post_index = UPDATE sphinx_helper SET main_maxts=main_tmp_maxts WHERE appid='blog_search';\n        sql_query_post_index = DELETE FROM sphinxklist WHERE ts < (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n}\n```\n可以看到，相对于之前的配置，这里只添加了一行\n```\nsql_query_post_index = DELETE FROM sphinxklist WHERE ts < (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search');\n```\n添加这行是为了防止之前运行引擎时留下的id再次被使用。\n之后修改临时索引：\n```\nsource srcdelta_temp : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_killlist = SELECT ID FROM wp_posts WHERE post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE \\\n                appid='blog_search') AND post_modified < @maxtsdelta UNION SELECT id FROM sphinxklist;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\n```\n也只是添加了一行，也就是将这次抓取的id与sphinxlist中的id合并。\n之后还需要修改Shell脚本\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/blog_search.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        #./indexer -c $conf --merge-klists --rotate --merge delta deltaTemp\n        ./indexer -c $conf  --merge-klists --rotate --merge delta delta_temp\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta_temp\n        fi\n        sleep 60\ndone\n```\n这个脚本相对于原来的只增加了--merge-klists这个参数，这个参数的意义是，将delta_temp合并到delta时，并不会删除delta的klist,而是将delta_temp的klist和delta的klist合并，这正是我们想要的。经过这样的变化，一个可以处理更新和删除的main+delta索引就建好了。\n\n感谢Sphinx团队，感谢Sphinx-for-chinese团队，给我们提供了一个这么好用的开源引擎。\n","slug":"用Sphinx提供的klist处理文章更新和删除","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cc003526s6ngipvocs"},{"title":"用Sphinx建立只有主索引的引擎","id":"670","date":"2014-04-14T05:12:11.000Z","_content":"\n因为一直都对Wordpress自带的搜索功能略有微词，可是又不想去改它，想想自己的博客一天都没有一个人会访问，更不用说这个搜索功能了。因为现在学习使用Sphinx-for-chinese，拿博客的数据来练练手。\n\n先从最简单的情况开始，以后再一步一步的完善功能，这样才符合学习的线路，从易到难，而不是一开始就给你一个很完善的模型，然后改改路径就好了。最简单的情况就是只有一个主索引，然后隔一段时间重建索引。得益于Sphinx的高效，建索引的速度非常快，在文档中说达到了10M/s, 按照一篇文章为4KB计算，一秒钟可以给250篇文章建索引了，对于博客来说，已经足够了。对于其它的应用，当数据不多时，只有一个主索引也是可以的。\n\n这里只使用了wp_posts表中的数据，只是用了ID, post_title, post_content, post_modified四个字段，所以非常的简单，直接上配置文件\n```\nsource base{\n        type = mysql\n        sql_host = localhost\n        sql_user = root\n        sql_pass = 123456\n        sql_db = blog\n        sql_port = 3306\n}\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < NOW();\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n\n}\nindex main {\n        source = srcmain\n        path = /home/long/sphinxforchinese/blog_search/var/data/main\n        docinfo = extern\n        charset_type = utf-8\n        chinese_dictionary = /home/long/sphinxforchinese/blog_search/etc/xdict\n}\nindexer {\n        mem_limit = 32M\n}\n\nsearchd {\n        listen = 9300\n        log = /home/long/sphinxforchinese/blog_search/var/log/searchd.log\n        query_log = /home/long/sphinxforchinese/var/log/query.log\n        read_timeout = 5\n        max_children = 30\n        pid_file = /home/long/sphinxforchinese/var/log/searchd.pid\n        max_matches = 1000\n        seamless_rotate = 1\n        preopen_indexes = 1\n        unlink_old = 1\n        workers = threads\n        binlog_path = /home/long/sphinxforchinese/var/data\n}\n```\n相关配置选项的意义可以查看示例，写的非常的详细。这里没有对post_content进行定义，因为只想对这个字段建索引，并不想保存它的原始内容，所以这里使用了默认行为，也就是只建索引。\n建好索引，搜索跑步的相关文章，得到如下结果\n1. document=41, weight=2661, post_title=跑步一周年, post_modified=Sun Apr 7 10:11:56 2013\n2. document=286, weight=2660, post_title=跑步两周年, post_modified=Fri Jan 4 12:49:47 2013\n3. document=537, weight=1642, post_title=写在广州马拉松之前, post_modified=Sat Nov 9 00:00:45 2013\n4. document=39, weight=1632, post_title=看棒球英豪漫画, post_modified=Sun Apr 7 09:57:34 2013\n5. document=2, weight=1626, post_title=关于我, post_modified=Fri Jun 14 19:49:08 2013\n6. document=565, weight=1626, post_title=2013广州马拉松纪实, post_modified=Sun Nov 24 22:10:57 2013\n7. document=43, weight=1617, post_title=三个月来的小结, post_modified=Sun Apr 7 10:10:22 2013\n8. document=56, weight=1617, post_title=价值博客们, post_modified=Sun Apr 7 09:52:51 2013\n9. document=205, weight=1617, post_title=2012扬州马拉松纪实, post_modified=Tue Apr 2 11:29:04 2013\n10. document=5, weight=1602, post_title=2011年的阅读, post_modified=Tue May 29 11:19:49 2012\n11. document=305, weight=1602, post_title=羽毛球心结, post_modified=Mon Apr 8 08:33:37 2013\n12. document=40, weight=1574, post_title=通关manufactoria, post_modified=Sun Apr 7 10:01:06 2013\n13. document=233, weight=1574, post_title=当了一回胃扩张, post_modified=Fri Jul 20 15:46:35 2012\n搜索结果还行吧。\n","source":"_posts/用Sphinx建立只有主索引的引擎.md","raw":"title: 用Sphinx建立只有主索引的引擎\ntags:\n  - Sphinx\n  - Sphinx-for-chinese\n  - 主索引\n  - 速度\nid: 670\ncategories:\n  - 搜索引擎\ndate: 2014-04-14 13:12:11\n---\n\n因为一直都对Wordpress自带的搜索功能略有微词，可是又不想去改它，想想自己的博客一天都没有一个人会访问，更不用说这个搜索功能了。因为现在学习使用Sphinx-for-chinese，拿博客的数据来练练手。\n\n先从最简单的情况开始，以后再一步一步的完善功能，这样才符合学习的线路，从易到难，而不是一开始就给你一个很完善的模型，然后改改路径就好了。最简单的情况就是只有一个主索引，然后隔一段时间重建索引。得益于Sphinx的高效，建索引的速度非常快，在文档中说达到了10M/s, 按照一篇文章为4KB计算，一秒钟可以给250篇文章建索引了，对于博客来说，已经足够了。对于其它的应用，当数据不多时，只有一个主索引也是可以的。\n\n这里只使用了wp_posts表中的数据，只是用了ID, post_title, post_content, post_modified四个字段，所以非常的简单，直接上配置文件\n```\nsource base{\n        type = mysql\n        sql_host = localhost\n        sql_user = root\n        sql_pass = 123456\n        sql_db = blog\n        sql_port = 3306\n}\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < NOW();\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n\n}\nindex main {\n        source = srcmain\n        path = /home/long/sphinxforchinese/blog_search/var/data/main\n        docinfo = extern\n        charset_type = utf-8\n        chinese_dictionary = /home/long/sphinxforchinese/blog_search/etc/xdict\n}\nindexer {\n        mem_limit = 32M\n}\n\nsearchd {\n        listen = 9300\n        log = /home/long/sphinxforchinese/blog_search/var/log/searchd.log\n        query_log = /home/long/sphinxforchinese/var/log/query.log\n        read_timeout = 5\n        max_children = 30\n        pid_file = /home/long/sphinxforchinese/var/log/searchd.pid\n        max_matches = 1000\n        seamless_rotate = 1\n        preopen_indexes = 1\n        unlink_old = 1\n        workers = threads\n        binlog_path = /home/long/sphinxforchinese/var/data\n}\n```\n相关配置选项的意义可以查看示例，写的非常的详细。这里没有对post_content进行定义，因为只想对这个字段建索引，并不想保存它的原始内容，所以这里使用了默认行为，也就是只建索引。\n建好索引，搜索跑步的相关文章，得到如下结果\n1. document=41, weight=2661, post_title=跑步一周年, post_modified=Sun Apr 7 10:11:56 2013\n2. document=286, weight=2660, post_title=跑步两周年, post_modified=Fri Jan 4 12:49:47 2013\n3. document=537, weight=1642, post_title=写在广州马拉松之前, post_modified=Sat Nov 9 00:00:45 2013\n4. document=39, weight=1632, post_title=看棒球英豪漫画, post_modified=Sun Apr 7 09:57:34 2013\n5. document=2, weight=1626, post_title=关于我, post_modified=Fri Jun 14 19:49:08 2013\n6. document=565, weight=1626, post_title=2013广州马拉松纪实, post_modified=Sun Nov 24 22:10:57 2013\n7. document=43, weight=1617, post_title=三个月来的小结, post_modified=Sun Apr 7 10:10:22 2013\n8. document=56, weight=1617, post_title=价值博客们, post_modified=Sun Apr 7 09:52:51 2013\n9. document=205, weight=1617, post_title=2012扬州马拉松纪实, post_modified=Tue Apr 2 11:29:04 2013\n10. document=5, weight=1602, post_title=2011年的阅读, post_modified=Tue May 29 11:19:49 2012\n11. document=305, weight=1602, post_title=羽毛球心结, post_modified=Mon Apr 8 08:33:37 2013\n12. document=40, weight=1574, post_title=通关manufactoria, post_modified=Sun Apr 7 10:01:06 2013\n13. document=233, weight=1574, post_title=当了一回胃扩张, post_modified=Fri Jul 20 15:46:35 2012\n搜索结果还行吧。\n","slug":"用Sphinx建立只有主索引的引擎","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cf003h26s6wkk3j1wv"},{"title":"用Sphinx建立main+delta索引(下篇)","id":"688","date":"2014-04-14T05:16:11.000Z","_content":"\n在[上篇](http://program.dengshilong.org/2014/04/14/用sphinx建立maindelta索引上篇/)中，我们介绍了一种建立主索引和增量索引的方法，这种方法有一种不足之处就是会改变主索引，因为每次增量索引都会与主索引合并成新的主索引。为此，我们可以想出另一种解决的办法，每次只改变增量索引，这就需要另外再建立一个临时索引。\n\n\n这里只需要改变少量地方，一个是增量索引，另外还需新增一个临时索引，具体配置如下：\n```\nsource srcdelta : srcmain{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' limit 0;\n        sql_query_post_index =\n}\nsource srcdelta_temp : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\nindex delta_temp : main{\n        source = srcdelta_temp\n        path = /home/long/sphinxforchinese/blog_search/var/data/delta_temp\n}\n```\n实际上，我们是先建立一个空的增量索引，之后临时索引中的数据慢慢合并到增量索引中。在这里，增量索引很像上篇中的主索引，而临时索引则像上篇中的增量索引。\n此时我们需要修改dist_blog_search,即增加临时索引\n```\nindex dist_blog_search {\n    type = distributed\n    local = main\n    local = delta\n    local = delta_temp\n    agent_connect_timeout = 1000\n    agent_query_timeout = 3000\n\n}\n```\n此后还需改变Shell脚本的内容\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/main_delta_temp.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        ./indexer -c $conf  --rotate --merge delta delta_temp\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta_temp\n        fi\n        sleep 60\ndone\n```\n事实上，改变的内容还是很少的。经过这样的改变，我们就无需再改变主索引了。第一次建立主索引后，就一直保持不变，变化的是增量索引。\n\n","source":"_posts/用Sphinx建立main+delta索引(下篇).md","raw":"title: 用Sphinx建立main+delta索引(下篇)\ntags:\n  - Sphinx-for-chinese\n  - 临时索引\n  - 增量索引\nid: 688\ncategories:\n  - 搜索引擎\ndate: 2014-04-14 13:16:11\n---\n\n在[上篇](http://program.dengshilong.org/2014/04/14/用sphinx建立maindelta索引上篇/)中，我们介绍了一种建立主索引和增量索引的方法，这种方法有一种不足之处就是会改变主索引，因为每次增量索引都会与主索引合并成新的主索引。为此，我们可以想出另一种解决的办法，每次只改变增量索引，这就需要另外再建立一个临时索引。\n\n\n这里只需要改变少量地方，一个是增量索引，另外还需新增一个临时索引，具体配置如下：\n```\nsource srcdelta : srcmain{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' limit 0;\n        sql_query_post_index =\n}\nsource srcdelta_temp : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\nindex delta_temp : main{\n        source = srcdelta_temp\n        path = /home/long/sphinxforchinese/blog_search/var/data/delta_temp\n}\n```\n实际上，我们是先建立一个空的增量索引，之后临时索引中的数据慢慢合并到增量索引中。在这里，增量索引很像上篇中的主索引，而临时索引则像上篇中的增量索引。\n此时我们需要修改dist_blog_search,即增加临时索引\n```\nindex dist_blog_search {\n    type = distributed\n    local = main\n    local = delta\n    local = delta_temp\n    agent_connect_timeout = 1000\n    agent_query_timeout = 3000\n\n}\n```\n此后还需改变Shell脚本的内容\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/main_delta_temp.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        ./indexer -c $conf  --rotate --merge delta delta_temp\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta_temp\n        fi\n        sleep 60\ndone\n```\n事实上，改变的内容还是很少的。经过这样的改变，我们就无需再改变主索引了。第一次建立主索引后，就一直保持不变，变化的是增量索引。\n\n","slug":"用Sphinx建立main+delta索引(下篇)","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ck003p26s6x8rlb10r"},{"title":"用Sphinx建立main+delta索引(上篇)","id":"686","date":"2014-04-14T05:14:18.000Z","_content":"\n虽然只建立主索引就可以满足许多应用，但当数据非常多时，每次都重建索引是一件非常耗时的事情，而且每次重建都会浪费CPU，这也是极为不好的。考虑这样一种情况，在数据库中一共有1千万个文档，而每天只新增一万个文档，如果每次都要重建索引，则第一次重建时，是1001万个文档，第二次时是1002万个文档，这都非常耗时的。如果建好主索引后，只对这些新增的一万个数据建一个增量索引，之后把它合并到主索引中，所需的时间将缩短。所以建立main+delta索引是一个不错的选择。\n\n这里依然以之前的博客搜索为例。为了便于做增量，我们需要记录每次抓取的时间，而为了持久保存这个时间，我们需要在数据中建立一个辅助表，建表语句如下\n```\ncreate table sphinx_helper(\n        appid varchar(300) not null primary key,\n        main_maxts datetime,\n        main_tmp_maxts datetime,\n        delta_maxts datetime,\n        delta_tmp_maxts datetime\n);\ninsert into sphinx_helper (appid) values ('blog_search');\n```\n在wp_posts表中, post_modified这个时间字段是随着每次文章的更新而自动变化的，所以可以使用它来做增量。主要思路就是用一个值来保存上次增量索引的时间，当需要再做增量索引时，则只需索引从这个保存的时间到现在这段时间里的数据。在sphinx_helper中，这个值用main_maxts来标示。对于主索引，写成配置文件如下，\n```\nsource base{\n        type = mysql\n        sql_host = localhost\n        sql_user = root\n        sql_pass = 123456\n        sql_db = blog\n        sql_port = 3306\n}\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = UPDATE sphinx_helper SET main_tmp_maxts=NOW() WHERE appid='blog_search';\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < (SELECT main_tmp_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_query_post_index = UPDATE sphinx_helper SET main_maxts=main_tmp_maxts WHERE appid='blog_search';\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n\n}\n```\n以上就是主索引的配置，之所以需要将NOW()得到的时间保存到数据库中，之后在sql_query_post_index中取出来用，是因为sql_query_post_index和sql_query不是用一个数据连接。而之所以在sql_query_post_index里才更新main_maxts，是为了保证只有在索引成功建立后才更新这个值。而对于增量索引的配置，则如下：\n```\nsource srcdelta : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\n```\n在sql_query中可以看到，每次增量索引的数据都是在[max_maxts, NOW()]之间，而只在sql_query_post_index中更新delta_maxts也是基于上述理由。剩下的配置如下：\n```\nindex main {\n        source = srcmain\n        path = /home/long/sphinxforchinese/blog_search/var/data/main\n        docinfo = extern\n        charset_type = utf-8\n        chinese_dictionary = /home/long/sphinxforchinese/blog_search/etc/xdict\n}\nindex delta : main {\n        source = srcdelta\n        path = /home/long/sphinxforchinese/blog_search/var/data/delta\n}\n\nindex dist_blog_search {\n        type = distributed\n        local = main\n        local = delta\n        agent_connect_timeout = 1000\n        agent_query_timeout = 3000\n}\n```\n这里我们多了一个dist_blog_search，它是结合main和delta的搜索结果，在客户端中搜索时，我们使用dist_blog_search这个索引的结果。剩下的配置与只有主索引时相同，这里就不累述了。\n\n写好配置文件后，还需要有一个步骤。因为我们的策略是每隔一段时间将增量索引与主索引合并，当合并之后，我们需要更新main_maxts这个值。如果我们是每个60秒做一次增量索引，这需要写一个shell脚本，脚本如下：\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/main_delta.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        ./indexer -c $conf --rotate --merge main delta\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta\n        fi\n        sleep 60\ndone\n```\n先执行\n```\n ./indexer -c $conf --rotate --merge main delta\n```\n这句是将主索引和增量索引合并，当合并成功时，则需要到数据库中修改main_maxts这个值，这个句子在post_merge.sql中，post_merge.sql的内容如下：\n```\nUPDATE sphinx_helper SET main_maxts=delta_maxts\\\n        WHERE appid='blog_search';\n```\n之后进行增量抓取\n```\n./indexer -c $conf --rotate delta\n```\n这里说说--rotate这个选项，这个选项非常有用。在主索引和增量索引合并时，indexer程序会将这两个索引合并成一个索引，当合并成功后，程序会发送一个SIGHUP信号给searchd，之后searchd就好去加载这个新的索引。\n\n到这里，一个main+delta的索引就完成了。\n","source":"_posts/用Sphinx建立main+delta索引(上篇).md","raw":"title: 用Sphinx建立main+delta索引(上篇)\ntags:\n  - delta\n  - main\n  - Sphinx\n  - Sphinx-for-chinese\n  - 增量索引\nid: 686\ncategories:\n  - 搜索引擎\ndate: 2014-04-14 13:14:18\n---\n\n虽然只建立主索引就可以满足许多应用，但当数据非常多时，每次都重建索引是一件非常耗时的事情，而且每次重建都会浪费CPU，这也是极为不好的。考虑这样一种情况，在数据库中一共有1千万个文档，而每天只新增一万个文档，如果每次都要重建索引，则第一次重建时，是1001万个文档，第二次时是1002万个文档，这都非常耗时的。如果建好主索引后，只对这些新增的一万个数据建一个增量索引，之后把它合并到主索引中，所需的时间将缩短。所以建立main+delta索引是一个不错的选择。\n\n这里依然以之前的博客搜索为例。为了便于做增量，我们需要记录每次抓取的时间，而为了持久保存这个时间，我们需要在数据中建立一个辅助表，建表语句如下\n```\ncreate table sphinx_helper(\n        appid varchar(300) not null primary key,\n        main_maxts datetime,\n        main_tmp_maxts datetime,\n        delta_maxts datetime,\n        delta_tmp_maxts datetime\n);\ninsert into sphinx_helper (appid) values ('blog_search');\n```\n在wp_posts表中, post_modified这个时间字段是随着每次文章的更新而自动变化的，所以可以使用它来做增量。主要思路就是用一个值来保存上次增量索引的时间，当需要再做增量索引时，则只需索引从这个保存的时间到现在这段时间里的数据。在sphinx_helper中，这个值用main_maxts来标示。对于主索引，写成配置文件如下，\n```\nsource base{\n        type = mysql\n        sql_host = localhost\n        sql_user = root\n        sql_pass = 123456\n        sql_db = blog\n        sql_port = 3306\n}\nsource srcmain : base{\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = UPDATE sphinx_helper SET main_tmp_maxts=NOW() WHERE appid='blog_search';\n        sql_query = \\\n                SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                        post_status='publish' AND post_modified < (SELECT main_tmp_maxts FROM sphinx_helper WHERE appid='blog_search');\n        sql_query_post_index = UPDATE sphinx_helper SET main_maxts=main_tmp_maxts WHERE appid='blog_search';\n        sql_attr_timestamp = post_modified\n        sql_field_string = post_title\n\n}\n```\n以上就是主索引的配置，之所以需要将NOW()得到的时间保存到数据库中，之后在sql_query_post_index中取出来用，是因为sql_query_post_index和sql_query不是用一个数据连接。而之所以在sql_query_post_index里才更新main_maxts，是为了保证只有在索引成功建立后才更新这个值。而对于增量索引的配置，则如下：\n```\nsource srcdelta : srcmain {\n        sql_query_pre = SET NAMES utf8\n        sql_query_pre = SET SESSION query_cache_type=OFF\n        sql_query_pre = SET @maxtsdelta:=NOW();\n        sql_query_pre = UPDATE sphinx_helper SET delta_tmp_maxts=@maxtsdelta WHERE appid='blog_search';\n        sql_query = SELECT ID, post_title, post_content, UNIX_TIMESTAMP(post_modified) AS post_modified FROM wp_posts WHERE \\\n                post_status='publish' AND post_modified >= (SELECT main_maxts FROM sphinx_helper WHERE appid='blog_search')\\\n                AND post_modified < @maxtsdelta;\n        sql_query_post_index = UPDATE sphinx_helper SET delta_maxts=delta_tmp_maxts WHERE appid='blog_search';\n}\n```\n在sql_query中可以看到，每次增量索引的数据都是在[max_maxts, NOW()]之间，而只在sql_query_post_index中更新delta_maxts也是基于上述理由。剩下的配置如下：\n```\nindex main {\n        source = srcmain\n        path = /home/long/sphinxforchinese/blog_search/var/data/main\n        docinfo = extern\n        charset_type = utf-8\n        chinese_dictionary = /home/long/sphinxforchinese/blog_search/etc/xdict\n}\nindex delta : main {\n        source = srcdelta\n        path = /home/long/sphinxforchinese/blog_search/var/data/delta\n}\n\nindex dist_blog_search {\n        type = distributed\n        local = main\n        local = delta\n        agent_connect_timeout = 1000\n        agent_query_timeout = 3000\n}\n```\n这里我们多了一个dist_blog_search，它是结合main和delta的搜索结果，在客户端中搜索时，我们使用dist_blog_search这个索引的结果。剩下的配置与只有主索引时相同，这里就不累述了。\n\n写好配置文件后，还需要有一个步骤。因为我们的策略是每隔一段时间将增量索引与主索引合并，当合并之后，我们需要更新main_maxts这个值。如果我们是每个60秒做一次增量索引，这需要写一个shell脚本，脚本如下：\n```\n#!/bin/bash\nbaseDir=/home/long/sphinxforchinese/blog_search\nconf=$baseDir/etc/main_delta.conf\nbinDir=$baseDir/bin\ncd $binDir\nwhile [ true ]\ndo\n        ./indexer -c $conf --rotate --merge main delta\n        if [ \"$?\" -eq \"0\" ]; then\n                cat $baseDir/script/post_merge.sql | mysql -u root --password=123456 blog\n                ./indexer -c $conf --rotate delta\n        fi\n        sleep 60\ndone\n```\n先执行\n```\n ./indexer -c $conf --rotate --merge main delta\n```\n这句是将主索引和增量索引合并，当合并成功时，则需要到数据库中修改main_maxts这个值，这个句子在post_merge.sql中，post_merge.sql的内容如下：\n```\nUPDATE sphinx_helper SET main_maxts=delta_maxts\\\n        WHERE appid='blog_search';\n```\n之后进行增量抓取\n```\n./indexer -c $conf --rotate delta\n```\n这里说说--rotate这个选项，这个选项非常有用。在主索引和增量索引合并时，indexer程序会将这两个索引合并成一个索引，当合并成功后，程序会发送一个SIGHUP信号给searchd，之后searchd就好去加载这个新的索引。\n\n到这里，一个main+delta的索引就完成了。\n","slug":"用Sphinx建立main+delta索引(上篇)","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cm003w26s6aehx1wfu"},{"title":"求一个数的质因子分解","id":"806","date":"2014-07-14T12:57:15.000Z","_content":"\n两年前面试4399时，和面试官说起用Python来做欧拉工程，于是面试官很感兴趣地说，有没有写一些小模块来求解，当时只是摇头，想想写写算法题还可以，写模块就太大了。现在想来，模块也无非是一些函数的集合，在接欧拉工程的过程中，就会经常遇到一些问题，需要用类似的方法解决，如果把这些共同的部分写在一起，不也是一个模块了？\n\n质因子分解是经常需要用到的，这里给一个解决的办法。例如要求120的质因子分解，先用2去除，一直到不能整除为止，记得到2^3,以及剩下的15，之后用3去除，得到3以及剩下的5，之后用5去除，得到5以及0，分解过程结束。写成程序如下：\n``` python\nfrom collections import defaultdict\ndef get_divisors(n):\n    divisors = defaultdict(int)\n    if n % 2 == 0:\n        while n % 2 == 0:\n            divisors[2] += 1\n            n /= 2\n    i = 3\n    while i * i <= n:\n        if n % i == 0:\n            while n % i == 0:\n                divisors[i] += 1\n                n /= i\n        i += 2\n    if n > 1:\n        divisors[n] += 1\n    return divisors\n```\n有了这个方法就可以用来求一些数的最小公倍数，例如求，2 3  5 8 的最小公倍数\n``` python\nL = [2, 3, 5, 8]\nfactors = defaultdict(int)\nfor i in L:\n    divisors = get_divisors(i)\n    for d in divisors.iterkeys():\n        factors[d] = max(factors[d], divisors[d])\nres = 1\nfor d in factors.iterkeys():\n    res *= d ** factors[d]\nprint res\n```","source":"_posts/求一个数的质因子分解.md","raw":"title: 求一个数的质因子分解\ntags:\n  - 最小公倍数\n  - 质因子\nid: 806\ncategories:\n  - 算法\ndate: 2014-07-14 20:57:15\n---\n\n两年前面试4399时，和面试官说起用Python来做欧拉工程，于是面试官很感兴趣地说，有没有写一些小模块来求解，当时只是摇头，想想写写算法题还可以，写模块就太大了。现在想来，模块也无非是一些函数的集合，在接欧拉工程的过程中，就会经常遇到一些问题，需要用类似的方法解决，如果把这些共同的部分写在一起，不也是一个模块了？\n\n质因子分解是经常需要用到的，这里给一个解决的办法。例如要求120的质因子分解，先用2去除，一直到不能整除为止，记得到2^3,以及剩下的15，之后用3去除，得到3以及剩下的5，之后用5去除，得到5以及0，分解过程结束。写成程序如下：\n``` python\nfrom collections import defaultdict\ndef get_divisors(n):\n    divisors = defaultdict(int)\n    if n % 2 == 0:\n        while n % 2 == 0:\n            divisors[2] += 1\n            n /= 2\n    i = 3\n    while i * i <= n:\n        if n % i == 0:\n            while n % i == 0:\n                divisors[i] += 1\n                n /= i\n        i += 2\n    if n > 1:\n        divisors[n] += 1\n    return divisors\n```\n有了这个方法就可以用来求一些数的最小公倍数，例如求，2 3  5 8 的最小公倍数\n``` python\nL = [2, 3, 5, 8]\nfactors = defaultdict(int)\nfor i in L:\n    divisors = get_divisors(i)\n    for d in divisors.iterkeys():\n        factors[d] = max(factors[d], divisors[d])\nres = 1\nfor d in factors.iterkeys():\n    res *= d ** factors[d]\nprint res\n```","slug":"求一个数的质因子分解","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cp004526s69xqem9ik"},{"title":"欧拉工程-问题9","id":"203","date":"2013-05-05T07:04:31.000Z","_content":"\n\n\n原题链接 [http://projecteuler.net/problem=9](http://projecteuler.net/problem=9)\n\nSpecial Pythagorean triplet\n\n\n\n\nA Pythagorean triplet is a set of three natural numbers, <var>a</var> < <var>b</var> < <var>c</var>, for which,\n<var>a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\nFor example, 3<sup>2</sup> + 4<sup>2</sup> = 9 + 16 = 25 = 5<sup>2</sup>.\n\nThere exists exactly one Pythagorean triplet for which <var>a</var> + <var>b</var> + <var>c</var> = 1000.\nFind the product <var>abc</var>.\n\n特殊的毕达哥拉斯三元组\n\n一个毕达哥拉斯三元组指的是三个自然数， <var>a</var> < <var>b</var> < <var>c</var> ,且\n\n<var>                         a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\n\n<sup>例如，</sup>3<sup>2</sup> + 4<sup>2</sup> = 9 + 16 = 25 = 5<sup>2</sup>.\n\n有且只有一组毕达哥拉斯三元组满足 <var>a</var> + <var>b</var> + <var>c</var> = 1000.\n\n求abc的乘积\n\n解答：\n\n将 c =  1000 - a - b代入<var>a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\n\n得到1000 * (a + b) = 500000 + a * b\n\n暴力找到满足这个条件的a和b.\n\n","source":"_posts/欧拉工程-问题9.md","raw":"title: 欧拉工程-问题9\ntags:\n  - 欧拉工程\n  - 毕达哥拉斯数\nid: 203\ncategories:\n  - 欧拉工程\ndate: 2013-05-05 15:04:31\n---\n\n\n\n原题链接 [http://projecteuler.net/problem=9](http://projecteuler.net/problem=9)\n\nSpecial Pythagorean triplet\n\n\n\n\nA Pythagorean triplet is a set of three natural numbers, <var>a</var> < <var>b</var> < <var>c</var>, for which,\n<var>a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\nFor example, 3<sup>2</sup> + 4<sup>2</sup> = 9 + 16 = 25 = 5<sup>2</sup>.\n\nThere exists exactly one Pythagorean triplet for which <var>a</var> + <var>b</var> + <var>c</var> = 1000.\nFind the product <var>abc</var>.\n\n特殊的毕达哥拉斯三元组\n\n一个毕达哥拉斯三元组指的是三个自然数， <var>a</var> < <var>b</var> < <var>c</var> ,且\n\n<var>                         a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\n\n<sup>例如，</sup>3<sup>2</sup> + 4<sup>2</sup> = 9 + 16 = 25 = 5<sup>2</sup>.\n\n有且只有一组毕达哥拉斯三元组满足 <var>a</var> + <var>b</var> + <var>c</var> = 1000.\n\n求abc的乘积\n\n解答：\n\n将 c =  1000 - a - b代入<var>a</var><sup>2</sup> + <var>b</var><sup>2</sup> = <var>c</var><sup>2</sup>\n\n得到1000 * (a + b) = 500000 + a * b\n\n暴力找到满足这个条件的a和b.\n\n","slug":"欧拉工程-问题9","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cu004b26s6nb0pgtu6"},{"title":"欧拉工程-问题8","id":"193","date":"2013-05-05T06:25:43.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=8](http://projecteuler.net/problem=8)\n\nLargest product in a series\nFind the greatest product of five consecutive digits in the 1000-digit number.\n\n73167176531330624919225119674426574742355349194934\n96983520312774506326239578318016984801869478851843\n85861560789112949495459501737958331952853208805511\n12540698747158523863050715693290963295227443043557\n66896648950445244523161731856403098711121722383113\n62229893423380308135336276614282806444486645238749\n30358907296290491560440772390713810515859307960866\n70172427121883998797908792274921901699720888093776\n65727333001053367881220235421809751254540594752243\n52584907711670556013604839586446706324415722155397\n53697817977846174064955149290862569321978468622482\n83972241375657056057490261407972968652414535100474\n82166370484403199890008895243450658541227588666881\n16427171479924442928230863465674813919123162824586\n17866458359124566529476545682848912883142607690042\n24219022671055626321111109370544217506941658960408\n07198403850962455444362981230987879927244284909188\n84580156166097919133875499200524063689912560717606\n05886116467109405077541002256983155200055935729725\n71636269561882670428252483600823257530420752963450\n\n连串数字的最大乘积\n求这1000个数字中，连续5个数字的乘积的最大值\n\n解答：\n这题没什么好说的。\n","source":"_posts/欧拉工程-问题8.md","raw":"title: 欧拉工程-问题8\ntags:\n  - 欧拉工程\n  - 连续乘积\nid: 193\ncategories:\n  - 欧拉工程\ndate: 2013-05-05 14:25:43\n---\n\n原题链接 [http://projecteuler.net/problem=8](http://projecteuler.net/problem=8)\n\nLargest product in a series\nFind the greatest product of five consecutive digits in the 1000-digit number.\n\n73167176531330624919225119674426574742355349194934\n96983520312774506326239578318016984801869478851843\n85861560789112949495459501737958331952853208805511\n12540698747158523863050715693290963295227443043557\n66896648950445244523161731856403098711121722383113\n62229893423380308135336276614282806444486645238749\n30358907296290491560440772390713810515859307960866\n70172427121883998797908792274921901699720888093776\n65727333001053367881220235421809751254540594752243\n52584907711670556013604839586446706324415722155397\n53697817977846174064955149290862569321978468622482\n83972241375657056057490261407972968652414535100474\n82166370484403199890008895243450658541227588666881\n16427171479924442928230863465674813919123162824586\n17866458359124566529476545682848912883142607690042\n24219022671055626321111109370544217506941658960408\n07198403850962455444362981230987879927244284909188\n84580156166097919133875499200524063689912560717606\n05886116467109405077541002256983155200055935729725\n71636269561882670428252483600823257530420752963450\n\n连串数字的最大乘积\n求这1000个数字中，连续5个数字的乘积的最大值\n\n解答：\n这题没什么好说的。\n","slug":"欧拉工程-问题8","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4cx004i26s6bn48o72a"},{"title":"欧拉工程-问题7","id":"174","date":"2013-05-05T05:02:36.000Z","_content":"\n\n原题链接 [http://projecteuler.net/problem=7](http://projecteuler.net/problem=7)\n\n10001st prime\n\n\nBy listing the first six prime numbers: 2, 3, 5, 7, 11, and 13, we can see that the 6th prime is 13.\n\nWhat is the 10 001st prime number?\n\n**第10001个素数**\n\n列出前六个素数：2, 3，5, 7, 11，和13，我们可以知道第6个素数是13.\n\n求第10001个素数。\n\n解答：\n没有想到什么好的方法，就用暴力解决。经过观察，对于大于6的正整数都可以用6n,6n + 1,6n + 2,6n + 3,6n + 4,6n + 5表示，其中只有6n + 1,6n + 5有可能是素数。所以可以用一个step变量来记录下一跳的步数，保证需要判断的数字在6n + 1和6n + 5中变换。要判断一个正整数是否是素数，只需用比它的平方根小的所有素数去除它，如果它可以被其中一个整除，则是素数，否则不是。\n","source":"_posts/欧拉工程-问题7.md","raw":"title: 欧拉工程-问题7\ntags:\n  - 欧拉工程\n  - 素数\nid: 174\ncategories:\n  - 欧拉工程\ndate: 2013-05-05 13:02:36\n---\n\n\n原题链接 [http://projecteuler.net/problem=7](http://projecteuler.net/problem=7)\n\n10001st prime\n\n\nBy listing the first six prime numbers: 2, 3, 5, 7, 11, and 13, we can see that the 6th prime is 13.\n\nWhat is the 10 001st prime number?\n\n**第10001个素数**\n\n列出前六个素数：2, 3，5, 7, 11，和13，我们可以知道第6个素数是13.\n\n求第10001个素数。\n\n解答：\n没有想到什么好的方法，就用暴力解决。经过观察，对于大于6的正整数都可以用6n,6n + 1,6n + 2,6n + 3,6n + 4,6n + 5表示，其中只有6n + 1,6n + 5有可能是素数。所以可以用一个step变量来记录下一跳的步数，保证需要判断的数字在6n + 1和6n + 5中变换。要判断一个正整数是否是素数，只需用比它的平方根小的所有素数去除它，如果它可以被其中一个整除，则是素数，否则不是。\n","slug":"欧拉工程-问题7","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4d1004n26s68h0tmub6"},{"title":"欧拉工程-问题60","id":"659","date":"2014-03-30T04:06:26.000Z","_content":"\n原题链接[http://projecteuler.net/problem=60](http://projecteuler.net/problem=60)\n\nPrime pair sets\n\nThe primes 3, 7, 109, and 673, are quite remarkable. By taking any two primes and concatenating them in any order the result will always be prime. For example, taking 7 and 109, both 7109 and 1097 are prime. The sum of these four primes, 792, represents the lowest sum for a set of four primes with this property.\n\nFind the lowest sum for a set of five primes for which any two primes concatenate to produce another prime.\n\n素数对集合\n\n素数3，7，109和673非常有特色。取其中任意两个素数，以任意顺序链接起来都是素数。例如，取7和109，7109和1097都是素数。这四个素数的和792，代表着具有这种特征的四素数集中的最小和。\n\n求具有取其中任意两个素数，连接起来都是素数的五素数集的最小和。\n\n解答：\n\n依然是暴力解决。唯一需要注意的是，判断素数的方法必须使用米勒-拉宾素性测试方法，否则速度无法接受。\n","source":"_posts/欧拉工程-问题60.md","raw":"title: 欧拉工程-问题60\ntags:\n  - 米勒-拉宾\n  - 素数判定\n  - 欧拉工程\nid: 659\ncategories:\n  - 欧拉工程\ndate: 2014-03-30 12:06:26\n---\n\n原题链接[http://projecteuler.net/problem=60](http://projecteuler.net/problem=60)\n\nPrime pair sets\n\nThe primes 3, 7, 109, and 673, are quite remarkable. By taking any two primes and concatenating them in any order the result will always be prime. For example, taking 7 and 109, both 7109 and 1097 are prime. The sum of these four primes, 792, represents the lowest sum for a set of four primes with this property.\n\nFind the lowest sum for a set of five primes for which any two primes concatenate to produce another prime.\n\n素数对集合\n\n素数3，7，109和673非常有特色。取其中任意两个素数，以任意顺序链接起来都是素数。例如，取7和109，7109和1097都是素数。这四个素数的和792，代表着具有这种特征的四素数集中的最小和。\n\n求具有取其中任意两个素数，连接起来都是素数的五素数集的最小和。\n\n解答：\n\n依然是暴力解决。唯一需要注意的是，判断素数的方法必须使用米勒-拉宾素性测试方法，否则速度无法接受。\n","slug":"欧拉工程-问题60","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4d4004r26s61xaz58gk"},{"title":"欧拉工程-问题6","id":"154","date":"2013-05-04T07:32:57.000Z","_content":"\n\n\n原题链接 [http://projecteuler.net/problem=6](http://projecteuler.net/problem=6)\n\nSum square difference\n\n\n\n\nThe sum of the squares of the first ten natural numbers is,\n1<sup>2</sup> + 2<sup>2</sup> + ... + 10<sup>2</sup> = 385\nThe square of the sum of the first ten natural numbers is,\n(1 + 2 + ... + 10)<sup>2</sup> = 55<sup>2</sup> = 3025\nHence the difference between the sum of the squares of the first ten natural numbers and the square of the sum is 3025 - 385 = 2640.\n\nFind the difference between the sum of the squares of the first one hundred natural numbers and the square of the sum.\n\n和平方差\n\n前10个自然数的平方和是，\n\n1<sup>2</sup> + 2<sup>2</sup> + ... + 10<sup>2</sup> = 385\n\n前10个自然数的和的平方是，\n\n(1 + 2 + ... + 10)<sup>2</sup> = 55<sup>2</sup> = 3025\n\n因此前10个自然数的和的平方与平方的和之间的差是 3025 - 385 = 2640.\n\n求前100个自然数的和的平方与平方的和之间的差。\n\n解答：\n\n其实就是用公式\n\n\\(1^2 + 2 ^2 + \\ldots + n^2 = \\frac{1}{6}n(n + 1)(2n + 1)\\)<sup>\n</sup>\n\n\\((1 + 2 + \\ldots + n)^2 = (\\frac{1}{2}n(n+1))^2\\)\n\n","source":"_posts/欧拉工程-问题6.md","raw":"title: 欧拉工程-问题6\ntags:\n  - 和的平方\n  - 平方的和\n  - 欧拉工程\nid: 154\ncategories:\n  - 欧拉工程\ndate: 2013-05-04 15:32:57\n---\n\n\n\n原题链接 [http://projecteuler.net/problem=6](http://projecteuler.net/problem=6)\n\nSum square difference\n\n\n\n\nThe sum of the squares of the first ten natural numbers is,\n1<sup>2</sup> + 2<sup>2</sup> + ... + 10<sup>2</sup> = 385\nThe square of the sum of the first ten natural numbers is,\n(1 + 2 + ... + 10)<sup>2</sup> = 55<sup>2</sup> = 3025\nHence the difference between the sum of the squares of the first ten natural numbers and the square of the sum is 3025 - 385 = 2640.\n\nFind the difference between the sum of the squares of the first one hundred natural numbers and the square of the sum.\n\n和平方差\n\n前10个自然数的平方和是，\n\n1<sup>2</sup> + 2<sup>2</sup> + ... + 10<sup>2</sup> = 385\n\n前10个自然数的和的平方是，\n\n(1 + 2 + ... + 10)<sup>2</sup> = 55<sup>2</sup> = 3025\n\n因此前10个自然数的和的平方与平方的和之间的差是 3025 - 385 = 2640.\n\n求前100个自然数的和的平方与平方的和之间的差。\n\n解答：\n\n其实就是用公式\n\n\\(1^2 + 2 ^2 + \\ldots + n^2 = \\frac{1}{6}n(n + 1)(2n + 1)\\)<sup>\n</sup>\n\n\\((1 + 2 + \\ldots + n)^2 = (\\frac{1}{2}n(n+1))^2\\)\n\n","slug":"欧拉工程-问题6","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4d8004y26s679sw1uh8"},{"title":"欧拉工程-问题59","id":"650","date":"2014-03-29T12:56:59.000Z","_content":"\n原题链接[http://projecteuler.net/problem=59](http://projecteuler.net/problem=59)\n\nXOR decryption\n\nEach character on a computer is assigned a unique code and the preferred standard is ASCII (American Standard Code for Information Interchange). For example, uppercase A = 65, asterisk (*) = 42, and lowercase k = 107.\n\nA modern encryption method is to take a text file, convert the bytes to ASCII, then XOR each byte with a given value, taken from a secret key. The advantage with the XOR function is that using the same encryption key on the cipher text, restores the plain text; for example, 65 XOR 42 = 107, then 107 XOR 42 = 65.\n\nFor unbreakable encryption, the key is the same length as the plain text message, and the key is made up of random bytes. The user would keep the encrypted message and the encryption key in different locations, and without both \"halves\", it is impossible to decrypt the message.\n\nUnfortunately, this method is impractical for most users, so the modified method is to use a password as a key. If the password is shorter than the message, which is likely, the key is repeated cyclically throughout the message. The balance for this method is using a sufficiently long password key for security, but short enough to be memorable.\n\nYour task has been made easy, as the encryption key consists of three lower case characters. Using [cipher1.txt](http://projecteuler.net/project/cipher1.txt) (right click and 'Save Link/Target As...'), a file containing the encrypted ASCII codes, and the knowledge that the plain text must contain common English words, decrypt the message and find the sum of the ASCII values in the original text.\n\n异或加密\n在计算机中的每个字符都被分配一个唯一的码值，最常用的标准是ASCII（美国标准信息交换码).例如，大写的A = 65，星号(*) = 42,小写的k = 107.\n\n有一种现代的加密方法是将文本文件转化成对应的ASCII,然后将每一个字节与密码中的一个值异或。使用异或方法加密的一个优点是，在密文中使用同样的密钥可以得到明文。例如, 65 XOR 42 = 107 , 之后 107 XOR 42 = 65.\n\n对于不可破解的加密，密钥的长度与明文一样长，并且密钥由随机的字节组成。一个用户将密文和密钥保存在不同的地方，如果没有同时拿到密文和密钥，将不可能破解信息。\n\n不幸的是，这种方法对于许多用户都不实际，因此一个改良的方法是使用密码作为密钥。如果密码的长度小于信息，这也是最常见的情况，那么密钥就要循环贯穿信息。综合考虑，这种方法为了保证安全，选择一个足够长的密钥，为了便于记忆，也必须足够短。\n\n你的任务已经简化了，因为密钥是由三个小写字母构成。使用[cipher1.txt](http://projecteuler.net/project/cipher1.txt)（右击，链接另存为），这是一个经过加密的ASCLL码，已经知道的是明文是由英文单词构成，请解密信息，并求原始信息中ASCLL码的总和.\n\n解答：\n暴力破解，用常见的英文单词the来判断。\n","source":"_posts/欧拉工程-问题59.md","raw":"title: 欧拉工程-问题59\ntags:\n  - 异或\n  - 欧拉工程\nid: 650\ncategories:\n  - 欧拉工程\ndate: 2014-03-29 20:56:59\n---\n\n原题链接[http://projecteuler.net/problem=59](http://projecteuler.net/problem=59)\n\nXOR decryption\n\nEach character on a computer is assigned a unique code and the preferred standard is ASCII (American Standard Code for Information Interchange). For example, uppercase A = 65, asterisk (*) = 42, and lowercase k = 107.\n\nA modern encryption method is to take a text file, convert the bytes to ASCII, then XOR each byte with a given value, taken from a secret key. The advantage with the XOR function is that using the same encryption key on the cipher text, restores the plain text; for example, 65 XOR 42 = 107, then 107 XOR 42 = 65.\n\nFor unbreakable encryption, the key is the same length as the plain text message, and the key is made up of random bytes. The user would keep the encrypted message and the encryption key in different locations, and without both \"halves\", it is impossible to decrypt the message.\n\nUnfortunately, this method is impractical for most users, so the modified method is to use a password as a key. If the password is shorter than the message, which is likely, the key is repeated cyclically throughout the message. The balance for this method is using a sufficiently long password key for security, but short enough to be memorable.\n\nYour task has been made easy, as the encryption key consists of three lower case characters. Using [cipher1.txt](http://projecteuler.net/project/cipher1.txt) (right click and 'Save Link/Target As...'), a file containing the encrypted ASCII codes, and the knowledge that the plain text must contain common English words, decrypt the message and find the sum of the ASCII values in the original text.\n\n异或加密\n在计算机中的每个字符都被分配一个唯一的码值，最常用的标准是ASCII（美国标准信息交换码).例如，大写的A = 65，星号(*) = 42,小写的k = 107.\n\n有一种现代的加密方法是将文本文件转化成对应的ASCII,然后将每一个字节与密码中的一个值异或。使用异或方法加密的一个优点是，在密文中使用同样的密钥可以得到明文。例如, 65 XOR 42 = 107 , 之后 107 XOR 42 = 65.\n\n对于不可破解的加密，密钥的长度与明文一样长，并且密钥由随机的字节组成。一个用户将密文和密钥保存在不同的地方，如果没有同时拿到密文和密钥，将不可能破解信息。\n\n不幸的是，这种方法对于许多用户都不实际，因此一个改良的方法是使用密码作为密钥。如果密码的长度小于信息，这也是最常见的情况，那么密钥就要循环贯穿信息。综合考虑，这种方法为了保证安全，选择一个足够长的密钥，为了便于记忆，也必须足够短。\n\n你的任务已经简化了，因为密钥是由三个小写字母构成。使用[cipher1.txt](http://projecteuler.net/project/cipher1.txt)（右击，链接另存为），这是一个经过加密的ASCLL码，已经知道的是明文是由英文单词构成，请解密信息，并求原始信息中ASCLL码的总和.\n\n解答：\n暴力破解，用常见的英文单词the来判断。\n","slug":"欧拉工程-问题59","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4dc005526s6lvgocwbg"},{"title":"欧拉工程-问题58","id":"556","date":"2013-09-02T05:10:13.000Z","_content":"\n原题链接[http://projecteuler.net/problem=58](http://projecteuler.net/problem=58)\n\n\nSpiral primes\n\nStarting with 1 and spiralling anticlockwise in the following way, a square spiral with side length 7 is formed.\n\n**37** 36 35 34 33 32 **31**\n38 **17** 16 15 14 **13** 30\n39 18  **5**  4  **3** 12 29\n40 19  6  1  2 11 28\n41 20  **7**  8  9 10 27\n42 21 22 23 24 25 26\n**43** 44 45 46 47 48 49\n\nIt is interesting to note that the odd squares lie along the bottom right diagonal, but what is more interesting is that 8 out of the 13 numbers lying along both diagonals are prime; that is, a ratio of 8/13 ~ 62%.\n\nIf one complete new layer is wrapped around the spiral above, a square spiral with side length 9 will be formed. If this process is continued, what is the side length of the square spiral for which the ratio of primes along both diagonals first falls below 10%?\n\n螺旋素数\n从1开始以如下方式逆时针螺旋，可以得到一个大小为7的螺旋方块\n\n**37** 36 35 34 33 32 **31**\n38 **17** 16 15 14 **13** 30\n39 18  **5**  4  **3** 12 29\n40 19  6  1  2 11 28\n41 20  **7**  8  9 10 27\n42 21 22 23 24 25 26\n**43** 44 45 46 47 48 49\n\n有趣的是奇数的平方都在对角线的右下角，更有趣的是，13个位于对角线的数中，有8个是素数；比率是8/13 约等于 62%。\n\n如果像上面的螺旋那样再加一层螺旋，将得到一个大小为9的螺旋方块。如果这个步骤一直持续下去，当螺旋方块的大小为多少时，对角线上的素数比率会小于10%？\n\n解答：\n表示对角线上的数与第28题相同，最难的部分是判定一个数是否是素数，用动态生成素数表的方法不行，太大了。最后找到了米勒-拉宾素数测试法，很快。等以后有空时专门写一篇关于素数判定方法。","source":"_posts/欧拉工程-问题58.md","raw":"title: 欧拉工程-问题58\ntags:\n  - 欧拉工程\n  - 米勒-拉宾\n  - 素数\nid: 556\ncategories:\n  - 欧拉工程\ndate: 2013-09-02 13:10:13\n---\n\n原题链接[http://projecteuler.net/problem=58](http://projecteuler.net/problem=58)\n\n\nSpiral primes\n\nStarting with 1 and spiralling anticlockwise in the following way, a square spiral with side length 7 is formed.\n\n**37** 36 35 34 33 32 **31**\n38 **17** 16 15 14 **13** 30\n39 18  **5**  4  **3** 12 29\n40 19  6  1  2 11 28\n41 20  **7**  8  9 10 27\n42 21 22 23 24 25 26\n**43** 44 45 46 47 48 49\n\nIt is interesting to note that the odd squares lie along the bottom right diagonal, but what is more interesting is that 8 out of the 13 numbers lying along both diagonals are prime; that is, a ratio of 8/13 ~ 62%.\n\nIf one complete new layer is wrapped around the spiral above, a square spiral with side length 9 will be formed. If this process is continued, what is the side length of the square spiral for which the ratio of primes along both diagonals first falls below 10%?\n\n螺旋素数\n从1开始以如下方式逆时针螺旋，可以得到一个大小为7的螺旋方块\n\n**37** 36 35 34 33 32 **31**\n38 **17** 16 15 14 **13** 30\n39 18  **5**  4  **3** 12 29\n40 19  6  1  2 11 28\n41 20  **7**  8  9 10 27\n42 21 22 23 24 25 26\n**43** 44 45 46 47 48 49\n\n有趣的是奇数的平方都在对角线的右下角，更有趣的是，13个位于对角线的数中，有8个是素数；比率是8/13 约等于 62%。\n\n如果像上面的螺旋那样再加一层螺旋，将得到一个大小为9的螺旋方块。如果这个步骤一直持续下去，当螺旋方块的大小为多少时，对角线上的素数比率会小于10%？\n\n解答：\n表示对角线上的数与第28题相同，最难的部分是判定一个数是否是素数，用动态生成素数表的方法不行，太大了。最后找到了米勒-拉宾素数测试法，很快。等以后有空时专门写一篇关于素数判定方法。","slug":"欧拉工程-问题58","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4df005a26s66rw44k19"},{"title":"欧拉工程-问题57","id":"552","date":"2013-09-02T05:04:15.000Z","_content":"\n原题链接[http://projecteuler.net/problem=57](http://projecteuler.net/problem=57)\n\n\nSquare root convergents\n\nIt is possible to show that the square root of two can be expressed as an infinite continued fraction.\n\nsqrt( 2) = 1 + 1/(2 + 1/(2 + 1/(2 + ... ))) = 1.414213...\n\nBy expanding this for the first four iterations, we get:\n\n1 + 1/2 = 3/2 = 1.5\n1 + 1/(2 + 1/2) = 7/5 = 1.4\n1 + 1/(2 + 1/(2 + 1/2)) = 17/12 = 1.41666...\n1 + 1/(2 + 1/(2 + 1/(2 + 1/2))) = 41/29 = 1.41379...\n\nThe next three expansions are 99/70, 239/169, and 577/408, but the eighth expansion, 1393/985, is the first example where the number of digits in the numerator exceeds the number of digits in the denominator.\n\nIn the first one-thousand expansions, how many fractions contain a numerator with more digits than denominator?\n\n&nbsp;\n\n平方根收敛\n\n有可能将2的平方根表示成无限分数：\n\nsqrt(2) = 1 + 1/(2 + 1/(2 + 1/(2 + ... ))) = 1.414213...\n\n扩展这个式子的前四项，我们得到\n\n1 + 1/2 = 3/2 = 1.5\n1 + 1/(2 + 1/2) = 7/5 = 1.4\n1 + 1/(2 + 1/(2 + 1/2)) = 17/12 = 1.41666...\n1 + 1/(2 + 1/(2 + 1/(2 + 1/2))) = 41/29 = 1.41379...\n\n之后的三项是99/70，239/169，和577/408，对于第八项，1393/985，是第一个分子中的数字个数超过分母中的数字个数的项\n\n在前1000项中，一共有多少个分数是分子中的数字个数超过分母的？\n\n解答：\n\n就是如何表示分数，之后定义分数的加法，不难。\n\n","source":"_posts/欧拉工程-问题57.md","raw":"title: 欧拉工程-问题57\ntags:\n  - 分数加法\n  - 欧拉工程\nid: 552\ncategories:\n  - 欧拉工程\ndate: 2013-09-02 13:04:15\n---\n\n原题链接[http://projecteuler.net/problem=57](http://projecteuler.net/problem=57)\n\n\nSquare root convergents\n\nIt is possible to show that the square root of two can be expressed as an infinite continued fraction.\n\nsqrt( 2) = 1 + 1/(2 + 1/(2 + 1/(2 + ... ))) = 1.414213...\n\nBy expanding this for the first four iterations, we get:\n\n1 + 1/2 = 3/2 = 1.5\n1 + 1/(2 + 1/2) = 7/5 = 1.4\n1 + 1/(2 + 1/(2 + 1/2)) = 17/12 = 1.41666...\n1 + 1/(2 + 1/(2 + 1/(2 + 1/2))) = 41/29 = 1.41379...\n\nThe next three expansions are 99/70, 239/169, and 577/408, but the eighth expansion, 1393/985, is the first example where the number of digits in the numerator exceeds the number of digits in the denominator.\n\nIn the first one-thousand expansions, how many fractions contain a numerator with more digits than denominator?\n\n&nbsp;\n\n平方根收敛\n\n有可能将2的平方根表示成无限分数：\n\nsqrt(2) = 1 + 1/(2 + 1/(2 + 1/(2 + ... ))) = 1.414213...\n\n扩展这个式子的前四项，我们得到\n\n1 + 1/2 = 3/2 = 1.5\n1 + 1/(2 + 1/2) = 7/5 = 1.4\n1 + 1/(2 + 1/(2 + 1/2)) = 17/12 = 1.41666...\n1 + 1/(2 + 1/(2 + 1/(2 + 1/2))) = 41/29 = 1.41379...\n\n之后的三项是99/70，239/169，和577/408，对于第八项，1393/985，是第一个分子中的数字个数超过分母中的数字个数的项\n\n在前1000项中，一共有多少个分数是分子中的数字个数超过分母的？\n\n解答：\n\n就是如何表示分数，之后定义分数的加法，不难。\n\n","slug":"欧拉工程-问题57","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4di005f26s6gbo2ugfy"},{"title":"欧拉工程-问题56","id":"545","date":"2013-08-25T02:18:39.000Z","_content":"\n原题链接[http://projecteuler.net/problem=56](http://projecteuler.net/problem=56)\n\n\nPowerful digit sum\n\nA googol (10<sup>100</sup>) is a massive number: one followed by one-hundred zeros; 100<sup>100</sup> is almost unimaginably large: one followed by two-hundred zeros. Despite their size, the sum of the digits in each number is only 1.\n\nConsidering natural numbers of the form, a<sup>b</sup>, where a, b < 100, what is the maximum digital sum?\n\n幂方数字和\n古戈尔 (10<sup>100</sup>)是一个天文数字：1后面跟着100个零；100<sup>100</sup>更是不可想象的大:1后面跟着200个零。尽管它们非常大，但是它们的数字和为1.\n\n\n求幂方a<sup>b</sup>中，a,b < 100,最大的数字和\n解法：\n暴力吧。\n","source":"_posts/欧拉工程-问题56.md","raw":"title: 欧拉工程-问题56\ntags:\n  - 幂方\n  - 欧拉工程\nid: 545\ncategories:\n  - 欧拉工程\ndate: 2013-08-25 10:18:39\n---\n\n原题链接[http://projecteuler.net/problem=56](http://projecteuler.net/problem=56)\n\n\nPowerful digit sum\n\nA googol (10<sup>100</sup>) is a massive number: one followed by one-hundred zeros; 100<sup>100</sup> is almost unimaginably large: one followed by two-hundred zeros. Despite their size, the sum of the digits in each number is only 1.\n\nConsidering natural numbers of the form, a<sup>b</sup>, where a, b < 100, what is the maximum digital sum?\n\n幂方数字和\n古戈尔 (10<sup>100</sup>)是一个天文数字：1后面跟着100个零；100<sup>100</sup>更是不可想象的大:1后面跟着200个零。尽管它们非常大，但是它们的数字和为1.\n\n\n求幂方a<sup>b</sup>中，a,b < 100,最大的数字和\n解法：\n暴力吧。\n","slug":"欧拉工程-问题56","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4dk005k26s6ufj2ypsg"},{"title":"欧拉工程-问题55","id":"543","date":"2013-08-25T02:16:33.000Z","_content":"\n原题链接[http://projecteuler.net/problem=55](http://projecteuler.net/problem=55)\n\n\nLychrel numbers\n\nIf we take 47, reverse and add, 47 + 74 = 121, which is palindromic.\n\nNot all numbers produce palindromes so quickly. For example,\n\n349 + 943 = 1292,\n1292 + 2921 = 4213\n4213 + 3124 = 7337\n\nThat is, 349 took three iterations to arrive at a palindrome.\n\nAlthough no one has proved it yet, it is thought that some numbers, like 196, never produce a palindrome. A number that never forms a palindrome through the reverse and add process is called a Lychrel number. Due to the theoretical nature of these numbers, and for the purpose of this problem, we shall assume that a number is Lychrel until proven otherwise. In addition you are given that for every number below ten-thousand, it will either (i) become a palindrome in less than fifty iterations, or, (ii) no one, with all the computing power that exists, has managed so far to map it to a palindrome. In fact, 10677 is the first number to be shown to require over fifty iterations before producing a palindrome: 4668731596684224866951378664 (53 iterations, 28-digits).\n\nSurprisingly, there are palindromic numbers that are themselves Lychrel numbers; the first example is 4994.\n\nHow many Lychrel numbers are there below ten-thousand?\n\nNOTE: Wording was modified slightly on 24 April 2007 to emphasise the theoretical nature of Lychrel numbers.\n利克瑞尔数\n\n如果我们取47，将它逆序并求和，47 + 74 = 121，是一个回文数。\n并不是所有的数都可以这么快产生回文数。例如\n349 + 943 = 1292，\n1292 + 2921 = 4213\n4213 + 3124 = 7337\n也就是说，349用了3此迭代得到一个回文数。\n虽然至今没有人证明，但是有猜想认为一些数，如196，永远不产生回文数。一个数通过逆序和迭代如果永远不产生回文数则称为利克瑞尔数。因为这些数的理论本质以及方便这个问题的目的，我们假设一个数是利克瑞尔数，直到证明不是。另外，对于每个小于10000的数，给定两种可能，它或者是(i)在小于50次迭代变成循环数(ii)没有一个人，在有限的计算能力下，能够将它迭代到一个回文数。事实上，10677是第一个超过50次迭代产生回文数：4668731596684224866951378664(53次迭代，28位数)\n令人惊奇的是，有一些回文数自身也是利克瑞尔数，第一个例子是4994.\n求10000以下一共有多少个利克瑞尔数？\n注意：为了强调利克瑞尔数的理论一些性质，一些单词于2007.4.24更改\n\n解答：\n没什么，遍历。","source":"_posts/欧拉工程-问题55.md","raw":"title: 欧拉工程-问题55\ntags:\n  - 利克瑞尔数\n  - 回文数\n  - 欧拉工程\nid: 543\ncategories:\n  - 欧拉工程\ndate: 2013-08-25 10:16:33\n---\n\n原题链接[http://projecteuler.net/problem=55](http://projecteuler.net/problem=55)\n\n\nLychrel numbers\n\nIf we take 47, reverse and add, 47 + 74 = 121, which is palindromic.\n\nNot all numbers produce palindromes so quickly. For example,\n\n349 + 943 = 1292,\n1292 + 2921 = 4213\n4213 + 3124 = 7337\n\nThat is, 349 took three iterations to arrive at a palindrome.\n\nAlthough no one has proved it yet, it is thought that some numbers, like 196, never produce a palindrome. A number that never forms a palindrome through the reverse and add process is called a Lychrel number. Due to the theoretical nature of these numbers, and for the purpose of this problem, we shall assume that a number is Lychrel until proven otherwise. In addition you are given that for every number below ten-thousand, it will either (i) become a palindrome in less than fifty iterations, or, (ii) no one, with all the computing power that exists, has managed so far to map it to a palindrome. In fact, 10677 is the first number to be shown to require over fifty iterations before producing a palindrome: 4668731596684224866951378664 (53 iterations, 28-digits).\n\nSurprisingly, there are palindromic numbers that are themselves Lychrel numbers; the first example is 4994.\n\nHow many Lychrel numbers are there below ten-thousand?\n\nNOTE: Wording was modified slightly on 24 April 2007 to emphasise the theoretical nature of Lychrel numbers.\n利克瑞尔数\n\n如果我们取47，将它逆序并求和，47 + 74 = 121，是一个回文数。\n并不是所有的数都可以这么快产生回文数。例如\n349 + 943 = 1292，\n1292 + 2921 = 4213\n4213 + 3124 = 7337\n也就是说，349用了3此迭代得到一个回文数。\n虽然至今没有人证明，但是有猜想认为一些数，如196，永远不产生回文数。一个数通过逆序和迭代如果永远不产生回文数则称为利克瑞尔数。因为这些数的理论本质以及方便这个问题的目的，我们假设一个数是利克瑞尔数，直到证明不是。另外，对于每个小于10000的数，给定两种可能，它或者是(i)在小于50次迭代变成循环数(ii)没有一个人，在有限的计算能力下，能够将它迭代到一个回文数。事实上，10677是第一个超过50次迭代产生回文数：4668731596684224866951378664(53次迭代，28位数)\n令人惊奇的是，有一些回文数自身也是利克瑞尔数，第一个例子是4994.\n求10000以下一共有多少个利克瑞尔数？\n注意：为了强调利克瑞尔数的理论一些性质，一些单词于2007.4.24更改\n\n解答：\n没什么，遍历。","slug":"欧拉工程-问题55","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4dp005p26s6iezvnssm"},{"title":"欧拉工程-问题54","id":"536","date":"2013-08-21T16:39:23.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=54](http://projecteuler.net/problem=54)\n\n\nPoker hands\n\nIn the card game poker, a hand consists of five cards and are ranked, from lowest to highest, in the following way:\n\n*   **High Card**: Highest value card.\n*   **One Pair**: Two cards of the same value.\n*   **Two Pairs**: Two different pairs.\n*   **Three of a Kind**: Three cards of the same value.\n*   **Straight**: All cards are consecutive values.\n*   **Flush**: All cards of the same suit.\n*   **Full House**: Three of a kind and a pair.\n*   **Four of a Kind**: Four cards of the same value.\n*   **Straight Flush**: All cards are consecutive values of same suit.\n*   **Royal Flush**:Ten, Jack, Queen, King, Ace, in same suit.\nThe cards are valued in the order:\n2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace.\n\nIf two players have the same ranked hands then the rank made up of the highest value wins; for example, a pair of eights beats a pair of fives (see example 1 below). But if two ranks tie, for example, both players have a pair of queens, then highest cards in each hand are compared (see example 4 below); if the highest cards tie then the next highest cards are compared, and so on.\n\nConsider the following five hands dealt to two players:\n\n<table>\n<tbody>\n<tr>\n<td>**Hand**</td>\n<td></td>\n<td>**Player 1**</td>\n<td></td>\n<td>**Player 2**</td>\n<td></td>\n<td>**Winner**</td>\n</tr>\n<tr>\n<td>**1**</td>\n<td></td>\n<td>5H 5C 6S 7S KD\nPair of Fives</td>\n<td></td>\n<td>2C 3S 8S 8D TD\nPair of Eights</td>\n<td></td>\n<td>Player 2</td>\n</tr>\n<tr>\n<td>**2**</td>\n<td></td>\n<td>5D 8C 9S JS AC\nHighest card Ace</td>\n<td></td>\n<td>2C 5C 7D 8S QH\nHighest card Queen</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n<tr>\n<td>**3**</td>\n<td></td>\n<td>2D 9C AS AH AC\nThree Aces</td>\n<td></td>\n<td>3D 6D 7D TD QD\nFlush with Diamonds</td>\n<td></td>\n<td>Player 2</td>\n</tr>\n<tr>\n<td>**4**</td>\n<td></td>\n<td>4D 6S 9H QH QC\nPair of Queens\nHighest card Nine</td>\n<td></td>\n<td>3D 6D 7H QD QS\nPair of Queens\nHighest card Seven</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n<tr>\n<td>**5**</td>\n<td></td>\n<td>2H 2D 4C 4D 4S\nFull House\nWith Three Fours</td>\n<td></td>\n<td>3C 3D 3S 9S 9D\nFull House\nwith Three Threes</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n</tbody>\n</table>\n\nThe file, [poker.txt](http://projecteuler.net/project/poker.txt), contains one-thousand random hands dealt to two players. Each line of the file contains ten cards (separated by a single space): the first five are Player 1's cards and the last five are Player 2's cards. You can assume that all hands are valid (no invalid characters or repeated cards), each player's hand is in no specific order, and in each hand there is a clear winner.\n\nHow many hands does Player 1 win?\n\n扑克手牌\n\n在扑克牌游戏中，一手牌由5张牌构成，有不同的等级，从最小到最大，规则如下：\n\n大牌：牌中最大的\n\n对子：两张相同的牌\n\n两对：有两对对子\n\n三条：三张相同的牌\n\n顺子：所有的牌是连续的\n\n同花：所有的牌是同一花色\n\n葫芦：三条和一对\n\n四条：四张相同的牌\n\n同花顺：所有的牌连续且是同花\n\n同花大顺：AKQJ10组成的同花顺\n\n牌值的顺序如下：\n\n2，3，4，5，6，7，8，9，10，J，Q，K，A\n\n如果两个玩家有相同等级的牌，则值更大的那个赢，例如一对8赢一对5（如下例1），但是如果等级相同，例如两个玩家都有一对Q，那么将比较手牌中的最大值（如下例4），如果最大的依然相同，则比较次大的，重复如上步骤。\n\n考虑如下5种两个玩家的对局情况：\n<table>\n<tbody>\n<tr>\n<td>**局**</td>\n<td></td>\n<td>**玩家1**</td>\n<td></td>\n<td>**玩家2**</td>\n<td></td>\n<td>**赢家**</td>\n</tr>\n<tr>\n<td>**1**</td>\n<td></td>\n<td>5H 5C 6S 7S KD\n一对5</td>\n<td></td>\n<td>2C 3S 8S 8D TD\n一对8</td>\n<td></td>\n<td>玩家2</td>\n</tr>\n<tr>\n<td>**2**</td>\n<td></td>\n<td>5D 8C 9S JS AC\n最大牌A</td>\n<td></td>\n<td>2C 5C 7D 8S QH\n最大牌Q</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n<tr>\n<td>**3**</td>\n<td></td>\n<td>2D 9C AS AH AC\n3张A</td>\n<td></td>\n<td>3D 6D 7D TD QD\n方块同花</td>\n<td></td>\n<td>玩家2</td>\n</tr>\n<tr>\n<td>**4**</td>\n<td></td>\n<td>4D 6S 9H QH QC\n一对Q\n最大9</td>\n<td></td>\n<td>3D 6D 7H QD QS\n一对Q\n最大7</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n<tr>\n<td>**5**</td>\n<td></td>\n<td>2H 2D 4C 4D 4S\n葫芦\n三个四</td>\n<td></td>\n<td>3C 3D 3S 9S 9D\n葫芦\n三个三</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n</tbody>\n</table>\n​\n文件 [poker.txt](http://projecteuler.net/project/poker.txt)中包含一千次两个玩家的对局情况，每一行有10张牌（空格分开），前5张牌是玩家1的牌，后5张牌是玩家2的牌，你可以假设手牌都是有效的（没有无效字符和重复的牌），每个玩家的手牌都没有特殊顺序，并且每一对局一定有一个赢。\n\n求玩家1共赢了多少次。\n\n解答：\n\n这题好麻烦啊，写的代码真是乱。就是按照扑克牌的规则比较大小，真是很麻烦，一度令我有放弃欧拉工程的冲动，还好坚持下来了。\n\n\n","source":"_posts/欧拉工程-问题54.md","raw":"title: 欧拉工程-问题54\ntags:\n  - 扑克牌\n  - 欧拉工程\nid: 536\ncategories:\n  - 欧拉工程\ndate: 2013-08-22 00:39:23\n---\n\n原题链接 [http://projecteuler.net/problem=54](http://projecteuler.net/problem=54)\n\n\nPoker hands\n\nIn the card game poker, a hand consists of five cards and are ranked, from lowest to highest, in the following way:\n\n*   **High Card**: Highest value card.\n*   **One Pair**: Two cards of the same value.\n*   **Two Pairs**: Two different pairs.\n*   **Three of a Kind**: Three cards of the same value.\n*   **Straight**: All cards are consecutive values.\n*   **Flush**: All cards of the same suit.\n*   **Full House**: Three of a kind and a pair.\n*   **Four of a Kind**: Four cards of the same value.\n*   **Straight Flush**: All cards are consecutive values of same suit.\n*   **Royal Flush**:Ten, Jack, Queen, King, Ace, in same suit.\nThe cards are valued in the order:\n2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace.\n\nIf two players have the same ranked hands then the rank made up of the highest value wins; for example, a pair of eights beats a pair of fives (see example 1 below). But if two ranks tie, for example, both players have a pair of queens, then highest cards in each hand are compared (see example 4 below); if the highest cards tie then the next highest cards are compared, and so on.\n\nConsider the following five hands dealt to two players:\n\n<table>\n<tbody>\n<tr>\n<td>**Hand**</td>\n<td></td>\n<td>**Player 1**</td>\n<td></td>\n<td>**Player 2**</td>\n<td></td>\n<td>**Winner**</td>\n</tr>\n<tr>\n<td>**1**</td>\n<td></td>\n<td>5H 5C 6S 7S KD\nPair of Fives</td>\n<td></td>\n<td>2C 3S 8S 8D TD\nPair of Eights</td>\n<td></td>\n<td>Player 2</td>\n</tr>\n<tr>\n<td>**2**</td>\n<td></td>\n<td>5D 8C 9S JS AC\nHighest card Ace</td>\n<td></td>\n<td>2C 5C 7D 8S QH\nHighest card Queen</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n<tr>\n<td>**3**</td>\n<td></td>\n<td>2D 9C AS AH AC\nThree Aces</td>\n<td></td>\n<td>3D 6D 7D TD QD\nFlush with Diamonds</td>\n<td></td>\n<td>Player 2</td>\n</tr>\n<tr>\n<td>**4**</td>\n<td></td>\n<td>4D 6S 9H QH QC\nPair of Queens\nHighest card Nine</td>\n<td></td>\n<td>3D 6D 7H QD QS\nPair of Queens\nHighest card Seven</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n<tr>\n<td>**5**</td>\n<td></td>\n<td>2H 2D 4C 4D 4S\nFull House\nWith Three Fours</td>\n<td></td>\n<td>3C 3D 3S 9S 9D\nFull House\nwith Three Threes</td>\n<td></td>\n<td>Player 1</td>\n</tr>\n</tbody>\n</table>\n\nThe file, [poker.txt](http://projecteuler.net/project/poker.txt), contains one-thousand random hands dealt to two players. Each line of the file contains ten cards (separated by a single space): the first five are Player 1's cards and the last five are Player 2's cards. You can assume that all hands are valid (no invalid characters or repeated cards), each player's hand is in no specific order, and in each hand there is a clear winner.\n\nHow many hands does Player 1 win?\n\n扑克手牌\n\n在扑克牌游戏中，一手牌由5张牌构成，有不同的等级，从最小到最大，规则如下：\n\n大牌：牌中最大的\n\n对子：两张相同的牌\n\n两对：有两对对子\n\n三条：三张相同的牌\n\n顺子：所有的牌是连续的\n\n同花：所有的牌是同一花色\n\n葫芦：三条和一对\n\n四条：四张相同的牌\n\n同花顺：所有的牌连续且是同花\n\n同花大顺：AKQJ10组成的同花顺\n\n牌值的顺序如下：\n\n2，3，4，5，6，7，8，9，10，J，Q，K，A\n\n如果两个玩家有相同等级的牌，则值更大的那个赢，例如一对8赢一对5（如下例1），但是如果等级相同，例如两个玩家都有一对Q，那么将比较手牌中的最大值（如下例4），如果最大的依然相同，则比较次大的，重复如上步骤。\n\n考虑如下5种两个玩家的对局情况：\n<table>\n<tbody>\n<tr>\n<td>**局**</td>\n<td></td>\n<td>**玩家1**</td>\n<td></td>\n<td>**玩家2**</td>\n<td></td>\n<td>**赢家**</td>\n</tr>\n<tr>\n<td>**1**</td>\n<td></td>\n<td>5H 5C 6S 7S KD\n一对5</td>\n<td></td>\n<td>2C 3S 8S 8D TD\n一对8</td>\n<td></td>\n<td>玩家2</td>\n</tr>\n<tr>\n<td>**2**</td>\n<td></td>\n<td>5D 8C 9S JS AC\n最大牌A</td>\n<td></td>\n<td>2C 5C 7D 8S QH\n最大牌Q</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n<tr>\n<td>**3**</td>\n<td></td>\n<td>2D 9C AS AH AC\n3张A</td>\n<td></td>\n<td>3D 6D 7D TD QD\n方块同花</td>\n<td></td>\n<td>玩家2</td>\n</tr>\n<tr>\n<td>**4**</td>\n<td></td>\n<td>4D 6S 9H QH QC\n一对Q\n最大9</td>\n<td></td>\n<td>3D 6D 7H QD QS\n一对Q\n最大7</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n<tr>\n<td>**5**</td>\n<td></td>\n<td>2H 2D 4C 4D 4S\n葫芦\n三个四</td>\n<td></td>\n<td>3C 3D 3S 9S 9D\n葫芦\n三个三</td>\n<td></td>\n<td>玩家1</td>\n</tr>\n</tbody>\n</table>\n​\n文件 [poker.txt](http://projecteuler.net/project/poker.txt)中包含一千次两个玩家的对局情况，每一行有10张牌（空格分开），前5张牌是玩家1的牌，后5张牌是玩家2的牌，你可以假设手牌都是有效的（没有无效字符和重复的牌），每个玩家的手牌都没有特殊顺序，并且每一对局一定有一个赢。\n\n求玩家1共赢了多少次。\n\n解答：\n\n这题好麻烦啊，写的代码真是乱。就是按照扑克牌的规则比较大小，真是很麻烦，一度令我有放弃欧拉工程的冲动，还好坚持下来了。\n\n\n","slug":"欧拉工程-问题54","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ds005w26s6jxfex6ca"},{"title":" 欧拉工程-问题53","id":"525","date":"2013-08-04T12:32:42.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=53](http://projecteuler.net/problem=53)\n\n#\n\nCombinatoric selections\n\nThere are exactly ten ways of selecting three from five, 12345:\n\n123, 124, 125, 134, 135, 145, 234, 235, 245, and 345\n\nIn combinatorics, we use the notation, <span style=\"font-size: medium;\">C(5,3)</span> = 10.\n\nIn general,\n\nC(n,r)=n!/(r!(n-r)!), where r <= n, n! = n * (n - 1) * ... * 3 * 2 * 1,and 0! = 1.\n\nIt is not until n = 23, that a value exceeds one-million: C(23,10) = 1144066.\n\nHow many, not necessarily distinct, values of  C(n,r), for 1 <= n <= 100, are greater than one-million？\n\n组合选择\n\n从五个，12345中选出三个一共有10中方法\n\n123, 124, 125, 134, 135, 145, 234, 235, 245, and 345\n\n在组合中我们使用记号C(5,3) = 10.\n\n一般来说\n\nC(n,r)=n!/(r!(n-r)!),r <= n, n! = n * (n - 1) * ... * 3 * 2 * 1, 且0! = 1\n\n直到n = 23,才出现值超过1000000: C(23,10) = 1144066.\n\n求一共有多少个值，没有必要是唯一的，使得C(n,r), 1 <=n<= 100,超过1000000？\n\n解答：\n\n遍历吧。\n","source":"_posts/欧拉工程-问题53.md","raw":"title: ' 欧拉工程-问题53'\ntags:\n  - 欧拉工程\n  - 阶乘\nid: 525\ncategories:\n  - 欧拉工程\ndate: 2013-08-04 20:32:42\n---\n\n原题链接 [http://projecteuler.net/problem=53](http://projecteuler.net/problem=53)\n\n#\n\nCombinatoric selections\n\nThere are exactly ten ways of selecting three from five, 12345:\n\n123, 124, 125, 134, 135, 145, 234, 235, 245, and 345\n\nIn combinatorics, we use the notation, <span style=\"font-size: medium;\">C(5,3)</span> = 10.\n\nIn general,\n\nC(n,r)=n!/(r!(n-r)!), where r <= n, n! = n * (n - 1) * ... * 3 * 2 * 1,and 0! = 1.\n\nIt is not until n = 23, that a value exceeds one-million: C(23,10) = 1144066.\n\nHow many, not necessarily distinct, values of  C(n,r), for 1 <= n <= 100, are greater than one-million？\n\n组合选择\n\n从五个，12345中选出三个一共有10中方法\n\n123, 124, 125, 134, 135, 145, 234, 235, 245, and 345\n\n在组合中我们使用记号C(5,3) = 10.\n\n一般来说\n\nC(n,r)=n!/(r!(n-r)!),r <= n, n! = n * (n - 1) * ... * 3 * 2 * 1, 且0! = 1\n\n直到n = 23,才出现值超过1000000: C(23,10) = 1144066.\n\n求一共有多少个值，没有必要是唯一的，使得C(n,r), 1 <=n<= 100,超过1000000？\n\n解答：\n\n遍历吧。\n","slug":"欧拉工程-问题53","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4dy006126s67k4pyugj"},{"title":"欧拉工程-问题52","id":"522","date":"2013-08-04T06:29:27.000Z","_content":"\n原题链接[http://projecteuler.net/problem=52](http://projecteuler.net/problem=52)\n\n\nPermuted multiples\n\nIt can be seen that the number, 125874, and its double, 251748, contain exactly the same digits, but in a different order.\n\nFind the smallest positive integer, _x_, such that 2_x_, 3_x_, 4_x_, 5_x_, and 6_x_, contain the same digits.\n倍数排列\n可以看到数125874和它的两倍251748，包含相同的数字，只是顺序不同。\n找出最小的正整数x,使得x,2x,3x,4x,5x,和6x包含相同的数字。\n\n解答：\n暴力吧，有一点要注意的是，第一个数字一定是1。\n","source":"_posts/欧拉工程-问题52.md","raw":"title: 欧拉工程-问题52\ntags:\n  - 倍数\n  - 排列\n  - 欧拉工程\nid: 522\ncategories:\n  - 欧拉工程\ndate: 2013-08-04 14:29:27\n---\n\n原题链接[http://projecteuler.net/problem=52](http://projecteuler.net/problem=52)\n\n\nPermuted multiples\n\nIt can be seen that the number, 125874, and its double, 251748, contain exactly the same digits, but in a different order.\n\nFind the smallest positive integer, _x_, such that 2_x_, 3_x_, 4_x_, 5_x_, and 6_x_, contain the same digits.\n倍数排列\n可以看到数125874和它的两倍251748，包含相同的数字，只是顺序不同。\n找出最小的正整数x,使得x,2x,3x,4x,5x,和6x包含相同的数字。\n\n解答：\n暴力吧，有一点要注意的是，第一个数字一定是1。\n","slug":"欧拉工程-问题52","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4e1006626s633y0a57s"},{"title":"欧拉工程-问题51","id":"518","date":"2013-08-04T06:26:14.000Z","_content":"\n原题链接[http://projecteuler.net/problem=51](http://projecteuler.net/problem=51)\n\n\nPrime digit replacements\n\nBy replacing the 1<sup>st</sup> digit of the 2-digit number *3, it turns out that six of the nine possible values: 13, 23, 43, 53, 73, and 83, are all prime.\n\nBy replacing the 3<sup>rd</sup> and 4<sup>th</sup> digits of 56**3 with the same digit, this 5-digit number is the first example having seven primes among the ten generated numbers, yielding the family: 56003, 56113, 56333, 56443, 56663, 56773, and 56993\\. Consequently 56003, being the first member of this family, is the smallest prime with this property.\n\nFind the smallest prime which, by replacing part of the number (not necessarily adjacent digits) with the same digit, is part of an eight prime value family.\n\n素数数字替换\n\n通过替换两位数*3的第一位数字，我们得到9个数字中的6个是素数：13，23，43，53，73和83.\n\n通过用同一数字替换数56**3的第3、4位，这个5位数是第一个数，使得替换之后的10个数中，有7个数是素数。这就形成一个家族，它们是：56003，56113，56333，56443，56773和56993。56003则是这个素数族的第一个成员，是具有这种性质的最小素数。\n\n找出最小的素数，通过用相同的数字替换这个素数中的一部分数字（没有必要想邻），可以得到一个素数，这个素数是8素数族的一部分。\n\n解答：\n\n一时还想不出好的办法，先空着。\n\n","source":"_posts/欧拉工程-问题51.md","raw":"title: 欧拉工程-问题51\ntags:\n  - 欧拉工程\n  - 素数族\nid: 518\ncategories:\n  - 欧拉工程\ndate: 2013-08-04 14:26:14\n---\n\n原题链接[http://projecteuler.net/problem=51](http://projecteuler.net/problem=51)\n\n\nPrime digit replacements\n\nBy replacing the 1<sup>st</sup> digit of the 2-digit number *3, it turns out that six of the nine possible values: 13, 23, 43, 53, 73, and 83, are all prime.\n\nBy replacing the 3<sup>rd</sup> and 4<sup>th</sup> digits of 56**3 with the same digit, this 5-digit number is the first example having seven primes among the ten generated numbers, yielding the family: 56003, 56113, 56333, 56443, 56663, 56773, and 56993\\. Consequently 56003, being the first member of this family, is the smallest prime with this property.\n\nFind the smallest prime which, by replacing part of the number (not necessarily adjacent digits) with the same digit, is part of an eight prime value family.\n\n素数数字替换\n\n通过替换两位数*3的第一位数字，我们得到9个数字中的6个是素数：13，23，43，53，73和83.\n\n通过用同一数字替换数56**3的第3、4位，这个5位数是第一个数，使得替换之后的10个数中，有7个数是素数。这就形成一个家族，它们是：56003，56113，56333，56443，56773和56993。56003则是这个素数族的第一个成员，是具有这种性质的最小素数。\n\n找出最小的素数，通过用相同的数字替换这个素数中的一部分数字（没有必要想邻），可以得到一个素数，这个素数是8素数族的一部分。\n\n解答：\n\n一时还想不出好的办法，先空着。\n\n","slug":"欧拉工程-问题51","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4e4006d26s6c6hn6hfx"},{"title":"欧拉工程-问题50","id":"509","date":"2013-07-28T04:27:29.000Z","_content":"\n原题链接[http://projecteuler.net/problem=50](http://projecteuler.net/problem=50)\n\n\nConsecutive prime sum\n\nThe prime 41, can be written as the sum of six consecutive primes:\n41 = 2 + 3 + 5 + 7 + 11 + 13\nThis is the longest sum of consecutive primes that adds to a prime below one-hundred.\n\nThe longest sum of consecutive primes below one-thousand that adds to a prime, contains 21 terms, and is equal to 953.\n\nWhich prime, below one-million, can be written as the sum of the most consecutive primes?\n\n连续素数的和\n素数41，可以写成6个连续素数的和：\n41 = 2 + 3 + 5 + 7 + 11 + 13\n这是100以下最长的连续素数的和等于一个素数\n1000以下最长的连续素数的和，包含21个数，等于953\n求1 000 000​以下能写成最长连续素数的和的素数\n\n​\n解法：\n不懂得数学方法，只好暴力了，先求出1000 000以下素数，之后双重循环。太暴力了，竟然用了18分钟，看来还是得想办法改进。果然还是有方法的，想办法生成一个三角形，最底层是1000 000以下素数，上一层是连续两个素数之和，再上一层是连续三个素数之和，。。最后一层就是所有素数之和，从上往下找，第一个小于1000000的素数就是答案。实际过程中，可以不用从最顶上开始找，可以从第一个大于1000000那一行开始往下找，然后由这一行的数生成下一行，继续找。","source":"_posts/欧拉工程-问题50.md","raw":"title: 欧拉工程-问题50\ntags:\n  - 欧拉工程\n  - 连续素数和\nid: 509\ncategories:\n  - 欧拉工程\ndate: 2013-07-28 12:27:29\n---\n\n原题链接[http://projecteuler.net/problem=50](http://projecteuler.net/problem=50)\n\n\nConsecutive prime sum\n\nThe prime 41, can be written as the sum of six consecutive primes:\n41 = 2 + 3 + 5 + 7 + 11 + 13\nThis is the longest sum of consecutive primes that adds to a prime below one-hundred.\n\nThe longest sum of consecutive primes below one-thousand that adds to a prime, contains 21 terms, and is equal to 953.\n\nWhich prime, below one-million, can be written as the sum of the most consecutive primes?\n\n连续素数的和\n素数41，可以写成6个连续素数的和：\n41 = 2 + 3 + 5 + 7 + 11 + 13\n这是100以下最长的连续素数的和等于一个素数\n1000以下最长的连续素数的和，包含21个数，等于953\n求1 000 000​以下能写成最长连续素数的和的素数\n\n​\n解法：\n不懂得数学方法，只好暴力了，先求出1000 000以下素数，之后双重循环。太暴力了，竟然用了18分钟，看来还是得想办法改进。果然还是有方法的，想办法生成一个三角形，最底层是1000 000以下素数，上一层是连续两个素数之和，再上一层是连续三个素数之和，。。最后一层就是所有素数之和，从上往下找，第一个小于1000000的素数就是答案。实际过程中，可以不用从最顶上开始找，可以从第一个大于1000000那一行开始往下找，然后由这一行的数生成下一行，继续找。","slug":"欧拉工程-问题50","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4e7006i26s6u9dlke5s"},{"title":"欧拉工程-问题5","id":"150","date":"2013-05-03T15:51:35.000Z","_content":"\n\n\n原题链接[http://projecteuler.net/problem=5](http://projecteuler.net/problem=5)\n\nSmallest multiple\n\n\n\n\n2520 is the smallest number that can be divided by each of the numbers from 1 to 10 without any remainder.\n\nWhat is the smallest positive number that is <dfn title=\"divisible with no remainder\">evenly divisible</dfn> by all of the numbers from 1 to 20?\n\n最小乘积\n\n2520是能够被1到10整除的正整数中最小的。\n\n求能够被1到20整除的正整数中最小的。\n\n解答：\n\n其实这题就是求1到10中的素数出现的最多次数，例如1到10中有素数2,3,5,7。其中2出现的次数最多为3次，即8；3出现的次数最多为2次，即9；其它为1次.所以最终的结果是8 * 9 * 5 * 7，即2520.\n\n对于1到20，则有素数2,3,5,7,11,13,17,19.其中2出现的次数最多为4次，即16；3出现的次数为2，即9；其它都为 1次。所以最终的结果是16 * 9 * 5 * 7 * 11 * 13 * 17 * 19。\n\n","source":"_posts/欧拉工程-问题5.md","raw":"title: 欧拉工程-问题5\ntags:\n  - 最小乘积\n  - 欧拉工程\nid: 150\ncategories:\n  - 欧拉工程\ndate: 2013-05-03 23:51:35\n---\n\n\n\n原题链接[http://projecteuler.net/problem=5](http://projecteuler.net/problem=5)\n\nSmallest multiple\n\n\n\n\n2520 is the smallest number that can be divided by each of the numbers from 1 to 10 without any remainder.\n\nWhat is the smallest positive number that is <dfn title=\"divisible with no remainder\">evenly divisible</dfn> by all of the numbers from 1 to 20?\n\n最小乘积\n\n2520是能够被1到10整除的正整数中最小的。\n\n求能够被1到20整除的正整数中最小的。\n\n解答：\n\n其实这题就是求1到10中的素数出现的最多次数，例如1到10中有素数2,3,5,7。其中2出现的次数最多为3次，即8；3出现的次数最多为2次，即9；其它为1次.所以最终的结果是8 * 9 * 5 * 7，即2520.\n\n对于1到20，则有素数2,3,5,7,11,13,17,19.其中2出现的次数最多为4次，即16；3出现的次数为2，即9；其它都为 1次。所以最终的结果是16 * 9 * 5 * 7 * 11 * 13 * 17 * 19。\n\n","slug":"欧拉工程-问题5","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ef006n26s6lu9bet63"},{"title":"欧拉工程-问题49","id":"505","date":"2013-07-27T07:30:54.000Z","_content":"\n原题链接[http://projecteuler.net/problem=49](http://projecteuler.net/problem=49)\n\n\nPrime permutations\n\n\n\n\nThe arithmetic sequence, 1487, 4817, 8147, in which each of the terms increases by 3330, is unusual in two ways: (i) each of the three terms are prime, and, (ii) each of the 4-digit numbers are permutations of one another.\n\nThere are no arithmetic sequences made up of three 1-, 2-, or 3-digit primes, exhibiting this property, but there is one other 4-digit increasing sequence.\n\nWhat 12-digit number do you form by concatenating the three terms in this sequence?\n\n\n\n素数排列\n算术序列1487，4817，8147是按照3330递增的，它有两个平常的性质：(1)这三个数都是素数 (2)这三个4位数中的每一个都是另一个的排列\n\n不存在1位，2位，3位具有这种性质的序列，但是还有另一个4位的具有这种性质的递增序列。\n\n求将这个序列中的三个数链接起来得到的12位数\n\n解答：\n没什么好说的，先生成一个素数判别表，之后就简单了。","source":"_posts/欧拉工程-问题49.md","raw":"title: 欧拉工程-问题49\ntags:\n  - 欧拉工程\n  - 素数\nid: 505\ncategories:\n  - 欧拉工程\ndate: 2013-07-27 15:30:54\n---\n\n原题链接[http://projecteuler.net/problem=49](http://projecteuler.net/problem=49)\n\n\nPrime permutations\n\n\n\n\nThe arithmetic sequence, 1487, 4817, 8147, in which each of the terms increases by 3330, is unusual in two ways: (i) each of the three terms are prime, and, (ii) each of the 4-digit numbers are permutations of one another.\n\nThere are no arithmetic sequences made up of three 1-, 2-, or 3-digit primes, exhibiting this property, but there is one other 4-digit increasing sequence.\n\nWhat 12-digit number do you form by concatenating the three terms in this sequence?\n\n\n\n素数排列\n算术序列1487，4817，8147是按照3330递增的，它有两个平常的性质：(1)这三个数都是素数 (2)这三个4位数中的每一个都是另一个的排列\n\n不存在1位，2位，3位具有这种性质的序列，但是还有另一个4位的具有这种性质的递增序列。\n\n求将这个序列中的三个数链接起来得到的12位数\n\n解答：\n没什么好说的，先生成一个素数判别表，之后就简单了。","slug":"欧拉工程-问题49","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4eh006s26s6uc9xvvnb"},{"title":"欧拉工程-问题48","id":"501","date":"2013-07-27T03:00:33.000Z","_content":"\n原题链接[http://projecteuler.net/problem=48](http://projecteuler.net/problem=48)\n\n\nSelf powers\n\nThe series, 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 10<sup>10</sup> = 10405071317.\n\nFind the last ten digits of the series, 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 1000<sup>1000</sup>.\n​自幂\n\n序列 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 10<sup>10</sup> = 10405071317\n求序列1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 1000<sup>1000</sup>​的最后十个数字​\n\n解答：\n无非是大数运算。在Python里很简单。暴力之，只是不知道有什么数学规律没，我想不到。","source":"_posts/欧拉工程-问题48.md","raw":"title: 欧拉工程-问题48\ntags:\n  - 大数运算\n  - 幂方\n  - 欧拉工程\nid: 501\ncategories:\n  - 欧拉工程\ndate: 2013-07-27 11:00:33\n---\n\n原题链接[http://projecteuler.net/problem=48](http://projecteuler.net/problem=48)\n\n\nSelf powers\n\nThe series, 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 10<sup>10</sup> = 10405071317.\n\nFind the last ten digits of the series, 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 1000<sup>1000</sup>.\n​自幂\n\n序列 1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 10<sup>10</sup> = 10405071317\n求序列1<sup>1</sup> + 2<sup>2</sup> + 3<sup>3</sup> + ... + 1000<sup>1000</sup>​的最后十个数字​\n\n解答：\n无非是大数运算。在Python里很简单。暴力之，只是不知道有什么数学规律没，我想不到。","slug":"欧拉工程-问题48","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ej006w26s63tgrds25"},{"title":"欧拉工程-问题47","id":"491","date":"2013-07-27T02:48:55.000Z","_content":"\n原题链接[http://projecteuler.net/problem=47](http://projecteuler.net/problem=47)\n\n\nDistinct primes factors\n\nThe first two consecutive numbers to have two distinct prime factors are:\n\n14 = 2 * 7\n15 = 3 * 5\n\nThe first three consecutive numbers to have three distinct prime factors are:\n644 = 2² * 7 * 23\n645 = 3 * 5 * 43\n646 = 2 * 17 * 19.\nFind the first four consecutive integers to have four distinct prime factors. What is the first of these numbers?\n\n不同的素数因子\n第一个连续两个数具有两个不同的素数因子的是：\n14 = 2 * 7\n15 = 3 * 5\n\n第一个连续三个数具有三个不同的素数因子的是：\n644 = 2² * 7 * 23\n645 = 3 * 5 * 43\n646 = 2 * 17 * 19.\n\n\n请找到第一个连续四个数具有四个不同的素数因子。这些数中的第一个是什么？\n\n解答：\n无非就是求素数因子，使用第3题中的方法，得到素数因子，剩下的就是暴力了。","source":"_posts/欧拉工程-问题47.md","raw":"title: 欧拉工程-问题47\ntags:\n  - 欧拉工程\n  - 素数因子\nid: 491\ncategories:\n  - 欧拉工程\ndate: 2013-07-27 10:48:55\n---\n\n原题链接[http://projecteuler.net/problem=47](http://projecteuler.net/problem=47)\n\n\nDistinct primes factors\n\nThe first two consecutive numbers to have two distinct prime factors are:\n\n14 = 2 * 7\n15 = 3 * 5\n\nThe first three consecutive numbers to have three distinct prime factors are:\n644 = 2² * 7 * 23\n645 = 3 * 5 * 43\n646 = 2 * 17 * 19.\nFind the first four consecutive integers to have four distinct prime factors. What is the first of these numbers?\n\n不同的素数因子\n第一个连续两个数具有两个不同的素数因子的是：\n14 = 2 * 7\n15 = 3 * 5\n\n第一个连续三个数具有三个不同的素数因子的是：\n644 = 2² * 7 * 23\n645 = 3 * 5 * 43\n646 = 2 * 17 * 19.\n\n\n请找到第一个连续四个数具有四个不同的素数因子。这些数中的第一个是什么？\n\n解答：\n无非就是求素数因子，使用第3题中的方法，得到素数因子，剩下的就是暴力了。","slug":"欧拉工程-问题47","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4el007226s6bdujs554"},{"title":"欧拉工程-问题46","id":"481","date":"2013-07-26T13:28:28.000Z","_content":"\n原题链接[http://projecteuler.net/problem=46](http://projecteuler.net/problem=46)\n\n\nGoldbach's other conjecture\n\nIt was proposed by Christian Goldbach that every odd composite number can be written as the sum of a prime and twice a square.\n\n9 = 7 + 2*1<sup>2</sup>\n15 = 7 + 2*2<sup>2</sup>\n21 = 3 + 2*3<sup>2</sup>\n25 = 7 + 2*3<sup>2</sup>\n27 = 19 + 2*2<sup>2</sup>\n33 = 31 + 2*1<sup>2</sup>\n\nIt turns out that the conjecture was false.\n\nWhat is the smallest odd composite that cannot be written as the sum of a prime and twice a square?\n\n\n哥德巴赫的另一个猜想\n这个猜想是克里斯蒂安.哥德巴赫提出的，它是这样的：任意一个合数，如果是奇数的话，则可以写成一个素数与一个平方数的两倍的和\n9 = 7 + 2*1<sup>2</sup>\n15 = 7 + 2*2<sup>2</sup>\n21 = 3 + 2*3<sup>2</sup>\n25 = 7 + 2*3<sup>2</sup>\n27 = 19 + 2*2<sup>2</sup>\n33 = 31 + 2*1<sup>2</sup>\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">结果这个猜想是错的。</span>\n求最小的不能写成一个素数与一个平方数的两倍的和的奇合数​\n\n解答：\n还是暴力吧。\n\n","source":"_posts/欧拉工程-问题46.md","raw":"title: 欧拉工程-问题46\ntags:\n  - 哥德巴赫的另一个猜想\n  - 欧拉工程\nid: 481\ncategories:\n  - 欧拉工程\ndate: 2013-07-26 21:28:28\n---\n\n原题链接[http://projecteuler.net/problem=46](http://projecteuler.net/problem=46)\n\n\nGoldbach's other conjecture\n\nIt was proposed by Christian Goldbach that every odd composite number can be written as the sum of a prime and twice a square.\n\n9 = 7 + 2*1<sup>2</sup>\n15 = 7 + 2*2<sup>2</sup>\n21 = 3 + 2*3<sup>2</sup>\n25 = 7 + 2*3<sup>2</sup>\n27 = 19 + 2*2<sup>2</sup>\n33 = 31 + 2*1<sup>2</sup>\n\nIt turns out that the conjecture was false.\n\nWhat is the smallest odd composite that cannot be written as the sum of a prime and twice a square?\n\n\n哥德巴赫的另一个猜想\n这个猜想是克里斯蒂安.哥德巴赫提出的，它是这样的：任意一个合数，如果是奇数的话，则可以写成一个素数与一个平方数的两倍的和\n9 = 7 + 2*1<sup>2</sup>\n15 = 7 + 2*2<sup>2</sup>\n21 = 3 + 2*3<sup>2</sup>\n25 = 7 + 2*3<sup>2</sup>\n27 = 19 + 2*2<sup>2</sup>\n33 = 31 + 2*1<sup>2</sup>\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">结果这个猜想是错的。</span>\n求最小的不能写成一个素数与一个平方数的两倍的和的奇合数​\n\n解答：\n还是暴力吧。\n\n","slug":"欧拉工程-问题46","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ep007726s64h5k3r7q"},{"title":"欧拉工程-问题45","id":"470","date":"2013-07-26T12:33:49.000Z","_content":"\n原题链接[http://projecteuler.net/problem=45](http://projecteuler.net/problem=45)\n\nTriangular, pentagonal, and hexagonal\n\nTriangle, pentagonal, and hexagonal numbers are generated by the following formulae:\n<table>\n<tbody>\n<tr>\n<td>Triangle</td>\n<td></td>\n<td>T(n)=_n_(_n_+1)/2</td>\n<td></td>\n<td>1, 3, 6, 10, 15, ...</td>\n</tr>\n<tr>\n<td>Pentagonal</td>\n<td></td>\n<td>P(n)=_n_(3_n-_1)/2</td>\n<td></td>\n<td>1, 5, 12, 22, 35, ...</td>\n</tr>\n<tr>\n<td>Hexagonal</td>\n<td></td>\n<td>H(n)=_n_(2_n-_1)</td>\n<td></td>\n<td>1, 6, 15, 28, 45, ...</td>\n</tr>\n</tbody>\n</table>\nIt can be verified that T(285) = P(165) = H(143) = 40755.\n\nFind the next triangle number that is also pentagonal and hexagonal.\n\n\n三角形的，五边形的和六边形的\n三角形的、五边形的和六边形的数可以由以下公式生成：\n三角形的 T(n)=n(n+1)/2 1,3,6,10,15,...\n五边形的 P(n)=n(3n-1)/2 1,5,12,22,35,...\n六边形的 H(n)=n(2n-1) 1,6,15,28,45,...\n可以验证T(285)=P(165)=H(143)=40755.\n求下一个既是五边形数，又是六边形数的三角形数。\n\n解法：\n没想到什么好的方法，只好暴力了。\n​\n","source":"_posts/欧拉工程-问题45.md","raw":"title: 欧拉工程-问题45\ntags:\n  - 三角形的\n  - 五边形的\n  - 六边形的\n  - 欧拉工程\nid: 470\ncategories:\n  - 欧拉工程\ndate: 2013-07-26 20:33:49\n---\n\n原题链接[http://projecteuler.net/problem=45](http://projecteuler.net/problem=45)\n\nTriangular, pentagonal, and hexagonal\n\nTriangle, pentagonal, and hexagonal numbers are generated by the following formulae:\n<table>\n<tbody>\n<tr>\n<td>Triangle</td>\n<td></td>\n<td>T(n)=_n_(_n_+1)/2</td>\n<td></td>\n<td>1, 3, 6, 10, 15, ...</td>\n</tr>\n<tr>\n<td>Pentagonal</td>\n<td></td>\n<td>P(n)=_n_(3_n-_1)/2</td>\n<td></td>\n<td>1, 5, 12, 22, 35, ...</td>\n</tr>\n<tr>\n<td>Hexagonal</td>\n<td></td>\n<td>H(n)=_n_(2_n-_1)</td>\n<td></td>\n<td>1, 6, 15, 28, 45, ...</td>\n</tr>\n</tbody>\n</table>\nIt can be verified that T(285) = P(165) = H(143) = 40755.\n\nFind the next triangle number that is also pentagonal and hexagonal.\n\n\n三角形的，五边形的和六边形的\n三角形的、五边形的和六边形的数可以由以下公式生成：\n三角形的 T(n)=n(n+1)/2 1,3,6,10,15,...\n五边形的 P(n)=n(3n-1)/2 1,5,12,22,35,...\n六边形的 H(n)=n(2n-1) 1,6,15,28,45,...\n可以验证T(285)=P(165)=H(143)=40755.\n求下一个既是五边形数，又是六边形数的三角形数。\n\n解法：\n没想到什么好的方法，只好暴力了。\n​\n","slug":"欧拉工程-问题45","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4er007c26s6prymzb1r"},{"title":"欧拉工程-问题44","id":"465","date":"2013-07-25T16:12:18.000Z","_content":"\n原题链接[http://projecteuler.net/problem=44](http://projecteuler.net/problem=44)\n\n\nPentagon numbers\n\nPentagonal numbers are generated by the formula, P(n)=<var>n</var>(3<var>n</var> − 1)/2. The first ten pentagonal numbers are:\n\n1, 5, 12, 22, 35, 51, 70, 92, 117, 145, ...\n\nIt can be seen that P(4) + P(7) = 22 + 70 = 92 = P(8). However, their difference, 70 − 22 = 48, is not pentagonal.\n\nFind the pair of pentagonal numbers, P(j)and P(k), for which their sum and difference are pentagonal and D = |P(k) − P(j)| is minimised; what is the value of D?\n\n五边形数\n五边形数可以由公式P(n) = n(3n-1)/2得到。前十个五边形数是\n\n1，5，12，22，35，51，70，92，117，145，。。。\n可以看到P(4) + P(7) = 22 + 70 = 92 = P(8).然而它们之间的差,70 - 22 = 48不是五边形数\n找到五边形数对，P(j)和P(k),使得它们的和与差都是五边形数，并且D=|P(k) - P(j)|最小，那么D的值是多少？\n\n解答：\n用蛮力解决了，正在思考数学方法。\n","source":"_posts/欧拉工程-问题44.md","raw":"title: 欧拉工程-问题44\ntags:\n  - 五边形数\n  - 欧拉工程\nid: 465\ncategories:\n  - 欧拉工程\ndate: 2013-07-26 00:12:18\n---\n\n原题链接[http://projecteuler.net/problem=44](http://projecteuler.net/problem=44)\n\n\nPentagon numbers\n\nPentagonal numbers are generated by the formula, P(n)=<var>n</var>(3<var>n</var> − 1)/2. The first ten pentagonal numbers are:\n\n1, 5, 12, 22, 35, 51, 70, 92, 117, 145, ...\n\nIt can be seen that P(4) + P(7) = 22 + 70 = 92 = P(8). However, their difference, 70 − 22 = 48, is not pentagonal.\n\nFind the pair of pentagonal numbers, P(j)and P(k), for which their sum and difference are pentagonal and D = |P(k) − P(j)| is minimised; what is the value of D?\n\n五边形数\n五边形数可以由公式P(n) = n(3n-1)/2得到。前十个五边形数是\n\n1，5，12，22，35，51，70，92，117，145，。。。\n可以看到P(4) + P(7) = 22 + 70 = 92 = P(8).然而它们之间的差,70 - 22 = 48不是五边形数\n找到五边形数对，P(j)和P(k),使得它们的和与差都是五边形数，并且D=|P(k) - P(j)|最小，那么D的值是多少？\n\n解答：\n用蛮力解决了，正在思考数学方法。\n","slug":"欧拉工程-问题44","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4eu007l26s6ayke7qyk"},{"title":"欧拉工程-问题43","id":"458","date":"2013-07-25T14:56:44.000Z","_content":"\n原题链接[http://projecteuler.net/problem=43](http://projecteuler.net/problem=43)\n\n\nSub-string divisibility\n\nThe number, 1406357289, is a 0 to 9 pandigital number because it is made up of each of the digits 0 to 9 in some order, but it also has a rather interesting sub-string divisibility property.\n\nLet d(1)be the 1<sup>st</sup> digit, d(2) be the 2<sup>nd</sup> digit, and so on. In this way, we note the following:\n\nd(2)d(3)d(4)=406 is divisible by 2\n\nd(3)d(4)d(5)=063 is divisible by 3\n\nd(4)d(5)d(6)=635  is divisible by 5\n\nd(5)d(6)d(7)=357  is divisible by 7\n\nd(6)d(7)d(8)=572  is divisible by 11\n\nd(7)d(8)d(9)=728 is divisible by 13\n\nd(8)d(9)d(10)=289  is divisible by 17\n\nFind the sum of all 0 to 9 pandigital numbers with this property.\n子串可除性\n数1406357289是一个0到9的全位数，因为它由0到9组成，每个数字出现一次，它有一个有趣的字串可除性特性\n令d(1)为第一个数字，d(2) 为第二个数字，以此类推。这种方式，我们注意如下：\nd(2)d(3)d(4)=406可以被2整除\nd(3)d(4)d(5)=063可以被3整除\nd(4)d(5)d(6)=635可以被5整除\nd(5)d(6)d(7)=357可以被7整除\nd(6)d(7)d(8)=572可以被11整除\nd(7)d(8)d(9)=728可以被13整除\nd(8)d(9)d(10)=289可以被17整除\n求所有具有这种性质的0到9的全位数的和\n\n解答：\n注意观察，观察，再观察，完全可以动手算出这题。而我不会写搜索的，只好写了一个非常丑陋的多重循环。\n","source":"_posts/欧拉工程-问题43.md","raw":"title: 欧拉工程-问题43\ntags:\n  - 推理\n  - 枚举\n  - 欧拉工程\nid: 458\ncategories:\n  - 欧拉工程\ndate: 2013-07-25 22:56:44\n---\n\n原题链接[http://projecteuler.net/problem=43](http://projecteuler.net/problem=43)\n\n\nSub-string divisibility\n\nThe number, 1406357289, is a 0 to 9 pandigital number because it is made up of each of the digits 0 to 9 in some order, but it also has a rather interesting sub-string divisibility property.\n\nLet d(1)be the 1<sup>st</sup> digit, d(2) be the 2<sup>nd</sup> digit, and so on. In this way, we note the following:\n\nd(2)d(3)d(4)=406 is divisible by 2\n\nd(3)d(4)d(5)=063 is divisible by 3\n\nd(4)d(5)d(6)=635  is divisible by 5\n\nd(5)d(6)d(7)=357  is divisible by 7\n\nd(6)d(7)d(8)=572  is divisible by 11\n\nd(7)d(8)d(9)=728 is divisible by 13\n\nd(8)d(9)d(10)=289  is divisible by 17\n\nFind the sum of all 0 to 9 pandigital numbers with this property.\n子串可除性\n数1406357289是一个0到9的全位数，因为它由0到9组成，每个数字出现一次，它有一个有趣的字串可除性特性\n令d(1)为第一个数字，d(2) 为第二个数字，以此类推。这种方式，我们注意如下：\nd(2)d(3)d(4)=406可以被2整除\nd(3)d(4)d(5)=063可以被3整除\nd(4)d(5)d(6)=635可以被5整除\nd(5)d(6)d(7)=357可以被7整除\nd(6)d(7)d(8)=572可以被11整除\nd(7)d(8)d(9)=728可以被13整除\nd(8)d(9)d(10)=289可以被17整除\n求所有具有这种性质的0到9的全位数的和\n\n解答：\n注意观察，观察，再观察，完全可以动手算出这题。而我不会写搜索的，只好写了一个非常丑陋的多重循环。\n","slug":"欧拉工程-问题43","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ey007q26s6525j4i7a"},{"title":"欧拉工程-问题42","id":"448","date":"2013-07-21T13:06:38.000Z","_content":"\n原题链接[http://projecteuler.net/problem=42](http://projecteuler.net/problem=42)\n\n\nCoded triangle numbers\n\nThe _n_<sup>th</sup> term of the sequence of triangle numbers is given by, t(n)= ½_n_(_n_+1); so the first ten triangle numbers are:\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\nBy converting each letter in a word to a number corresponding to its alphabetical position and adding these values we form a word value. For example, the word value for SKY is 19 + 11 + 25 = 55 = _t_<sub>10</sub>. If the word value is a triangle number then we shall call the word a triangle word.\n\nUsing [words.txt](http://projecteuler.net/project/words.txt) (right click and 'Save Link/Target As...'), a 16K text file containing nearly two-thousand common English words, how many are triangle words?\n\n三角数编码\n\n第n个三角数可以由t(n) = n * (n + 1) / 2给出，所以前面十个三角数是\n1，3，6，10，15，21，28，36，45，55，...\n将单词中的每个字母与一个数字相对应，这个数字是字母在字母表中的顺序相对应，将这些数字相加就的到字母的值。例如，单词SKY的值是19 + 11 + 25 <span style=\"font-family: 'Trebuchet MS', sans-serif;\">= 55 = t(10) 如果单词的值是三角数，那么我们就称这个单词为三角单词。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">使用[words.txt](http://projecteuler.net/project/words.txt) (鼠标右击，然后‘保存链接/目标另存为...')​,在这个16K的文本文件中包含将近2000个常用的英文单词。</span>\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">求一共有多少个三角单词。</span>\n\n解答：\n这题没有什么好说的，唯一要注意的一点是要去除单词两边的双引号。\n","source":"_posts/欧拉工程-问题42.md","raw":"title: 欧拉工程-问题42\ntags:\n  - 三角数\n  - 欧拉工程\nid: 448\ncategories:\n  - 欧拉工程\ndate: 2013-07-21 21:06:38\n---\n\n原题链接[http://projecteuler.net/problem=42](http://projecteuler.net/problem=42)\n\n\nCoded triangle numbers\n\nThe _n_<sup>th</sup> term of the sequence of triangle numbers is given by, t(n)= ½_n_(_n_+1); so the first ten triangle numbers are:\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\nBy converting each letter in a word to a number corresponding to its alphabetical position and adding these values we form a word value. For example, the word value for SKY is 19 + 11 + 25 = 55 = _t_<sub>10</sub>. If the word value is a triangle number then we shall call the word a triangle word.\n\nUsing [words.txt](http://projecteuler.net/project/words.txt) (right click and 'Save Link/Target As...'), a 16K text file containing nearly two-thousand common English words, how many are triangle words?\n\n三角数编码\n\n第n个三角数可以由t(n) = n * (n + 1) / 2给出，所以前面十个三角数是\n1，3，6，10，15，21，28，36，45，55，...\n将单词中的每个字母与一个数字相对应，这个数字是字母在字母表中的顺序相对应，将这些数字相加就的到字母的值。例如，单词SKY的值是19 + 11 + 25 <span style=\"font-family: 'Trebuchet MS', sans-serif;\">= 55 = t(10) 如果单词的值是三角数，那么我们就称这个单词为三角单词。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">使用[words.txt](http://projecteuler.net/project/words.txt) (鼠标右击，然后‘保存链接/目标另存为...')​,在这个16K的文本文件中包含将近2000个常用的英文单词。</span>\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif;\">求一共有多少个三角单词。</span>\n\n解答：\n这题没有什么好说的，唯一要注意的一点是要去除单词两边的双引号。\n","slug":"欧拉工程-问题42","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4f1007x26s6o1bja2nx"},{"title":"欧拉工程-问题41","id":"444","date":"2013-07-21T13:05:29.000Z","_content":"\n原题链接[http://projecteuler.net/problem=41](http://projecteuler.net/problem=41)\nPandigital prime\nWe shall say that an n-digit number is pandigital if it makes use of all the digits 1 to n exactly once. For example, 2143 is a 4-digit pandigital and is also prime.\nWhat is the largest n-digit pandigital prime that exists?\n\n全位素数\n我们称一个数是n位的全位数当这个数包含1到n正好一次，例如2143是一个四位的全位数，同时它也是一个素数。\n求最大的n位全位素数\n\n解法：\n还是暴力，从最大的9位素数开始往更小的素数找。方法太笨了，所以速度很慢。的确是太慢了，所以一定有更好的解决方法。经过观察，是不存在8位和9位的全位数是素数的情况，至于为什么，自己观察。\n​","source":"_posts/欧拉工程-问题41.md","raw":"title: 欧拉工程-问题41\ntags:\n  - 全位数\n  - 欧拉工程\n  - 素数\nid: 444\ncategories:\n  - 欧拉工程\ndate: 2013-07-21 21:05:29\n---\n\n原题链接[http://projecteuler.net/problem=41](http://projecteuler.net/problem=41)\nPandigital prime\nWe shall say that an n-digit number is pandigital if it makes use of all the digits 1 to n exactly once. For example, 2143 is a 4-digit pandigital and is also prime.\nWhat is the largest n-digit pandigital prime that exists?\n\n全位素数\n我们称一个数是n位的全位数当这个数包含1到n正好一次，例如2143是一个四位的全位数，同时它也是一个素数。\n求最大的n位全位素数\n\n解法：\n还是暴力，从最大的9位素数开始往更小的素数找。方法太笨了，所以速度很慢。的确是太慢了，所以一定有更好的解决方法。经过观察，是不存在8位和9位的全位数是素数的情况，至于为什么，自己观察。\n​","slug":"欧拉工程-问题41","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4f4008226s66459rxr4"},{"title":"欧拉工程-问题40","id":"421","date":"2013-07-18T13:11:05.000Z","_content":"\n原题链接[http://projecteuler.net/problem=40](http://projecteuler.net/problem=40)\n\n\nAn irrational decimal fraction is created by concatenating the positive integers:\n\n0.123456789101112131415161718192021...\n\nIt can be seen that the 12<sup>th</sup> digit of the fractional part is 1.\n\nIf d(n)represents the _n_<sup>th</sup> digit of the fractional part, find the value of the following expression.\n\nd(1) * d(10) * d(100) * d(1000) * d(10000) * d(100000) * d(1000000)\n\n\nChampernowne数\n将正整数连接起来可以得到一个无规则的十进制小数\n0.123456789101112131415161718192021...\n可以看到小数点后的第12位是1\n如果记d(n) 代表小数点后的第 _n_位，求下面表达式的值\nd(1) * d(10) * d(100) * d(1000) * d(10000) * d(100000) * d(1000000)\n\n解答：\n不知道数学解法，只好暴力了。\n\n","source":"_posts/欧拉工程-问题40.md","raw":"title: 欧拉工程-问题40\ntags:\n  - Champernowne数\n  - 欧拉工程\nid: 421\ncategories:\n  - 欧拉工程\ndate: 2013-07-18 21:11:05\n---\n\n原题链接[http://projecteuler.net/problem=40](http://projecteuler.net/problem=40)\n\n\nAn irrational decimal fraction is created by concatenating the positive integers:\n\n0.123456789101112131415161718192021...\n\nIt can be seen that the 12<sup>th</sup> digit of the fractional part is 1.\n\nIf d(n)represents the _n_<sup>th</sup> digit of the fractional part, find the value of the following expression.\n\nd(1) * d(10) * d(100) * d(1000) * d(10000) * d(100000) * d(1000000)\n\n\nChampernowne数\n将正整数连接起来可以得到一个无规则的十进制小数\n0.123456789101112131415161718192021...\n可以看到小数点后的第12位是1\n如果记d(n) 代表小数点后的第 _n_位，求下面表达式的值\nd(1) * d(10) * d(100) * d(1000) * d(10000) * d(100000) * d(1000000)\n\n解答：\n不知道数学解法，只好暴力了。\n\n","slug":"欧拉工程-问题40","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4f9008826s6hunnl33a"},{"title":"欧拉工程-问题4","id":"138","date":"2013-04-29T02:10:21.000Z","_content":"\n原题链接[http://projecteuler.net/problem=4](http://projecteuler.net/problem=4)\nLargest palindrome product\nA palindromic number reads the same both ways. The largest palindrome made from the product of two 2-digit numbers is 9009 = 91 * 99.\n\nFind the largest palindrome made from the product of two 3-digit numbers.\n\n最大的回文乘积\n\n回文数的定义是从左右两边读都是相同的。在两个两位数的乘积中，最大的回文数是9009 = 91 * 99.\n\n求两个三位数的乘积中，最大的回文数是什么？\n\n解法：\n这题没找到什么好的方法，暴力解决。","source":"_posts/欧拉工程-问题4.md","raw":"title: 欧拉工程-问题4\ntags:\n  - 回文数\n  - 欧拉工程\nid: 138\ncategories:\n  - 欧拉工程\ndate: 2013-04-29 10:10:21\n---\n\n原题链接[http://projecteuler.net/problem=4](http://projecteuler.net/problem=4)\nLargest palindrome product\nA palindromic number reads the same both ways. The largest palindrome made from the product of two 2-digit numbers is 9009 = 91 * 99.\n\nFind the largest palindrome made from the product of two 3-digit numbers.\n\n最大的回文乘积\n\n回文数的定义是从左右两边读都是相同的。在两个两位数的乘积中，最大的回文数是9009 = 91 * 99.\n\n求两个三位数的乘积中，最大的回文数是什么？\n\n解法：\n这题没找到什么好的方法，暴力解决。","slug":"欧拉工程-问题4","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4fw008d26s6f662e8vi"},{"title":"欧拉工程-问题39","id":"414","date":"2013-06-16T05:20:37.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=39](http://projecteuler.net/problem=39)\n\n\nInteger right triangles\n\n\n\n\nIf _p_ is the perimeter of a right angle triangle with integral length sides, {_a_,_b_,_c_}, there are exactly three solutions for _p_ = 120.\n\n{20,48,52}, {24,45,51}, {30,40,50}\n\nFor which value of _p_ <= 1000, is the number of solutions maximised?\n\n直角三角形的个数\n\n如果p是直角三角形的周长，它的三个边为{a,b,c},对于p = 120,正好有三个直角三角形\n\n{20,48,52},{24,45,51},{30,40,50}\n\n对于p <= 1000,求存在三角形个数最多的数\n\n解答：\n\n这题没什么好说的。\n\n","source":"_posts/欧拉工程-问题39.md","raw":"title: 欧拉工程-问题39\ntags:\n  - 欧拉工程\n  - 直角三角形\nid: 414\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 13:20:37\n---\n\n原题链接 [http://projecteuler.net/problem=39](http://projecteuler.net/problem=39)\n\n\nInteger right triangles\n\n\n\n\nIf _p_ is the perimeter of a right angle triangle with integral length sides, {_a_,_b_,_c_}, there are exactly three solutions for _p_ = 120.\n\n{20,48,52}, {24,45,51}, {30,40,50}\n\nFor which value of _p_ <= 1000, is the number of solutions maximised?\n\n直角三角形的个数\n\n如果p是直角三角形的周长，它的三个边为{a,b,c},对于p = 120,正好有三个直角三角形\n\n{20,48,52},{24,45,51},{30,40,50}\n\n对于p <= 1000,求存在三角形个数最多的数\n\n解答：\n\n这题没什么好说的。\n\n","slug":"欧拉工程-问题39","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4fz008h26s6fudq62l7"},{"title":"欧拉工程-问题38","id":"409","date":"2013-06-16T04:59:16.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=38](http://projecteuler.net/problem=38)\n\n\nPandigital multiples\n\n\n\n\nTake the number 192 and multiply it by each of 1, 2, and 3:\n\n192 * 1 = 192\n\n192 * 2 = 384\n\n192 * 3 = 576\n\nBy concatenating each product we get the 1 to 9 pandigital, 192384576\\. We will call 192384576 the concatenated product of 192 and (1,2,3)\n\nThe same can be achieved by starting with 9 and multiplying by 1, 2, 3, 4, and 5, giving the pandigital, 918273645, which is the concatenated product of 9 and (1,2,3,4,5).\n\nWhat is the largest 1 to 9 pandigital 9-digit number that can be formed as the concatenated product of an integer with (1,2, ... , <var>n</var>) where <var>n</var> >1?\n\n全位数乘数\n\n取数字192，将它乘以分别乘以1,2和3：\n\n192 * 1 = 192\n\n192 * 2 = 384\n\n192 * 3 = 576\n\n将这些乘积连接起来，我们将得到一个从1到9的全位数，192384576.我们称192384576为192和(1,2,3)的乘积连接\n\n类似的，我们可以从9开始，将它乘以1,2,3,4和5，得到一个全位数，918273645，即为9和(1,2,3,4,5)的乘积连接。\n\n求由一个整数和(1,2,...,n, n > 1)的乘积连接中得到的1到9的全位数中，最大的那个。\n\n解法：\n\n这题没什么好说的。\n\n","source":"_posts/欧拉工程-问题38.md","raw":"title: 欧拉工程-问题38\ntags:\n  - 全位数\n  - 欧拉工程\nid: 409\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 12:59:16\n---\n\n原题链接 [http://projecteuler.net/problem=38](http://projecteuler.net/problem=38)\n\n\nPandigital multiples\n\n\n\n\nTake the number 192 and multiply it by each of 1, 2, and 3:\n\n192 * 1 = 192\n\n192 * 2 = 384\n\n192 * 3 = 576\n\nBy concatenating each product we get the 1 to 9 pandigital, 192384576\\. We will call 192384576 the concatenated product of 192 and (1,2,3)\n\nThe same can be achieved by starting with 9 and multiplying by 1, 2, 3, 4, and 5, giving the pandigital, 918273645, which is the concatenated product of 9 and (1,2,3,4,5).\n\nWhat is the largest 1 to 9 pandigital 9-digit number that can be formed as the concatenated product of an integer with (1,2, ... , <var>n</var>) where <var>n</var> >1?\n\n全位数乘数\n\n取数字192，将它乘以分别乘以1,2和3：\n\n192 * 1 = 192\n\n192 * 2 = 384\n\n192 * 3 = 576\n\n将这些乘积连接起来，我们将得到一个从1到9的全位数，192384576.我们称192384576为192和(1,2,3)的乘积连接\n\n类似的，我们可以从9开始，将它乘以1,2,3,4和5，得到一个全位数，918273645，即为9和(1,2,3,4,5)的乘积连接。\n\n求由一个整数和(1,2,...,n, n > 1)的乘积连接中得到的1到9的全位数中，最大的那个。\n\n解法：\n\n这题没什么好说的。\n\n","slug":"欧拉工程-问题38","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4g1008m26s6sxanpok5"},{"title":"欧拉工程-问题37","id":"404","date":"2013-06-16T04:40:41.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=37](http://projecteuler.net/problem=37)\n\n\nTruncatable primes\n\n\n\n\nThe number 3797 has an interesting property. Being prime itself, it is possible to continuously remove digits from left to right, and remain prime at each stage: 3797, 797, 97, and 7\\. Similarly we can work from right to left: 3797, 379, 37, and 3.\n\nFind the sum of the only eleven primes that are both truncatable from left to right and right to left.\n\nNOTE: 2, 3, 5, and 7 are not considered to be truncatable primes.\n\n可截断的素数\n\n数3797有一个有趣的特性。它本身是素数，而且从左到右删除数字依然是素数：3797,797,97和7.类似的，从右到左也是这样：3797,379,37，和3.\n\n求唯一的11个从左到右，从右到左都可截断的素数的和\n\n注意：2,3,5，和7不认为是可截断的素数\n\n解答：\n\n这题没什么好说的。依然是筛法生成素数表，只是不知道素数到底会大到什么程度，所以写的有些丑陋。\n\n","source":"_posts/欧拉工程-问题37.md","raw":"title: 欧拉工程-问题37\ntags:\n  - 欧拉工程\n  - 筛法\n  - 素数\nid: 404\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 12:40:41\n---\n\n原题链接 [http://projecteuler.net/problem=37](http://projecteuler.net/problem=37)\n\n\nTruncatable primes\n\n\n\n\nThe number 3797 has an interesting property. Being prime itself, it is possible to continuously remove digits from left to right, and remain prime at each stage: 3797, 797, 97, and 7\\. Similarly we can work from right to left: 3797, 379, 37, and 3.\n\nFind the sum of the only eleven primes that are both truncatable from left to right and right to left.\n\nNOTE: 2, 3, 5, and 7 are not considered to be truncatable primes.\n\n可截断的素数\n\n数3797有一个有趣的特性。它本身是素数，而且从左到右删除数字依然是素数：3797,797,97和7.类似的，从右到左也是这样：3797,379,37，和3.\n\n求唯一的11个从左到右，从右到左都可截断的素数的和\n\n注意：2,3,5，和7不认为是可截断的素数\n\n解答：\n\n这题没什么好说的。依然是筛法生成素数表，只是不知道素数到底会大到什么程度，所以写的有些丑陋。\n\n","slug":"欧拉工程-问题37","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4g4008q26s6s67fmc31"},{"title":"欧拉工程-问题36","id":"395","date":"2013-06-16T03:37:26.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=36](http://projecteuler.net/problem=36)\n\n\nDouble-base palindromes\n\n\n\n\nThe decimal number, 585 = 1001001001 (binary), is palindromic in both bases.\n\nFind the sum of all numbers, less than one million, which are palindromic in base 10 and base 2.\n\n(Please note that the palindromic number, in either base, may not include leading zeros.)\n\n双进制回文数\n\n对于10进制数，585 = 1001001001(二进制),在两种进制下都是回文数。\n\n求小于1 000 000的数，求所有满足10进制和二进制都是回文数的数的和\n\n(注意，对于所有的回文数，在任何进制中，都不包括开头中的0)\n\n解答：\n\n这题没什么好说的，无非就是进制的转换以及判断回文数。\n\n","source":"_posts/欧拉工程-问题36.md","raw":"title: 欧拉工程-问题36\ntags:\n  - 回文数\n  - 欧拉工程\n  - 进制\nid: 395\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 11:37:26\n---\n\n原题链接 [http://projecteuler.net/problem=36](http://projecteuler.net/problem=36)\n\n\nDouble-base palindromes\n\n\n\n\nThe decimal number, 585 = 1001001001 (binary), is palindromic in both bases.\n\nFind the sum of all numbers, less than one million, which are palindromic in base 10 and base 2.\n\n(Please note that the palindromic number, in either base, may not include leading zeros.)\n\n双进制回文数\n\n对于10进制数，585 = 1001001001(二进制),在两种进制下都是回文数。\n\n求小于1 000 000的数，求所有满足10进制和二进制都是回文数的数的和\n\n(注意，对于所有的回文数，在任何进制中，都不包括开头中的0)\n\n解答：\n\n这题没什么好说的，无非就是进制的转换以及判断回文数。\n\n","slug":"欧拉工程-问题36","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4g9008v26s6dg2jd7vl"},{"title":"欧拉工程-问题35","id":"390","date":"2013-06-16T03:17:09.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=35](http://projecteuler.net/problem=35)\nCircular primes\nThe number, 197, is called a circular prime because all rotations of the digits: 197, 971, and 719, are themselves prime.\n\nThere are thirteen such primes below 100: 2, 3, 5, 7, 11, 13, 17, 31, 37, 71, 73, 79, and 97.\n\nHow many circular primes are there below one million?\n\n循环素数\n\n对于数字，197，我们称它为循环素数，这是因为旋转数的数字得到的所有数：197，971和719都是素数\n\n100一下一共有13个这种素数：2,3,5,7,11,13,17,31,37,71,73,79和97.\n\n求1000000一下，一共有多少个循环素数？\n\n解答：\n关键还是生成一个素数判断表，用筛法。其它没什么好说的。","source":"_posts/欧拉工程-问题35.md","raw":"title: 欧拉工程-问题35\ntags:\n  - 欧拉工程\n  - 筛法\n  - 素数\nid: 390\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 11:17:09\n---\n\n原题链接 [http://projecteuler.net/problem=35](http://projecteuler.net/problem=35)\nCircular primes\nThe number, 197, is called a circular prime because all rotations of the digits: 197, 971, and 719, are themselves prime.\n\nThere are thirteen such primes below 100: 2, 3, 5, 7, 11, 13, 17, 31, 37, 71, 73, 79, and 97.\n\nHow many circular primes are there below one million?\n\n循环素数\n\n对于数字，197，我们称它为循环素数，这是因为旋转数的数字得到的所有数：197，971和719都是素数\n\n100一下一共有13个这种素数：2,3,5,7,11,13,17,31,37,71,73,79和97.\n\n求1000000一下，一共有多少个循环素数？\n\n解答：\n关键还是生成一个素数判断表，用筛法。其它没什么好说的。","slug":"欧拉工程-问题35","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4gi009126s6mtftwk2m"},{"title":"欧拉工程-问题34","id":"386","date":"2013-06-16T03:15:07.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=34](http://projecteuler.net/problem=34)\n\n\nDigit factorials\n\n\n\n\n145 is a curious number, as 1! + 4! + 5! = 1 + 24 + 120 = 145.\n\nFind the sum of all numbers which are equal to the sum of the factorial of their digits.\n\nNote: as 1! = 1 and 2! = 2 are not sums they are not included.\n\n数字的阶乘\n\n145是一个特殊的数字，因为1! + 4! + 5! = 1 + 24 + 120 = 145.\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求所有满足数的每位数的阶乘之和等于数本身这个条件的数的和</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：因为1！= 1 和 2！= 2不是和，所以没有被包括进来。</span>","source":"_posts/欧拉工程-问题34.md","raw":"title: 欧拉工程-问题34\ntags:\n  - 欧拉工程\n  - 阶乘\nid: 386\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 11:15:07\n---\n\n原题链接 [http://projecteuler.net/problem=34](http://projecteuler.net/problem=34)\n\n\nDigit factorials\n\n\n\n\n145 is a curious number, as 1! + 4! + 5! = 1 + 24 + 120 = 145.\n\nFind the sum of all numbers which are equal to the sum of the factorial of their digits.\n\nNote: as 1! = 1 and 2! = 2 are not sums they are not included.\n\n数字的阶乘\n\n145是一个特殊的数字，因为1! + 4! + 5! = 1 + 24 + 120 = 145.\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求所有满足数的每位数的阶乘之和等于数本身这个条件的数的和</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：因为1！= 1 和 2！= 2不是和，所以没有被包括进来。</span>","slug":"欧拉工程-问题34","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4gl009626s6cjyxz7ur"},{"title":"欧拉工程-问题33","id":"381","date":"2013-06-16T01:59:32.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=33](http://projecteuler.net/problem=33)\n\n\nDigit canceling fractions\n\n\n\n\nThe fraction <sup>49</sup>/<sub>98</sub> is a curious fraction, as an inexperienced mathematician in attempting to simplify it may incorrectly believe that<sup>49</sup>/<sub>98</sub> = <sup>4</sup>/<sub>8</sub>, which is correct, is obtained by cancelling the 9s.\n\nWe shall consider fractions like, <sup>30</sup>/<sub>50</sub> = <sup>3</sup>/<sub>5</sub>, to be trivial examples.\n\nThere are exactly four non-trivial examples of this type of fraction, less than one in value, and containing two digits in the numerator and denominator.\n\nIf the product of these four fractions is given in its lowest common terms, find the value of the denominator.\n\n数字约分\n\n分数49/98是一个特殊的分数，对于一个不熟练的数学爱好者在尝试化简它时，可能会错误地消去9，认为49/98 = 4 / 8,最终的到的结果是正确的。\n\n对于分数30/50 = 3/5,我们认为这是平凡的例子\n\n正好存在4个这种不平凡的分数，它们的值小于1，分子和分母都是两位数。\n\n如果将这四个分数的乘积化简为最简形式，得到的分母是什么？\n\n解答：\n\n这题没什么好说的。\n\n","source":"_posts/欧拉工程-问题33.md","raw":"title: 欧拉工程-问题33\ntags:\n  - 分数化简\n  - 欧拉工程\nid: 381\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 09:59:32\n---\n\n原题链接 [http://projecteuler.net/problem=33](http://projecteuler.net/problem=33)\n\n\nDigit canceling fractions\n\n\n\n\nThe fraction <sup>49</sup>/<sub>98</sub> is a curious fraction, as an inexperienced mathematician in attempting to simplify it may incorrectly believe that<sup>49</sup>/<sub>98</sub> = <sup>4</sup>/<sub>8</sub>, which is correct, is obtained by cancelling the 9s.\n\nWe shall consider fractions like, <sup>30</sup>/<sub>50</sub> = <sup>3</sup>/<sub>5</sub>, to be trivial examples.\n\nThere are exactly four non-trivial examples of this type of fraction, less than one in value, and containing two digits in the numerator and denominator.\n\nIf the product of these four fractions is given in its lowest common terms, find the value of the denominator.\n\n数字约分\n\n分数49/98是一个特殊的分数，对于一个不熟练的数学爱好者在尝试化简它时，可能会错误地消去9，认为49/98 = 4 / 8,最终的到的结果是正确的。\n\n对于分数30/50 = 3/5,我们认为这是平凡的例子\n\n正好存在4个这种不平凡的分数，它们的值小于1，分子和分母都是两位数。\n\n如果将这四个分数的乘积化简为最简形式，得到的分母是什么？\n\n解答：\n\n这题没什么好说的。\n\n","slug":"欧拉工程-问题33","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4gn009a26s66pbv97ak"},{"title":"欧拉工程-问题32","id":"375","date":"2013-06-16T01:30:13.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=32](http://projecteuler.net/problem=32)\n\n\nPandigital products\n\n\n\n\nWe shall say that an <var>n</var>-digit number is pandigital if it makes use of all the digits 1 to <var>n</var> exactly once; for example, the 5-digit number, 15234, is 1 through 5 pandigital.\n\nThe product 7254 is unusual, as the identity, 39  * 186 = 7254, containing multiplicand, multiplier, and product is 1 through 9 pandigital.\n\nFind the sum of all products whose multiplicand/multiplier/product identity can be written as a 1 through 9 pandigital.\nHINT: Some products can be obtained in more than one way so be sure to only include it once in your sum.\n\n\n全位数乘积\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">如果一个n位数恰好使用1到n各一次，我们称这个数为全位数；例如，5位数，15234，是一个1到5的全位数。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\"> </span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">乘积7254不寻常，对于恒等式 39 * 186 = 7254，包括被乘数，乘数，乘积，正好是一个1到9的全位数</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\"> </span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求所有满足被乘数，乘数，乘积这个恒等式是从1到9的全位数这个条件的乘积的和。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">提示：有些乘积可以有不只一种形式，要确保只计算一次。</span>\n解法：\n这题没什么好说的。","source":"_posts/欧拉工程-问题32.md","raw":"title: 欧拉工程-问题32\ntags:\n  - 全位数\n  - 欧拉工程\nid: 375\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 09:30:13\n---\n\n原题链接 [http://projecteuler.net/problem=32](http://projecteuler.net/problem=32)\n\n\nPandigital products\n\n\n\n\nWe shall say that an <var>n</var>-digit number is pandigital if it makes use of all the digits 1 to <var>n</var> exactly once; for example, the 5-digit number, 15234, is 1 through 5 pandigital.\n\nThe product 7254 is unusual, as the identity, 39  * 186 = 7254, containing multiplicand, multiplier, and product is 1 through 9 pandigital.\n\nFind the sum of all products whose multiplicand/multiplier/product identity can be written as a 1 through 9 pandigital.\nHINT: Some products can be obtained in more than one way so be sure to only include it once in your sum.\n\n\n全位数乘积\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">如果一个n位数恰好使用1到n各一次，我们称这个数为全位数；例如，5位数，15234，是一个1到5的全位数。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\"> </span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">乘积7254不寻常，对于恒等式 39 * 186 = 7254，包括被乘数，乘数，乘积，正好是一个1到9的全位数</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\"> </span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求所有满足被乘数，乘数，乘积这个恒等式是从1到9的全位数这个条件的乘积的和。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">提示：有些乘积可以有不只一种形式，要确保只计算一次。</span>\n解法：\n这题没什么好说的。","slug":"欧拉工程-问题32","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4gq009f26s6bbioktdl"},{"title":"欧拉工程-问题31","id":"369","date":"2013-06-16T01:10:01.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=31](http://projecteuler.net/problem=31)\n\n\nCoin sums\n\n\n\n\nIn England the currency is made up of pound, £, and pence, p, and there are eight coins in general circulation:\n\n1p, 2p, 5p, 10p, 20p, 50p, £1 (100p) and £2 (200p).\n\nIt is possible to make £2 in the following way:\n\n1*£1 + 1*50p + 2*20p + 1*5p + 1*2p + 3*1p\n\nHow many different ways can £2 be made using any number of coins?\n\n硬币的和\n\n在英国，货币单位有磅(£),便士(p),一共有八种硬币发行：\n\n1p, 2p, 5p, 10p, 20p, 50p, £1 (100p) and £2 (200p).\n\n对于£2可以有以下组成形式：\n\n1*£1 + 1*50p + 2*20p + 1*5p + 1*2p + 3*1p\n\n求£2的组成方式一共有多少种？\n\n解法：\n\n这是一个多重背包问题。两个循环解决问题，注意循环的顺序。\n\n","source":"_posts/欧拉工程-问题31.md","raw":"title: 欧拉工程-问题31\ntags:\n  - 动态规划\n  - 多重背包\n  - 欧拉工程\nid: 369\ncategories:\n  - 欧拉工程\ndate: 2013-06-16 09:10:01\n---\n\n原题链接 [http://projecteuler.net/problem=31](http://projecteuler.net/problem=31)\n\n\nCoin sums\n\n\n\n\nIn England the currency is made up of pound, £, and pence, p, and there are eight coins in general circulation:\n\n1p, 2p, 5p, 10p, 20p, 50p, £1 (100p) and £2 (200p).\n\nIt is possible to make £2 in the following way:\n\n1*£1 + 1*50p + 2*20p + 1*5p + 1*2p + 3*1p\n\nHow many different ways can £2 be made using any number of coins?\n\n硬币的和\n\n在英国，货币单位有磅(£),便士(p),一共有八种硬币发行：\n\n1p, 2p, 5p, 10p, 20p, 50p, £1 (100p) and £2 (200p).\n\n对于£2可以有以下组成形式：\n\n1*£1 + 1*50p + 2*20p + 1*5p + 1*2p + 3*1p\n\n求£2的组成方式一共有多少种？\n\n解法：\n\n这是一个多重背包问题。两个循环解决问题，注意循环的顺序。\n\n","slug":"欧拉工程-问题31","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4gy009j26s6mn40xjkg"},{"title":"欧拉工程-问题30","id":"358","date":"2013-06-15T15:39:05.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=30](http://projecteuler.net/problem=30)\n\n\nDigit fifth powers\n\n\n\n\nSurprisingly there are only three numbers that can be written as the sum of fourth powers of their digits:\n\n1634 = 1<sup>4</sup> + 6<sup>4</sup> + 3<sup>4</sup> + 4<sup>4</sup>\n8208 = 8<sup>4</sup> + 2<sup>4</sup> + 0<sup>4</sup> + 8<sup>4</sup>\n9474 = 9<sup>4</sup> + 4<sup>4</sup> + 7<sup>4</sup> + 4<sup>4</sup>\n\nAs 1 = 1<sup>4</sup> is not a sum it is not included.\n\nThe sum of these numbers is 1634 + 8208 + 9474 = 19316.\n\nFind the sum of all the numbers that can be written as the sum of fifth powers of their digits.\n\n数字的5次幂\n\n令人惊奇的是只存在3个数可以写成数的每位数字的4次幂的和\n\n1634 = 1<sup>4</sup> + 6<sup>4</sup> + 3<sup>4</sup> + 4<sup>4</sup>\n8208 = 8<sup>4</sup> + 2<sup>4</sup> + 0<sup>4</sup> + 8<sup>4</sup>\n9474 = 9<sup>4</sup> + 4<sup>4</sup> + 7<sup>4</sup> + 4<sup>4</sup>\n\n这里1 = 1<sup>4</sup> 不是和所以没有包括进来\n\n这些数字的和为1634 + 8208 + 9474 = 19316.\n\n<span style=\"font-size: medium;\">求所有满足数的每位数字的5次幂等于数本身这个条件的数的和</span>\n\n解法：\n\n没什么好说的。\n\n","source":"_posts/欧拉工程-问题30.md","raw":"title: 欧拉工程-问题30\ntags:\n  - 幂\n  - 欧拉工程\nid: 358\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 23:39:05\n---\n\n原题链接 [http://projecteuler.net/problem=30](http://projecteuler.net/problem=30)\n\n\nDigit fifth powers\n\n\n\n\nSurprisingly there are only three numbers that can be written as the sum of fourth powers of their digits:\n\n1634 = 1<sup>4</sup> + 6<sup>4</sup> + 3<sup>4</sup> + 4<sup>4</sup>\n8208 = 8<sup>4</sup> + 2<sup>4</sup> + 0<sup>4</sup> + 8<sup>4</sup>\n9474 = 9<sup>4</sup> + 4<sup>4</sup> + 7<sup>4</sup> + 4<sup>4</sup>\n\nAs 1 = 1<sup>4</sup> is not a sum it is not included.\n\nThe sum of these numbers is 1634 + 8208 + 9474 = 19316.\n\nFind the sum of all the numbers that can be written as the sum of fifth powers of their digits.\n\n数字的5次幂\n\n令人惊奇的是只存在3个数可以写成数的每位数字的4次幂的和\n\n1634 = 1<sup>4</sup> + 6<sup>4</sup> + 3<sup>4</sup> + 4<sup>4</sup>\n8208 = 8<sup>4</sup> + 2<sup>4</sup> + 0<sup>4</sup> + 8<sup>4</sup>\n9474 = 9<sup>4</sup> + 4<sup>4</sup> + 7<sup>4</sup> + 4<sup>4</sup>\n\n这里1 = 1<sup>4</sup> 不是和所以没有包括进来\n\n这些数字的和为1634 + 8208 + 9474 = 19316.\n\n<span style=\"font-size: medium;\">求所有满足数的每位数字的5次幂等于数本身这个条件的数的和</span>\n\n解法：\n\n没什么好说的。\n\n","slug":"欧拉工程-问题30","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4h1009q26s6kf8wjiky"},{"title":"欧拉工程-问题3","id":"130","date":"2013-04-29T01:41:47.000Z","_content":"\n原题链接[http://projecteuler.net/problem=3](http://projecteuler.net/problem=3)\n\nLargest prime factor\nThe prime factors of 13195 are 5, 7, 13 and 29.\n\nWhat is the largest prime factor of the number 600851475143 ?\n\n最大的素数因子\n\n整数13195的素数因子有5, 7, 13和29.\n\n求数600851475143的最大素数因子？\n\n解法：\n这一题本来想先求出600851475143的以内的素数，然后再从最小的素数开始，找到它的最大因子。可是程序运行时出现了OverflowError: Python int too large to convert to C long错误，也就是600851475143已经超出了C语言中整型的范围，这是因为xrange这个函数的范围限制在C的long长度，在32位的机器中，传入xrange的数不能大于2 ** 31 - 1.上网找这个错误时，在[StackOverFlow](http://stackoverflow.com/questions/9816603/range-is-too-large-python/9833011#9833011)中找到了这个错误的解答，其中有一个人给出了一个方法。\n下面举例来说明这个方法，例如要求360的素数因子，先从素数2开始，360一直除以2知道不在整除，得到45；之后一直除以素数3知道不能整除，得到5；之后3 + 2得到5，于是除以5，得到1，结束。","source":"_posts/欧拉工程-问题3.md","raw":"title: 欧拉工程-问题3\ntags:\n  - 最大素数因子\n  - 欧拉工程\nid: 130\ncategories:\n  - 欧拉工程\ndate: 2013-04-29 09:41:47\n---\n\n原题链接[http://projecteuler.net/problem=3](http://projecteuler.net/problem=3)\n\nLargest prime factor\nThe prime factors of 13195 are 5, 7, 13 and 29.\n\nWhat is the largest prime factor of the number 600851475143 ?\n\n最大的素数因子\n\n整数13195的素数因子有5, 7, 13和29.\n\n求数600851475143的最大素数因子？\n\n解法：\n这一题本来想先求出600851475143的以内的素数，然后再从最小的素数开始，找到它的最大因子。可是程序运行时出现了OverflowError: Python int too large to convert to C long错误，也就是600851475143已经超出了C语言中整型的范围，这是因为xrange这个函数的范围限制在C的long长度，在32位的机器中，传入xrange的数不能大于2 ** 31 - 1.上网找这个错误时，在[StackOverFlow](http://stackoverflow.com/questions/9816603/range-is-too-large-python/9833011#9833011)中找到了这个错误的解答，其中有一个人给出了一个方法。\n下面举例来说明这个方法，例如要求360的素数因子，先从素数2开始，360一直除以2知道不在整除，得到45；之后一直除以素数3知道不能整除，得到5；之后3 + 2得到5，于是除以5，得到1，结束。","slug":"欧拉工程-问题3","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4h5009v26s6uoga7x40"},{"title":"欧拉工程-问题29","id":"350","date":"2013-06-15T15:38:46.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=29](http://projecteuler.net/problem=29)\n\n\n\nDistinct powers\n\n\n\n\nConsider all integer combinations of _a_<sup>_b_</sup> for 2 <= _a_  <= 5 and 2 <= _b_  <= 5:\n\n2<sup>2</sup>=4, 2<sup>3</sup>=8, 2<sup>4</sup>=16, 2<sup>5</sup>=32\n3<sup>2</sup>=9, 3<sup>3</sup>=27, 3<sup>4</sup>=81, 3<sup>5</sup>=243\n4<sup>2</sup>=16, 4<sup>3</sup>=64, 4<sup>4</sup>=256, 4<sup>5</sup>=1024\n5<sup>2</sup>=25, 5<sup>3</sup>=125, 5<sup>4</sup>=625, 5<sup>5</sup>=3125\n\nIf they are then placed in numerical order, with any repeats removed, we get the following sequence of 15 distinct terms:\n\n4, 8, 9, 16, 25, 27, 32, 64, 81, 125, 243, 256, 625, 1024, 3125\n\nHow many distinct terms are in the sequence generated by _a_<sup>_b_</sup> for 2  <= _a_ <= 100 and 2 <= _b_  <= 100?\n\n唯一的幂方\n\n考虑_a_<sup>_b_</sup>形式的所有整数，其中2 <= a <= 5,2 <= b <= 5:\n\n2<sup>2</sup>=4, 2<sup>3</sup>=8, 2<sup>4</sup>=16, 2<sup>5</sup>=32\n3<sup>2</sup>=9, 3<sup>3</sup>=27, 3<sup>4</sup>=81, 3<sup>5</sup>=243\n4<sup>2</sup>=16, 4<sup>3</sup>=64, 4<sup>4</sup>=256, 4<sup>5</sup>=1024\n5<sup>2</sup>=25, 5<sup>3</sup>=125, 5<sup>4</sup>=625, 5<sup>5</sup>=3125\n\n如果将它们按大小排序，去除重复数字，我们可以得到如下15个唯一的数：\n\n4, 8, 9, 16, 25, 27, 32, 64, 81, 125, 243, 256, 625, 1024, 3125\n\n求在_a_<sup>_b_</sup> 其中 2 <= _a_ <= 100 ，2  <= _b_  <= 100中，唯一的数有多少个？\n\n解法：\n\n这里用一个set来存。数学方法还没想到。\n\n","source":"_posts/欧拉工程-问题29.md","raw":"title: 欧拉工程-问题29\ntags:\n  - 幂方\n  - 欧拉工程\nid: 350\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 23:38:46\n---\n\n原题链接 [http://projecteuler.net/problem=29](http://projecteuler.net/problem=29)\n\n\n\nDistinct powers\n\n\n\n\nConsider all integer combinations of _a_<sup>_b_</sup> for 2 <= _a_  <= 5 and 2 <= _b_  <= 5:\n\n2<sup>2</sup>=4, 2<sup>3</sup>=8, 2<sup>4</sup>=16, 2<sup>5</sup>=32\n3<sup>2</sup>=9, 3<sup>3</sup>=27, 3<sup>4</sup>=81, 3<sup>5</sup>=243\n4<sup>2</sup>=16, 4<sup>3</sup>=64, 4<sup>4</sup>=256, 4<sup>5</sup>=1024\n5<sup>2</sup>=25, 5<sup>3</sup>=125, 5<sup>4</sup>=625, 5<sup>5</sup>=3125\n\nIf they are then placed in numerical order, with any repeats removed, we get the following sequence of 15 distinct terms:\n\n4, 8, 9, 16, 25, 27, 32, 64, 81, 125, 243, 256, 625, 1024, 3125\n\nHow many distinct terms are in the sequence generated by _a_<sup>_b_</sup> for 2  <= _a_ <= 100 and 2 <= _b_  <= 100?\n\n唯一的幂方\n\n考虑_a_<sup>_b_</sup>形式的所有整数，其中2 <= a <= 5,2 <= b <= 5:\n\n2<sup>2</sup>=4, 2<sup>3</sup>=8, 2<sup>4</sup>=16, 2<sup>5</sup>=32\n3<sup>2</sup>=9, 3<sup>3</sup>=27, 3<sup>4</sup>=81, 3<sup>5</sup>=243\n4<sup>2</sup>=16, 4<sup>3</sup>=64, 4<sup>4</sup>=256, 4<sup>5</sup>=1024\n5<sup>2</sup>=25, 5<sup>3</sup>=125, 5<sup>4</sup>=625, 5<sup>5</sup>=3125\n\n如果将它们按大小排序，去除重复数字，我们可以得到如下15个唯一的数：\n\n4, 8, 9, 16, 25, 27, 32, 64, 81, 125, 243, 256, 625, 1024, 3125\n\n求在_a_<sup>_b_</sup> 其中 2 <= _a_ <= 100 ，2  <= _b_  <= 100中，唯一的数有多少个？\n\n解法：\n\n这里用一个set来存。数学方法还没想到。\n\n","slug":"欧拉工程-问题29","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4h800a026s634xo2t7s"},{"title":"欧拉工程-问题28","id":"345","date":"2013-06-15T15:38:39.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=28](http://projecteuler.net/problem=28)\n\n\nNumber spiral diagonals\n\n\n\n\nStarting with the number 1 and moving to the right in a clockwise direction a 5 by 5 spiral is formed as follows:\n\n**21** 22 23 24 **25**\n20  **7**  8  **9** 10\n19  6  **1**  2 11\n18  **5**  4  **3** 12\n**17** 16 15 14 **13**\n\nIt can be verified that the sum of the numbers on the diagonals is 101.\n\nWhat is the sum of the numbers on the diagonals in a 1001 by 1001 spiral formed in the same way?\n\n数字螺旋的对角线\n\n从1开始向右顺时针方向螺旋得到一个5 * 5的螺旋数如下：\n\n**21** 22 23 24 **25**\n20  **7**  8  **9** 10\n19  6  **1**  2 11\n18  **5**  4  **3** 12\n**17** 16 15 14 **13**\n\n可以验证对角线上的数之和为101\n\n求以相同形式构成的1001 * 1001的螺旋数的对角线之和。\n\n解答：\n\n这题没什么好说的，就是找规律。\n\n","source":"_posts/欧拉工程-问题28.md","raw":"title: 欧拉工程-问题28\ntags:\n  - 欧拉工程\n  - 螺旋\nid: 345\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 23:38:39\n---\n\n原题链接 [http://projecteuler.net/problem=28](http://projecteuler.net/problem=28)\n\n\nNumber spiral diagonals\n\n\n\n\nStarting with the number 1 and moving to the right in a clockwise direction a 5 by 5 spiral is formed as follows:\n\n**21** 22 23 24 **25**\n20  **7**  8  **9** 10\n19  6  **1**  2 11\n18  **5**  4  **3** 12\n**17** 16 15 14 **13**\n\nIt can be verified that the sum of the numbers on the diagonals is 101.\n\nWhat is the sum of the numbers on the diagonals in a 1001 by 1001 spiral formed in the same way?\n\n数字螺旋的对角线\n\n从1开始向右顺时针方向螺旋得到一个5 * 5的螺旋数如下：\n\n**21** 22 23 24 **25**\n20  **7**  8  **9** 10\n19  6  **1**  2 11\n18  **5**  4  **3** 12\n**17** 16 15 14 **13**\n\n可以验证对角线上的数之和为101\n\n求以相同形式构成的1001 * 1001的螺旋数的对角线之和。\n\n解答：\n\n这题没什么好说的，就是找规律。\n\n","slug":"欧拉工程-问题28","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4hk00a426s6om17j45t"},{"title":"欧拉工程-问题27","id":"335","date":"2013-06-15T15:37:48.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=27](http://projecteuler.net/problem=27)\n\nQuadratic primes\n\nEuler discovered the remarkable quadratic formula:\n\n_n_² + _n_ + 41\n\nIt turns out that the formula will produce 40 primes for the consecutive values _n_ = 0 to 39\\. However, when _n_ = 40, 40<sup>2</sup> + 40 + 41 = 40(40 + 1) + 41 is divisible by 41, and certainly when _n_ = 41, 41² + 41 + 41 is clearly divisible by 41.\n\nThe incredible formula  _n_² -79_n_ + 1601 was discovered, which produces 80 primes for the consecutive values _n_ = 0 to 79\\. The product of the coefficients, -79 and 1601, is -126479.\n\nConsidering quadratics of the form:\n\n_n_² + _an_ + _b_, where |_a_| <1000 and |_b_| <1000\nwhere |_n_| is the modulus/absolute value of _n_\n_ e.g. |11| = 11 and |-4| = 4_\nFind the product of the coefficients, _a_ and _b_, for the quadratic expression that produces the maximum number of primes for consecutive values of _n_, starting with _n_ = 0.\n\n二项式素数\n\n欧拉发现著名的二项式公式：\n\n_n_² + _n_ + 41\n\n当n从0到39时，这个公式可以产生40个连续的素数。然而，当n = 40时, 40<sup>2</sup> + 40 + 41 = 40(40 + 1) + 41可以被41整除,毫无疑问的,当n = 41时，41² + 41 + 41可以被41整除\n\n另一个惊人的公式_n_² ![−](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/32FB5CDF0BD546C0BE622982593696C7/symbol_minus.gif) 79_n_ + 1601 被发现，这个公式当n = 0到79时可以产生80个连续的素数。两个系数-79和1601的乘积为-126479.\n\n考虑如下的二项式形式\n\n_n_² + _an_ + _b_, 且|_a_| <1000 ， |_b_| <1000\n\n这里 |_n_| 是 _n的绝对值_\ne.g. |11| = 11 and |-4| = 4\n\n求对于这个二项式表达式，从n = 0开始，连续产生最多素数的系数a和b的乘积。\n\n解法：\n\n这题没什么好说的，先用筛法生成一个素数判断表，之后就是遍历了。\n","source":"_posts/欧拉工程-问题27.md","raw":"title: 欧拉工程-问题27\ntags:\n  - 二项式公式\n  - 欧拉工程\n  - 素数\nid: 335\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 23:37:48\n---\n\n原题链接 [http://projecteuler.net/problem=27](http://projecteuler.net/problem=27)\n\nQuadratic primes\n\nEuler discovered the remarkable quadratic formula:\n\n_n_² + _n_ + 41\n\nIt turns out that the formula will produce 40 primes for the consecutive values _n_ = 0 to 39\\. However, when _n_ = 40, 40<sup>2</sup> + 40 + 41 = 40(40 + 1) + 41 is divisible by 41, and certainly when _n_ = 41, 41² + 41 + 41 is clearly divisible by 41.\n\nThe incredible formula  _n_² -79_n_ + 1601 was discovered, which produces 80 primes for the consecutive values _n_ = 0 to 79\\. The product of the coefficients, -79 and 1601, is -126479.\n\nConsidering quadratics of the form:\n\n_n_² + _an_ + _b_, where |_a_| <1000 and |_b_| <1000\nwhere |_n_| is the modulus/absolute value of _n_\n_ e.g. |11| = 11 and |-4| = 4_\nFind the product of the coefficients, _a_ and _b_, for the quadratic expression that produces the maximum number of primes for consecutive values of _n_, starting with _n_ = 0.\n\n二项式素数\n\n欧拉发现著名的二项式公式：\n\n_n_² + _n_ + 41\n\n当n从0到39时，这个公式可以产生40个连续的素数。然而，当n = 40时, 40<sup>2</sup> + 40 + 41 = 40(40 + 1) + 41可以被41整除,毫无疑问的,当n = 41时，41² + 41 + 41可以被41整除\n\n另一个惊人的公式_n_² ![−](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/32FB5CDF0BD546C0BE622982593696C7/symbol_minus.gif) 79_n_ + 1601 被发现，这个公式当n = 0到79时可以产生80个连续的素数。两个系数-79和1601的乘积为-126479.\n\n考虑如下的二项式形式\n\n_n_² + _an_ + _b_, 且|_a_| <1000 ， |_b_| <1000\n\n这里 |_n_| 是 _n的绝对值_\ne.g. |11| = 11 and |-4| = 4\n\n求对于这个二项式表达式，从n = 0开始，连续产生最多素数的系数a和b的乘积。\n\n解法：\n\n这题没什么好说的，先用筛法生成一个素数判断表，之后就是遍历了。\n","slug":"欧拉工程-问题27","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4hv00a926s6zz4csof9"},{"title":"欧拉工程-问题26","id":"322","date":"2013-06-15T15:37:28.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=26](http://projecteuler.net/problem=26)\n\n\nReciprocal cycles\n\n\n\n\nA unit fraction contains 1 in the numerator. The decimal representation of the unit fractions with denominators 2 to 10 are given:\n\n<sup>1</sup>/<sub>2</sub>= 0.5\n\n<sup>1</sup>/<sub>3</sub>= 0.(3)\n\n<sup>1</sup>/<sub>4</sub>= 0.25\n\n<sup>1</sup>/<sub>5</sub>= 0.2\n\n<sup>1</sup>/<sub>6</sub>= 0.1(6)\n\n<sup>1</sup>/<sub>7</sub>= 0.(142857)\n\n<sup>1</sup>/<sub>8</sub>= 0.125\n\n<sup>1</sup>/<sub>9</sub>= 0.(1)\n\n<sup>1</sup>/<sub>10</sub>= 0.1\n\nWhere 0.1(6) means 0.166666..., and has a 1-digit recurring cycle. It can be seen that <sup>1</sup>/<sub>7</sub> has a 6-digit recurring cycle.\n\nFind the value of _d_ ![<](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/A3CBA8A8420C404E87F8E517902F6949/symbol_lt.gif) 1000 for which <sup>1</sup>/<sub>_d_</sub> contains the longest recurring cycle in its decimal fraction part.\n\n倒数循环\n\n单分数指的是分子为1的分数。分母为2到10的单分数的小数表示为：\n\n<sup>1</sup>/<sub>2</sub>= 0.5\n\n<sup>1</sup>/<sub>3</sub>= 0.(3)\n\n<sup>1</sup>/<sub>4</sub>= 0.25\n\n<sup>1</sup>/<sub>5</sub>= 0.2\n\n<sup>1</sup>/<sub>6</sub>= 0.1(6)\n\n<sup>1</sup>/<sub>7</sub>= 0.(142857)\n\n<sup>1</sup>/<sub>8</sub>= 0.125\n\n<sup>1</sup>/<sub>9</sub>= 0.(1)\n\n<sup>1</sup>/<sub>10</sub>= 0.1\n\n其中0.1（6）表示0.166666...,也就是有一个循环数字.可以看到1/7有6个循环数字.\n\n求d < 1000中 1/d包含最多循环数字的那个d.\n\n解法：\n\n这题还没想好。\n\n更新于2013年8月15日：问题解决了，现在才知道，如果尝试自己去实现表示无穷小数，就会发现规律。\n\n","source":"_posts/欧拉工程-问题26.md","raw":"title: 欧拉工程-问题26\ntags:\n  - 单分数\n  - 循环小数\n  - 欧拉工程\nid: 322\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 23:37:28\n---\n\n原题链接 [http://projecteuler.net/problem=26](http://projecteuler.net/problem=26)\n\n\nReciprocal cycles\n\n\n\n\nA unit fraction contains 1 in the numerator. The decimal representation of the unit fractions with denominators 2 to 10 are given:\n\n<sup>1</sup>/<sub>2</sub>= 0.5\n\n<sup>1</sup>/<sub>3</sub>= 0.(3)\n\n<sup>1</sup>/<sub>4</sub>= 0.25\n\n<sup>1</sup>/<sub>5</sub>= 0.2\n\n<sup>1</sup>/<sub>6</sub>= 0.1(6)\n\n<sup>1</sup>/<sub>7</sub>= 0.(142857)\n\n<sup>1</sup>/<sub>8</sub>= 0.125\n\n<sup>1</sup>/<sub>9</sub>= 0.(1)\n\n<sup>1</sup>/<sub>10</sub>= 0.1\n\nWhere 0.1(6) means 0.166666..., and has a 1-digit recurring cycle. It can be seen that <sup>1</sup>/<sub>7</sub> has a 6-digit recurring cycle.\n\nFind the value of _d_ ![<](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/A3CBA8A8420C404E87F8E517902F6949/symbol_lt.gif) 1000 for which <sup>1</sup>/<sub>_d_</sub> contains the longest recurring cycle in its decimal fraction part.\n\n倒数循环\n\n单分数指的是分子为1的分数。分母为2到10的单分数的小数表示为：\n\n<sup>1</sup>/<sub>2</sub>= 0.5\n\n<sup>1</sup>/<sub>3</sub>= 0.(3)\n\n<sup>1</sup>/<sub>4</sub>= 0.25\n\n<sup>1</sup>/<sub>5</sub>= 0.2\n\n<sup>1</sup>/<sub>6</sub>= 0.1(6)\n\n<sup>1</sup>/<sub>7</sub>= 0.(142857)\n\n<sup>1</sup>/<sub>8</sub>= 0.125\n\n<sup>1</sup>/<sub>9</sub>= 0.(1)\n\n<sup>1</sup>/<sub>10</sub>= 0.1\n\n其中0.1（6）表示0.166666...,也就是有一个循环数字.可以看到1/7有6个循环数字.\n\n求d < 1000中 1/d包含最多循环数字的那个d.\n\n解法：\n\n这题还没想好。\n\n更新于2013年8月15日：问题解决了，现在才知道，如果尝试自己去实现表示无穷小数，就会发现规律。\n\n","slug":"欧拉工程-问题26","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4hz00af26s6f2eg27ez"},{"title":"欧拉工程-问题25","id":"308","date":"2013-06-15T08:15:40.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=25](http://projecteuler.net/problem=25)\n\n\n1000-digit Fibonacci number\n\n\n\n\nThe Fibonacci sequence is defined by the recurrence relation:\n\nF(n) = F(n-1)+ F(n-2), where F<sub>1</sub> = 1 and F<sub>2</sub> = 1.\n\nHence the first 12 terms will be:\n\nF<sub>1</sub> = 1\nF<sub>2</sub> = 1\nF<sub>3</sub> = 2\nF<sub>4</sub> = 3\nF<sub>5</sub> = 5\nF<sub>6</sub> = 8\nF<sub>7</sub> = 13\nF<sub>8</sub> = 21\nF<sub>9</sub> = 34\nF<sub>10</sub> = 55\nF<sub>11</sub> = 89\nF<sub>12</sub> = 144\n\n_The 12th term, F<sub>12</sub>, is the first term to contain three digits._\n\nWhat is the first term in the Fibonacci sequence to contain 1000 digits?\n\n1000个数字的斐波纳契数\n\n斐波那契数列由如下递归关系定义：\n\nF(n) = F(n-1)+ F(n-2), 且 F<sub>1</sub> = 1 ，F<sub>2</sub> = 1\n\n因此数列的前12项为：\n\nF<sub>1</sub> = 1\nF<sub>2</sub> = 1\nF<sub>3</sub> = 2\nF<sub>4</sub> = 3\nF<sub>5</sub> = 5\nF<sub>6</sub> = 8\nF<sub>7</sub> = 13\nF<sub>8</sub> = 21\nF<sub>9</sub> = 34\nF<sub>10</sub> = 55\nF<sub>11</sub> = 89\nF<sub>12</sub> = 144\n\n第12项，即是第一个包含三个数字的项\n\n求数列中第一个包含1000个数字的项\n\n解法：\n\n用第二题中的方法，生成斐波那契数列，之后判断。\n\n","source":"_posts/欧拉工程-问题25.md","raw":"title: 欧拉工程-问题25\ntags:\n  - 斐波那契数列\n  - 欧拉工程\nid: 308\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 16:15:40\n---\n\n原题链接 [http://projecteuler.net/problem=25](http://projecteuler.net/problem=25)\n\n\n1000-digit Fibonacci number\n\n\n\n\nThe Fibonacci sequence is defined by the recurrence relation:\n\nF(n) = F(n-1)+ F(n-2), where F<sub>1</sub> = 1 and F<sub>2</sub> = 1.\n\nHence the first 12 terms will be:\n\nF<sub>1</sub> = 1\nF<sub>2</sub> = 1\nF<sub>3</sub> = 2\nF<sub>4</sub> = 3\nF<sub>5</sub> = 5\nF<sub>6</sub> = 8\nF<sub>7</sub> = 13\nF<sub>8</sub> = 21\nF<sub>9</sub> = 34\nF<sub>10</sub> = 55\nF<sub>11</sub> = 89\nF<sub>12</sub> = 144\n\n_The 12th term, F<sub>12</sub>, is the first term to contain three digits._\n\nWhat is the first term in the Fibonacci sequence to contain 1000 digits?\n\n1000个数字的斐波纳契数\n\n斐波那契数列由如下递归关系定义：\n\nF(n) = F(n-1)+ F(n-2), 且 F<sub>1</sub> = 1 ，F<sub>2</sub> = 1\n\n因此数列的前12项为：\n\nF<sub>1</sub> = 1\nF<sub>2</sub> = 1\nF<sub>3</sub> = 2\nF<sub>4</sub> = 3\nF<sub>5</sub> = 5\nF<sub>6</sub> = 8\nF<sub>7</sub> = 13\nF<sub>8</sub> = 21\nF<sub>9</sub> = 34\nF<sub>10</sub> = 55\nF<sub>11</sub> = 89\nF<sub>12</sub> = 144\n\n第12项，即是第一个包含三个数字的项\n\n求数列中第一个包含1000个数字的项\n\n解法：\n\n用第二题中的方法，生成斐波那契数列，之后判断。\n\n","slug":"欧拉工程-问题25","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4i500am26s67kkp4khe"},{"title":"欧拉工程-问题24","id":"306","date":"2013-06-15T07:05:14.000Z","_content":"\n原文链接 [http://projecteuler.net/problem=24](http://projecteuler.net/problem=24)\n\n\n\nLexicographic permutations\n\n\n\n\nA permutation is an ordered arrangement of objects. For example, 3124 is one possible permutation of the digits 1, 2, 3 and 4\\. If all of the permutations are listed numerically or alphabetically, we call it lexicographic order. The lexicographic permutations of 0, 1 and 2 are:\n\n012   021   102   120   201   210\n\nWhat is the millionth lexicographic permutation of the digits 0, 1, 2, 3, 4, 5, 6, 7, 8 and 9?\n\n&nbsp;\n\n字典排列\n\n排列是指将一些东西进行有序排列。例如，3124就是数字1,2,3和4的一种排列。如果将所有排列按照数字序或者字母序列出，我们称之为字典序排列。0,1和2的字典序排列是：\n\n012   021   102   120   201   210\n\n求0,1,2,3,4,5,6,7,8和9的字典序排列中第一百万个排列。\n\n解法：\n\n写一个函数，用非递归方法生成下一个排列，具体方法到算法书找。有了这个函数后，一个循环就可以搞定。\n\n&nbsp;\n\n","source":"_posts/欧拉工程-问题24.md","raw":"title: 欧拉工程-问题24\ntags:\n  - 全排列\n  - 欧拉工程\n  - 非递归\nid: 306\ncategories:\n  - 欧拉工程\ndate: 2013-06-15 15:05:14\n---\n\n原文链接 [http://projecteuler.net/problem=24](http://projecteuler.net/problem=24)\n\n\n\nLexicographic permutations\n\n\n\n\nA permutation is an ordered arrangement of objects. For example, 3124 is one possible permutation of the digits 1, 2, 3 and 4\\. If all of the permutations are listed numerically or alphabetically, we call it lexicographic order. The lexicographic permutations of 0, 1 and 2 are:\n\n012   021   102   120   201   210\n\nWhat is the millionth lexicographic permutation of the digits 0, 1, 2, 3, 4, 5, 6, 7, 8 and 9?\n\n&nbsp;\n\n字典排列\n\n排列是指将一些东西进行有序排列。例如，3124就是数字1,2,3和4的一种排列。如果将所有排列按照数字序或者字母序列出，我们称之为字典序排列。0,1和2的字典序排列是：\n\n012   021   102   120   201   210\n\n求0,1,2,3,4,5,6,7,8和9的字典序排列中第一百万个排列。\n\n解法：\n\n写一个函数，用非递归方法生成下一个排列，具体方法到算法书找。有了这个函数后，一个循环就可以搞定。\n\n&nbsp;\n\n","slug":"欧拉工程-问题24","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4i900ar26s61ege0al0"},{"title":"欧拉工程-问题23","id":"302","date":"2013-06-10T16:26:54.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=23](http://projecteuler.net/problem=23)\n\n\nNon-abundant sums\n\n\n\n\nA perfect number is a number for which the sum of its proper divisors is exactly equal to the number. For example, the sum of the proper divisors of 28 would be 1 + 2 + 4 + 7 + 14 = 28, which means that 28 is a perfect number.\n\nA number <var>n</var> is called deficient if the sum of its proper divisors is less than <var>n</var> and it is called abundant if this sum exceeds <var>n</var>.\n\nAs 12 is the smallest abundant number, 1 + 2 + 3 + 4 + 6 = 16, the smallest number that can be written as the sum of two abundant numbers is 24\\. By mathematical analysis, it can be shown that all integers greater than 28123 can be written as the sum of two abundant numbers. However, this upper limit cannot be reduced any further by analysis even though it is known that the greatest number that cannot be expressed as the sum of two abundant numbers is less than this limit.\n\nFind the sum of all the positive integers which cannot be written as the sum of two abundant numbers.\n\n非盈数之和\n\n如果一个数的所有真因子之和等于数本身，则这个数被称为完美数。例如，28的所有真因子之和为1 + 2 + 4 + 7 + 14 = 28，这也就是说28是一个完美数。\n\n一个数的所有真因子之和如果小于这个数则这个数称为亏数，如果大于这个数，则这个数称为盈数。\n\n12是最小的盈数，因为1 + 2 + 3 + 4 + 6 = 16。能够被写成两个盈数之和的数是24.通过数学分析，可以知道，大于28123的所有整数都可以写成两个盈数之和。然而，通过分析，无法推断出这个上限，即使已经知道不能被表示成两个盈数之和的数中最大的数不会超过这个限制。\n\n求所有不能被表示成两个盈数之和的正整数之和。\n\n这题没什么好说的，直接算就是了。\n\n","source":"_posts/欧拉工程-问题23.md","raw":"title: 欧拉工程-问题23\ntags:\n  - 亏数\n  - 完美数\n  - 欧拉工程\n  - 盈数\nid: 302\ncategories:\n  - 欧拉工程\ndate: 2013-06-11 00:26:54\n---\n\n原题链接 [http://projecteuler.net/problem=23](http://projecteuler.net/problem=23)\n\n\nNon-abundant sums\n\n\n\n\nA perfect number is a number for which the sum of its proper divisors is exactly equal to the number. For example, the sum of the proper divisors of 28 would be 1 + 2 + 4 + 7 + 14 = 28, which means that 28 is a perfect number.\n\nA number <var>n</var> is called deficient if the sum of its proper divisors is less than <var>n</var> and it is called abundant if this sum exceeds <var>n</var>.\n\nAs 12 is the smallest abundant number, 1 + 2 + 3 + 4 + 6 = 16, the smallest number that can be written as the sum of two abundant numbers is 24\\. By mathematical analysis, it can be shown that all integers greater than 28123 can be written as the sum of two abundant numbers. However, this upper limit cannot be reduced any further by analysis even though it is known that the greatest number that cannot be expressed as the sum of two abundant numbers is less than this limit.\n\nFind the sum of all the positive integers which cannot be written as the sum of two abundant numbers.\n\n非盈数之和\n\n如果一个数的所有真因子之和等于数本身，则这个数被称为完美数。例如，28的所有真因子之和为1 + 2 + 4 + 7 + 14 = 28，这也就是说28是一个完美数。\n\n一个数的所有真因子之和如果小于这个数则这个数称为亏数，如果大于这个数，则这个数称为盈数。\n\n12是最小的盈数，因为1 + 2 + 3 + 4 + 6 = 16。能够被写成两个盈数之和的数是24.通过数学分析，可以知道，大于28123的所有整数都可以写成两个盈数之和。然而，通过分析，无法推断出这个上限，即使已经知道不能被表示成两个盈数之和的数中最大的数不会超过这个限制。\n\n求所有不能被表示成两个盈数之和的正整数之和。\n\n这题没什么好说的，直接算就是了。\n\n","slug":"欧拉工程-问题23","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4id00ay26s66gll655m"},{"title":"欧拉工程-问题22","id":"286","date":"2013-05-26T08:37:09.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=22](http://projecteuler.net/problem=22)\n\n\nNames scores\n\n\n\n\nUsing [names.txt](http://projecteuler.net/project/names.txt) (right click and 'Save Link/Target As...'), a 46K text file containing over five-thousand first names, begin by sorting it into alphabetical order. Then working out the alphabetical value for each name, multiply this value by its alphabetical position in the list to obtain a name score.\n\nFor example, when the list is sorted into alphabetical order, COLIN, which is worth 3 + 15 + 12 + 9 + 14 = 53, is the 938th name in the list. So, COLIN would obtain a score of 938 * 53 = 49714.\n\nWhat is the total of all the name scores in the file?\n\n名字得分\n\n使用[names.txt](http://projecteuler.net/project/names.txt) (右击然后’链接另存为...‘),一个大小为46K的文本文件，包含有查过5000个姓名，以字典顺序排列。然后计算给每个姓计算字母的值，乘以它在姓名列表的位置,得到一个姓名得分。\n\n例如，当姓名表以字典顺序排列时，COLIN, 字母值为3 + 15 + 12 + 9 + 14 = 53，在姓名表中为第938个，最终，\n\nCOLIN的得分为938 * 53 = 49714。\n\n求文件中所有姓名的得分总和。\n\n解答：\n\n这题没什么好说的，将名字排序，默认就是字典序了，然后按照说明算就行了。\n\n","source":"_posts/欧拉工程-问题22.md","raw":"title: 欧拉工程-问题22\ntags:\n  - 字典序\n  - 欧拉工程\nid: 286\ncategories:\n  - 欧拉工程\ndate: 2013-05-26 16:37:09\n---\n\n原题链接 [http://projecteuler.net/problem=22](http://projecteuler.net/problem=22)\n\n\nNames scores\n\n\n\n\nUsing [names.txt](http://projecteuler.net/project/names.txt) (right click and 'Save Link/Target As...'), a 46K text file containing over five-thousand first names, begin by sorting it into alphabetical order. Then working out the alphabetical value for each name, multiply this value by its alphabetical position in the list to obtain a name score.\n\nFor example, when the list is sorted into alphabetical order, COLIN, which is worth 3 + 15 + 12 + 9 + 14 = 53, is the 938th name in the list. So, COLIN would obtain a score of 938 * 53 = 49714.\n\nWhat is the total of all the name scores in the file?\n\n名字得分\n\n使用[names.txt](http://projecteuler.net/project/names.txt) (右击然后’链接另存为...‘),一个大小为46K的文本文件，包含有查过5000个姓名，以字典顺序排列。然后计算给每个姓计算字母的值，乘以它在姓名列表的位置,得到一个姓名得分。\n\n例如，当姓名表以字典顺序排列时，COLIN, 字母值为3 + 15 + 12 + 9 + 14 = 53，在姓名表中为第938个，最终，\n\nCOLIN的得分为938 * 53 = 49714。\n\n求文件中所有姓名的得分总和。\n\n解答：\n\n这题没什么好说的，将名字排序，默认就是字典序了，然后按照说明算就行了。\n\n","slug":"欧拉工程-问题22","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ir00b726s6q8395wqj"},{"title":"欧拉工程-问题21","id":"284","date":"2013-05-26T08:21:18.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=21](http://projecteuler.net/problem=21)\n\n\nAmicable numbers\n\n\n\n\nLet d(_n_) be defined as the sum of proper divisors of _n_ (numbers less than _n_ which divide evenly into _n_).\nIf d(_a_) = _b_ and d(_b_) = _a_, where _a_ ！=_b_, then _a_ and _b_ are an amicable pair and each of _a_ and _b_ are called amicable numbers.\n\nFor example, the proper divisors of 220 are 1, 2, 4, 5, 10, 11, 20, 22, 44, 55 and 110; therefore d(220) = 284\\. The proper divisors of 284 are 1, 2, 4, 71 and 142; so d(284) = 220.\n\nEvaluate the sum of all the amicable numbers under 10000.\n\n亲和数\n\n令d(n)为数n的所有真因子(小于n且可以整除n)的和.如果d(a) = b且d(b) = a,并且a ！= b,那么a和b组成亲和数对，a和b都被称为亲和数。\n\n例如，220的真因子有1,2,4,5,10,11,20,22,44,55和110,则d(220) = 284。284的真因子是1,2,4,71和143，所以d(284) = 220。\n\n找到1000以内所有亲和数的和。\n\n解答：\n\n这题我没想到好的方法，暴力解决，复杂度为 O(n^2),一分钟之内可以得出结果，也就没想再优化了。\n\n","source":"_posts/欧拉工程-问题21.md","raw":"title: 欧拉工程-问题21\ntags:\n  - 亲和数\n  - 欧拉工程\nid: 284\ncategories:\n  - 欧拉工程\ndate: 2013-05-26 16:21:18\n---\n\n原题链接 [http://projecteuler.net/problem=21](http://projecteuler.net/problem=21)\n\n\nAmicable numbers\n\n\n\n\nLet d(_n_) be defined as the sum of proper divisors of _n_ (numbers less than _n_ which divide evenly into _n_).\nIf d(_a_) = _b_ and d(_b_) = _a_, where _a_ ！=_b_, then _a_ and _b_ are an amicable pair and each of _a_ and _b_ are called amicable numbers.\n\nFor example, the proper divisors of 220 are 1, 2, 4, 5, 10, 11, 20, 22, 44, 55 and 110; therefore d(220) = 284\\. The proper divisors of 284 are 1, 2, 4, 71 and 142; so d(284) = 220.\n\nEvaluate the sum of all the amicable numbers under 10000.\n\n亲和数\n\n令d(n)为数n的所有真因子(小于n且可以整除n)的和.如果d(a) = b且d(b) = a,并且a ！= b,那么a和b组成亲和数对，a和b都被称为亲和数。\n\n例如，220的真因子有1,2,4,5,10,11,20,22,44,55和110,则d(220) = 284。284的真因子是1,2,4,71和143，所以d(284) = 220。\n\n找到1000以内所有亲和数的和。\n\n解答：\n\n这题我没想到好的方法，暴力解决，复杂度为 O(n^2),一分钟之内可以得出结果，也就没想再优化了。\n\n","slug":"欧拉工程-问题21","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4iu00bc26s6gg1tgmtp"},{"title":"欧拉工程-问题20","id":"281","date":"2013-05-26T04:23:59.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=20](http://projecteuler.net/problem=20)\n\n\nFactorial digit sum\n\n\n\n\n_n_! means _n_ *(_n_ * 1) * ... *3 *2 * 1\n\nFor example, 10! = 10 * 9 * ... *3 * 2 * 1 = 3628800,\nand the sum of the digits in the number 10! is 3 + 6 + 2 + 8 + 8 + 0 + 0 = 27.\n\nFind the sum of the digits in the number 100!\n\nn!的意思是 n * (n - 1) * ... * 3 * 2 * 1\n\n例如,10! = 10 * 9 * ... * 3 * 2 * 1 = 3628800,\n\n在10！这个数中的数字之和是 3 + 6 + 2 + 8 + 8 + 0 + 0 = 27.\n\n求100！这个数中的数字之和。\n\n解答：\n\n这题没什么好说的，没找到什么规律。只好算出100！用Python很随意。\n\n","source":"_posts/欧拉工程-问题20.md","raw":"title: 欧拉工程-问题20\ntags:\n  - 欧拉工程\n  - 阶乘\nid: 281\ncategories:\n  - 欧拉工程\ndate: 2013-05-26 12:23:59\n---\n\n原题链接 [http://projecteuler.net/problem=20](http://projecteuler.net/problem=20)\n\n\nFactorial digit sum\n\n\n\n\n_n_! means _n_ *(_n_ * 1) * ... *3 *2 * 1\n\nFor example, 10! = 10 * 9 * ... *3 * 2 * 1 = 3628800,\nand the sum of the digits in the number 10! is 3 + 6 + 2 + 8 + 8 + 0 + 0 = 27.\n\nFind the sum of the digits in the number 100!\n\nn!的意思是 n * (n - 1) * ... * 3 * 2 * 1\n\n例如,10! = 10 * 9 * ... * 3 * 2 * 1 = 3628800,\n\n在10！这个数中的数字之和是 3 + 6 + 2 + 8 + 8 + 0 + 0 = 27.\n\n求100！这个数中的数字之和。\n\n解答：\n\n这题没什么好说的，没找到什么规律。只好算出100！用Python很随意。\n\n","slug":"欧拉工程-问题20","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ix00bh26s6n1o0f0fx"},{"title":"欧拉工程-问题2","id":"115","date":"2013-04-26T06:52:45.000Z","_content":"\n原题地址  [http://projecteuler.net/problem=2](http://projecteuler.net/problem=2)\n\nEven Fibonacci numbers\n\nEach new term in the Fibonacci sequence is generated by adding the previous two terms. By starting with 1 and 2, the first 10 terms will be:\n\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, ...\n\nBy considering the terms in the Fibonacci sequence whose values do not exceed four million, find the sum of the even-valued terms.\n\n偶数斐波纳契数\n斐波那契数列中的每一个数等于前面两个数的和，从1和2开始，前面十项为：\n\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89，。。。\n\n考虑斐波那契数中不超过4000000的数，求这些数中所有偶数的和。\n\n解法：\n\n这题不多说，关键是生成斐波那契数列，这里使用了一个迭代器的技巧。代码如下：\n\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-4-26\n\n@author: shilong\n@email: long470884130@163.com\n'''\n\ndef fibonacci():\n    \"\"\"一个迭代函数，每次得到一个斐波那契数,依次将得到1, 2, 3, 5...\"\"\"\n    a = 1\n    b = 1\n    while True:\n        yield a\n        a, b = a + b, a\n\nif __name__ == \"__main__\":\n    fi = fibonacci()\n    s = 0\n    while True:\n        n = next(fi)\n        if n >= 4000000:\n            break\n        if n % 2 == 0:\n            s += n\n    print s\n```","source":"_posts/欧拉工程-问题2.md","raw":"title: 欧拉工程-问题2\ntags:\n  - 斐波那契数列\n  - 欧拉工程\nid: 115\ncategories:\n  - 欧拉工程\ndate: 2013-04-26 14:52:45\n---\n\n原题地址  [http://projecteuler.net/problem=2](http://projecteuler.net/problem=2)\n\nEven Fibonacci numbers\n\nEach new term in the Fibonacci sequence is generated by adding the previous two terms. By starting with 1 and 2, the first 10 terms will be:\n\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89, ...\n\nBy considering the terms in the Fibonacci sequence whose values do not exceed four million, find the sum of the even-valued terms.\n\n偶数斐波纳契数\n斐波那契数列中的每一个数等于前面两个数的和，从1和2开始，前面十项为：\n\n1, 2, 3, 5, 8, 13, 21, 34, 55, 89，。。。\n\n考虑斐波那契数中不超过4000000的数，求这些数中所有偶数的和。\n\n解法：\n\n这题不多说，关键是生成斐波那契数列，这里使用了一个迭代器的技巧。代码如下：\n\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-4-26\n\n@author: shilong\n@email: long470884130@163.com\n'''\n\ndef fibonacci():\n    \"\"\"一个迭代函数，每次得到一个斐波那契数,依次将得到1, 2, 3, 5...\"\"\"\n    a = 1\n    b = 1\n    while True:\n        yield a\n        a, b = a + b, a\n\nif __name__ == \"__main__\":\n    fi = fibonacci()\n    s = 0\n    while True:\n        n = next(fi)\n        if n >= 4000000:\n            break\n        if n % 2 == 0:\n            s += n\n    print s\n```","slug":"欧拉工程-问题2","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4j000bl26s6wza9f2wd"},{"title":"欧拉工程-问题19","id":"277","date":"2013-05-26T04:17:47.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=19](http://projecteuler.net/problem=19)\n\n\nCounting Sundays\n\n\n\n\nYou are given the following information, but you may prefer to do some research for yourself.\n\n*   1 Jan 1900 was a Monday.\n*   Thirty days has September,\nApril, June and November.\nAll the rest have thirty-one,\nSaving February alone,\nWhich has twenty-eight, rain or shine.\nAnd on leap years, twenty-nine.\n*   A leap year occurs on any year evenly divisible by 4, but not on a century unless it is divisible by 400.\nHow many Sundays fell on the first of the month during the twentieth century (1 Jan 1901 to 31 Dec 2000)?\n\n计算星期天的天数\n\n你将得到如下信息，你也可以自己做些探索。\n\n*   1900年1月1日是星期一\n*   一个月有三十天的月份有9月，4月，6月，11月。其它的月份都有31天，除了2月，如果是闰年29天，其它时候28天\n\n*   闰年是正好被4整除的年份，但不是世纪，除非此时它也可以被400整除。\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求二十世纪(1901年1月1日到2000年12月21日),一共有多少个星期天是每月的第一天。</span>\n\n解答：\n这题没什么好说的，就是模拟，另外要知道怎么判断闰年。\n","source":"_posts/欧拉工程-问题19.md","raw":"title: 欧拉工程-问题19\ntags:\n  - 日期\n  - 欧拉工程\n  - 闰年\nid: 277\ncategories:\n  - 欧拉工程\ndate: 2013-05-26 12:17:47\n---\n\n原题链接 [http://projecteuler.net/problem=19](http://projecteuler.net/problem=19)\n\n\nCounting Sundays\n\n\n\n\nYou are given the following information, but you may prefer to do some research for yourself.\n\n*   1 Jan 1900 was a Monday.\n*   Thirty days has September,\nApril, June and November.\nAll the rest have thirty-one,\nSaving February alone,\nWhich has twenty-eight, rain or shine.\nAnd on leap years, twenty-nine.\n*   A leap year occurs on any year evenly divisible by 4, but not on a century unless it is divisible by 400.\nHow many Sundays fell on the first of the month during the twentieth century (1 Jan 1901 to 31 Dec 2000)?\n\n计算星期天的天数\n\n你将得到如下信息，你也可以自己做些探索。\n\n*   1900年1月1日是星期一\n*   一个月有三十天的月份有9月，4月，6月，11月。其它的月份都有31天，除了2月，如果是闰年29天，其它时候28天\n\n*   闰年是正好被4整除的年份，但不是世纪，除非此时它也可以被400整除。\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求二十世纪(1901年1月1日到2000年12月21日),一共有多少个星期天是每月的第一天。</span>\n\n解答：\n这题没什么好说的，就是模拟，另外要知道怎么判断闰年。\n","slug":"欧拉工程-问题19","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4j200bp26s6ebo8ys8l"},{"title":"欧拉工程-问题18","id":"272","date":"2013-05-25T12:54:47.000Z","_content":"\n原题链接 http://projecteuler.net/problem=18\nMaximum path sum I\nBy starting at the top of the triangle below and moving to adjacent numbers on the row below, the maximum total from top to bottom is 23.\n\n<span style=\"color:red\">3</span>\n<span style=\"color:red\">7</span> 4\n2 <span style=\"color:red\">4</span> 6\n8 5 <span style=\"color:red\">9</span> 3\n\nThat is, 3 + 7 + 4 + 9 = 23.\n\nFind the maximum total from top to bottom of the triangle below:\n\n75\n95 64\n17 47 82\n18 35 87 10\n20 04 82 47 65\n19 01 23 75 03 34\n88 02 77 73 07 63 67\n99 65 04 28 06 16 70 92\n41 41 26 56 83 40 80 70 33\n41 48 72 33 47 32 37 16 94 29\n53 71 44 65 25 43 91 52 97 51 14\n70 11 33 28 77 73 17 78 39 68 17 57\n91 71 52 38 17 14 91 43 58 50 27 29 48\n63 66 04 68 89 53 67 30 73 16 69 87 40 31\n04 62 98 27 23 09 70 98 73 93 38 53 60 04 23\n\nNOTE: As there are only 16384 routes, it is possible to solve this problem by trying every route. However, Problem 67, is the same challenge with a triangle containing one-hundred rows; it cannot be solved by brute force, and requires a clever method! ;o)\n\n路径的最大和(1)\n\n从下面的三角形顶部开始移动到下面一层相邻的数字，一直到底部，这条路径上的和为23.\n\n也就是，3 + 7 + 4 + 9 = 23\\. \n\n在下面的三角形中，找到从顶部到底部的路径的最大值\n\n注意：在这个三角形中一共只有16384条从顶部到底部的路径，所以可以通过尝试每条路径来解决这个问题。但是，在问题67中，也是同样的问题，但是有100层，你不可能使用暴力方法，所以需要更聪明的方法!;0）\n\n解答：\n这题可以用动态规划。从下往上更容易一些。","source":"_posts/欧拉工程-问题18.md","raw":"title: 欧拉工程-问题18\ntags:\n  - 动态规划\n  - 欧拉工程\nid: 272\ncategories:\n  - 欧拉工程\ndate: 2013-05-25 20:54:47\n---\n\n原题链接 http://projecteuler.net/problem=18\nMaximum path sum I\nBy starting at the top of the triangle below and moving to adjacent numbers on the row below, the maximum total from top to bottom is 23.\n\n<span style=\"color:red\">3</span>\n<span style=\"color:red\">7</span> 4\n2 <span style=\"color:red\">4</span> 6\n8 5 <span style=\"color:red\">9</span> 3\n\nThat is, 3 + 7 + 4 + 9 = 23.\n\nFind the maximum total from top to bottom of the triangle below:\n\n75\n95 64\n17 47 82\n18 35 87 10\n20 04 82 47 65\n19 01 23 75 03 34\n88 02 77 73 07 63 67\n99 65 04 28 06 16 70 92\n41 41 26 56 83 40 80 70 33\n41 48 72 33 47 32 37 16 94 29\n53 71 44 65 25 43 91 52 97 51 14\n70 11 33 28 77 73 17 78 39 68 17 57\n91 71 52 38 17 14 91 43 58 50 27 29 48\n63 66 04 68 89 53 67 30 73 16 69 87 40 31\n04 62 98 27 23 09 70 98 73 93 38 53 60 04 23\n\nNOTE: As there are only 16384 routes, it is possible to solve this problem by trying every route. However, Problem 67, is the same challenge with a triangle containing one-hundred rows; it cannot be solved by brute force, and requires a clever method! ;o)\n\n路径的最大和(1)\n\n从下面的三角形顶部开始移动到下面一层相邻的数字，一直到底部，这条路径上的和为23.\n\n也就是，3 + 7 + 4 + 9 = 23\\. \n\n在下面的三角形中，找到从顶部到底部的路径的最大值\n\n注意：在这个三角形中一共只有16384条从顶部到底部的路径，所以可以通过尝试每条路径来解决这个问题。但是，在问题67中，也是同样的问题，但是有100层，你不可能使用暴力方法，所以需要更聪明的方法!;0）\n\n解答：\n这题可以用动态规划。从下往上更容易一些。","slug":"欧拉工程-问题18","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4j400bw26s626in9xah"},{"title":"欧拉工程-问题17","id":"267","date":"2013-05-25T11:58:06.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=17](http://projecteuler.net/problem=17)\n\n\nNumber letter counts\n\n\n\n\nIf the numbers 1 to 5 are written out in words: one, two, three, four, five, then there are 3 + 3 + 5 + 4 + 4 = 19 letters used in total.\n\nIf all the numbers from 1 to 1000 (one thousand) inclusive were written out in words, how many letters would be used?\n**NOTE:** Do not count spaces or hyphens. For example, 342 (three hundred and forty-two) contains 23 letters and 115 (one hundred and fifteen) contains 20 letters. The use of \"and\" when writing out numbers is in compliance with British usage.\n\n数字字母统计\n\n如果数字1到5写成单词的话是：one,two,three,four,five,那么一共用了3 + 3 + 5 + 4 + 4 = 19个字母\n\n如果将1到1000(one thousand)都写成单词，一共需要用多少个字母\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：不需要统计空格和连字符。例如342(three hundred and forty-two)包括23个字母，115(one hundred and fifteen)包括20个字母. 当写数字时使用\"and\"是遵循英国写法。</span>\n\n解答：\n\n这题没什么好说的，就是数字转化为英文单词。\n\n","source":"_posts/欧拉工程-问题17.md","raw":"title: 欧拉工程-问题17\ntags:\n  - 数字写成单词\n  - 欧拉工程\nid: 267\ncategories:\n  - 欧拉工程\ndate: 2013-05-25 19:58:06\n---\n\n原题链接 [http://projecteuler.net/problem=17](http://projecteuler.net/problem=17)\n\n\nNumber letter counts\n\n\n\n\nIf the numbers 1 to 5 are written out in words: one, two, three, four, five, then there are 3 + 3 + 5 + 4 + 4 = 19 letters used in total.\n\nIf all the numbers from 1 to 1000 (one thousand) inclusive were written out in words, how many letters would be used?\n**NOTE:** Do not count spaces or hyphens. For example, 342 (three hundred and forty-two) contains 23 letters and 115 (one hundred and fifteen) contains 20 letters. The use of \"and\" when writing out numbers is in compliance with British usage.\n\n数字字母统计\n\n如果数字1到5写成单词的话是：one,two,three,four,five,那么一共用了3 + 3 + 5 + 4 + 4 = 19个字母\n\n如果将1到1000(one thousand)都写成单词，一共需要用多少个字母\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：不需要统计空格和连字符。例如342(three hundred and forty-two)包括23个字母，115(one hundred and fifteen)包括20个字母. 当写数字时使用\"and\"是遵循英国写法。</span>\n\n解答：\n\n这题没什么好说的，就是数字转化为英文单词。\n\n","slug":"欧拉工程-问题17","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4j700c026s6oxa92yep"},{"title":"欧拉工程-问题16","id":"264","date":"2013-05-25T09:04:00.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=16](http://projecteuler.net/problem=16)\n\n\nPower digit sum\n\n\n\n\n2<sup>15</sup> = 32768 and the sum of its digits is 3 + 2 + 7 + 6 + 8 = 26.\n\nWhat is the sum of the digits of the number 2<sup>1000</sup>?\n\n幂方的数字和\n\n2<sup>15</sup> = 32768，它的所有数字的和是 3 + 2 + 7 + 6 + 8 = 26.\n\n求数2<sup>1000</sup>所有数字的和\n\n解答：\n\n没想到好的方法，只好暴力了。\n\n&nbsp;\n\n","source":"_posts/欧拉工程-问题16.md","raw":"title: 欧拉工程-问题16\ntags:\n  - 幂\n  - 欧拉工程\nid: 264\ncategories:\n  - 欧拉工程\ndate: 2013-05-25 17:04:00\n---\n\n原题链接 [http://projecteuler.net/problem=16](http://projecteuler.net/problem=16)\n\n\nPower digit sum\n\n\n\n\n2<sup>15</sup> = 32768 and the sum of its digits is 3 + 2 + 7 + 6 + 8 = 26.\n\nWhat is the sum of the digits of the number 2<sup>1000</sup>?\n\n幂方的数字和\n\n2<sup>15</sup> = 32768，它的所有数字的和是 3 + 2 + 7 + 6 + 8 = 26.\n\n求数2<sup>1000</sup>所有数字的和\n\n解答：\n\n没想到好的方法，只好暴力了。\n\n&nbsp;\n\n","slug":"欧拉工程-问题16","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ja00c526s645twdp4k"},{"title":"欧拉工程-问题15","id":"259","date":"2013-05-25T08:40:26.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=15](http://projecteuler.net/problem=15)\n\n\nLattice paths\n\n\n\n\nStarting in the top left corner of a 2 * 2 grid, and only being able to move to the right and down, there are exactly 6 routes to the bottom right corner.\n![](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/60DD8C58AB7942FE9A06094F27ABE259/p_015.gif)\nHow many such routes are there through a 20 * 20 grid?\n\n格子路径\n\n从2 * 2格子的左上角开始，只能右走和向下走，一共有6条路可以到达右下角。\n\n求在20 * 20的格子中，一共有多少条路可以从左上角到右下角。\n\n解答：\n这题从数学的观点看是这样的，在2 * 2的格子中，一共要走4步才能从左上角到右下角，其中一定有两步是向下走，所以总共次数为 \\(C_4^2 = 6\\),对于20 * 20也可以这样计算。\n\n","source":"_posts/欧拉工程-问题15.md","raw":"title: 欧拉工程-问题15\ntags:\n  - 欧拉工程\n  - 组合\nid: 259\ncategories:\n  - 欧拉工程\ndate: 2013-05-25 16:40:26\n---\n\n原题链接 [http://projecteuler.net/problem=15](http://projecteuler.net/problem=15)\n\n\nLattice paths\n\n\n\n\nStarting in the top left corner of a 2 * 2 grid, and only being able to move to the right and down, there are exactly 6 routes to the bottom right corner.\n![](file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/images/60DD8C58AB7942FE9A06094F27ABE259/p_015.gif)\nHow many such routes are there through a 20 * 20 grid?\n\n格子路径\n\n从2 * 2格子的左上角开始，只能右走和向下走，一共有6条路可以到达右下角。\n\n求在20 * 20的格子中，一共有多少条路可以从左上角到右下角。\n\n解答：\n这题从数学的观点看是这样的，在2 * 2的格子中，一共要走4步才能从左上角到右下角，其中一定有两步是向下走，所以总共次数为 \\(C_4^2 = 6\\),对于20 * 20也可以这样计算。\n\n","slug":"欧拉工程-问题15","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jc00c926s62q81as1j"},{"title":"欧拉工程-问题14","id":"250","date":"2013-05-24T16:01:24.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=14](http://projecteuler.net/problem=14)\n\n\nLongest Collatz sequence\n\n\n\n\nThe following iterative sequence is defined for the set of positive integers:\n\n<var>n</var> -><var>n</var>/2 (<var>n</var> is even)\n<var>n</var> ->3<var>n</var> + 1 (<var>n</var> is odd)\n\nUsing the rule above and starting with 13, we generate the following sequence:\n13 -> 40 ->20 ->10 ->5 ->16 -> 8 -> 4 ->2 ->1\nIt can be seen that this sequence (starting at 13 and finishing at 1) contains 10 terms. Although it has not been proved yet (Collatz Problem), it is thought that all starting numbers finish at 1.\n\nWhich starting number, under one million, produces the longest chain?\n\n**NOTE:** Once the chain starts the terms are allowed to go above one million.\n\n最长的考拉兹数：\n\n在正整数上定义如下迭代序列：\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">     n -> n / 2 (n是偶数)</span>\n\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">     n -> 3n + 1 (n是奇数)</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">从13开始，使用上面的规则，我们将得到如下序列：</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">13 -> 40 -> 20 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">我们可以看到这个序列(从13开始到1结束)包含10个数。虽然这个还没有被证明(考拉兹问题),但我们可以认为所有的数都将在1结束。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求1 000 000以下的数，从哪一个数开始，产生的序列最长。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：一旦这个序列开始后，其中的数允许超过1 000 000。</span>\n\n解答：\n如果将1到1000000都按照上述过程迭代，速度将会很慢，所以要保存一些计算结果，这样速度就会快很多了。\n代码面前，了无秘密。直接上代码：\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-5-24\n\n@author: shilong\n@email: long470884130@163.com\n'''\ncol = {}\ncol[1] = 1\ndef collatz(n):\n    if n in col:\n        return col[n]\n    else:\n        if n % 2 == 0:\n            col[n] = collatz(n / 2) + 1\n        else:\n            col[n] = collatz(3 * n + 1) + 1\n        return col[n]\n```\n\n\n","source":"_posts/欧拉工程-问题14.md","raw":"title: 欧拉工程-问题14\ntags:\n  - collatz\n  - 欧拉工程\n  - 考拉兹问题\nid: 250\ncategories:\n  - 欧拉工程\ndate: 2013-05-25 00:01:24\n---\n\n原题链接 [http://projecteuler.net/problem=14](http://projecteuler.net/problem=14)\n\n\nLongest Collatz sequence\n\n\n\n\nThe following iterative sequence is defined for the set of positive integers:\n\n<var>n</var> -><var>n</var>/2 (<var>n</var> is even)\n<var>n</var> ->3<var>n</var> + 1 (<var>n</var> is odd)\n\nUsing the rule above and starting with 13, we generate the following sequence:\n13 -> 40 ->20 ->10 ->5 ->16 -> 8 -> 4 ->2 ->1\nIt can be seen that this sequence (starting at 13 and finishing at 1) contains 10 terms. Although it has not been proved yet (Collatz Problem), it is thought that all starting numbers finish at 1.\n\nWhich starting number, under one million, produces the longest chain?\n\n**NOTE:** Once the chain starts the terms are allowed to go above one million.\n\n最长的考拉兹数：\n\n在正整数上定义如下迭代序列：\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">     n -> n / 2 (n是偶数)</span>\n\n\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">     n -> 3n + 1 (n是奇数)</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">从13开始，使用上面的规则，我们将得到如下序列：</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">13 -> 40 -> 20 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">我们可以看到这个序列(从13开始到1结束)包含10个数。虽然这个还没有被证明(考拉兹问题),但我们可以认为所有的数都将在1结束。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">求1 000 000以下的数，从哪一个数开始，产生的序列最长。</span>\n<span style=\"font-family: 'Trebuchet MS', sans-serif; font-size: medium;\">注意：一旦这个序列开始后，其中的数允许超过1 000 000。</span>\n\n解答：\n如果将1到1000000都按照上述过程迭代，速度将会很慢，所以要保存一些计算结果，这样速度就会快很多了。\n代码面前，了无秘密。直接上代码：\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-5-24\n\n@author: shilong\n@email: long470884130@163.com\n'''\ncol = {}\ncol[1] = 1\ndef collatz(n):\n    if n in col:\n        return col[n]\n    else:\n        if n % 2 == 0:\n            col[n] = collatz(n / 2) + 1\n        else:\n            col[n] = collatz(3 * n + 1) + 1\n        return col[n]\n```\n\n\n","slug":"欧拉工程-问题14","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4je00ce26s6vx52rn9d"},{"title":"欧拉工程-问题13","id":"247","date":"2013-05-24T13:58:45.000Z","_content":"\n原题连接 [http://projecteuler.net/problem=13](http://projecteuler.net/problem=13)\n\n\n\nLarge sum\n\n\n\n\nWork out the first ten digits of the sum of the following one-hundred 50-digit numbers.\n37107287533902102798797998220837590246510135740250\n46376937677490009712648124896970078050417018260538\n74324986199524741059474233309513058123726617309629\n91942213363574161572522430563301811072406154908250\n23067588207539346171171980310421047513778063246676\n89261670696623633820136378418383684178734361726757\n28112879812849979408065481931592621691275889832738\n44274228917432520321923589422876796487670272189318\n47451445736001306439091167216856844588711603153276\n70386486105843025439939619828917593665686757934951\n62176457141856560629502157223196586755079324193331\n64906352462741904929101432445813822663347944758178\n92575867718337217661963751590579239728245598838407\n58203565325359399008402633568948830189458628227828\n80181199384826282014278194139940567587151170094390\n35398664372827112653829987240784473053190104293586\n86515506006295864861532075273371959191420517255829\n71693888707715466499115593487603532921714970056938\n54370070576826684624621495650076471787294438377604\n53282654108756828443191190634694037855217779295145\n36123272525000296071075082563815656710885258350721\n45876576172410976447339110607218265236877223636045\n17423706905851860660448207621209813287860733969412\n81142660418086830619328460811191061556940512689692\n51934325451728388641918047049293215058642563049483\n62467221648435076201727918039944693004732956340691\n15732444386908125794514089057706229429197107928209\n55037687525678773091862540744969844508330393682126\n18336384825330154686196124348767681297534375946515\n80386287592878490201521685554828717201219257766954\n78182833757993103614740356856449095527097864797581\n16726320100436897842553539920931837441497806860984\n48403098129077791799088218795327364475675590848030\n87086987551392711854517078544161852424320693150332\n59959406895756536782107074926966537676326235447210\n69793950679652694742597709739166693763042633987085\n41052684708299085211399427365734116182760315001271\n65378607361501080857009149939512557028198746004375\n35829035317434717326932123578154982629742552737307\n94953759765105305946966067683156574377167401875275\n88902802571733229619176668713819931811048770190271\n25267680276078003013678680992525463401061632866526\n36270218540497705585629946580636237993140746255962\n24074486908231174977792365466257246923322810917141\n91430288197103288597806669760892938638285025333403\n34413065578016127815921815005561868836468420090470\n23053081172816430487623791969842487255036638784583\n11487696932154902810424020138335124462181441773470\n63783299490636259666498587618221225225512486764533\n67720186971698544312419572409913959008952310058822\n95548255300263520781532296796249481641953868218774\n76085327132285723110424803456124867697064507995236\n37774242535411291684276865538926205024910326572967\n23701913275725675285653248258265463092207058596522\n29798860272258331913126375147341994889534765745501\n18495701454879288984856827726077713721403798879715\n38298203783031473527721580348144513491373226651381\n34829543829199918180278916522431027392251122869539\n40957953066405232632538044100059654939159879593635\n29746152185502371307642255121183693803580388584903\n41698116222072977186158236678424689157993532961922\n62467957194401269043877107275048102390895523597457\n23189706772547915061505504953922979530901129967519\n86188088225875314529584099251203829009407770775672\n11306739708304724483816533873502340845647058077308\n82959174767140363198008187129011875491310547126581\n97623331044818386269515456334926366572897563400500\n42846280183517070527831839425882145521227251250327\n55121603546981200581762165212827652751691296897789\n32238195734329339946437501907836945765883352399886\n75506164965184775180738168837861091527357929701337\n62177842752192623401942399639168044983993173312731\n32924185707147349566916674687634660915035914677504\n99518671430235219628894890102423325116913619626622\n73267460800591547471830798392868535206946944540724\n76841822524674417161514036427982273348055556214818\n97142617910342598647204516893989422179826088076852\n87783646182799346313767754307809363333018982642090\n10848802521674670883215120185883543223812876952786\n71329612474782464538636993009049310363619763878039\n62184073572399794223406235393808339651327408011116\n66627891981488087797941876876144230030984490851411\n60661826293682836764744779239180335110989069790714\n85786944089552990653640447425576083659976645795096\n66024396409905389607120198219976047599490197230297\n64913982680032973156037120041377903785566085089252\n16730939319872750275468906903707539413042652315011\n94809377245048795150954100921645863754710598436791\n78639167021187492431995700641917969777599028300699\n15368713711936614952811305876380278410754449733078\n40789923115535562561142322423255033685442488917353\n44889911501440648020369068063960672322193204149535\n41503128880339536053299340368006977710650566631954\n81234880673210146739058568557934581403627822703280\n82616570773948327592232845941706525094512325230608\n22918802058777319719839450180888072429661980811197\n77158542502016545090413245809786882778948721859617\n72107838435069186155435662884062257473692284509516\n20849603980134001723930671666823555245252804609722\n53503534226472524250874054075591789781264330331690\n\n\n大整数求和\n\n求这150个数相加得到的和的前10个数字.\n\n解答：\n\n这题没什么好说的，无非就是大整数求和，然后去前10个数字，如果用C++还有得写，用Python就很随意了。\n\n\n","source":"_posts/欧拉工程-问题13.md","raw":"title: 欧拉工程-问题13\ntags:\n  - 大整数求和\n  - 欧拉工程\nid: 247\ncategories:\n  - 欧拉工程\ndate: 2013-05-24 21:58:45\n---\n\n原题连接 [http://projecteuler.net/problem=13](http://projecteuler.net/problem=13)\n\n\n\nLarge sum\n\n\n\n\nWork out the first ten digits of the sum of the following one-hundred 50-digit numbers.\n37107287533902102798797998220837590246510135740250\n46376937677490009712648124896970078050417018260538\n74324986199524741059474233309513058123726617309629\n91942213363574161572522430563301811072406154908250\n23067588207539346171171980310421047513778063246676\n89261670696623633820136378418383684178734361726757\n28112879812849979408065481931592621691275889832738\n44274228917432520321923589422876796487670272189318\n47451445736001306439091167216856844588711603153276\n70386486105843025439939619828917593665686757934951\n62176457141856560629502157223196586755079324193331\n64906352462741904929101432445813822663347944758178\n92575867718337217661963751590579239728245598838407\n58203565325359399008402633568948830189458628227828\n80181199384826282014278194139940567587151170094390\n35398664372827112653829987240784473053190104293586\n86515506006295864861532075273371959191420517255829\n71693888707715466499115593487603532921714970056938\n54370070576826684624621495650076471787294438377604\n53282654108756828443191190634694037855217779295145\n36123272525000296071075082563815656710885258350721\n45876576172410976447339110607218265236877223636045\n17423706905851860660448207621209813287860733969412\n81142660418086830619328460811191061556940512689692\n51934325451728388641918047049293215058642563049483\n62467221648435076201727918039944693004732956340691\n15732444386908125794514089057706229429197107928209\n55037687525678773091862540744969844508330393682126\n18336384825330154686196124348767681297534375946515\n80386287592878490201521685554828717201219257766954\n78182833757993103614740356856449095527097864797581\n16726320100436897842553539920931837441497806860984\n48403098129077791799088218795327364475675590848030\n87086987551392711854517078544161852424320693150332\n59959406895756536782107074926966537676326235447210\n69793950679652694742597709739166693763042633987085\n41052684708299085211399427365734116182760315001271\n65378607361501080857009149939512557028198746004375\n35829035317434717326932123578154982629742552737307\n94953759765105305946966067683156574377167401875275\n88902802571733229619176668713819931811048770190271\n25267680276078003013678680992525463401061632866526\n36270218540497705585629946580636237993140746255962\n24074486908231174977792365466257246923322810917141\n91430288197103288597806669760892938638285025333403\n34413065578016127815921815005561868836468420090470\n23053081172816430487623791969842487255036638784583\n11487696932154902810424020138335124462181441773470\n63783299490636259666498587618221225225512486764533\n67720186971698544312419572409913959008952310058822\n95548255300263520781532296796249481641953868218774\n76085327132285723110424803456124867697064507995236\n37774242535411291684276865538926205024910326572967\n23701913275725675285653248258265463092207058596522\n29798860272258331913126375147341994889534765745501\n18495701454879288984856827726077713721403798879715\n38298203783031473527721580348144513491373226651381\n34829543829199918180278916522431027392251122869539\n40957953066405232632538044100059654939159879593635\n29746152185502371307642255121183693803580388584903\n41698116222072977186158236678424689157993532961922\n62467957194401269043877107275048102390895523597457\n23189706772547915061505504953922979530901129967519\n86188088225875314529584099251203829009407770775672\n11306739708304724483816533873502340845647058077308\n82959174767140363198008187129011875491310547126581\n97623331044818386269515456334926366572897563400500\n42846280183517070527831839425882145521227251250327\n55121603546981200581762165212827652751691296897789\n32238195734329339946437501907836945765883352399886\n75506164965184775180738168837861091527357929701337\n62177842752192623401942399639168044983993173312731\n32924185707147349566916674687634660915035914677504\n99518671430235219628894890102423325116913619626622\n73267460800591547471830798392868535206946944540724\n76841822524674417161514036427982273348055556214818\n97142617910342598647204516893989422179826088076852\n87783646182799346313767754307809363333018982642090\n10848802521674670883215120185883543223812876952786\n71329612474782464538636993009049310363619763878039\n62184073572399794223406235393808339651327408011116\n66627891981488087797941876876144230030984490851411\n60661826293682836764744779239180335110989069790714\n85786944089552990653640447425576083659976645795096\n66024396409905389607120198219976047599490197230297\n64913982680032973156037120041377903785566085089252\n16730939319872750275468906903707539413042652315011\n94809377245048795150954100921645863754710598436791\n78639167021187492431995700641917969777599028300699\n15368713711936614952811305876380278410754449733078\n40789923115535562561142322423255033685442488917353\n44889911501440648020369068063960672322193204149535\n41503128880339536053299340368006977710650566631954\n81234880673210146739058568557934581403627822703280\n82616570773948327592232845941706525094512325230608\n22918802058777319719839450180888072429661980811197\n77158542502016545090413245809786882778948721859617\n72107838435069186155435662884062257473692284509516\n20849603980134001723930671666823555245252804609722\n53503534226472524250874054075591789781264330331690\n\n\n大整数求和\n\n求这150个数相加得到的和的前10个数字.\n\n解答：\n\n这题没什么好说的，无非就是大整数求和，然后去前10个数字，如果用C++还有得写，用Python就很随意了。\n\n\n","slug":"欧拉工程-问题13","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jh00cl26s6abrkyioj"},{"title":"欧拉工程-问题12","id":"243","date":"2013-05-24T13:52:14.000Z","_content":"\n原题链接 [http://projecteuler.net/problem=12](http://projecteuler.net/problem=12)\n\nHighly divisible triangular number\n\n\nThe sequence of triangle numbers is generated by adding the natural numbers. So the 7<sup>th</sup> triangle number would be 1 + 2 + 3 + 4 + 5 + 6 + 7 = 28\\. The first ten terms would be:\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\nLet us list the factors of the first seven triangle numbers:\n> ** 1**: 1\r> \n> ** 3**: 1,3\r> \n> ** 6**: 1,2,3,6\r> \n> **10**: 1,2,5,10\r> \n> **15**: 1,3,5,15\r> \n> **21**: 1,3,7,21\r> \n> **28**: 1,2,4,7,14,28\nWe can see that 28 is the first triangle number to have over five divisors.\n\nWhat is the value of the first triangle number to have over five hundred divisors?\n\n三角数序列是由自然数相加形成的。第七个三角数是 1 + 2 + 3 + 4 + 5 + 6 + 7 = 28.前十个三角数是：\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\n我们列举出前7个三角形数的因子：\n\n1: 1\n\n3: 1,3\n\n6: 1,2,3,6\n\n10: 1,2,5,10\n\n15: 1,3,5,10\n\n21: 1,3,7,21\n\n28: 1,2,4,7,14,28\n\n我们可以看到28是第一个有超过5个因子的三角数\n\n求第一个超过500个因子的三角数\n\n解答：\n\n这题的题意其实就是求素数因子，将三角数表示成素数因子乘积的形式，如 \\(28 = 2^2 * 7\\),这里素数因子2的次数的取值为0,1,2三种可能，素数因子7的次数的取值为0,1两种可能，所以28的因子有6个。按照这个思路，去做就可以了。\n\n","source":"_posts/欧拉工程-问题12.md","raw":"title: 欧拉工程-问题12\ntags:\n  - 三角数\n  - 因子个数\n  - 欧拉工程\nid: 243\ncategories:\n  - 欧拉工程\ndate: 2013-05-24 21:52:14\n---\n\n原题链接 [http://projecteuler.net/problem=12](http://projecteuler.net/problem=12)\n\nHighly divisible triangular number\n\n\nThe sequence of triangle numbers is generated by adding the natural numbers. So the 7<sup>th</sup> triangle number would be 1 + 2 + 3 + 4 + 5 + 6 + 7 = 28\\. The first ten terms would be:\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\nLet us list the factors of the first seven triangle numbers:\n> ** 1**: 1\r> \n> ** 3**: 1,3\r> \n> ** 6**: 1,2,3,6\r> \n> **10**: 1,2,5,10\r> \n> **15**: 1,3,5,15\r> \n> **21**: 1,3,7,21\r> \n> **28**: 1,2,4,7,14,28\nWe can see that 28 is the first triangle number to have over five divisors.\n\nWhat is the value of the first triangle number to have over five hundred divisors?\n\n三角数序列是由自然数相加形成的。第七个三角数是 1 + 2 + 3 + 4 + 5 + 6 + 7 = 28.前十个三角数是：\n\n1, 3, 6, 10, 15, 21, 28, 36, 45, 55, ...\n\n我们列举出前7个三角形数的因子：\n\n1: 1\n\n3: 1,3\n\n6: 1,2,3,6\n\n10: 1,2,5,10\n\n15: 1,3,5,10\n\n21: 1,3,7,21\n\n28: 1,2,4,7,14,28\n\n我们可以看到28是第一个有超过5个因子的三角数\n\n求第一个超过500个因子的三角数\n\n解答：\n\n这题的题意其实就是求素数因子，将三角数表示成素数因子乘积的形式，如 \\(28 = 2^2 * 7\\),这里素数因子2的次数的取值为0,1,2三种可能，素数因子7的次数的取值为0,1两种可能，所以28的因子有6个。按照这个思路，去做就可以了。\n\n","slug":"欧拉工程-问题12","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jk00cq26s63j6jad3n"},{"title":"欧拉工程-问题11","id":"229","date":"2013-05-05T08:28:22.000Z","_content":"\n\n\n原题链接 [http://projecteuler.net/problem=11](http://projecteuler.net/problem=11)\n\nLargest product in a grid\n\n\n\n\nIn the 20 * 20 grid below, four numbers along a diagonal line have been marked in red.\n\n08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 08\n49 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 00\n81 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 65\n52 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 91\n22 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 80\n24 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 50\n32 98 81 28 64 23 67 10 <span style=\"color:red\">26</span> 38 40 67 59 54 70 66 18 38 64 70\n67 26 20 68 02 62 12 20 95 <span style=\"color:red\">63</span> 94 39 63 08 40 91 66 49 94 21\n24 55 58 05 66 73 99 26 97 17 <span style=\"color:red\">78</span> 78 96 83 14 88 34 89 63 72\n21 36 23 09 75 00 76 44 20 45 35 <span style=\"color:red\">14</span> 00 61 33 97 34 31 33 95\n78 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 92\n16 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 57\n86 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 58\n19 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 40\n04 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 66\n88 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 69\n04 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 36\n20 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 16\n20 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 54\n01 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48\n\nThe product of these numbers is 26  * 63  * 78  *  14 = 1788696.\n\nWhat is the greatest product of four adjacent numbers in the same direction (up, down, left, right, or diagonally) in the 20 * 20 grid?\n\n在格子中最大的乘积\n\n在下面的20 * 20的格子中，四个沿着对角线的数用红色标出\n\n它们的乘积是 26 * 63 * 78 * 14 = 1788696.\n\n求在这个20 * 20的格子中，四个相邻数的最大乘积(这四个相邻数必须在同一条直线上，向上，下，左，右，或者对角线)\n\n解答：\n这题没什么好说的，遍历。\n\n","source":"_posts/欧拉工程-问题11.md","raw":"title: 欧拉工程-问题11\ntags:\n  - 欧拉工程\n  - 连续乘积\nid: 229\ncategories:\n  - 欧拉工程\ndate: 2013-05-05 16:28:22\n---\n\n\n\n原题链接 [http://projecteuler.net/problem=11](http://projecteuler.net/problem=11)\n\nLargest product in a grid\n\n\n\n\nIn the 20 * 20 grid below, four numbers along a diagonal line have been marked in red.\n\n08 02 22 97 38 15 00 40 00 75 04 05 07 78 52 12 50 77 91 08\n49 49 99 40 17 81 18 57 60 87 17 40 98 43 69 48 04 56 62 00\n81 49 31 73 55 79 14 29 93 71 40 67 53 88 30 03 49 13 36 65\n52 70 95 23 04 60 11 42 69 24 68 56 01 32 56 71 37 02 36 91\n22 31 16 71 51 67 63 89 41 92 36 54 22 40 40 28 66 33 13 80\n24 47 32 60 99 03 45 02 44 75 33 53 78 36 84 20 35 17 12 50\n32 98 81 28 64 23 67 10 <span style=\"color:red\">26</span> 38 40 67 59 54 70 66 18 38 64 70\n67 26 20 68 02 62 12 20 95 <span style=\"color:red\">63</span> 94 39 63 08 40 91 66 49 94 21\n24 55 58 05 66 73 99 26 97 17 <span style=\"color:red\">78</span> 78 96 83 14 88 34 89 63 72\n21 36 23 09 75 00 76 44 20 45 35 <span style=\"color:red\">14</span> 00 61 33 97 34 31 33 95\n78 17 53 28 22 75 31 67 15 94 03 80 04 62 16 14 09 53 56 92\n16 39 05 42 96 35 31 47 55 58 88 24 00 17 54 24 36 29 85 57\n86 56 00 48 35 71 89 07 05 44 44 37 44 60 21 58 51 54 17 58\n19 80 81 68 05 94 47 69 28 73 92 13 86 52 17 77 04 89 55 40\n04 52 08 83 97 35 99 16 07 97 57 32 16 26 26 79 33 27 98 66\n88 36 68 87 57 62 20 72 03 46 33 67 46 55 12 32 63 93 53 69\n04 42 16 73 38 25 39 11 24 94 72 18 08 46 29 32 40 62 76 36\n20 69 36 41 72 30 23 88 34 62 99 69 82 67 59 85 74 04 36 16\n20 73 35 29 78 31 90 01 74 31 49 71 48 86 81 16 23 57 05 54\n01 70 54 71 83 51 54 69 16 92 33 48 61 43 52 01 89 19 67 48\n\nThe product of these numbers is 26  * 63  * 78  *  14 = 1788696.\n\nWhat is the greatest product of four adjacent numbers in the same direction (up, down, left, right, or diagonally) in the 20 * 20 grid?\n\n在格子中最大的乘积\n\n在下面的20 * 20的格子中，四个沿着对角线的数用红色标出\n\n它们的乘积是 26 * 63 * 78 * 14 = 1788696.\n\n求在这个20 * 20的格子中，四个相邻数的最大乘积(这四个相邻数必须在同一条直线上，向上，下，左，右，或者对角线)\n\n解答：\n这题没什么好说的，遍历。\n\n","slug":"欧拉工程-问题11","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jm00cw26s690gmu8gj"},{"title":"欧拉工程-问题10","id":"211","date":"2013-05-05T07:58:56.000Z","_content":"\n\n\n原题链接 [http://projecteuler.net/problem=10](http://projecteuler.net/problem=10)\n\nSummation of primes\n\n\n\n\nThe sum of the primes below 10 is 2 + 3 + 5 + 7 = 17.\n\nFind the sum of all the primes below two million.\n\n素数的和\n\n10以下的所有素数的和是 2 + 3 + 5 + 7 = 17.\n\n求2000000以下所有素数的和。\n\n解答：\n用筛法求得2000000以下的所有素数，之后求和\n\n写成代码如下：\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-5-5\n\n@author: shilong\n@email: long470884130@163.com\n'''\nfrom math import sqrt\ndef generate_prime(n):\n    '''得到[1,n]以内的素数'''\n    primes = [True for i in xrange(n + 1)]\n    primes[0] = primes[1] = False\n    for i in xrange(2,int(sqrt(n)) + 1):\n        if primes[i]:\n            s = i ** 2\n            while s <= n:\n                primes[s] = False\n                s += i\n    primes = [i for i in xrange(2,n + 1) if primes[i]]\n    return primes\n\nif __name__ == \"__main__\":\n    n = 2000000\n    primes = generate_prime(n)\n    print sum(primes)\n```\n","source":"_posts/欧拉工程-问题10.md","raw":"title: 欧拉工程-问题10\ntags:\n  - 欧拉工程\n  - 筛法\n  - 素数\nid: 211\ncategories:\n  - 欧拉工程\ndate: 2013-05-05 15:58:56\n---\n\n\n\n原题链接 [http://projecteuler.net/problem=10](http://projecteuler.net/problem=10)\n\nSummation of primes\n\n\n\n\nThe sum of the primes below 10 is 2 + 3 + 5 + 7 = 17.\n\nFind the sum of all the primes below two million.\n\n素数的和\n\n10以下的所有素数的和是 2 + 3 + 5 + 7 = 17.\n\n求2000000以下所有素数的和。\n\n解答：\n用筛法求得2000000以下的所有素数，之后求和\n\n写成代码如下：\n``` python\n#!/usr/bin/python\n# -*- coding:utf-8 -*-\n'''\nCreated on 2013-5-5\n\n@author: shilong\n@email: long470884130@163.com\n'''\nfrom math import sqrt\ndef generate_prime(n):\n    '''得到[1,n]以内的素数'''\n    primes = [True for i in xrange(n + 1)]\n    primes[0] = primes[1] = False\n    for i in xrange(2,int(sqrt(n)) + 1):\n        if primes[i]:\n            s = i ** 2\n            while s <= n:\n                primes[s] = False\n                s += i\n    primes = [i for i in xrange(2,n + 1) if primes[i]]\n    return primes\n\nif __name__ == \"__main__\":\n    n = 2000000\n    primes = generate_prime(n)\n    print sum(primes)\n```\n","slug":"欧拉工程-问题10","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jo00d026s6lce0ugy9"},{"title":"欧拉工程-问题1","id":"99","date":"2013-04-26T06:51:38.000Z","_content":"\n决定以后有空时就翻译欧拉工程，从今天开始。不知道应不应该把解法贴出来，有点损人品了，还是决定贴吧。\n\n原文链接  [http://projecteuler.net/problem=1](http://projecteuler.net/problem=1)\n\nMultiples of 3 and 5\n\nIf we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9\\. The sum of these multiples is 23.\n\nFind the sum of all the multiples of 3 or 5 below 1000.\n\n3和5的倍数\n\n如果我们列出10以内是3或者5的倍数的自然数，我们将得到3,5,6和9.这些倍数的总和是23.\n\n求1000以内3或者5的倍数的总和。\n\n解答：\n\n最直接的方法，判断[1, 1000)中的自然数，将是3或者5的倍数相加，Python就一句\n\n``` python\nprint sum([i for i in xrange(1, n) if i % 3 == 0 or i % 5 == 0])\n```\n\n还有一种更简便的方法，可以直接用笔算出来。例如求[1, 1000)中3的倍数的和，\n这里3的倍数是3，6，9，。。。，999。也就是3 * 1，3 * 2，3 * 3，。。。3 * 333。所以求得1 + 2 + 。。。+ 333后乘以3就得到了最终结果，写成Python代码如下。\n\n``` python\nsum(xrange(1, 1 + (1000 - 1) / 3)) * 3\n```\n","source":"_posts/欧拉工程-问题1.md","raw":"title: 欧拉工程-问题1\ntags:\n  - 倍数\n  - 欧拉工程\nid: 99\ncategories:\n  - 欧拉工程\ndate: 2013-04-26 14:51:38\n---\n\n决定以后有空时就翻译欧拉工程，从今天开始。不知道应不应该把解法贴出来，有点损人品了，还是决定贴吧。\n\n原文链接  [http://projecteuler.net/problem=1](http://projecteuler.net/problem=1)\n\nMultiples of 3 and 5\n\nIf we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9\\. The sum of these multiples is 23.\n\nFind the sum of all the multiples of 3 or 5 below 1000.\n\n3和5的倍数\n\n如果我们列出10以内是3或者5的倍数的自然数，我们将得到3,5,6和9.这些倍数的总和是23.\n\n求1000以内3或者5的倍数的总和。\n\n解答：\n\n最直接的方法，判断[1, 1000)中的自然数，将是3或者5的倍数相加，Python就一句\n\n``` python\nprint sum([i for i in xrange(1, n) if i % 3 == 0 or i % 5 == 0])\n```\n\n还有一种更简便的方法，可以直接用笔算出来。例如求[1, 1000)中3的倍数的和，\n这里3的倍数是3，6，9，。。。，999。也就是3 * 1，3 * 2，3 * 3，。。。3 * 333。所以求得1 + 2 + 。。。+ 333后乘以3就得到了最终结果，写成Python代码如下。\n\n``` python\nsum(xrange(1, 1 + (1000 - 1) / 3)) * 3\n```\n","slug":"欧拉工程-问题1","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jr00d526s6n6xejla8"},{"title":"查看端口是否被占用","id":"968","date":"2014-12-03T14:10:03.000Z","_content":"\n如要查看8080端口被进程占用，以前都是用 lsof命令的,\nlsof -i:8080\n\n现在lsof命令不能用了，于是改成netstat\nnetstat  -nltp | grep 8080\n\n以前执行这个命令时没有加上p参数，后来仔细看netstat的帮助，知道p参数是显示进程id和名字用的","source":"_posts/查看端口是否被占用.md","raw":"title: 查看端口是否被占用\ntags:\n  - lsof\n  - netstat\nid: 968\ncategories:\n  - shell\ndate: 2014-12-03 22:10:03\n---\n\n如要查看8080端口被进程占用，以前都是用 lsof命令的,\nlsof -i:8080\n\n现在lsof命令不能用了，于是改成netstat\nnetstat  -nltp | grep 8080\n\n以前执行这个命令时没有加上p参数，后来仔细看netstat的帮助，知道p参数是显示进程id和名字用的","slug":"查看端口是否被占用","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jv00d926s696cuza9u"},{"title":"查找矩阵","id":"1046","date":"2015-10-29T03:53:15.000Z","_content":"\n已知一个m行n列的矩阵M,它的元素满足一个很特殊的性质，即任一元素M[i][j]都小于它右边与下方的元素(如果存在的话),换言之，M[i][j] < M[i][j + 1]且M[i][j] < M[i + 1][j]。如int[ ][ ] nums = { {1, 4, 7, 11, 15},{2, 5, 8, 12, 19},{3, 6, 9, 16, 22},{10, 13, 14, 17, 24},{18, 21, 23, 26, 30}};\n\n现在有一个值K，编写一个程序，检查矩阵M中是否有K。\n\n对于矩阵M，可以将它划分成两部分区域，一部分是小于等于K的区域，一部分是大于K的区域。沿着两部分区域的边界线查找K即可。\n``` java\npublic class SearchaMatrix {\n\tpublic static boolean searchMatrix(int[][] matrix, int target) {\n\t\tint m = matrix.length;\n\t\tint n = matrix[0].length;\n        int i = 0;\n        int j = n - 1;\n        while (i < m && j >= 0) {\n        \tif (matrix[i][j] > target) {\n        \t\tj--;\n        \t} else if (matrix[i][j] < target) {\n        \t\ti++;\n        \t} else {\n        \t\treturn true;\n        \t}   \t\n        }\n        return false;\n    }\n\tpublic static void main(String[] args) {\n\t\tint[][] nums = { {1, 4, 7, 11, 15},{2, 5, 8, 12, 19},{3, 6, 9, 16, 22},{10, 13, 14, 17, 24},{18, 21, 23, 26, 30}};\n\t\tSystem.out.println(searchMatrix(nums, 17));\n\t}\n}\n```","source":"_posts/查找矩阵.md","raw":"title: 查找矩阵\ntags:\n  - C名题百则\nid: 1046\ncategories:\n  - 算法\ndate: 2015-10-29 11:53:15\n---\n\n已知一个m行n列的矩阵M,它的元素满足一个很特殊的性质，即任一元素M[i][j]都小于它右边与下方的元素(如果存在的话),换言之，M[i][j] < M[i][j + 1]且M[i][j] < M[i + 1][j]。如int[ ][ ] nums = { {1, 4, 7, 11, 15},{2, 5, 8, 12, 19},{3, 6, 9, 16, 22},{10, 13, 14, 17, 24},{18, 21, 23, 26, 30}};\n\n现在有一个值K，编写一个程序，检查矩阵M中是否有K。\n\n对于矩阵M，可以将它划分成两部分区域，一部分是小于等于K的区域，一部分是大于K的区域。沿着两部分区域的边界线查找K即可。\n``` java\npublic class SearchaMatrix {\n\tpublic static boolean searchMatrix(int[][] matrix, int target) {\n\t\tint m = matrix.length;\n\t\tint n = matrix[0].length;\n        int i = 0;\n        int j = n - 1;\n        while (i < m && j >= 0) {\n        \tif (matrix[i][j] > target) {\n        \t\tj--;\n        \t} else if (matrix[i][j] < target) {\n        \t\ti++;\n        \t} else {\n        \t\treturn true;\n        \t}   \t\n        }\n        return false;\n    }\n\tpublic static void main(String[] args) {\n\t\tint[][] nums = { {1, 4, 7, 11, 15},{2, 5, 8, 12, 19},{3, 6, 9, 16, 22},{10, 13, 14, 17, 24},{18, 21, 23, 26, 30}};\n\t\tSystem.out.println(searchMatrix(nums, 17));\n\t}\n}\n```","slug":"查找矩阵","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4jz00df26s62867e1zg"},{"title":"最长平台","id":"1025","date":"2015-10-22T06:32:33.000Z","_content":"\n最近又把冼镜光的《C语言名题精选百则--技巧篇》拿出来看看，确实不错。\n\n已知一个已经从小到大排序的数组，这个数组中的一个平台(plateau) 就是连续的一串相同的元素，并且这一串元素不能再延伸。例如，在1，2，2，3，3，3，4，5，5，6中1，2.2，3.3.3，4，5.5，6都是平台。试编写一个程序，接受一个数组，把这个数组中最长的平台找出来。在上面的例子中，3.3.3就是该数组的最长平台。\n这个问题曾经困扰过计算机科学家David Gries，他给出的方法如下\n\n``` java\npublic class Pleateau {\n\tpublic static int pleateau(int[] nums) {\n\t\tint length = 1;\n\t\tfor (int i = 1; i < nums.length; i++) {\n\t\t\tif (nums[i] == nums[i - length]) {\n\t\t\t\tlength++;\n\t\t\t}\n\t\t}\n\t\treturn length;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6};\n\t\tSystem.out.println(pleateau(nums));\n\t}\n}\n```\n\n自己想到的方法如下\n\n``` java\npublic class Pleateau {\n\tpublic static int pleateau(int[] nums) {\n\t\tint length = 1;\n\t\tint i = 0;\n\t\twhile (i + length < nums.length) {\n\t\t\tif (nums[i] == nums[i + length]) {\n\t\t\t\tlength++;\n\t\t\t} else {\n\t\t\t\ti += length;\n\t\t\t\twhile (i < nums.length && i > 0 &&  nums[i] == nums[i - 1]) {\n\t\t\t\t\ti--;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn length;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6};\n\t\tSystem.out.println(pleateau(nums));\n\t}\n}\n```","source":"_posts/最长平台.md","raw":"title: 最长平台\ntags:\n  - C名题百则\nid: 1025\ncategories:\n  - 算法\ndate: 2015-10-22 14:32:33\n---\n\n最近又把冼镜光的《C语言名题精选百则--技巧篇》拿出来看看，确实不错。\n\n已知一个已经从小到大排序的数组，这个数组中的一个平台(plateau) 就是连续的一串相同的元素，并且这一串元素不能再延伸。例如，在1，2，2，3，3，3，4，5，5，6中1，2.2，3.3.3，4，5.5，6都是平台。试编写一个程序，接受一个数组，把这个数组中最长的平台找出来。在上面的例子中，3.3.3就是该数组的最长平台。\n这个问题曾经困扰过计算机科学家David Gries，他给出的方法如下\n\n``` java\npublic class Pleateau {\n\tpublic static int pleateau(int[] nums) {\n\t\tint length = 1;\n\t\tfor (int i = 1; i < nums.length; i++) {\n\t\t\tif (nums[i] == nums[i - length]) {\n\t\t\t\tlength++;\n\t\t\t}\n\t\t}\n\t\treturn length;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6};\n\t\tSystem.out.println(pleateau(nums));\n\t}\n}\n```\n\n自己想到的方法如下\n\n``` java\npublic class Pleateau {\n\tpublic static int pleateau(int[] nums) {\n\t\tint length = 1;\n\t\tint i = 0;\n\t\twhile (i + length < nums.length) {\n\t\t\tif (nums[i] == nums[i + length]) {\n\t\t\t\tlength++;\n\t\t\t} else {\n\t\t\t\ti += length;\n\t\t\t\twhile (i < nums.length && i > 0 &&  nums[i] == nums[i - 1]) {\n\t\t\t\t\ti--;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn length;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6};\n\t\tSystem.out.println(pleateau(nums));\n\t}\n}\n```","slug":"最长平台","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4k200di26s6hcio7u7b"},{"title":"最短编辑距离","id":"810","date":"2014-07-14T13:58:59.000Z","_content":"\n最短编辑距离说的是两个字符串A和B，求用最少的字符操作将字符串A转化为字符串B。这里所说的字符操作包括\n1.删除一个字符\n2.插入一个字符\n3.将一个字符改为另一个字符\n\n分析：\n先比较A和B的第一个字符，分两种情况\n1.两个字符相等\n此时只需要计算A和B剩下字符的编辑距离\n2.两个字符不相等\n此时有三种选择，\n（1）删除A的第一个字符，之后求A剩下的字符与B的编辑距离\n（2）在A中插入B的第一个字符，之后求A与B剩下字符的编辑距离\n（3）将A的第一个字符变成B的第一个字符，之后求A剩下的字符与B剩下的字符的编辑距离\n之后返回这三种情况的最小值，再加上1，即是A转化为B的最短编辑距离\n\n依照上述方法，很容易写出一个递归方法\n``` python\ndef edit_distance(a, b):\n    if a == '':\n        return len(b)\n    if b == '':\n        return len(a)\n    if a[0] == b[0]:\n        return edit_distance(a[1:], b[1:])\n    else:\n        return min(edit_distance(a[1:], b), edit_distance(a, b[1:]), edit_distance(a[1:], b[1:])) + 1\nA=\"fxpimu\"\nB=\"xwrs\"    \nprint edit_distance(A, B)\n```\n唯一的缺点是，这种方法太慢了，于是想到用动态规划，此时最好还是从后面考虑，也就是考虑A和B最后一个字符的相等情况，再根据上面的分析计算。\n``` python\ndef edit_distance(a, b):\n    la = len(a)\n    lb = len(b)\n    dp = [[0 for i in xrange(lb + 1)] for j in xrange(la + 1)]\n    for i in xrange(1, la + 1):\n        dp[i][0] = i\n    for j in xrange(1, lb + 1):\n        dp[0][j] = j\n    for i in xrange(la):\n        for j in xrange(lb):\n            if a[i] == b[j]:\n                dp[i + 1][j + 1] = dp[i][j]\n            else:\n                dp[i + 1][j + 1] = min(dp[i + 1][j], dp[i][j + 1], dp[i][j]) + 1\n    return dp[la][lb]\n\nA=\"fxpimu\"\nB=\"xwrs\"\nprint edit_distance(A, B)\n```","source":"_posts/最短编辑距离.md","raw":"title: 最短编辑距离\ntags:\n  - 动态规划\n  - 编辑距离\n  - 递归\nid: 810\ncategories:\n  - 算法\ndate: 2014-07-14 21:58:59\n---\n\n最短编辑距离说的是两个字符串A和B，求用最少的字符操作将字符串A转化为字符串B。这里所说的字符操作包括\n1.删除一个字符\n2.插入一个字符\n3.将一个字符改为另一个字符\n\n分析：\n先比较A和B的第一个字符，分两种情况\n1.两个字符相等\n此时只需要计算A和B剩下字符的编辑距离\n2.两个字符不相等\n此时有三种选择，\n（1）删除A的第一个字符，之后求A剩下的字符与B的编辑距离\n（2）在A中插入B的第一个字符，之后求A与B剩下字符的编辑距离\n（3）将A的第一个字符变成B的第一个字符，之后求A剩下的字符与B剩下的字符的编辑距离\n之后返回这三种情况的最小值，再加上1，即是A转化为B的最短编辑距离\n\n依照上述方法，很容易写出一个递归方法\n``` python\ndef edit_distance(a, b):\n    if a == '':\n        return len(b)\n    if b == '':\n        return len(a)\n    if a[0] == b[0]:\n        return edit_distance(a[1:], b[1:])\n    else:\n        return min(edit_distance(a[1:], b), edit_distance(a, b[1:]), edit_distance(a[1:], b[1:])) + 1\nA=\"fxpimu\"\nB=\"xwrs\"    \nprint edit_distance(A, B)\n```\n唯一的缺点是，这种方法太慢了，于是想到用动态规划，此时最好还是从后面考虑，也就是考虑A和B最后一个字符的相等情况，再根据上面的分析计算。\n``` python\ndef edit_distance(a, b):\n    la = len(a)\n    lb = len(b)\n    dp = [[0 for i in xrange(lb + 1)] for j in xrange(la + 1)]\n    for i in xrange(1, la + 1):\n        dp[i][0] = i\n    for j in xrange(1, lb + 1):\n        dp[0][j] = j\n    for i in xrange(la):\n        for j in xrange(lb):\n            if a[i] == b[j]:\n                dp[i + 1][j + 1] = dp[i][j]\n            else:\n                dp[i + 1][j + 1] = min(dp[i + 1][j], dp[i][j + 1], dp[i][j]) + 1\n    return dp[la][lb]\n\nA=\"fxpimu\"\nB=\"xwrs\"\nprint edit_distance(A, B)\n```","slug":"最短编辑距离","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4k500dl26s6y7o2urh0"},{"title":"最小的K个数","id":"865","date":"2014-08-14T04:37:31.000Z","_content":"\n对于求最大的K个数和最小的K个数，一个解决的办法是使用堆，这里以最小的K个数为例。\n题目描述：\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n\n输入：\n每个测试案例包括2行：\n第一行为2个整数n，k(1<=n，k<=200000)，表示数组的长度。\n第二行包含n个整数，表示这n个数，数组中的数的范围是[0,1000 000 000]。\n\n输出：\n对应每个测试案例，输出最小的k个数，并按从小到大顺序打印。\n\n样例输入：\n8 4\n4 5 1 6 2 7 3 8\n样例输出：\n1 2 3 4\n\n对于这题，可以使用堆来解决。首先建立一个K个元素的大顶堆，对于之后的n-k个元素，每个与堆顶比较，如果大于堆顶，则它不可能是最小的K个数之一，如果小于堆顶，则将堆顶替换，并重建大顶堆。之后剩下的K个元素就是最小的K个数。对它们从小到大排序就可以得到结果。\n写成代码如下：\n``` c\n#include <stdio.h>\n#include <stdlib.h>\nvoid swap(int &a, int &b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\nvoid adjust_heap(int *a, int cur, int n) {\n    int left, right;\n    while (true) {\n        left = 2 * cur + 1;\n        right = 2 * cur + 2;\n        int index = cur;\n        if (left < n && a[left] > a[index]) {\n            index = left;\n        }\n        if (right < n && a[right] > a[index]) {\n            index = right;\n        }\n        if (index != cur) {\n            swap(a[cur], a[index]);\n            cur = index;\n        } else {\n            break;\n        }\n    }\n}\nvoid build_heap(int *a, int n) {\n    for (int i = (n - 1) / 2; i >= 0; i--) {\n        adjust_heap(a, i, n);\n    }\n}\nvoid heap_sort(int *a, int n) {\n    build_heap(a, n);\n    for (int i = n - 1; i > 0; i--) {\n        swap(a[0], a[i]);\n        adjust_heap(a, 0, i);\n    }\n} \nint main() {\n    int n, k, num;\n    while(scanf(\"%d %d\", &n, &k) != EOF) {\n        int *a = new int[k];\n        for (int i = 0; i < n; i++) {\n            scanf(\"%d\", &num);\n            if (i <= k - 1) {\n                a[i] = num;\n                if (i == k - 1) {\n                    build_heap(a, k);\n                }\n            } else {\n                if (a[0] > num) {\n                    swap(a[0], num);\n                    adjust_heap(a, 0, k);\n                }\n            }\n        }\n        heap_sort(a, k);\n        for (int i = 0; i < k - 1; i++) {\n            printf(\"%d \", a[i]);\n        }\n        printf(\"%d\\n\", a[k - 1]);\n        delete[] a;\n    }\n    return 0;\n}\n```\n","source":"_posts/最小的K个数.md","raw":"title: 最小的K个数\ntags:\n  - 堆\n  - 最小的K个数\nid: 865\ncategories:\n  - 算法\ndate: 2014-08-14 12:37:31\n---\n\n对于求最大的K个数和最小的K个数，一个解决的办法是使用堆，这里以最小的K个数为例。\n题目描述：\n输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4,。\n\n输入：\n每个测试案例包括2行：\n第一行为2个整数n，k(1<=n，k<=200000)，表示数组的长度。\n第二行包含n个整数，表示这n个数，数组中的数的范围是[0,1000 000 000]。\n\n输出：\n对应每个测试案例，输出最小的k个数，并按从小到大顺序打印。\n\n样例输入：\n8 4\n4 5 1 6 2 7 3 8\n样例输出：\n1 2 3 4\n\n对于这题，可以使用堆来解决。首先建立一个K个元素的大顶堆，对于之后的n-k个元素，每个与堆顶比较，如果大于堆顶，则它不可能是最小的K个数之一，如果小于堆顶，则将堆顶替换，并重建大顶堆。之后剩下的K个元素就是最小的K个数。对它们从小到大排序就可以得到结果。\n写成代码如下：\n``` c\n#include <stdio.h>\n#include <stdlib.h>\nvoid swap(int &a, int &b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\nvoid adjust_heap(int *a, int cur, int n) {\n    int left, right;\n    while (true) {\n        left = 2 * cur + 1;\n        right = 2 * cur + 2;\n        int index = cur;\n        if (left < n && a[left] > a[index]) {\n            index = left;\n        }\n        if (right < n && a[right] > a[index]) {\n            index = right;\n        }\n        if (index != cur) {\n            swap(a[cur], a[index]);\n            cur = index;\n        } else {\n            break;\n        }\n    }\n}\nvoid build_heap(int *a, int n) {\n    for (int i = (n - 1) / 2; i >= 0; i--) {\n        adjust_heap(a, i, n);\n    }\n}\nvoid heap_sort(int *a, int n) {\n    build_heap(a, n);\n    for (int i = n - 1; i > 0; i--) {\n        swap(a[0], a[i]);\n        adjust_heap(a, 0, i);\n    }\n} \nint main() {\n    int n, k, num;\n    while(scanf(\"%d %d\", &n, &k) != EOF) {\n        int *a = new int[k];\n        for (int i = 0; i < n; i++) {\n            scanf(\"%d\", &num);\n            if (i <= k - 1) {\n                a[i] = num;\n                if (i == k - 1) {\n                    build_heap(a, k);\n                }\n            } else {\n                if (a[0] > num) {\n                    swap(a[0], num);\n                    adjust_heap(a, 0, k);\n                }\n            }\n        }\n        heap_sort(a, k);\n        for (int i = 0; i < k - 1; i++) {\n            printf(\"%d \", a[i]);\n        }\n        printf(\"%d\\n\", a[k - 1]);\n        delete[] a;\n    }\n    return 0;\n}\n```\n","slug":"最小的K个数","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4k800ds26s67k3viirh"},{"title":"最大连续子序列","id":"828","date":"2014-07-15T00:23:30.000Z","_content":"\n知道这题，是在冼镜光的《C名题精选百则》中。记得这题是自己做出来的，所以稍微回忆一下，就能记起来。也许算法之所以这么难，就是因为不是自己想出来的，所以虽然看过，却很容易忘记。或许应该不只是看算法，而要知道原始作者的思考过程，这样才能真正理解。就像要想理解TCP/IP协议一样，比较好的办法是自己去设计TCP协议，看如何保证可靠传输。扯远了。\n\n对于这题，很容易写出如下程序：\n``` python\ndef max_con_sum(s):\n    length = len(s)\n    max_sum = s[0]\n    i = 0\n    temp_sum = s[0]\n    while i + 1 < length:\n        i += 1\n        if temp_sum < 0:\n            temp_sum = 0;\n        temp_sum += s[i]\n        if temp_sum > max_sum:\n            max_sum = temp_sum\n\n    return max_sum\nL = [2,-3,3,50]\nprint max_con_sum(L)\n```\n而如果还想知道最大连续子序列的开始位置和结束位置，之需要再增加额外的记录信息即可。\n``` python\ndef max_con_sum(s):\n    length = len(s)\n    max_sum = s[0]\n    start = 0;\n    end = 0\n    i = 0\n    temp_sum = s[0]\n    while i + 1 < length:\n        i += 1\n        if temp_sum < 0:\n            temp_sum = 0;\n            start = i\n        temp_sum += s[i]\n        if temp_sum > max_sum:\n            max_sum = temp_sum\n            end = i\n\n    return (max_sum,start,end)\nL = [2, -3, 3, 50]\nmax_sum,start,end =  max_con_sum(L)\nprint max_sum,start,end\n```","source":"_posts/最大连续子序列.md","raw":"title: 最大连续子序列\ntags:\n  - 最大连续子序列\nid: 828\ncategories:\n  - 算法\ndate: 2014-07-15 08:23:30\n---\n\n知道这题，是在冼镜光的《C名题精选百则》中。记得这题是自己做出来的，所以稍微回忆一下，就能记起来。也许算法之所以这么难，就是因为不是自己想出来的，所以虽然看过，却很容易忘记。或许应该不只是看算法，而要知道原始作者的思考过程，这样才能真正理解。就像要想理解TCP/IP协议一样，比较好的办法是自己去设计TCP协议，看如何保证可靠传输。扯远了。\n\n对于这题，很容易写出如下程序：\n``` python\ndef max_con_sum(s):\n    length = len(s)\n    max_sum = s[0]\n    i = 0\n    temp_sum = s[0]\n    while i + 1 < length:\n        i += 1\n        if temp_sum < 0:\n            temp_sum = 0;\n        temp_sum += s[i]\n        if temp_sum > max_sum:\n            max_sum = temp_sum\n\n    return max_sum\nL = [2,-3,3,50]\nprint max_con_sum(L)\n```\n而如果还想知道最大连续子序列的开始位置和结束位置，之需要再增加额外的记录信息即可。\n``` python\ndef max_con_sum(s):\n    length = len(s)\n    max_sum = s[0]\n    start = 0;\n    end = 0\n    i = 0\n    temp_sum = s[0]\n    while i + 1 < length:\n        i += 1\n        if temp_sum < 0:\n            temp_sum = 0;\n            start = i\n        temp_sum += s[i]\n        if temp_sum > max_sum:\n            max_sum = temp_sum\n            end = i\n\n    return (max_sum,start,end)\nL = [2, -3, 3, 50]\nmax_sum,start,end =  max_con_sum(L)\nprint max_sum,start,end\n```","slug":"最大连续子序列","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kb00dy26s6tmggl3qn"},{"title":"最大连续元素和","id":"1041","date":"2015-10-26T09:08:41.000Z","_content":"\n已知数组x[ ]储存了一组整数，请写一个程序，找出在数组中连续元素的和中最大的一个。举例而言，如果有数组1，2，-6，3，-2，4，-1，3，2，-4，那么连续的元素和有1 + 2 = 3，1 + 2 + (-6) = -3，2 + (-6) = -4，。。。，但最大的就是3 + (-2) + 4 + (-1) + 3 + 2这一段，值为9。这个题目通常叫做最大连续元素和问题，或者叫做最大连续子数组。\n\n一个自然的办法是使用双重循环，但是性能不好。这个问题要求O(n)解法，需要动点脑筋。\n``` java\npublic class MaximumSubarray {\n\tpublic static int maxSubArray(int[] nums) {\n\t\tint result = nums[0];\n\t\tint sum = nums[0];\n\t\tfor (int i = 1; i < nums.length; i++) {\n\t\t\tif (sum < 0) {\n\t\t\t\tsum = 0;\n\t\t\t}\n\t\t\tsum += nums[i];\n\t\t\tresult = Math.max(result, sum);\n\t\t}\n\t\treturn result;      \n    }\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, -6, 3, -2, 4, -1, 3, 2, -4};\n\t\tSystem.out.println(maxSubArray(nums));\n\t}\n}\n```\n还有一种是分治的方法，效率慢一些\n``` java\npublic class MaximumSubarray {\n\tpublic static int maxSubArray(int[] nums) {\n\t\treturn maxSubArray(nums, 0, nums.length - 1);    \n    }\n\tpublic static int maxSubArray(int[] nums, int left, int right) {\n\t\tif (left > right) {\n\t\t\treturn Integer.MIN_VALUE;\n\t\t} else if (left == right) {\n\t\t\treturn nums[left];\n\t\t} else {\n\t\t\tint middle = (right - left) / 2 + left;\n\t\t\tint leftMax = maxSubArray(nums, left, middle);\n\t\t\tint rightMax = maxSubArray(nums, middle + 1, right);\n\t\t\tint sum = 0;\n\t\t\tint maxToLeft = Integer.MIN_VALUE;\n\t\t\tfor (int i = middle; i >= left; i--) {\n\t\t\t\tsum += nums[i];\n\t\t\t\tmaxToLeft = Math.max(maxToLeft, sum);\n\t\t\t}\n\t\t\tsum = 0;\n\t\t\tint maxToRight = Integer.MIN_VALUE;\n\t\t\tfor (int i = middle + 1; i <= right; i++) {\n\t\t\t\tsum += nums[i];\n\t\t\t\tmaxToRight = Math.max(maxToRight, sum);\n\t\t\t}\n\t\t\tint result = maxToLeft + maxToRight;\n\t\t\tresult = Math.max(result, leftMax);\n\t\t\tresult = Math.max(result, rightMax);\n\t\t\treturn result;\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, -6, 3, -2, 4, -1, 3, 2, -4};\n\t\tSystem.out.println(maxSubArray(nums));\n\t}\n}\n```","source":"_posts/最大连续元素和.md","raw":"title: 最大连续元素和\ntags:\n  - C名题百则\nid: 1041\ncategories:\n  - 算法\ndate: 2015-10-26 17:08:41\n---\n\n已知数组x[ ]储存了一组整数，请写一个程序，找出在数组中连续元素的和中最大的一个。举例而言，如果有数组1，2，-6，3，-2，4，-1，3，2，-4，那么连续的元素和有1 + 2 = 3，1 + 2 + (-6) = -3，2 + (-6) = -4，。。。，但最大的就是3 + (-2) + 4 + (-1) + 3 + 2这一段，值为9。这个题目通常叫做最大连续元素和问题，或者叫做最大连续子数组。\n\n一个自然的办法是使用双重循环，但是性能不好。这个问题要求O(n)解法，需要动点脑筋。\n``` java\npublic class MaximumSubarray {\n\tpublic static int maxSubArray(int[] nums) {\n\t\tint result = nums[0];\n\t\tint sum = nums[0];\n\t\tfor (int i = 1; i < nums.length; i++) {\n\t\t\tif (sum < 0) {\n\t\t\t\tsum = 0;\n\t\t\t}\n\t\t\tsum += nums[i];\n\t\t\tresult = Math.max(result, sum);\n\t\t}\n\t\treturn result;      \n    }\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, -6, 3, -2, 4, -1, 3, 2, -4};\n\t\tSystem.out.println(maxSubArray(nums));\n\t}\n}\n```\n还有一种是分治的方法，效率慢一些\n``` java\npublic class MaximumSubarray {\n\tpublic static int maxSubArray(int[] nums) {\n\t\treturn maxSubArray(nums, 0, nums.length - 1);    \n    }\n\tpublic static int maxSubArray(int[] nums, int left, int right) {\n\t\tif (left > right) {\n\t\t\treturn Integer.MIN_VALUE;\n\t\t} else if (left == right) {\n\t\t\treturn nums[left];\n\t\t} else {\n\t\t\tint middle = (right - left) / 2 + left;\n\t\t\tint leftMax = maxSubArray(nums, left, middle);\n\t\t\tint rightMax = maxSubArray(nums, middle + 1, right);\n\t\t\tint sum = 0;\n\t\t\tint maxToLeft = Integer.MIN_VALUE;\n\t\t\tfor (int i = middle; i >= left; i--) {\n\t\t\t\tsum += nums[i];\n\t\t\t\tmaxToLeft = Math.max(maxToLeft, sum);\n\t\t\t}\n\t\t\tsum = 0;\n\t\t\tint maxToRight = Integer.MIN_VALUE;\n\t\t\tfor (int i = middle + 1; i <= right; i++) {\n\t\t\t\tsum += nums[i];\n\t\t\t\tmaxToRight = Math.max(maxToRight, sum);\n\t\t\t}\n\t\t\tint result = maxToLeft + maxToRight;\n\t\t\tresult = Math.max(result, leftMax);\n\t\t\tresult = Math.max(result, rightMax);\n\t\t\treturn result;\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, -6, 3, -2, 4, -1, 3, 2, -4};\n\t\tSystem.out.println(maxSubArray(nums));\n\t}\n}\n```","slug":"最大连续元素和","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ke00e226s6lwh27aps"},{"title":"最大子矩阵","id":"876","date":"2014-08-16T05:50:19.000Z","_content":"\n昨天去面试，面试官出了一道最大连续子序列的题目后，很快就做出来，因为前不久还做过笔记的。之后出了一道，最大子矩阵的题目。也就是给出一个矩阵，如：\n0 -2 -7 0 \n9 2 -6 2 \n-4 1 -4 1 \n-1 8 0 -2 \n求它的子矩阵的最大和。\n如\n9 2 \n-4 1 \n-1 8\n是最大子矩阵，和为15.​\n\n想了一会之后，找到了一个转化为最大连续子序列的办法。也就是先对列求和，之后再用最大连续子序列的方法。给出这个办法后，还想考虑优化，只是一直想不出来。回来之后，想起编程之美上有类似的题目，看了之后，没想到已经是最优的了。又想起以前在POJ应该做过类似的题目，于是找到了POJ1050- To The Max. 编写代码如下：\n``` c\n#include <stdio.h>\n#include <stdlib.h>\n#define N 100\nint a[N][N];\nint b[N];\nint max_sub_array(int *a, int n) {\n    int max_sum = a[0];\n    int sum = a[0];\n    for (int i = 1; i < n; i++) {\n        if (sum < 0) {\n            sum = 0;\n        }\n        sum += a[i];\n        if (sum > max_sum) {\n            max_sum = sum;\n        }\n    }\n    return max_sum;\n}\nint main() {\n    int n;\n    scanf(\"%d\", &n);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            scanf(\"%d\", &a[i][j]);\n        }\n    }\n    int max_sum = -127 * 100 * 100;\n    for (int i = 0; i < n; i++) {\n        for (int k = 0; k < n; k++) {\n            b[k] = 0;\n        }\n        for (int j = i; j < n; j++) {\n            for (int k = 0; k < n; k++) {\n                b[k] += a[j][k];\n            }\n            int sum = max_sub_array(b, n);\n            if (sum > max_sum) {\n                max_sum = sum;\n            }\n        }\n    }\n    printf(\"%d\\n\", max_sum);\n    return 0;\n}\n```","source":"_posts/最大子矩阵.md","raw":"title: 最大子矩阵\ntags:\n  - 最大子矩阵\n  - 最大连续子序列\nid: 876\ncategories:\n  - 算法\ndate: 2014-08-16 13:50:19\n---\n\n昨天去面试，面试官出了一道最大连续子序列的题目后，很快就做出来，因为前不久还做过笔记的。之后出了一道，最大子矩阵的题目。也就是给出一个矩阵，如：\n0 -2 -7 0 \n9 2 -6 2 \n-4 1 -4 1 \n-1 8 0 -2 \n求它的子矩阵的最大和。\n如\n9 2 \n-4 1 \n-1 8\n是最大子矩阵，和为15.​\n\n想了一会之后，找到了一个转化为最大连续子序列的办法。也就是先对列求和，之后再用最大连续子序列的方法。给出这个办法后，还想考虑优化，只是一直想不出来。回来之后，想起编程之美上有类似的题目，看了之后，没想到已经是最优的了。又想起以前在POJ应该做过类似的题目，于是找到了POJ1050- To The Max. 编写代码如下：\n``` c\n#include <stdio.h>\n#include <stdlib.h>\n#define N 100\nint a[N][N];\nint b[N];\nint max_sub_array(int *a, int n) {\n    int max_sum = a[0];\n    int sum = a[0];\n    for (int i = 1; i < n; i++) {\n        if (sum < 0) {\n            sum = 0;\n        }\n        sum += a[i];\n        if (sum > max_sum) {\n            max_sum = sum;\n        }\n    }\n    return max_sum;\n}\nint main() {\n    int n;\n    scanf(\"%d\", &n);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            scanf(\"%d\", &a[i][j]);\n        }\n    }\n    int max_sum = -127 * 100 * 100;\n    for (int i = 0; i < n; i++) {\n        for (int k = 0; k < n; k++) {\n            b[k] = 0;\n        }\n        for (int j = i; j < n; j++) {\n            for (int k = 0; k < n; k++) {\n                b[k] += a[j][k];\n            }\n            int sum = max_sub_array(b, n);\n            if (sum > max_sum) {\n                max_sum = sum;\n            }\n        }\n    }\n    printf(\"%d\\n\", max_sum);\n    return 0;\n}\n```","slug":"最大子矩阵","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kg00e526s698sewiuw"},{"title":"无解的难题","id":"757","date":"2014-06-21T14:19:36.000Z","_content":"\n知道这个题目，是在任晓祎的博客里，据悉是加德纳改编的。题目如下：\n\n某天, 老师召集了他最聪明的两个学生P和S, 递给每人一张纸条, 然后说, 有两个不小于2的整数x和y,满足x != y, 且x+y < 100\\. 给P的纸条上写有两个数的乘积p = x * y, 给S的纸条上写有两个数的和s = x+y, 请他们确定这两个数具体的值是多少. 于是P和S进行对话:\n\n1.  P: 我无法确定这两个数是多少.\n2.  S: 我知道你无法确定这两个数是多少.\n3.  P: 既然这样, 那我知道这两个数是多少了.\n4.  S: 既然这样, 那我也知道这两个数是多少了.\n请读者根据以上信息确定这两个数是多少.\n\n当时看到这个题目后，和绍祝师兄一起做这道题，同时告诉海龙同学。和师兄讨论后，知道了题意，于是着手写代码，师兄用C++，我用C，结果两人都没写出来。很快海龙同学就得到了一个答案，是用手算得到的。我和师兄两人都汗颜了，有趣的是，这个答案就是唯一解。\n\n回顾这道题，理清题意,大致如下：\n\n1.P:我无法确定这两个数是多少。从这里可以得到，乘积p的分解不只一种，如12，可以分解成2 * 6， 3 * 4。\n\n2.S:我知道你无法确定这两个数是多少。从这里可以得到，和s的分解中，x和y得到的乘积的分解不只一种，所有分解都满足条件1.如s为11时,可以分成2 + 9, 3 + 8, 4 + 7, 5 + 6,其中2和9的乘积为18，可以分解成2 * 9, 3 * 6; 对于3和8，4和7，5和6也是类似。\n\n3.P: 既然这样, 那我知道这两个数是多少了。从这里可以得到乘积p的所有分解中，只有一个分解满足条件2。如18，18可以分解成2 * 9, 3 * 6,只有2和9的和11满足条件2，3和6的乘积不满足条件2.类似的还有24，28.\n\n4.S: 既然这样, 那我也知道这两个数是多少了. 从这里可以得到s的所有分解中只有一组满足条件3.所以11不满足这个条件,因为11的分解中2 + 9, 3 + 8, 4 + 7，分别得到的18，24，28都满足条件3.\n\n对于这种题目，还是用Python写比较方便。写成代码如下：\n\n``` python\n#coding:utf-8\nfrom math import sqrt\n\ndef pone(p, u):\n    c = 0\n    for x in xrange(2, int(sqrt(p)) + 1):\n        if p % x == 0 and x + p / x < u:\n            c += 1\n    return c >= 2\n\ndef sone(s, u):\n    for x in xrange(2, s / 2):\n        y = s - x\n        if not pone(x * y, u):\n            return False\n    return True\n\ndef ptwo(p, u):\n    c = 0\n    for x in xrange(2, int(sqrt(p)) + 1):\n        if p % x == 0 and x + p / x < u:\n            y = p / x\n            if sone(x + y, u):\n                c += 1\n    return c == 1\ndef stwo(s, u):\n    c = 0\n    for x in xrange(2, s / 2):\n        y = s - x\n        if ptwo(x * y, u):\n            c += 1\n    return c == 1\n\nif __name__ == \"__main__\":\n    u = 100\n    for x in xrange(2, u / 2):\n        for y in xrange(x + 1, u - x):\n            p = x * y\n            s = x + y\n            if pone(p, u) and sone(s, u) and ptwo(p, u) and stwo(s, u):\n                print \"x:%d, y:%d, p:%d, s:%d \" % (x, y, p, s)\n```","source":"_posts/无解的难题.md","raw":"title: 无解的难题\ntags:\n  - 加德纳\n  - 无解的难题\nid: 757\ncategories:\n  - 数学\ndate: 2014-06-21 22:19:36\n---\n\n知道这个题目，是在任晓祎的博客里，据悉是加德纳改编的。题目如下：\n\n某天, 老师召集了他最聪明的两个学生P和S, 递给每人一张纸条, 然后说, 有两个不小于2的整数x和y,满足x != y, 且x+y < 100\\. 给P的纸条上写有两个数的乘积p = x * y, 给S的纸条上写有两个数的和s = x+y, 请他们确定这两个数具体的值是多少. 于是P和S进行对话:\n\n1.  P: 我无法确定这两个数是多少.\n2.  S: 我知道你无法确定这两个数是多少.\n3.  P: 既然这样, 那我知道这两个数是多少了.\n4.  S: 既然这样, 那我也知道这两个数是多少了.\n请读者根据以上信息确定这两个数是多少.\n\n当时看到这个题目后，和绍祝师兄一起做这道题，同时告诉海龙同学。和师兄讨论后，知道了题意，于是着手写代码，师兄用C++，我用C，结果两人都没写出来。很快海龙同学就得到了一个答案，是用手算得到的。我和师兄两人都汗颜了，有趣的是，这个答案就是唯一解。\n\n回顾这道题，理清题意,大致如下：\n\n1.P:我无法确定这两个数是多少。从这里可以得到，乘积p的分解不只一种，如12，可以分解成2 * 6， 3 * 4。\n\n2.S:我知道你无法确定这两个数是多少。从这里可以得到，和s的分解中，x和y得到的乘积的分解不只一种，所有分解都满足条件1.如s为11时,可以分成2 + 9, 3 + 8, 4 + 7, 5 + 6,其中2和9的乘积为18，可以分解成2 * 9, 3 * 6; 对于3和8，4和7，5和6也是类似。\n\n3.P: 既然这样, 那我知道这两个数是多少了。从这里可以得到乘积p的所有分解中，只有一个分解满足条件2。如18，18可以分解成2 * 9, 3 * 6,只有2和9的和11满足条件2，3和6的乘积不满足条件2.类似的还有24，28.\n\n4.S: 既然这样, 那我也知道这两个数是多少了. 从这里可以得到s的所有分解中只有一组满足条件3.所以11不满足这个条件,因为11的分解中2 + 9, 3 + 8, 4 + 7，分别得到的18，24，28都满足条件3.\n\n对于这种题目，还是用Python写比较方便。写成代码如下：\n\n``` python\n#coding:utf-8\nfrom math import sqrt\n\ndef pone(p, u):\n    c = 0\n    for x in xrange(2, int(sqrt(p)) + 1):\n        if p % x == 0 and x + p / x < u:\n            c += 1\n    return c >= 2\n\ndef sone(s, u):\n    for x in xrange(2, s / 2):\n        y = s - x\n        if not pone(x * y, u):\n            return False\n    return True\n\ndef ptwo(p, u):\n    c = 0\n    for x in xrange(2, int(sqrt(p)) + 1):\n        if p % x == 0 and x + p / x < u:\n            y = p / x\n            if sone(x + y, u):\n                c += 1\n    return c == 1\ndef stwo(s, u):\n    c = 0\n    for x in xrange(2, s / 2):\n        y = s - x\n        if ptwo(x * y, u):\n            c += 1\n    return c == 1\n\nif __name__ == \"__main__\":\n    u = 100\n    for x in xrange(2, u / 2):\n        for y in xrange(x + 1, u - x):\n            p = x * y\n            s = x + y\n            if pone(p, u) and sone(s, u) and ptwo(p, u) and stwo(s, u):\n                print \"x:%d, y:%d, p:%d, s:%d \" % (x, y, p, s)\n```","slug":"无解的难题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ki00ea26s6yhanz03o"},{"title":"整数划分","id":"833","date":"2014-07-15T07:57:33.000Z","_content":"\n整数划分说的是给定一个正整数N，求一共有多少种方式将N分解成不超过N的正整数和。\n例如：N=4时，一共有5种划分，如下：\n4 = 4\n4 = 3 + 1\n4 = 2 + 2\n4 = 2 + 1 + 1\n4 = 1 + 1 + 1 + 1\n\n如果没记错的话，在《C名题精选百则》中出现过这题。我们可以考虑更普遍的情况，将正整数N分解成不超过M的整数和的情况。\n对于这种情况，可以将分解分成包含整数M和不包含整数M的情况。令f(N,M)为总共的分解方式，则\nf(N,M) = f(N - M, M) + f(N, M -1)，于是写成程序如下：\n``` python\ndef partition(n):\n    return _partition(n, n)\n\ndef _partition(n, m):\n    if n == 0:\n        return 1\n    if n < 0:\n        return 0\n    if m == 1:\n        return 1\n    else:\n        return _partition(n - m, m) + _partition(n, m - 1)\nfor i in xrange(1, 10):\n    print i, partition(i)\n```\n只是当n比较大时，递归的效率太慢了，于是用动态规划重写：\n``` python\ndef partition(n):\n    dp = [[0 for i in xrange(n + 1)] for j in xrange(n + 1)]\n    for i in xrange(n + 1):\n        dp[i][1] = 1\n        dp[0][i] = 1\n    for i in xrange(1, n + 1):\n        for j in xrange(1, n + 1):\n            if i - j >= 0:\n                dp[i][j] = dp[i - j][j] + dp[i][j - 1]\n            else:\n                dp[i][j] = dp[i][j - 1]\n    return dp[n][n]\n\nfor i in xrange(1, 10):\n    print i, partition(i)\n```","source":"_posts/整数划分.md","raw":"title: 整数划分\ntags:\n  - 动态规划\n  - 整数划分\n  - 递归\nid: 833\ncategories:\n  - 算法\ndate: 2014-07-15 15:57:33\n---\n\n整数划分说的是给定一个正整数N，求一共有多少种方式将N分解成不超过N的正整数和。\n例如：N=4时，一共有5种划分，如下：\n4 = 4\n4 = 3 + 1\n4 = 2 + 2\n4 = 2 + 1 + 1\n4 = 1 + 1 + 1 + 1\n\n如果没记错的话，在《C名题精选百则》中出现过这题。我们可以考虑更普遍的情况，将正整数N分解成不超过M的整数和的情况。\n对于这种情况，可以将分解分成包含整数M和不包含整数M的情况。令f(N,M)为总共的分解方式，则\nf(N,M) = f(N - M, M) + f(N, M -1)，于是写成程序如下：\n``` python\ndef partition(n):\n    return _partition(n, n)\n\ndef _partition(n, m):\n    if n == 0:\n        return 1\n    if n < 0:\n        return 0\n    if m == 1:\n        return 1\n    else:\n        return _partition(n - m, m) + _partition(n, m - 1)\nfor i in xrange(1, 10):\n    print i, partition(i)\n```\n只是当n比较大时，递归的效率太慢了，于是用动态规划重写：\n``` python\ndef partition(n):\n    dp = [[0 for i in xrange(n + 1)] for j in xrange(n + 1)]\n    for i in xrange(n + 1):\n        dp[i][1] = 1\n        dp[0][i] = 1\n    for i in xrange(1, n + 1):\n        for j in xrange(1, n + 1):\n            if i - j >= 0:\n                dp[i][j] = dp[i - j][j] + dp[i][j - 1]\n            else:\n                dp[i][j] = dp[i][j - 1]\n    return dp[n][n]\n\nfor i in xrange(1, 10):\n    print i, partition(i)\n```","slug":"整数划分","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kl00eh26s6rz18zjkd"},{"title":"数字漩涡 ","id":"893","date":"2014-08-22T02:56:26.000Z","_content":"\n还在学校的时候，绍祝师兄每次面试回来，如果有趣题都会和我讨论，因为正好坐他边上，记得这题也是那时讨论的一题。记得当时想了一会后就做出来了。只是时隔多年，再次遇到这题，已经忘记当初是怎么做了。\n\n题目很简单，对于3 打印\n 1 2 3\n8 9 4\n7 6 5\n对于4，打印\n 1  2   3  4\n12 13 14  5\n11 16 15  6\n10  9  8  7\n​​\n观察之后发现规律，先是向右一直走，之后向下一直走，之后向左，最后向上，每次变换方向的原因有两个，一个是走到矩形的边界，另一个是沿着这个方向走，前面的一个位置已经走过了。在当前位置，要找下一个有效位置，只需按顺序遍历上面四个方向即可。写成代码如下：\n``` python\ndef spiral_number(N):\n    step_x = [0, 1, 0, -1]\n    step_y = [1, 0, -1, 0]\n    a = [[0 for j in xrange(N)] for j in xrange(N)]\n    dir = 0\n    i = 0\n    j = 0\n    a[i][j] = 1\n    n = 2\n    while n <= N ** 2:\n        x = i + step_x[dir]\n        y = j + step_y[dir]\n        if x >= 0 and x < N and y >= 0 and y < N and a[x][y] == 0:\n            a[x][y] = n\n            n += 1\n            i = x\n            j = y\n        else:\n            dir = (dir + 1 + len(step_x)) % len(step_x)\n\n    for i in xrange(N):\n        for j in xrange(N):\n            print a[i][j],\n        print\n\nspiral_number(4)\n```","source":"_posts/数字漩涡.md","raw":"title: '数字漩涡 '\ntags:\n  - 枚举\n  - 漩涡\nid: 893\ncategories:\n  - 算法\ndate: 2014-08-22 10:56:26\n---\n\n还在学校的时候，绍祝师兄每次面试回来，如果有趣题都会和我讨论，因为正好坐他边上，记得这题也是那时讨论的一题。记得当时想了一会后就做出来了。只是时隔多年，再次遇到这题，已经忘记当初是怎么做了。\n\n题目很简单，对于3 打印\n 1 2 3\n8 9 4\n7 6 5\n对于4，打印\n 1  2   3  4\n12 13 14  5\n11 16 15  6\n10  9  8  7\n​​\n观察之后发现规律，先是向右一直走，之后向下一直走，之后向左，最后向上，每次变换方向的原因有两个，一个是走到矩形的边界，另一个是沿着这个方向走，前面的一个位置已经走过了。在当前位置，要找下一个有效位置，只需按顺序遍历上面四个方向即可。写成代码如下：\n``` python\ndef spiral_number(N):\n    step_x = [0, 1, 0, -1]\n    step_y = [1, 0, -1, 0]\n    a = [[0 for j in xrange(N)] for j in xrange(N)]\n    dir = 0\n    i = 0\n    j = 0\n    a[i][j] = 1\n    n = 2\n    while n <= N ** 2:\n        x = i + step_x[dir]\n        y = j + step_y[dir]\n        if x >= 0 and x < N and y >= 0 and y < N and a[x][y] == 0:\n            a[x][y] = n\n            n += 1\n            i = x\n            j = y\n        else:\n            dir = (dir + 1 + len(step_x)) % len(step_x)\n\n    for i in xrange(N):\n        for j in xrange(N):\n            print a[i][j],\n        print\n\nspiral_number(4)\n```","slug":"数字漩涡","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ko00en26s6hh6t6rg4"},{"title":"收到金融学结业证书","id":"733","date":"2014-05-25T03:14:21.000Z","_content":"\n今天收到了金融学的结业证书，心中的一个结也解开了。两年前就选修这门课，可是由于时间因素，没有学完，心中一直耿耿于怀。今年抽空把这么课学完，并拿到了结业证书。\n\n事实上，学完之后，很多知识又忘记了。可是上完这么课后，我知道了，股票是一个好东西。\n\n[![金融学结业证书](http://program.dengshilong.org/wp-content/uploads/2014/05/金融学结业证书.png)](http://program.dengshilong.org/wp-content/uploads/2014/05/金融学结业证书.png)","source":"_posts/收到金融学结业证书.md","raw":"title: 收到金融学结业证书\ntags:\n  - 股票\n  - 金融学\nid: 733\ncategories:\n  - 未分类\ndate: 2014-05-25 11:14:21\n---\n\n今天收到了金融学的结业证书，心中的一个结也解开了。两年前就选修这门课，可是由于时间因素，没有学完，心中一直耿耿于怀。今年抽空把这么课学完，并拿到了结业证书。\n\n事实上，学完之后，很多知识又忘记了。可是上完这么课后，我知道了，股票是一个好东西。\n\n[![金融学结业证书](http://program.dengshilong.org/wp-content/uploads/2014/05/金融学结业证书.png)](http://program.dengshilong.org/wp-content/uploads/2014/05/金融学结业证书.png)","slug":"收到金融学结业证书","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kq00es26s63uu9iru2"},{"title":"支配值数目","id":"1033","date":"2015-10-22T07:14:00.000Z","_content":"\n已知f[]与g[]两个整数数组，元素已经从小到大排列，请写一个程序，算出f[]中比g[]元素大的对数。换句话说，f[0]比g[]中多少个元素大，f[1]比g[]中多少元素大等，这些值的总和就是要求的答案。\n\n例如，如果f[]中有1，3，5，7，9，而g[]中有2，3，4，7，8，比g[0]大的有f[1]~f[4], 比g[1]大的有f[2]~f[4]，比g[2]大的有f[2]~f[4]，比g[3]大的有f[4]，比g[4]大的有f[4]，因此答案是4 + 3 + 3 + 1 + 1 = 12\n\n利用数组已经排好序的这个特性，可以写出高效的程序.\n``` java\npublic class GTCount {\n\tpublic static int gtCount(int[] f, int[] g) {\n\t\tint i = 0;\n\t\tint j = 0;\n\t\tint result = 0;\n\t\twhile (i < f.length && j < g.length) {\n\t\t\tif (f[i] > g[j]) {\n\t\t\t\tresult += f.length - i;\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] f = {1, 3, 5, 7, 9};\n\t\tint[] g = {2, 3, 4, 7, 8};\n\t\tSystem.out.println(gtCount(f, g));\n\t}\n}\n```","source":"_posts/支配值数目.md","raw":"title: 支配值数目\ntags:\n  - C名题百则\nid: 1033\ncategories:\n  - 算法\ndate: 2015-10-22 15:14:00\n---\n\n已知f[]与g[]两个整数数组，元素已经从小到大排列，请写一个程序，算出f[]中比g[]元素大的对数。换句话说，f[0]比g[]中多少个元素大，f[1]比g[]中多少元素大等，这些值的总和就是要求的答案。\n\n例如，如果f[]中有1，3，5，7，9，而g[]中有2，3，4，7，8，比g[0]大的有f[1]~f[4], 比g[1]大的有f[2]~f[4]，比g[2]大的有f[2]~f[4]，比g[3]大的有f[4]，比g[4]大的有f[4]，因此答案是4 + 3 + 3 + 1 + 1 = 12\n\n利用数组已经排好序的这个特性，可以写出高效的程序.\n``` java\npublic class GTCount {\n\tpublic static int gtCount(int[] f, int[] g) {\n\t\tint i = 0;\n\t\tint j = 0;\n\t\tint result = 0;\n\t\twhile (i < f.length && j < g.length) {\n\t\t\tif (f[i] > g[j]) {\n\t\t\t\tresult += f.length - i;\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] f = {1, 3, 5, 7, 9};\n\t\tint[] g = {2, 3, 4, 7, 8};\n\t\tSystem.out.println(gtCount(f, g));\n\t}\n}\n```","slug":"支配值数目","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kt00ex26s6od49iplb"},{"title":"搭建Sphinx-for-chinese引擎时遇到的问题","id":"668","date":"2014-04-11T01:00:08.000Z","_content":"\n在[关于sphinx引擎的一些想法](http://program.dengshilong.org/2014/04/11/关于sphinx引擎的一些想法/)说过用Sphinx给同事搭引擎，可是那是建立在之前的配置文件之上，我只要依葫芦画瓢，改一改路径以及查询语句就搞定了，实质上没学到什么东西。在我看来，要想真正了解它，还是得重新造轮子，从头到尾自己搭一遍，在这个过程中出现了许多奇怪的错误，在这里记录一下。\n\n1.checking for clock_gettime in -lrt...\n这是我遇到的第一个问题，事实证明，这根本不是问题。到Sphinx-for-chinese下载了编译包，开始编译，之后就卡在了这里。刚开始以为是缺少librt，然而我在lib中找到了这个链接库。将编译包放在其它机器上编译，又是可以通过的，百思不得其解。只好到Sphinx-fro-chinese的QQ群里发问，黑猫给出解答是要将librt所在路径加入到etc/ld.so.conf，并运行ldconfig命令。按照他的办法，结果运行ldconfig命令时卡住了，于是可以断定是机器的问题。\n\n2.ERROR: cannot find MySQL include files.\n这个问题比较好解决，就是缺少MySQL的库文件。因为虚拟机装的是Ubuntu，只要运行以下命令就好了。\nsudo apt-get install libmysql++-dev libmysqlclient15-dev checkinstall\n如果是其它系统，相信也是类似的方法。如果已经有库文件了，则只需要将路径加入到/etc/ld.so.conf中，并执行ldconfig命令\n\n3.index 'test1': search error: query too complex, not enough stack (thread_stack=1217498K or higher required).\n这也是一个很奇怪的错误。我是按照文档中给出的例子建好索引，之后用命令行工具，也就是search要搜索的，结果就出现了这个错误。在网上搜索这个错误，没找到有用的信息，于是又求助于Sphinx-for-chinese群，群里的人说是因为命令行存在问题，用客户端搜就没问题。于是用客户端搜果然没问题，可是我还是无法释怀，因为之前公司的引擎中，用命令行是没有问题的。于是对照着公司用的引擎中的配置文件，发现配置文件中没有这一行，在自己的配置文件中注释掉这行后，果然没问题了。\n所以对于这个错误的解决办法就是，将`sql_query_info = SELECT * FROM documents WHERE id=$id`这行注释掉.\n这个确实太坑人了，连官方的配置文件都会出错，得浪费多少人的时间。\n\n4.ERROR: index 'main': No fields in schema - will not index.\n光运行例子是不行的，还是得自己写一些东西，于是将自己的博客文章来搜索。用了Wordpress中wp_posts表中的数据，我只用的四个字段ID,post_title,post_content,post_modified,将post_title,post_content定义成sql_attr_string,sql_attr_timestamp,结果就出现了这个错误。在网上找了，发现在官方bug报告中有提到这个问题\n[http://sphinxsearch.com/bugs/view.php?id=1632](http://sphinxsearch.com/bugs/view.php?id=1632)\n管理员说，引擎中需要一个全文索引字段，否则就没有东西需要索引了，这样它就不会建索引。管理员建议定义为sql_field_string,这样就会对这个字段既索引又保存内容。对于我的配置，我并不想保存post_content这个字段，所以不想将它定义为sql_field_string,那怎样才能让它只被所以呢？看过文档之后，才知道默认情况下，是会被索引。这也是为什么，在上面的帖子中，将sql_attr_string = text注释掉就可以建索引了。所以我只能说管理员也没有真正理解这个错误的原因，看来不能迷信权威啊。\n\n5.FATAL: there must be 2 indexes to merge specified\n这个是在测试Klist的时，出现的。文档中说，当合并两个索引时，使用--merge-klists就可以将两个索引的klist合并，于是我在合并时加上了这个参数。具体如下：\n```\n./indexer -c $conf --rotate --merge --merge-klists delta deltaTemp\n```\n运行时就出现这个错误，我纳闷了，明明官方文档中说加入这个参数是没问题的。到网上找资料，有人是用--merge-killlists这个参数，试过之后，同样报这个错误。无奈之际，将--merge-klist参数放到--rotate前面，\n./indexer -c $conf --merge-klists --rotate --merge delta deltaTemp\n奇迹出现了，这次没有报错。我只能说，这真是个坑。\n\n《Introduction to Search with Sphinx》写的还是非常不错的，毕竟是Sphinx的作者，表达能力和写作能力自然非同凡响，关于Sphinx的知识，许多都来自本书。等有时间了，可以将引擎的搭建过程写一写，应该可以帮助一些人。这次搭建过程，我学到了许多，虽然用的是开源的引擎，但真要从头到尾搭建一个引擎，并提供可靠的服务，并不是那么容易的，还是得多实践才行。\n","source":"_posts/搭建Sphinx-for-chinese引擎时遇到的问题.md","raw":"title: 搭建Sphinx-for-chinese引擎时遇到的问题\ntags:\n  - Klist\n  - Sphinx\n  - Sphinx-for-chinese\nid: 668\ncategories:\n  - 搜索引擎\ndate: 2014-04-11 09:00:08\n---\n\n在[关于sphinx引擎的一些想法](http://program.dengshilong.org/2014/04/11/关于sphinx引擎的一些想法/)说过用Sphinx给同事搭引擎，可是那是建立在之前的配置文件之上，我只要依葫芦画瓢，改一改路径以及查询语句就搞定了，实质上没学到什么东西。在我看来，要想真正了解它，还是得重新造轮子，从头到尾自己搭一遍，在这个过程中出现了许多奇怪的错误，在这里记录一下。\n\n1.checking for clock_gettime in -lrt...\n这是我遇到的第一个问题，事实证明，这根本不是问题。到Sphinx-for-chinese下载了编译包，开始编译，之后就卡在了这里。刚开始以为是缺少librt，然而我在lib中找到了这个链接库。将编译包放在其它机器上编译，又是可以通过的，百思不得其解。只好到Sphinx-fro-chinese的QQ群里发问，黑猫给出解答是要将librt所在路径加入到etc/ld.so.conf，并运行ldconfig命令。按照他的办法，结果运行ldconfig命令时卡住了，于是可以断定是机器的问题。\n\n2.ERROR: cannot find MySQL include files.\n这个问题比较好解决，就是缺少MySQL的库文件。因为虚拟机装的是Ubuntu，只要运行以下命令就好了。\nsudo apt-get install libmysql++-dev libmysqlclient15-dev checkinstall\n如果是其它系统，相信也是类似的方法。如果已经有库文件了，则只需要将路径加入到/etc/ld.so.conf中，并执行ldconfig命令\n\n3.index 'test1': search error: query too complex, not enough stack (thread_stack=1217498K or higher required).\n这也是一个很奇怪的错误。我是按照文档中给出的例子建好索引，之后用命令行工具，也就是search要搜索的，结果就出现了这个错误。在网上搜索这个错误，没找到有用的信息，于是又求助于Sphinx-for-chinese群，群里的人说是因为命令行存在问题，用客户端搜就没问题。于是用客户端搜果然没问题，可是我还是无法释怀，因为之前公司的引擎中，用命令行是没有问题的。于是对照着公司用的引擎中的配置文件，发现配置文件中没有这一行，在自己的配置文件中注释掉这行后，果然没问题了。\n所以对于这个错误的解决办法就是，将`sql_query_info = SELECT * FROM documents WHERE id=$id`这行注释掉.\n这个确实太坑人了，连官方的配置文件都会出错，得浪费多少人的时间。\n\n4.ERROR: index 'main': No fields in schema - will not index.\n光运行例子是不行的，还是得自己写一些东西，于是将自己的博客文章来搜索。用了Wordpress中wp_posts表中的数据，我只用的四个字段ID,post_title,post_content,post_modified,将post_title,post_content定义成sql_attr_string,sql_attr_timestamp,结果就出现了这个错误。在网上找了，发现在官方bug报告中有提到这个问题\n[http://sphinxsearch.com/bugs/view.php?id=1632](http://sphinxsearch.com/bugs/view.php?id=1632)\n管理员说，引擎中需要一个全文索引字段，否则就没有东西需要索引了，这样它就不会建索引。管理员建议定义为sql_field_string,这样就会对这个字段既索引又保存内容。对于我的配置，我并不想保存post_content这个字段，所以不想将它定义为sql_field_string,那怎样才能让它只被所以呢？看过文档之后，才知道默认情况下，是会被索引。这也是为什么，在上面的帖子中，将sql_attr_string = text注释掉就可以建索引了。所以我只能说管理员也没有真正理解这个错误的原因，看来不能迷信权威啊。\n\n5.FATAL: there must be 2 indexes to merge specified\n这个是在测试Klist的时，出现的。文档中说，当合并两个索引时，使用--merge-klists就可以将两个索引的klist合并，于是我在合并时加上了这个参数。具体如下：\n```\n./indexer -c $conf --rotate --merge --merge-klists delta deltaTemp\n```\n运行时就出现这个错误，我纳闷了，明明官方文档中说加入这个参数是没问题的。到网上找资料，有人是用--merge-killlists这个参数，试过之后，同样报这个错误。无奈之际，将--merge-klist参数放到--rotate前面，\n./indexer -c $conf --merge-klists --rotate --merge delta deltaTemp\n奇迹出现了，这次没有报错。我只能说，这真是个坑。\n\n《Introduction to Search with Sphinx》写的还是非常不错的，毕竟是Sphinx的作者，表达能力和写作能力自然非同凡响，关于Sphinx的知识，许多都来自本书。等有时间了，可以将引擎的搭建过程写一写，应该可以帮助一些人。这次搭建过程，我学到了许多，虽然用的是开源的引擎，但真要从头到尾搭建一个引擎，并提供可靠的服务，并不是那么容易的，还是得多实践才行。\n","slug":"搭建Sphinx-for-chinese引擎时遇到的问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kv00f026s61finrxe3"},{"title":"搜索第二页实现","date":"2016-03-16T09:38:01.000Z","_content":"在搜索引擎中，要得到第一页的结果，可以使用堆这个数据结构来实现。在[最小的K个数](http://program.dengshilong.org/2014/08/14/最小的K个数/)有这样的例子，这里需要将最小的K个数，改成最大的K个数实现。也就是说，建立一个大小为K的小顶堆，对于之后的元素，每个与堆顶比较，如果小于堆顶，则它不可能是最大的K个数之一，如果大于堆顶，则将堆顶替换，并重建小顶堆。之后剩下的K个元素就是最大的K个数，而堆顶是这K个元素中最小的。之后取出堆顶，得到这K个元素中最小的，然后重建小顶堆，再取出堆顶，得到这K个元素中第二小的，一直到堆中没有元素。\n\n要得到第二页的结果，其实也是类似的。假设每页是K个元素，则先建立一个大小为2K的小顶堆。之后按照最大K个数的做法得到最大的2K个数。然后取出这2K个元素中的后面K个元素即是第二页的结果。\n\n在Solr的QueryCompent.java中，mergeIds函数里就是这样做的。","source":"_posts/搜索第二页实现.md","raw":"title: 搜索第二页实现\ndate: 2016-03-16 17:38:01\ntags: Solr\ncategories: 搜索引擎\n---\n在搜索引擎中，要得到第一页的结果，可以使用堆这个数据结构来实现。在[最小的K个数](http://program.dengshilong.org/2014/08/14/最小的K个数/)有这样的例子，这里需要将最小的K个数，改成最大的K个数实现。也就是说，建立一个大小为K的小顶堆，对于之后的元素，每个与堆顶比较，如果小于堆顶，则它不可能是最大的K个数之一，如果大于堆顶，则将堆顶替换，并重建小顶堆。之后剩下的K个元素就是最大的K个数，而堆顶是这K个元素中最小的。之后取出堆顶，得到这K个元素中最小的，然后重建小顶堆，再取出堆顶，得到这K个元素中第二小的，一直到堆中没有元素。\n\n要得到第二页的结果，其实也是类似的。假设每页是K个元素，则先建立一个大小为2K的小顶堆。之后按照最大K个数的做法得到最大的2K个数。然后取出这2K个元素中的后面K个元素即是第二页的结果。\n\n在Solr的QueryCompent.java中，mergeIds函数里就是这样做的。","slug":"搜索第二页实现","published":1,"updated":"2016-03-16T10:02:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4kx00f526s64xc41ylq"},{"title":"提取雪球搜索页面主要内容","id":"975","date":"2014-12-12T12:46:55.000Z","_content":"\n虽然在索引组，但有时还需要干解析的活，而这时，正则表达式就派上用场了。一段时间没写正则后，写起来就没有办法那么畅快，例如这次就是提取不到结果，想了之后，最后锁定在点号不能匹配换行符，试了之后，果然是这样。在Java中，加上Pattern.DOTALL就好了，以下就是用来提取雪球搜索页面里主要内容的函数，这个主要内容提取出来后是一个JSON格式的.\n``` java\npublic static String getXueQiuContent(String httpBody) {\n    Pattern pattern = Pattern.compile(\"SNB.data.search\\\\s*?=\\\\s*?(\\\\{.+?\\\\});.*?seajs.use\", Pattern.DOTALL);\n    Matcher m = pattern.matcher(httpBody);\n    if (m.find()) {\n        httpBody = m.group(1);\n        JSONObject obj;\n        try {\n            obj = new JSONObject(httpBody);\n            JSONArray jsonArr =  (JSONArray) obj.get(\"list\");\n            httpBody = jsonArr.toString();\n        } catch (JSONException e) {\n          // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n    }\n    return httpBody;\n}\n```\n如果不知道这个Pattern.DOTALL,其实用[\\\\s\\\\S]也是可以得，因为\\s匹配空白字符,\\S匹配非空白字符，两者合在一起就可以匹配任何字符了。\n对于爬虫组来说，要发现新的站点，都雪球这些网站去搜索一番还是可以尝试的。\n","source":"_posts/提取雪球搜索页面主要内容.md","raw":"title: 提取雪球搜索页面主要内容\ntags:\n  - 正则\n  - 点号\nid: 975\ncategories:\n  - Java\ndate: 2014-12-12 20:46:55\n---\n\n虽然在索引组，但有时还需要干解析的活，而这时，正则表达式就派上用场了。一段时间没写正则后，写起来就没有办法那么畅快，例如这次就是提取不到结果，想了之后，最后锁定在点号不能匹配换行符，试了之后，果然是这样。在Java中，加上Pattern.DOTALL就好了，以下就是用来提取雪球搜索页面里主要内容的函数，这个主要内容提取出来后是一个JSON格式的.\n``` java\npublic static String getXueQiuContent(String httpBody) {\n    Pattern pattern = Pattern.compile(\"SNB.data.search\\\\s*?=\\\\s*?(\\\\{.+?\\\\});.*?seajs.use\", Pattern.DOTALL);\n    Matcher m = pattern.matcher(httpBody);\n    if (m.find()) {\n        httpBody = m.group(1);\n        JSONObject obj;\n        try {\n            obj = new JSONObject(httpBody);\n            JSONArray jsonArr =  (JSONArray) obj.get(\"list\");\n            httpBody = jsonArr.toString();\n        } catch (JSONException e) {\n          // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n    }\n    return httpBody;\n}\n```\n如果不知道这个Pattern.DOTALL,其实用[\\\\s\\\\S]也是可以得，因为\\s匹配空白字符,\\S匹配非空白字符，两者合在一起就可以匹配任何字符了。\n对于爬虫组来说，要发现新的站点，都雪球这些网站去搜索一番还是可以尝试的。\n","slug":"提取雪球搜索页面主要内容","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4l000f926s6f9zwmewt"},{"title":"扔蛋问题","id":"815","date":"2014-07-14T23:30:38.000Z","_content":"\n扔蛋问题说的是，100层楼，给两个特制鸡蛋。从某层扔下鸡蛋，鸡蛋就会碎。问至少要测试多少次才能试出这个层数。对于这个问题，许多人都可以背出答案14层。但如果是200层呢?\n\n事实上，还可以对这题进行扩展，假设n层，e个鸡蛋，求至少要测试多少次，才能测出这个层数。\n\n对于这题，可以用动态规划。还是在面4399时，面试官要我解释什么是动态规划，当时没能解释清楚。现在想来，动态规划有两个重要的因素，一个是最优子结构，还有一个是重叠子问题。按我的理解，最优子结构说的是，当前的最优解包含了子问题的最优解。重叠子问题说的是，子问题具有重叠部分。\n\n而对于这题，可以写出一个递推公式,设n为楼层数,e为鸡蛋数。\nf(n,e) = 1 + min{max{f(n - r, e),f(r - 1, e -1)}} 其中r属于{2,3,...,n - 1},初始条件为f(n,1) = n, f(1,e) = 1, f(2,e) = 2\\. 这里要求n,e都是正整数。\n写成程序如下：\n``` python\ndef egg(n, e=2):\n    dp = [[n for i in xrange(e + 1)] for j in xrange(n + 1)]\n    for i in xrange(1, n + 1):\n        dp[i][1] = i\n    for i in xrange(1, e + 1):\n        dp[1][i] = 1\n        dp[2][i] = 2\n    for i in xrange(3, n + 1):\n        for j in xrange(2, e + 1):\n            for r in xrange(1, n):\n                dp[i][j] = min(dp[i][j], 1 + max(dp[i - r][j], dp[r - 1][j - 1]))\n\n    return dp[n][e]\n\nprint egg(100, 2)\n```\n\n对于鸡蛋数为2时，还有特殊的解法。在鸡蛋数为2时，楼层数与测试次数如下：\n1 1\n2 2\n3 2\n4 3\n5 3\n6 3\n7 4\n8 4\n9 4\n10 4\n11 5\n...\n于是可以猜测,对于楼层数n ,只要找到第一个x ,使得 x * (x + 1) / 2 >= n即可，对于100,正好是14。类似地，对于开头提出的鸡蛋数为2，楼层数为200时，测试层数也可以类似的求解","source":"_posts/扔蛋问题.md","raw":"title: 扔蛋问题\ntags:\n  - 动态规划\n  - 扔蛋问题\nid: 815\ncategories:\n  - 算法\ndate: 2014-07-15 07:30:38\n---\n\n扔蛋问题说的是，100层楼，给两个特制鸡蛋。从某层扔下鸡蛋，鸡蛋就会碎。问至少要测试多少次才能试出这个层数。对于这个问题，许多人都可以背出答案14层。但如果是200层呢?\n\n事实上，还可以对这题进行扩展，假设n层，e个鸡蛋，求至少要测试多少次，才能测出这个层数。\n\n对于这题，可以用动态规划。还是在面4399时，面试官要我解释什么是动态规划，当时没能解释清楚。现在想来，动态规划有两个重要的因素，一个是最优子结构，还有一个是重叠子问题。按我的理解，最优子结构说的是，当前的最优解包含了子问题的最优解。重叠子问题说的是，子问题具有重叠部分。\n\n而对于这题，可以写出一个递推公式,设n为楼层数,e为鸡蛋数。\nf(n,e) = 1 + min{max{f(n - r, e),f(r - 1, e -1)}} 其中r属于{2,3,...,n - 1},初始条件为f(n,1) = n, f(1,e) = 1, f(2,e) = 2\\. 这里要求n,e都是正整数。\n写成程序如下：\n``` python\ndef egg(n, e=2):\n    dp = [[n for i in xrange(e + 1)] for j in xrange(n + 1)]\n    for i in xrange(1, n + 1):\n        dp[i][1] = i\n    for i in xrange(1, e + 1):\n        dp[1][i] = 1\n        dp[2][i] = 2\n    for i in xrange(3, n + 1):\n        for j in xrange(2, e + 1):\n            for r in xrange(1, n):\n                dp[i][j] = min(dp[i][j], 1 + max(dp[i - r][j], dp[r - 1][j - 1]))\n\n    return dp[n][e]\n\nprint egg(100, 2)\n```\n\n对于鸡蛋数为2时，还有特殊的解法。在鸡蛋数为2时，楼层数与测试次数如下：\n1 1\n2 2\n3 2\n4 3\n5 3\n6 3\n7 4\n8 4\n9 4\n10 4\n11 5\n...\n于是可以猜测,对于楼层数n ,只要找到第一个x ,使得 x * (x + 1) / 2 >= n即可，对于100,正好是14。类似地，对于开头提出的鸡蛋数为2，楼层数为200时，测试层数也可以类似的求解","slug":"扔蛋问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4l300fg26s63d6o081l"},{"title":"常用正则备忘","id":"776","date":"2014-07-13T03:19:33.000Z","_content":"\n判断一个字符串是否是IP地址\n^([1-9]?[0-9]{1}|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\.([1-9]?[0-9]{1}|1[0-9]{2}|2[0-4][0-9]|25[0-5])){3}$","source":"_posts/常用正则备忘.md","raw":"title: 常用正则备忘\ntags:\n  - 正则\nid: 776\ncategories:\n  - 编程\ndate: 2014-07-13 11:19:33\n---\n\n判断一个字符串是否是IP地址\n^([1-9]?[0-9]{1}|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\.([1-9]?[0-9]{1}|1[0-9]{2}|2[0-4][0-9]|25[0-5])){3}$","slug":"常用正则备忘","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4l500fl26s6j00t24lc"},{"title":"寻找极小值","date":"2015-12-12T04:00:58.000Z","_content":"## 题目\n一个数组是以循环顺序排列的，也就是说在数组中有某个元素i，从x[i]开始有这样的关系，即x[0] < x[1] < x[2] < ... < x[i - 1]，x[i] < x[i + 1] < ... < x[n] < x[0]。例如8，10，14，15，2，6这7个元素就是循环顺序排列的，因为从2开始为递增，到了最后一个元素就转化为第1个元素，再一次顺序递增。换句话说，如果把x[i]，x[i + 1]，...，x[n]取出，并且接到数组开头，于是就是一个从小到大的顺序(这不是个旋转的工作吗？)。编写一个程序，接收一个以循环顺序排列的数组，把它的极小值找出来，以上面的数据为例，程序应该会输出2.\n\n## 说明\n因为从x[0]起顺序是递增的，一直到极小值出现，马上就会出现相反的顺序，于是很多人马上就会想出这个做法：\nfor (i = 1; i < n && x[i] >= x[i - 1]; i++)\n一旦这个循环停下来了，如果i等于n那就表示每一个元素都大于在它前面的哪一个，因而极小值为x[0]；但若i < n，且x[i] < x[i - 1]，因此极小值为x[i]。\n这是个正确的做法，但效率却不够高，因为在最坏的情况下可能要做n - 1次的比较。不过，这个数组严格说还是有顺序性的，根据这一特性应该可以找出更好、更快的方法，不妨试试看。\n\n## 解法\n解决的办法是用二分查找。也许会质疑这个数组并没有完全依顺序排列，所以不能用二分查找法。其实只要能够把问题分成两部分，而有办法判断解答在其中一部分的话，这就是个二分查找。\n\n现在处理x[L]与x[R]之间的元素(包含两个端点)，去中间元素x[M], M = (R - L) / 2 + L，会出现以下两中情况\n1. x[M] < x[R]，因为从左到右是递增的，直到极小值开始才下降，之后又开始递增。而第一个递增部分的任意一个元素大于第二个递增部分的任意元素。所以极小值一定不会在M的右边。所以下一个R = M。\n2. x[M] >= x[R]，会出现这种情况，说明M在第一个递增部分，R在第二个递增部分，所以极小值一定在M的右边。所以下一个L = M + 1。\n\n就这样一直反复下去，等到L=R的时候， x[L]就是极小值。\n## 代码\n写成代码如下：\n```\npublic class MinimumInRotatedSortedArray {\n    public static int findMin(int[] nums) {\n        int left = 0;\n        int right = nums.length - 1;\n        int mid = 0;\n        while (left < right) {\n            mid = (right - left) / 2 + left;\n            if (nums[mid] < nums[right]) {\n                right = mid;\n            } else {\n                left = mid + 1;\n            }\n        }\n        return nums[left];\n    }\n    \n    public static void main(String[] args) {\n        int[] temp = {6, 7, 1, 2, 3, 4};\n        System.out.println(findMin(temp));\n    }\n}\n```\n","source":"_posts/寻找极小值.md","raw":"title: 寻找极小值\ndate: 2015-12-12 12:00:58\ntags: C命题百则\ncategories: 算法\n---\n## 题目\n一个数组是以循环顺序排列的，也就是说在数组中有某个元素i，从x[i]开始有这样的关系，即x[0] < x[1] < x[2] < ... < x[i - 1]，x[i] < x[i + 1] < ... < x[n] < x[0]。例如8，10，14，15，2，6这7个元素就是循环顺序排列的，因为从2开始为递增，到了最后一个元素就转化为第1个元素，再一次顺序递增。换句话说，如果把x[i]，x[i + 1]，...，x[n]取出，并且接到数组开头，于是就是一个从小到大的顺序(这不是个旋转的工作吗？)。编写一个程序，接收一个以循环顺序排列的数组，把它的极小值找出来，以上面的数据为例，程序应该会输出2.\n\n## 说明\n因为从x[0]起顺序是递增的，一直到极小值出现，马上就会出现相反的顺序，于是很多人马上就会想出这个做法：\nfor (i = 1; i < n && x[i] >= x[i - 1]; i++)\n一旦这个循环停下来了，如果i等于n那就表示每一个元素都大于在它前面的哪一个，因而极小值为x[0]；但若i < n，且x[i] < x[i - 1]，因此极小值为x[i]。\n这是个正确的做法，但效率却不够高，因为在最坏的情况下可能要做n - 1次的比较。不过，这个数组严格说还是有顺序性的，根据这一特性应该可以找出更好、更快的方法，不妨试试看。\n\n## 解法\n解决的办法是用二分查找。也许会质疑这个数组并没有完全依顺序排列，所以不能用二分查找法。其实只要能够把问题分成两部分，而有办法判断解答在其中一部分的话，这就是个二分查找。\n\n现在处理x[L]与x[R]之间的元素(包含两个端点)，去中间元素x[M], M = (R - L) / 2 + L，会出现以下两中情况\n1. x[M] < x[R]，因为从左到右是递增的，直到极小值开始才下降，之后又开始递增。而第一个递增部分的任意一个元素大于第二个递增部分的任意元素。所以极小值一定不会在M的右边。所以下一个R = M。\n2. x[M] >= x[R]，会出现这种情况，说明M在第一个递增部分，R在第二个递增部分，所以极小值一定在M的右边。所以下一个L = M + 1。\n\n就这样一直反复下去，等到L=R的时候， x[L]就是极小值。\n## 代码\n写成代码如下：\n```\npublic class MinimumInRotatedSortedArray {\n    public static int findMin(int[] nums) {\n        int left = 0;\n        int right = nums.length - 1;\n        int mid = 0;\n        while (left < right) {\n            mid = (right - left) / 2 + left;\n            if (nums[mid] < nums[right]) {\n                right = mid;\n            } else {\n                left = mid + 1;\n            }\n        }\n        return nums[left];\n    }\n    \n    public static void main(String[] args) {\n        int[] temp = {6, 7, 1, 2, 3, 4};\n        System.out.println(findMin(temp));\n    }\n}\n```\n","slug":"寻找极小值","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4l700fo26s6byt6m54j"},{"title":"安装jdk源码","date":"2015-12-21T12:05:43.000Z","_content":"要想提高Java水平，阅读jdk源码是很有必要的，所以要安装jdk源码。所幸安装过程很简单。\n\n在jdk目录下，如(/home/long/jdk1.7.0_80)，有src.zip文件，这里保存了jdk源码。安装过程如下:\n\n1. 进入jdk目录\ncd /home/long/jdk1.7.0_80\n2. 新建src子目录\nmkdir src\n3. 进入src子目录\ncd src\n4. 解压jdk源码\nunzip ../src.zip\n\n这样，在Eclipse中，按住ctrl键，单击类名，就可以看到源码了。\n","source":"_posts/安装jdk源码.md","raw":"title: 安装jdk源码\ndate: 2015-12-21 20:05:43\ntags: jdk\ncategories: Java\n---\n要想提高Java水平，阅读jdk源码是很有必要的，所以要安装jdk源码。所幸安装过程很简单。\n\n在jdk目录下，如(/home/long/jdk1.7.0_80)，有src.zip文件，这里保存了jdk源码。安装过程如下:\n\n1. 进入jdk目录\ncd /home/long/jdk1.7.0_80\n2. 新建src子目录\nmkdir src\n3. 进入src子目录\ncd src\n4. 解压jdk源码\nunzip ../src.zip\n\n这样，在Eclipse中，按住ctrl键，单击类名，就可以看到源码了。\n","slug":"安装jdk源码","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4l900fs26s6jek5a4mj"},{"title":"安装Maven","id":"621","date":"2014-03-08T04:10:01.000Z","_content":"\n很早之前，在写第一个Servlet时，一直配置不成功，写一个Hello World!都成问题，于是转而奔向PHP，最近由于工作需要，要重新拾起Java那套东西。因为是用Maven做的管理，于是要安装Maven，到网上找参考资料，竟没安装好，于是到官网找解答，最终找到。\n\n安装Maven之前，已经假设你安装好JDK.有一点需要注意的是,Maven3.2要求JDK1.6及以上,Maven3.0/3.1则要求JDK1.5及以上，否则会出现版本错误\n\n1.下载Maven\n\n到官网http://maven.apache.org/下载Maven,当前最新稳定版本为3.2.1\n\n对于Windows系统，下载Maven 3.2.1 (Binary zip)\n\n2.解压Maven,配置环境变量\n\n将Maven解压，这里假设放在d:\\apache-maven-3.2.1\n\n之后进行环境变量配置，\n\n在系统变量中增加M2_HOME,值为d:\\apache-maven-3.2.1\n\n在系统变量中增加M2,值为%M2_HOME%\\bin\n\n如果已经存在用户变量Path，则在值的前面增加%M2%； 注意一定要加上这个分号\n\n如果不存在用户变量Path,则新建它，并赋值为%M2%\n\n3.测试Maven\n\n在命令行中执行mvn --version，在我的电脑上显示如下,\n\nApache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9; 2014-02-15T01:37:5\n\n2+08:00)\n\nMaven home: d:\\apache-maven-3.2.1\n\nJava version: 1.6.0_15, vendor: Sun Microsystems Inc.\n\nJava home: D:\\Java\\jdk1.6.0\\jre\n\nDefault locale: zh_CN, platform encoding: GBK\n\nOS name: \"windows 7\", version: \"6.1\", arch: \"x86\", family: \"windows\"\n\n如果不是这样，看看环境变量是否配置正确，以及JDK版本是否匹配\n\n4.Eclipse的Maven插件安装\n\n在插件安装上，网上的资料很多已经过时了，因为都是很早之前的链接。顺着官网找到了eclipse的Maven插件安装链接http://download.eclipse.org/technology/m2e/releases/\n\n我用的是Eclipse Kepler.在Help->Install new software中，将以上安装链接加入，名字为Maven，之后即可下载插件\n\n[![Maven插件安装](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven插件安装.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven插件安装.png)\n\n5.配置Maven插件\n\n在Window->Preferences中,选择Maven\n\n[![Maven-Installations配置](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置.png)\n\n点击Installations,此时还是用插件自带的Maven版本3.0.4,而且Global settings是空的我们需要添加自己安装的版本，点击Add,打开D:\\apache-maven-3.2.1即可，最终结果如下：\n\n[![Maven-Installations配置结果](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置结果.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置结果.png)\n\n此时Maven插件将会使用安装的Maven3.2.1版本\n\n之后点击User Settings,可以看到如下结果\n\n这里也许最让你迷惑的是这三个概念，Global Settings, User Settings,以及Local Repository。因为我也未深入理解，所以也只能在这里说说我的理解。简单来说，\n\nGlobal Settings就是一些全局设置，设置了中央jar仓库的位置等等.\n\nUser Settings设置了用户私有jar仓库的位置等等.\n\nLocal Repository是本地jar仓库的位置.\n\n假设你现在在开发一个应用，它需要使用一个jar,则Maven会先到Local Repository中寻找，如果没找到这个jar,则它会到User Settings中设置的用户私有jar仓库中查找，如果还是没找到，则到Global Settings设置的中央jar仓库中查找，如果还是没找到，Maven将报错，指示jar未找到。\n\n网上还有介绍另外一种方法，也就是先去下载Eclipse的Maven插件，之后再将插件导入到Eclipse, 只是因为直接用URL的方法已经解决了安装问题，所以没有尝试。\n\n6.Hello World例子\n\n之后用《Maven by Example》中的一个例子来介绍安装介绍。命令行进入Eclipse工作目录，我这里是d:\\workspace,执行以下命令\n\nmvn archetype:generate -DgroupId=org.sonatype.mavenbook -DartifactId=simple -Dpackage=org.sonatype.mavenbook -Dversion=1.0-SNAPSHOT\n\n之后敲几次回车，一个最简单的HelloWorld项目就建立好了。\n\n之后cd simple进入simple目录，如果你有兴趣，可以看看Maven生成的内容，\n\n其目录结构如下\n\nsimple/\n\nsimple/pom.xml\n\nsimple/src/main\n\nsimple/src/main/java\n\nsimple/src/test\n\nsimple/src/test/java\n\n其中src/main存放源文件,src/test存放测试文件,pom.xml为Maven提供编译信息，\n\n执行mvn install，编译,测试，打包项目\n\n执行java -cp target/simple-1.0-SNAPSHOT.jar org.sonatype.mavenbook.App\n\n看到输出的 Hello World！\n\n事实上，在命令行中，一个困惑是如何选择新建项目的类型，命令行里一共列出了九百多种，而很难知道哪个编号对应的是哪一种项目类型。\n\n关于Maven的更多内容可以去sonatype官网下载《Maven by Example》,绝对值得一看。\n\n参考文章：\n\nhttp://www.blogjava.net/fancydeepin/archive/2012/07/13/eclipse_maven3_plugin.html","source":"_posts/安装Maven.md","raw":"title: 安装Maven\ntags:\n  - Maven\nid: 621\ncategories:\n  - 软件安装\ndate: 2014-03-08 12:10:01\n---\n\n很早之前，在写第一个Servlet时，一直配置不成功，写一个Hello World!都成问题，于是转而奔向PHP，最近由于工作需要，要重新拾起Java那套东西。因为是用Maven做的管理，于是要安装Maven，到网上找参考资料，竟没安装好，于是到官网找解答，最终找到。\n\n安装Maven之前，已经假设你安装好JDK.有一点需要注意的是,Maven3.2要求JDK1.6及以上,Maven3.0/3.1则要求JDK1.5及以上，否则会出现版本错误\n\n1.下载Maven\n\n到官网http://maven.apache.org/下载Maven,当前最新稳定版本为3.2.1\n\n对于Windows系统，下载Maven 3.2.1 (Binary zip)\n\n2.解压Maven,配置环境变量\n\n将Maven解压，这里假设放在d:\\apache-maven-3.2.1\n\n之后进行环境变量配置，\n\n在系统变量中增加M2_HOME,值为d:\\apache-maven-3.2.1\n\n在系统变量中增加M2,值为%M2_HOME%\\bin\n\n如果已经存在用户变量Path，则在值的前面增加%M2%； 注意一定要加上这个分号\n\n如果不存在用户变量Path,则新建它，并赋值为%M2%\n\n3.测试Maven\n\n在命令行中执行mvn --version，在我的电脑上显示如下,\n\nApache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9; 2014-02-15T01:37:5\n\n2+08:00)\n\nMaven home: d:\\apache-maven-3.2.1\n\nJava version: 1.6.0_15, vendor: Sun Microsystems Inc.\n\nJava home: D:\\Java\\jdk1.6.0\\jre\n\nDefault locale: zh_CN, platform encoding: GBK\n\nOS name: \"windows 7\", version: \"6.1\", arch: \"x86\", family: \"windows\"\n\n如果不是这样，看看环境变量是否配置正确，以及JDK版本是否匹配\n\n4.Eclipse的Maven插件安装\n\n在插件安装上，网上的资料很多已经过时了，因为都是很早之前的链接。顺着官网找到了eclipse的Maven插件安装链接http://download.eclipse.org/technology/m2e/releases/\n\n我用的是Eclipse Kepler.在Help->Install new software中，将以上安装链接加入，名字为Maven，之后即可下载插件\n\n[![Maven插件安装](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven插件安装.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven插件安装.png)\n\n5.配置Maven插件\n\n在Window->Preferences中,选择Maven\n\n[![Maven-Installations配置](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置.png)\n\n点击Installations,此时还是用插件自带的Maven版本3.0.4,而且Global settings是空的我们需要添加自己安装的版本，点击Add,打开D:\\apache-maven-3.2.1即可，最终结果如下：\n\n[![Maven-Installations配置结果](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置结果.png)](http://program.dengshilong.org/wp-content/uploads/2014/03/Maven-Installations配置结果.png)\n\n此时Maven插件将会使用安装的Maven3.2.1版本\n\n之后点击User Settings,可以看到如下结果\n\n这里也许最让你迷惑的是这三个概念，Global Settings, User Settings,以及Local Repository。因为我也未深入理解，所以也只能在这里说说我的理解。简单来说，\n\nGlobal Settings就是一些全局设置，设置了中央jar仓库的位置等等.\n\nUser Settings设置了用户私有jar仓库的位置等等.\n\nLocal Repository是本地jar仓库的位置.\n\n假设你现在在开发一个应用，它需要使用一个jar,则Maven会先到Local Repository中寻找，如果没找到这个jar,则它会到User Settings中设置的用户私有jar仓库中查找，如果还是没找到，则到Global Settings设置的中央jar仓库中查找，如果还是没找到，Maven将报错，指示jar未找到。\n\n网上还有介绍另外一种方法，也就是先去下载Eclipse的Maven插件，之后再将插件导入到Eclipse, 只是因为直接用URL的方法已经解决了安装问题，所以没有尝试。\n\n6.Hello World例子\n\n之后用《Maven by Example》中的一个例子来介绍安装介绍。命令行进入Eclipse工作目录，我这里是d:\\workspace,执行以下命令\n\nmvn archetype:generate -DgroupId=org.sonatype.mavenbook -DartifactId=simple -Dpackage=org.sonatype.mavenbook -Dversion=1.0-SNAPSHOT\n\n之后敲几次回车，一个最简单的HelloWorld项目就建立好了。\n\n之后cd simple进入simple目录，如果你有兴趣，可以看看Maven生成的内容，\n\n其目录结构如下\n\nsimple/\n\nsimple/pom.xml\n\nsimple/src/main\n\nsimple/src/main/java\n\nsimple/src/test\n\nsimple/src/test/java\n\n其中src/main存放源文件,src/test存放测试文件,pom.xml为Maven提供编译信息，\n\n执行mvn install，编译,测试，打包项目\n\n执行java -cp target/simple-1.0-SNAPSHOT.jar org.sonatype.mavenbook.App\n\n看到输出的 Hello World！\n\n事实上，在命令行中，一个困惑是如何选择新建项目的类型，命令行里一共列出了九百多种，而很难知道哪个编号对应的是哪一种项目类型。\n\n关于Maven的更多内容可以去sonatype官网下载《Maven by Example》,绝对值得一看。\n\n参考文章：\n\nhttp://www.blogjava.net/fancydeepin/archive/2012/07/13/eclipse_maven3_plugin.html","slug":"安装Maven","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lc00fw26s6scpb2f30"},{"title":"如何实现site查询","id":"949","date":"2014-10-27T13:55:46.000Z","_content":"\n在Solr的索引记录里看到，很多HostName是逆序的，如news.qq.com记录成moc.qq.swen, www.qq.com记录成moc.qq.www,moc.qq,finance.qq.com记录成moc.qq.ecnanif。后来才知道，这是为了实现像google那样的site功能.\n\nsite功能就是要查找索引中某一域名下的记录。一个实现办法就是实现上面的逆序存储。如此，要找出qq.com下的所有记录只需要用moc.qq.*去比较HostName即可。","source":"_posts/如何实现site查询.md","raw":"title: 如何实现site查询\ntags:\n  - site查询\nid: 949\ncategories:\n  - 搜索引擎\ndate: 2014-10-27 21:55:46\n---\n\n在Solr的索引记录里看到，很多HostName是逆序的，如news.qq.com记录成moc.qq.swen, www.qq.com记录成moc.qq.www,moc.qq,finance.qq.com记录成moc.qq.ecnanif。后来才知道，这是为了实现像google那样的site功能.\n\nsite功能就是要查找索引中某一域名下的记录。一个实现办法就是实现上面的逆序存储。如此，要找出qq.com下的所有记录只需要用moc.qq.*去比较HostName即可。","slug":"如何实现site查询","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lf00g126s6nhj627g0"},{"title":"如何判断一个数是否是素数","id":"566","date":"2014-03-31T12:16:40.000Z","_content":"\n这个问题对于学习编程的人来说不陌生，但并没有想象中那么简单，这里面还是很深的。一般来说是用比这个数小的素数去除，如果都不能整除，则是素数。可是这种方法必须要求你知道比这个数小的所有素数，所以我觉得不是很实用。\n\n去年找实习时，微软的面试官也问了我这题。刚开始只想到最基础的方法，假设需要判断的是n, 如果n是2则是素数，如果n是1或者是大于2的偶数，则是素数，如果n是大于2的奇数，则从2开始到 n的平方根，如果n可以被其中任何一个整除则这个数不是素数，否则是素数。\n\n之后面试官问还有没有更好的方法，考虑之后，想到《C语言名题百则精选中曾提到过一种方法，对于大于等于6的数，都可以表示成6n,6n + 1,6n + 2, 6n + 3, 6n + 4, 6n + 5,其中只有6n + 1和6n + 5是素数，所以对于大于6的数，如果不能被2 ， 3 ， 5整除，则只需用6n + 1和6n + 5这些数去除。\n\n最近在做欧拉工程第58题，我先生成一个很大的素数表，然后来判断是否是素数，可是这个题目中用到的素数实在是太大了，这种方法不实际。之后用了前面两种方法，也是不行，速度太慢了。最后上网找方法，找到了米勒-拉宾素性测试法，终于把问题解决了。难道说，当时的面试官是想问这种方法？\n以下内容来自[http://en.wikipedia.org/wiki/Miller-Rabin_primality_test](http://en.widipedia.org/wiki/Miller-Rabin_primality_test) 。这个方法需要用到费马小定理，x^2 = 1 (mod p)，费马这厮真是有趣，搞出几个定理都不给出证明，这个小定理还好，最要命的是那个大定理，耗费了几百年才被人给出证明。这里空白太少，写不下证明，只好直接拿来用了。\n\n先给一个引理，当p是素数,若x^2 = 1 (mod p),则x = 1(mod p)或者 x = -1(mod p),这个引理的证明很简单，由x ^ 2 = 1 (mod p)得(x + 1)(x – 1) = 0 （mod p)，而由于p是素数，所以x + 1 = 0 (mod p)或者x – 1 = 0 (mod p).\n\n现在设n是一个素数且n > 2,则 n – 1一定是偶数，并且可以表示成2 ^s * d的形式，其中s和d都为正整数，且d是奇数。那么对于任意2 <= a < n,\n a^d = 1 (mod n)或者a^(2^r * d) = - 1(mod n),其中0 <= r <= s – 1。\n\n证明如下：\n 由费马小定理可知，当n是素数时\n a^(n – 1) = 1 (mod n), 我们将n – 1表示成2^s * d,再由上面的引理得，如果我们对n – 1进行开方，则可以得到a^(2^(s – 1) *d)=1 (mod n)或者a^(2^(s-1) *d) = -1 (mod n),如果是后者，则已经满足了，如果是前者，则继续这个开方过程，如果我们一直都是得到1，最终就是\n a^d = 1(mod n).\n\n而米勒-拉宾测试法就是用了这个定理的逆否命题。也就是，如果 a^d != 1 (mod n)且a^(2^r *d) != -1 (mod n)对于所有的0<=r<=s-1,则n不是素数。\n","source":"_posts/如何判断一个数是否是素数.md","raw":"title: 如何判断一个数是否是素数\ntags:\n  - 米勒-拉宾\n  - 素数\nid: 566\ncategories:\n  - 数学\ndate: 2014-03-31 20:16:40\n---\n\n这个问题对于学习编程的人来说不陌生，但并没有想象中那么简单，这里面还是很深的。一般来说是用比这个数小的素数去除，如果都不能整除，则是素数。可是这种方法必须要求你知道比这个数小的所有素数，所以我觉得不是很实用。\n\n去年找实习时，微软的面试官也问了我这题。刚开始只想到最基础的方法，假设需要判断的是n, 如果n是2则是素数，如果n是1或者是大于2的偶数，则是素数，如果n是大于2的奇数，则从2开始到 n的平方根，如果n可以被其中任何一个整除则这个数不是素数，否则是素数。\n\n之后面试官问还有没有更好的方法，考虑之后，想到《C语言名题百则精选中曾提到过一种方法，对于大于等于6的数，都可以表示成6n,6n + 1,6n + 2, 6n + 3, 6n + 4, 6n + 5,其中只有6n + 1和6n + 5是素数，所以对于大于6的数，如果不能被2 ， 3 ， 5整除，则只需用6n + 1和6n + 5这些数去除。\n\n最近在做欧拉工程第58题，我先生成一个很大的素数表，然后来判断是否是素数，可是这个题目中用到的素数实在是太大了，这种方法不实际。之后用了前面两种方法，也是不行，速度太慢了。最后上网找方法，找到了米勒-拉宾素性测试法，终于把问题解决了。难道说，当时的面试官是想问这种方法？\n以下内容来自[http://en.wikipedia.org/wiki/Miller-Rabin_primality_test](http://en.widipedia.org/wiki/Miller-Rabin_primality_test) 。这个方法需要用到费马小定理，x^2 = 1 (mod p)，费马这厮真是有趣，搞出几个定理都不给出证明，这个小定理还好，最要命的是那个大定理，耗费了几百年才被人给出证明。这里空白太少，写不下证明，只好直接拿来用了。\n\n先给一个引理，当p是素数,若x^2 = 1 (mod p),则x = 1(mod p)或者 x = -1(mod p),这个引理的证明很简单，由x ^ 2 = 1 (mod p)得(x + 1)(x – 1) = 0 （mod p)，而由于p是素数，所以x + 1 = 0 (mod p)或者x – 1 = 0 (mod p).\n\n现在设n是一个素数且n > 2,则 n – 1一定是偶数，并且可以表示成2 ^s * d的形式，其中s和d都为正整数，且d是奇数。那么对于任意2 <= a < n,\n a^d = 1 (mod n)或者a^(2^r * d) = - 1(mod n),其中0 <= r <= s – 1。\n\n证明如下：\n 由费马小定理可知，当n是素数时\n a^(n – 1) = 1 (mod n), 我们将n – 1表示成2^s * d,再由上面的引理得，如果我们对n – 1进行开方，则可以得到a^(2^(s – 1) *d)=1 (mod n)或者a^(2^(s-1) *d) = -1 (mod n),如果是后者，则已经满足了，如果是前者，则继续这个开方过程，如果我们一直都是得到1，最终就是\n a^d = 1(mod n).\n\n而米勒-拉宾测试法就是用了这个定理的逆否命题。也就是，如果 a^d != 1 (mod n)且a^(2^r *d) != -1 (mod n)对于所有的0<=r<=s-1,则n不是素数。\n","slug":"如何判断一个数是否是素数","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lh00g526s6mmz324hg"},{"title":"填方格问题","id":"48","date":"2013-04-25T02:20:21.000Z","_content":"\n昨天去找堂姐，看到堂姐买给她儿子的玩具，其中一个是放格子玩具。也就是在一个有6 * 6，一共36格的盒子中，放入6个1,6个2,6个3，。。。，6个6，使得各行各列的数字不重复。这个挺简单的，于是对它进行扩展，也就是在各行各列的数字不重复的基础上，还要求斜边不重复，当场没做出来，回来之后写程序。想起了以前的八皇后问题，运行了一下\nN皇后问题解的个数\n1    1\n2    0\n3    0\n4    2\n5    10\n6    4\n7    40\n8    92\n9    352\n10    724\n11    2680    \n12    14200\n13    73712\n14    365596    \n15    2279184    \n16    14772512\n17    95815104\n发现六皇后问题，只有4个解，所以断定上面的扩展问题无解。不知道上面的数字有什么规律。顺便做了以下两个问题。\n问题1\n在n * n个格子里填入  n 个1，n个2，。。。 n 个 n使得各行各列出现的数字不重复\n如在3 * 3的格子中填入\n1 2 3\n3 1 2\n2 3 1\n这个就可以满足条件\n问对于1 * 1, 2 * 2 ,3 * 3, ...， 6 * 6分别有几种填法？\n解答如下\n1 1\n2 2\n3 12\n4 576\n5 161280\n由于6 * 6 时解的个数已经很多，程序跑的很慢，所以这个次数还不知道。\n\n问题2\n在n * n个格子里填入  n 个1，n个2，。。。 n 个 n使得各行各列，以及斜边出现的数字不重复\n此时对于3 * 3的格子中填入\n1 2 3\n3 1 2\n2 3 1\n这个就不可以满足条件了，因为从左上角往右下角方向看，有3 3,1 1 1,2 2 在同一条直线上。\n而对于 5 * 5的格子中填入\n1 2 3 4 5\n3 4 5 1 2\n5 1 2 3 4\n2 3 4 5 1\n4 5 1 2 3\n这个就可以满足条件了。\n问对于1 * 1, 2 * 2 ,3 * 3, ...， 6 * 6分别有几种填法？\n解答如下\n1 1\n2 0\n3 0 \n4 0\n5 240\n6 0","source":"_posts/填方格问题.md","raw":"title: 填方格问题\ntags:\n  - 八皇后问题\n  - 方格\nid: 48\ncategories:\n  - 数学\ndate: 2013-04-25 10:20:21\n---\n\n昨天去找堂姐，看到堂姐买给她儿子的玩具，其中一个是放格子玩具。也就是在一个有6 * 6，一共36格的盒子中，放入6个1,6个2,6个3，。。。，6个6，使得各行各列的数字不重复。这个挺简单的，于是对它进行扩展，也就是在各行各列的数字不重复的基础上，还要求斜边不重复，当场没做出来，回来之后写程序。想起了以前的八皇后问题，运行了一下\nN皇后问题解的个数\n1    1\n2    0\n3    0\n4    2\n5    10\n6    4\n7    40\n8    92\n9    352\n10    724\n11    2680    \n12    14200\n13    73712\n14    365596    \n15    2279184    \n16    14772512\n17    95815104\n发现六皇后问题，只有4个解，所以断定上面的扩展问题无解。不知道上面的数字有什么规律。顺便做了以下两个问题。\n问题1\n在n * n个格子里填入  n 个1，n个2，。。。 n 个 n使得各行各列出现的数字不重复\n如在3 * 3的格子中填入\n1 2 3\n3 1 2\n2 3 1\n这个就可以满足条件\n问对于1 * 1, 2 * 2 ,3 * 3, ...， 6 * 6分别有几种填法？\n解答如下\n1 1\n2 2\n3 12\n4 576\n5 161280\n由于6 * 6 时解的个数已经很多，程序跑的很慢，所以这个次数还不知道。\n\n问题2\n在n * n个格子里填入  n 个1，n个2，。。。 n 个 n使得各行各列，以及斜边出现的数字不重复\n此时对于3 * 3的格子中填入\n1 2 3\n3 1 2\n2 3 1\n这个就不可以满足条件了，因为从左上角往右下角方向看，有3 3,1 1 1,2 2 在同一条直线上。\n而对于 5 * 5的格子中填入\n1 2 3 4 5\n3 4 5 1 2\n5 1 2 3 4\n2 3 4 5 1\n4 5 1 2 3\n这个就可以满足条件了。\n问对于1 * 1, 2 * 2 ,3 * 3, ...， 6 * 6分别有几种填法？\n解答如下\n1 1\n2 0\n3 0 \n4 0\n5 240\n6 0","slug":"填方格问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ll00g926s6k4mcx722"},{"title":"堆排序","id":"861","date":"2014-08-13T12:00:07.000Z","_content":"\n对于求最小的K个数和最大的K个数，一种解决办法是使用堆。对于堆，数据结构的书籍中都有讲到，可是面试时不知是紧张还是什么原因，连堆都忘记了，悲哀，真是悲哀。\n\n想来堆排序还是不难的，如果要对n个数字从小到大排序，则先建立这n个数字的大顶堆，之后堆顶与最后一个数字交换，此时就得到最大的数字，且在最后一位中，之后之需要对前n-1个数字排序。这里堆顶与最后一个数字交换后，会破坏了大顶堆，需要重建堆。对于大顶堆，意思就是堆顶的元素是最大的，之后是堆顶的左右子节点。\n\n这里主要就是两个步骤，一个是建立大顶堆，一个是重建堆。\n看代码可能会更容易一些\n``` c\n#include <stdio.h>\n#include <stdlib.h>\nvoid swap(int &a, int &b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\nvoid adjust_heap(int *a, int cur, int n) {\n    int left, right;\n    while (true) {\n        left = 2 * cur + 1;\n        right = 2 * cur + 2;\n        int index = cur;\n        if (left < n && a[left] > a[index]) {\n            index = left;\n        }\n        if (right < n && a[right] > a[index]) {\n            index = right;\n        }\n        if (index != cur) {\n            swap(a[cur], a[index]);\n            cur = index;\n        } else {\n            break;\n        }\n    }\n}\nvoid build_heap(int *a, int n) {\n    for (int i = (n - 1) / 2; i >= 0; i--) {\n        adjust_heap(a, i, n);\n    }\n}\nvoid heap_sort(int *a, int n) {\n    build_heap(a, n);\n    for (int i = n - 1; i > 0; i--) {\n        swap(a[0], a[i]);\n        adjust_heap(a, 0, i);\n    }\n} \nint main() {\n    int a[] = {10, 2, 5, 7, 6, 13 , 8, 7};\n    int n = sizeof(a) / sizeof(int);\n    heap_sort(a, n);\n    for (int i = 0; i < n - 1; i++) {\n        printf(\"%d \", a[i]);\n    }\n    printf(\"%d\\n\", a[n - 1]);\n    return 0;\n}\n```","source":"_posts/堆排序.md","raw":"title: 堆排序\ntags:\n  - 堆\n  - 堆排序\nid: 861\ncategories:\n  - 数据结构\ndate: 2014-08-13 20:00:07\n---\n\n对于求最小的K个数和最大的K个数，一种解决办法是使用堆。对于堆，数据结构的书籍中都有讲到，可是面试时不知是紧张还是什么原因，连堆都忘记了，悲哀，真是悲哀。\n\n想来堆排序还是不难的，如果要对n个数字从小到大排序，则先建立这n个数字的大顶堆，之后堆顶与最后一个数字交换，此时就得到最大的数字，且在最后一位中，之后之需要对前n-1个数字排序。这里堆顶与最后一个数字交换后，会破坏了大顶堆，需要重建堆。对于大顶堆，意思就是堆顶的元素是最大的，之后是堆顶的左右子节点。\n\n这里主要就是两个步骤，一个是建立大顶堆，一个是重建堆。\n看代码可能会更容易一些\n``` c\n#include <stdio.h>\n#include <stdlib.h>\nvoid swap(int &a, int &b) {\n    int temp = a;\n    a = b;\n    b = temp;\n}\nvoid adjust_heap(int *a, int cur, int n) {\n    int left, right;\n    while (true) {\n        left = 2 * cur + 1;\n        right = 2 * cur + 2;\n        int index = cur;\n        if (left < n && a[left] > a[index]) {\n            index = left;\n        }\n        if (right < n && a[right] > a[index]) {\n            index = right;\n        }\n        if (index != cur) {\n            swap(a[cur], a[index]);\n            cur = index;\n        } else {\n            break;\n        }\n    }\n}\nvoid build_heap(int *a, int n) {\n    for (int i = (n - 1) / 2; i >= 0; i--) {\n        adjust_heap(a, i, n);\n    }\n}\nvoid heap_sort(int *a, int n) {\n    build_heap(a, n);\n    for (int i = n - 1; i > 0; i--) {\n        swap(a[0], a[i]);\n        adjust_heap(a, 0, i);\n    }\n} \nint main() {\n    int a[] = {10, 2, 5, 7, 6, 13 , 8, 7};\n    int n = sizeof(a) / sizeof(int);\n    heap_sort(a, n);\n    for (int i = 0; i < n - 1; i++) {\n        printf(\"%d \", a[i]);\n    }\n    printf(\"%d\\n\", a[n - 1]);\n    return 0;\n}\n```","slug":"堆排序","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lo00gf26s69olz00pp"},{"title":"在Intellij中启动ElasticSearch","date":"2016-04-03T13:03:21.000Z","_content":"有时候真的很郁闷，想要对Solr和Elasticsearch进行二次开发，结果在Eclipse和Intellij上，都不知道怎么启动，官网也没有说，只能上网找或者自己摸索。上网找也是很耗时间的，这些人就不能在官网上记一下吗？这里记下遇到的问题，目前使用Intellij进行Java开发，所以只纪录Intellij的情况。\n\n## 下载源码\n官网没有提供源码的下载，所以只好到github仓库上下载，尝试用`git clone -b 2.3 https://github.com/elastic/elasticsearch.git`, 但下载到的是2.3.1的，于是纠结要怎么样才能得到2.3.0的，最后求助于之前的搜索同事，知道在[https://github.com/elastic/elasticsearch/releases](https://github.com/elastic/elasticsearch/releases)里可以下载。\n\n## 主程序入口\n查看elasticsearch脚本，发现程序入口是org.elasticsearch.bootstrap.ElasticSearch\n\n## path.home is not configured\n\n参考[elasticsearch2.0源码在开发环境eclipse中启动的问题及解决方案](http://blog.csdn.net/jianjun200607/article/details/49821813#reply)\n\n查看执行./elasticsearch脚本启动时添加的参数，设置VM options为\n```\n-Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -Dfile.encoding=UTF-8 -Djna.nosys=true -Des.path.home=/Users/long/elasticsearch\n```\n其中主要是设置es.path.home,目录位置并没有限制。设置Program arguments为start\n\n## \"java.lang.IllegalStateException\" jar hell!\n\n参考[https://github.com/elastic/elasticsearch/pull/13465](https://github.com/elastic/elasticsearch/pull/13465)\n\n```\nI stripped the SDK classpath in IntelliJ down to the default sun.boot.class.path and I am not seeing jar hell failures anymore. Specifically:\n\njre/lib/charsets.jar\njre/lib/jce.jar\njre/lib/jfr.jar\njre/lib/jsse.jar\njre/lib/resources.jar\njre/lib/rt.jar\n```\n到这里才想起来Intellij在导入jdk时，将许多的jar包加入到Classpath中了，进入File->Other Settings->Default Project Structure,修改jdk的Classpath为\n```\njre/lib/charsets.jar\njre/lib/jce.jar\njre/lib/jfr.jar\njre/lib/jsse.jar\njre/lib/resources.jar\njre/lib/rt.jar\n```\n## 提示找不到config目录\n在/Users/long/program/java/elasticsearch-2.3.0/core目录下新建config目录，将官方发布的Elasticsearch可执行包里的config目录拷贝到这里。\n\n之后启动org.elasticsearch.bootstrap.Elasticsearch, 成功。\n","source":"_posts/在Intellij中启动ElasticSearch.md","raw":"title: 在Intellij中启动ElasticSearch\ndate: 2016-04-03 21:03:21\ntags: \n    - Elasticsearch\n    - Intellij\ncategories:\n    - 搜索引擎\n---\n有时候真的很郁闷，想要对Solr和Elasticsearch进行二次开发，结果在Eclipse和Intellij上，都不知道怎么启动，官网也没有说，只能上网找或者自己摸索。上网找也是很耗时间的，这些人就不能在官网上记一下吗？这里记下遇到的问题，目前使用Intellij进行Java开发，所以只纪录Intellij的情况。\n\n## 下载源码\n官网没有提供源码的下载，所以只好到github仓库上下载，尝试用`git clone -b 2.3 https://github.com/elastic/elasticsearch.git`, 但下载到的是2.3.1的，于是纠结要怎么样才能得到2.3.0的，最后求助于之前的搜索同事，知道在[https://github.com/elastic/elasticsearch/releases](https://github.com/elastic/elasticsearch/releases)里可以下载。\n\n## 主程序入口\n查看elasticsearch脚本，发现程序入口是org.elasticsearch.bootstrap.ElasticSearch\n\n## path.home is not configured\n\n参考[elasticsearch2.0源码在开发环境eclipse中启动的问题及解决方案](http://blog.csdn.net/jianjun200607/article/details/49821813#reply)\n\n查看执行./elasticsearch脚本启动时添加的参数，设置VM options为\n```\n-Xms256m -Xmx1g -Djava.awt.headless=true -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+HeapDumpOnOutOfMemoryError -XX:+DisableExplicitGC -Dfile.encoding=UTF-8 -Djna.nosys=true -Des.path.home=/Users/long/elasticsearch\n```\n其中主要是设置es.path.home,目录位置并没有限制。设置Program arguments为start\n\n## \"java.lang.IllegalStateException\" jar hell!\n\n参考[https://github.com/elastic/elasticsearch/pull/13465](https://github.com/elastic/elasticsearch/pull/13465)\n\n```\nI stripped the SDK classpath in IntelliJ down to the default sun.boot.class.path and I am not seeing jar hell failures anymore. Specifically:\n\njre/lib/charsets.jar\njre/lib/jce.jar\njre/lib/jfr.jar\njre/lib/jsse.jar\njre/lib/resources.jar\njre/lib/rt.jar\n```\n到这里才想起来Intellij在导入jdk时，将许多的jar包加入到Classpath中了，进入File->Other Settings->Default Project Structure,修改jdk的Classpath为\n```\njre/lib/charsets.jar\njre/lib/jce.jar\njre/lib/jfr.jar\njre/lib/jsse.jar\njre/lib/resources.jar\njre/lib/rt.jar\n```\n## 提示找不到config目录\n在/Users/long/program/java/elasticsearch-2.3.0/core目录下新建config目录，将官方发布的Elasticsearch可执行包里的config目录拷贝到这里。\n\n之后启动org.elasticsearch.bootstrap.Elasticsearch, 成功。\n","slug":"在Intellij中启动ElasticSearch","published":1,"updated":"2016-04-08T06:16:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lr00gl26s6bwo3jube"},{"title":"在C++的sort排序中永远让比较函数对相等的值返回false","id":"640","date":"2014-03-24T13:16:05.000Z","_content":"\n很久之前，线上的程序跑着跑着，莫名其妙的就coredump了，找了很久都不知道原因。因为coredump的次数不是很多，有时好几天了也才dump了一次，所以也很难确定是在哪个地方出错了。通过版本回溯，慢慢缩小了出错的范围，可是我还是不知道在哪里出错了，直到今天晚上组长和我说了可能出错的地方，才知道原来有这么一个坑存在。\n\n他说使用sort排序时，比较函数编写时，如果两个值相等返回true可能会存在问题，于是我看了自己写的，两个值相等时，正是返回true.\n```\nint cmp(const int &a, const int &b) {\n    return a >= b;\n}\n```\n可是我还是看不出这里有什么错误，google之后找到了解答,在一篇文章里说到，当排序的个数超过16个时，且这些书数全部相等时，如果比较函数在两个值相等返回true时就会出错。这是因为sort行数的实现中，当超过16个数时，使用快速排序，而且假定一定存在两个数不相等。具体可参看[http://blog.sina.com.cn/s/blog_79d599dc01012m7l.html](http://blog.sina.com.cn/s/blog_79d599dc01012m7l.html)\n","source":"_posts/在C++的sort排序中永远让比较函数对相等的值返回false.md","raw":"title: 在C++的sort排序中永远让比较函数对相等的值返回false\ntags:\n  - C++\n  - coredump\n  - sort\n  - 比较函数\nid: 640\ncategories:\n  - 编程\ndate: 2014-03-24 21:16:05\n---\n\n很久之前，线上的程序跑着跑着，莫名其妙的就coredump了，找了很久都不知道原因。因为coredump的次数不是很多，有时好几天了也才dump了一次，所以也很难确定是在哪个地方出错了。通过版本回溯，慢慢缩小了出错的范围，可是我还是不知道在哪里出错了，直到今天晚上组长和我说了可能出错的地方，才知道原来有这么一个坑存在。\n\n他说使用sort排序时，比较函数编写时，如果两个值相等返回true可能会存在问题，于是我看了自己写的，两个值相等时，正是返回true.\n```\nint cmp(const int &a, const int &b) {\n    return a >= b;\n}\n```\n可是我还是看不出这里有什么错误，google之后找到了解答,在一篇文章里说到，当排序的个数超过16个时，且这些书数全部相等时，如果比较函数在两个值相等返回true时就会出错。这是因为sort行数的实现中，当超过16个数时，使用快速排序，而且假定一定存在两个数不相等。具体可参看[http://blog.sina.com.cn/s/blog_79d599dc01012m7l.html](http://blog.sina.com.cn/s/blog_79d599dc01012m7l.html)\n","slug":"在C++的sort排序中永远让比较函数对相等的值返回false","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4lw00gr26s6neacr07w"},{"title":"取石子游戏","id":"813","date":"2014-07-14T15:23:03.000Z","_content":"\n取石子游戏说的是有两堆任意数量的小石子，游戏由两个人轮流取石子，对于取法，游戏规定有两种，一种是可以在任意的一堆中，取走任意多的石子；一种是在两堆中同时取走相同数量的石子。游戏规定，最后把石子全部取完的为胜者。现在假设初始时两堆石子的数目为a和b, a <=  b，假设双方都采取最好的策略，问先取的人是胜者还是败者。\n\n对于这题，可以得到在以下情况下，先取的人必败，其它情况下，先取的人必胜。\n1 2\n3 5\n4 7\n6 10\n8 13\n9 16\n...\n\n可以看出，这两个数字之间一定有规律，而说到规律，很容易想到的是黄金分割比。记得那时还很粗心的将其中的数字写错了，于是任晓祎同学就过来纠正了。时光飞逝啊，已经过去三年了。","source":"_posts/取石子游戏.md","raw":"title: 取石子游戏\ntags:\n  - 取石子\n  - 黄金分割比\nid: 813\ncategories:\n  - 数学\ndate: 2014-07-14 23:23:03\n---\n\n取石子游戏说的是有两堆任意数量的小石子，游戏由两个人轮流取石子，对于取法，游戏规定有两种，一种是可以在任意的一堆中，取走任意多的石子；一种是在两堆中同时取走相同数量的石子。游戏规定，最后把石子全部取完的为胜者。现在假设初始时两堆石子的数目为a和b, a <=  b，假设双方都采取最好的策略，问先取的人是胜者还是败者。\n\n对于这题，可以得到在以下情况下，先取的人必败，其它情况下，先取的人必胜。\n1 2\n3 5\n4 7\n6 10\n8 13\n9 16\n...\n\n可以看出，这两个数字之间一定有规律，而说到规律，很容易想到的是黄金分割比。记得那时还很粗心的将其中的数字写错了，于是任晓祎同学就过来纠正了。时光飞逝啊，已经过去三年了。","slug":"取石子游戏","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4m300h126s6m3eenkf1"},{"title":"几道数学笔试题","id":"942","date":"2014-10-25T09:01:44.000Z","_content":"\n从扬大数院毕业后，与数学渐行渐远，许多时候，考虑问题都角度渐渐变得工程，也就是直观，而不是从抽象的角度来解决。组里有一个实习生，带来了几道笔试题，思考后，解决了，从解决问题的角度，明显看出，越来越工程化了。\n\n第一题说的是用6种颜色去涂一个立方体，问有几种涂法？\n\n一个明显的解答是6的阶乘，也就是720次，可是其中有很多种涂色，经过旋转后是一样的，所以这是错的。看到这题，立刻想到了魔方，之后想到了骰子，考虑到骰子更加直观，就用骰子。思考之后，其实挺简单的。把1这面朝上，那么1的对面，也就是底面有5种可能的情况。之后再看侧面的情况，对于侧面，固定一面之后，它的对面还有3中可能的情况，之后剩下两个侧面，有2种情况。所以一共有5 * 3 * 2 = 30种情况。这题一个难点是最开始的1这面的选择，以及侧面时，固定一面的选择。对于1这面的选择，是不能算概率的，因为无论怎么排，总是可以把1这面朝上。而对于侧面时固定一面，这固定一面也是不能算概率的，因为无论怎么排，都可以固定一面。\n\n第二题说的是，对于座位编号从1到5的5个人，将他们的座位打乱，每个人都不在自己座位上的情况有几种？\n\n经过上一题的训练后，抽象一下题目 ，对于座位编号从1到 n的n个人，将他们的座位打乱，每个人都不在自己座位上的情况有几种\n所以对于这题，相当于n为5的情况。依然用上面的类似方法。对于编号1的人，他一共有4种情况不在自己的座位上，假设他占了编号为5的座位。那么对于编号为5的这个人，他有两种情况可以选择，第一种，他占了座位1，则此时还剩三个人，这相当于n为3的情况，计算得到一种有2种可能；第二种情况是5不在座位1上，那么剩下的情况就相当于n=4的情形，计算得到有9中可能。于是最终结果等于5 * (2 + 9) = 44。而从这里也可以得到一个递推公式。设t(n)为人数为n时的可能情形。则t(n) = (n - 1) * (t(n - 1) + t(n - 2)，于是得到一个序列为0 1 2 9 44 265 ....\n\n第三题说的是，一共有27个人想喝饮料，三个空瓶子可以换一瓶饮料，那么一共需要买多少瓶饮料才能保证每个人都能喝到一瓶饮料？\n\n对于这题，立刻想到经典的借瓶子策略，对于这里，即只需要2个空瓶就可以喝一瓶饮料，这是因为当有2个空瓶时，可以向老板借一个空瓶，凑齐三个空瓶换来一瓶饮料，喝完之后，把空瓶换给老板。我想这里也是可以用到这个策略，于是写了一个序列1 2 6 18，等于27。所以最终的答案是18瓶。","source":"_posts/几道数学笔试题.md","raw":"title: 几道数学笔试题\ntags:\n  - 排列\n  - 笔试题\n  - 组合\nid: 942\ncategories:\n  - 数学\ndate: 2014-10-25 17:01:44\n---\n\n从扬大数院毕业后，与数学渐行渐远，许多时候，考虑问题都角度渐渐变得工程，也就是直观，而不是从抽象的角度来解决。组里有一个实习生，带来了几道笔试题，思考后，解决了，从解决问题的角度，明显看出，越来越工程化了。\n\n第一题说的是用6种颜色去涂一个立方体，问有几种涂法？\n\n一个明显的解答是6的阶乘，也就是720次，可是其中有很多种涂色，经过旋转后是一样的，所以这是错的。看到这题，立刻想到了魔方，之后想到了骰子，考虑到骰子更加直观，就用骰子。思考之后，其实挺简单的。把1这面朝上，那么1的对面，也就是底面有5种可能的情况。之后再看侧面的情况，对于侧面，固定一面之后，它的对面还有3中可能的情况，之后剩下两个侧面，有2种情况。所以一共有5 * 3 * 2 = 30种情况。这题一个难点是最开始的1这面的选择，以及侧面时，固定一面的选择。对于1这面的选择，是不能算概率的，因为无论怎么排，总是可以把1这面朝上。而对于侧面时固定一面，这固定一面也是不能算概率的，因为无论怎么排，都可以固定一面。\n\n第二题说的是，对于座位编号从1到5的5个人，将他们的座位打乱，每个人都不在自己座位上的情况有几种？\n\n经过上一题的训练后，抽象一下题目 ，对于座位编号从1到 n的n个人，将他们的座位打乱，每个人都不在自己座位上的情况有几种\n所以对于这题，相当于n为5的情况。依然用上面的类似方法。对于编号1的人，他一共有4种情况不在自己的座位上，假设他占了编号为5的座位。那么对于编号为5的这个人，他有两种情况可以选择，第一种，他占了座位1，则此时还剩三个人，这相当于n为3的情况，计算得到一种有2种可能；第二种情况是5不在座位1上，那么剩下的情况就相当于n=4的情形，计算得到有9中可能。于是最终结果等于5 * (2 + 9) = 44。而从这里也可以得到一个递推公式。设t(n)为人数为n时的可能情形。则t(n) = (n - 1) * (t(n - 1) + t(n - 2)，于是得到一个序列为0 1 2 9 44 265 ....\n\n第三题说的是，一共有27个人想喝饮料，三个空瓶子可以换一瓶饮料，那么一共需要买多少瓶饮料才能保证每个人都能喝到一瓶饮料？\n\n对于这题，立刻想到经典的借瓶子策略，对于这里，即只需要2个空瓶就可以喝一瓶饮料，这是因为当有2个空瓶时，可以向老板借一个空瓶，凑齐三个空瓶换来一瓶饮料，喝完之后，把空瓶换给老板。我想这里也是可以用到这个策略，于是写了一个序列1 2 6 18，等于27。所以最终的答案是18瓶。","slug":"几道数学笔试题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4m600h726s68h1crgyw"},{"title":"关于Sphinx引擎的一些想法","id":"666","date":"2014-04-11T00:58:37.000Z","_content":"\n因为自留地越来越像我的心情博客了，于是决定将学习笔记都记录在这个博客上，于是将之前关于Sphinx的一些文章全部转移到这里。\n\n最近一个星期都在看Sphinx搜索引擎的文档,并和组里的一个同事合作为公司的企业空间搜索建立索引，提供搜索服务，所以对于Sphinx有了一些了解，顺便几下来，以后用到了可以再看看。\n\n先八卦一下，Sphinx首先是俄罗斯人Andrew Aksyonoff开发的全文搜索引擎，开源之后有其他人参与进来，功能更加强大了。俄罗斯人还是真是厉害，之前是Nginx,现在是Sphinx。可是Sphinx不支持中文，所以要下载Sphinxforchinese才可以用。\n\nSphinx的数据源主要来自数据库，如Mysql,这也是最常见的方式。以下主要写给公司配置引擎时的一些体会。\n\n1.一般使用都是一个主索引和增量索引，主索引建立后一直不变，变化的是增量索引，搜索的结果为合并主索引和增量索引的搜索结果。每隔一段时间就到数据源中抓取数据，保存在一个tmp索引中，然后这个tmp索引和增量索引合并，当然也可以隔一段时间就将增量索引和主索引合并，但这个时间间隔最好长一些。\n\n2.建索引需要的数据分布在许多个表上，所以要先写爬虫将这些表的数据从数据库中抓取出来，存到另一个表中。之后在Sphin的配置文件中，数据就可以来自这个新建的表。这个新建的表最好有一个自动变化的时间字段，也就是每次在这个表中插入数据或更新数据，这个时间自动都会变化，这个字段将用于增量索引。另外还需要建一个表来保存上一次抓取的时间，从这个时间往后，抓取新的数据。\n\n3.默认情况下，从数据源中选出的数据都是建索引的。而默认情况下，对于建索引的数据,Sphinx将不会保存原始数据，如果需要Sphinx既建索引，又要保存数据，在配置文件中，将这个字段写为sql_field_string。对于时间类型，在sql_query中select数据时，就要用函数unix_timestamp将它转为整形的时间戳，在配置文件中，要将这个字段写为sql_attr_timestamp，这样在客户端中调用api转化时间时才会准确。\n\n4.sql_query_post和sql_query_post_index是有区别的。前者是当Sphinx从数据库中得到数据后，立刻就会运行，而后者只有当索引真正成功建立后才会运行，这个区别还是很重要的。对于真正严格的程序，不应该在sql_query_pre和sql_query_post中更新增量时间，而应该在sql_query_post_index中更新增量时间。还有一个区别是sql_query_post和sql_query_post_index是存在与两个不同的tcp连接中，因为Sphinx从数据库中得到数据后去建索引，将会花费很长时间，所以它会将数据库连接关闭，等到索引建好之后，再去连接数据库，所以sql_query_post_index会在另一个连接中\n\n5.对于可以使用id来做增量索引的数据，需要将这次增量的最大id保存到数据库中。一个很诱人的做法是，将这次增量的最大id保存在一个值中，然后在sql_query_post_index中将这个值保存到数据库中，这其实是不对的。因为上一条中说过，sql_query_post_index会在另一个连接中，所以之前连接中的值在这个连接中失效了。一个做法是将增量的最大id保存到数据库中一个tmp字段中，等到索引建成功后，在sql_query_post_index中，将这个最大id从数据库中读出，写到用于做增量索引的字段中。\n\n6.事实上，比较难的一点是在于数据有更新的情况下，如何处理。当数据有更新时，在主索引中原来的数据将会失效，但是搜索时还是会搜到它。一个解决的办法是将原来的数据标示为删除，这就需要一个标示字段了。这个办法是我组长想出来的，在sql_query中就给它添加一个字段，标示未删除的。每次增量索引结束后，就通过每条记录的id(在Sphinx中，会给每条记录一个id)，将主索引中相应的记录标示为删除。在搜索时，只需要搜索出标示为未删除的就可以了。对于官方文档中，我还没有看到如何解决这个问题的介绍。\n\n7.如果能写一个程序来自动生成配置文件，那就再好不过了。上次我是手动输的，既容易出错，有耗眼力和精力。\n\n整个过程最重要的还是将分布在多个表中的数据合并为一个表以及处理更新这两步上，如果能解决这两个问题，一个可用的全文搜索就完成了。暂时先写到这里，等以后有了新的体会再补充。\n\n看来是我错了，文档中有说到数据更新这个问题，是用Klist,具体可以看文档。看Sphinx的源码很不舒服，因为可恶的匈牙利命名。","source":"_posts/关于Sphinx引擎的一些想法.md","raw":"title: 关于Sphinx引擎的一些想法\ntags:\n  - Sphinx\n  - 增量索引\n  - 更新\nid: 666\ncategories:\n  - 搜索引擎\ndate: 2014-04-11 08:58:37\n---\n\n因为自留地越来越像我的心情博客了，于是决定将学习笔记都记录在这个博客上，于是将之前关于Sphinx的一些文章全部转移到这里。\n\n最近一个星期都在看Sphinx搜索引擎的文档,并和组里的一个同事合作为公司的企业空间搜索建立索引，提供搜索服务，所以对于Sphinx有了一些了解，顺便几下来，以后用到了可以再看看。\n\n先八卦一下，Sphinx首先是俄罗斯人Andrew Aksyonoff开发的全文搜索引擎，开源之后有其他人参与进来，功能更加强大了。俄罗斯人还是真是厉害，之前是Nginx,现在是Sphinx。可是Sphinx不支持中文，所以要下载Sphinxforchinese才可以用。\n\nSphinx的数据源主要来自数据库，如Mysql,这也是最常见的方式。以下主要写给公司配置引擎时的一些体会。\n\n1.一般使用都是一个主索引和增量索引，主索引建立后一直不变，变化的是增量索引，搜索的结果为合并主索引和增量索引的搜索结果。每隔一段时间就到数据源中抓取数据，保存在一个tmp索引中，然后这个tmp索引和增量索引合并，当然也可以隔一段时间就将增量索引和主索引合并，但这个时间间隔最好长一些。\n\n2.建索引需要的数据分布在许多个表上，所以要先写爬虫将这些表的数据从数据库中抓取出来，存到另一个表中。之后在Sphin的配置文件中，数据就可以来自这个新建的表。这个新建的表最好有一个自动变化的时间字段，也就是每次在这个表中插入数据或更新数据，这个时间自动都会变化，这个字段将用于增量索引。另外还需要建一个表来保存上一次抓取的时间，从这个时间往后，抓取新的数据。\n\n3.默认情况下，从数据源中选出的数据都是建索引的。而默认情况下，对于建索引的数据,Sphinx将不会保存原始数据，如果需要Sphinx既建索引，又要保存数据，在配置文件中，将这个字段写为sql_field_string。对于时间类型，在sql_query中select数据时，就要用函数unix_timestamp将它转为整形的时间戳，在配置文件中，要将这个字段写为sql_attr_timestamp，这样在客户端中调用api转化时间时才会准确。\n\n4.sql_query_post和sql_query_post_index是有区别的。前者是当Sphinx从数据库中得到数据后，立刻就会运行，而后者只有当索引真正成功建立后才会运行，这个区别还是很重要的。对于真正严格的程序，不应该在sql_query_pre和sql_query_post中更新增量时间，而应该在sql_query_post_index中更新增量时间。还有一个区别是sql_query_post和sql_query_post_index是存在与两个不同的tcp连接中，因为Sphinx从数据库中得到数据后去建索引，将会花费很长时间，所以它会将数据库连接关闭，等到索引建好之后，再去连接数据库，所以sql_query_post_index会在另一个连接中\n\n5.对于可以使用id来做增量索引的数据，需要将这次增量的最大id保存到数据库中。一个很诱人的做法是，将这次增量的最大id保存在一个值中，然后在sql_query_post_index中将这个值保存到数据库中，这其实是不对的。因为上一条中说过，sql_query_post_index会在另一个连接中，所以之前连接中的值在这个连接中失效了。一个做法是将增量的最大id保存到数据库中一个tmp字段中，等到索引建成功后，在sql_query_post_index中，将这个最大id从数据库中读出，写到用于做增量索引的字段中。\n\n6.事实上，比较难的一点是在于数据有更新的情况下，如何处理。当数据有更新时，在主索引中原来的数据将会失效，但是搜索时还是会搜到它。一个解决的办法是将原来的数据标示为删除，这就需要一个标示字段了。这个办法是我组长想出来的，在sql_query中就给它添加一个字段，标示未删除的。每次增量索引结束后，就通过每条记录的id(在Sphinx中，会给每条记录一个id)，将主索引中相应的记录标示为删除。在搜索时，只需要搜索出标示为未删除的就可以了。对于官方文档中，我还没有看到如何解决这个问题的介绍。\n\n7.如果能写一个程序来自动生成配置文件，那就再好不过了。上次我是手动输的，既容易出错，有耗眼力和精力。\n\n整个过程最重要的还是将分布在多个表中的数据合并为一个表以及处理更新这两步上，如果能解决这两个问题，一个可用的全文搜索就完成了。暂时先写到这里，等以后有了新的体会再补充。\n\n看来是我错了，文档中有说到数据更新这个问题，是用Klist,具体可以看文档。看Sphinx的源码很不舒服，因为可恶的匈牙利命名。","slug":"关于Sphinx引擎的一些想法","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4m900hd26s6k5j5l5zr"},{"title":"使用virtualenvwrapper隔离Python环境","date":"2016-04-21T12:11:19.000Z","_content":"以前使用virtualenv来隔离Python环境。最近知道了virtualenvwrapper, 才知道之前使用virtualenv的方法不对,而virtualenv也有一些不便，而virtualenvwrapper就是用来解决这些不便。\n\n* 统一环境存储位置\n* 方便环境切换\n\n具体查看[virtualwapper官方文档](https://virtualenvwrapper.readthedocs.org/en/latest/index.html)。工欲善其事，必先利其器确实很有道理。\n\n想想以前花费在Windowns系统安装和软件安装的时间，太不值了。\n","source":"_posts/使用virtualenvwrapper隔离Python环境.md","raw":"title: 使用virtualenvwrapper隔离Python环境\ndate: 2016-04-21 20:11:19\ntags:\n    - virtualenvwrapper\n    - virtual\ncategories:\n    - 软件安装\n---\n以前使用virtualenv来隔离Python环境。最近知道了virtualenvwrapper, 才知道之前使用virtualenv的方法不对,而virtualenv也有一些不便，而virtualenvwrapper就是用来解决这些不便。\n\n* 统一环境存储位置\n* 方便环境切换\n\n具体查看[virtualwapper官方文档](https://virtualenvwrapper.readthedocs.org/en/latest/index.html)。工欲善其事，必先利其器确实很有道理。\n\n想想以前花费在Windowns系统安装和软件安装的时间，太不值了。\n","slug":"使用virtualenvwrapper隔离Python环境","published":1,"updated":"2016-04-21T12:12:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mb00hi26s6avw95gn2"},{"title":"产生所有排列--字典顺序","id":"1063","date":"2015-10-31T02:01:09.000Z","_content":"\n编写一个程序，用字典顺序列出n个元素的所有排列(Permutation).\n\n说明:\n下面是一个n = 4，用字典顺序列出来的所有排列，一共为4! = 24个。\n1234    2134    3124    4123\n1243    2143    3142    4132\n1324    2314    3214    4213\n1342    2341    3241    4231\n1423    2413    3412    4312\n1432    2431    3421    4321\n\n这里是一个递归的做法。看上面4! = 24个排列的第一列，它们的第一个元素都是1，第一列的最后一个是以1开头，用字典顺序排出来的最后，自然是1432.事实上，如果是n个元素的排列，以1开头的最后一个应该是1n(n-1)...432。下一列是2开头，把n(n-1)...432中最小的一个与第一个互换，也就是把倒数第一个与第一个互换，得到2n(n-1)..431，但这不是1n(n-1)...432的下一个，但是如果把后面的n - 1个元素反过来，就会得到2134...(n-1)n，是正确的顺序，于是进入第二列。\n\n第二列的最后一个应该是2n(n-1)...431,把 n(n-1)...431中最小的与第一个互换，但因为1已经出现过了，所以把倒数第二个元素(自然是3)与第一个互换，得到3n(n-1)...421，再把后面的n - 1个元素反过来，得到3124...(n-1)n，就得到第三列的第一个。\n\n第三列的最后一个是3n(n-1)...421, 把n(n-1)...421中最小的与第一个互换，但因为1，2已经出现过了，所以把倒数第3个元素(自然是4)与第一个互换，得到4n(n-1)...321，再将后面n - 1个反过来排，得到4123...(n - 1)n，正好是第4列的第一个元素。\n\n于是我们可以得到一个递归的做法，从1234...n起，用一个递归的程序\n1\\. i = n\n2\\. 对后面n - 1个进行排列(递归的)\n3\\. 把第i位与第1位互换\n4\\. i减去1​\n5\\. 把后面的n - 1位反过来排\n6\\. 回到第2步\n当i到第一位时程序结束。\n\n需要注意的一点是，排序结束后，数组元素的位置是逆置的，要保证不改变数组元素，我们需要将数组进行一个逆置。\n``` java\npackage chapter3;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class Permutions {\n\tpublic static List<List<Integer>> permute(int[] nums) {\n\t\tList<List<Integer>> result = new ArrayList<List<Integer>>();\n\t\tif (nums.length == 0)\n\t\t\treturn result;\n\t\tpermute(nums, 0, result);\n\t\treverse(nums, 0, nums.length - 1); //after permutation, we need to reverse array\n\t\treturn result;\n\t}\n\tpublic static void swap(int[] nums, int i, int j) {\n\t\tint temp = nums[i];\n\t\tnums[i] = nums[j];\n\t\tnums[j] = temp;\n\t}\n\tpublic static void reverse(int[] nums, int begin, int end) {\n\t\twhile (begin < end) {\n\t\t\tswap(nums, begin, end);\n\t\t\tbegin++;\n\t\t\tend--;\n\t\t}\n\t}\n\tpublic static void permute(int[] nums, int start, List<List<Integer>> result) {\n\t\tif (start == nums.length - 1) {\n\t\t\tList<Integer> temp = new ArrayList<Integer>();\n\t\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\t\ttemp.add(nums[i]);\n\t\t\t}\n\t\t\tresult.add(temp);\n\t\t\treturn;\n\t\t}\n\t\tint i = nums.length;\n\t\twhile (i > start) {\n\t\t\tpermute(nums, start + 1, result);\n\t\t\tswap(nums, start, i - 1);\n\t\t\ti--;\n\t\t\tif (i <= start)\n\t\t\t\tbreak;\n\t\t\treverse(nums, start + 1, nums.length - 1);\t\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 3, 4};\n\t\tList<List<Integer>> result = permute(nums);\n\t\tfor (List<Integer> list: result) {\n\t\t\tfor (Integer i: list) {\n\t\t\t\tSystem.out.print(i);\n\t\t\t}\n\t\t\tSystem.out.println(\"\");\n\t\t}\n\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\tSystem.out.print(nums[i] + \" \");\n\t\t}\n\t}\n}\n```","source":"_posts/产生所有排列--字典顺序.md","raw":"title: 产生所有排列--字典顺序\ntags:\n  - C名题百则\nid: 1063\ncategories:\n  - 算法\ndate: 2015-10-31 10:01:09\n---\n\n编写一个程序，用字典顺序列出n个元素的所有排列(Permutation).\n\n说明:\n下面是一个n = 4，用字典顺序列出来的所有排列，一共为4! = 24个。\n1234    2134    3124    4123\n1243    2143    3142    4132\n1324    2314    3214    4213\n1342    2341    3241    4231\n1423    2413    3412    4312\n1432    2431    3421    4321\n\n这里是一个递归的做法。看上面4! = 24个排列的第一列，它们的第一个元素都是1，第一列的最后一个是以1开头，用字典顺序排出来的最后，自然是1432.事实上，如果是n个元素的排列，以1开头的最后一个应该是1n(n-1)...432。下一列是2开头，把n(n-1)...432中最小的一个与第一个互换，也就是把倒数第一个与第一个互换，得到2n(n-1)..431，但这不是1n(n-1)...432的下一个，但是如果把后面的n - 1个元素反过来，就会得到2134...(n-1)n，是正确的顺序，于是进入第二列。\n\n第二列的最后一个应该是2n(n-1)...431,把 n(n-1)...431中最小的与第一个互换，但因为1已经出现过了，所以把倒数第二个元素(自然是3)与第一个互换，得到3n(n-1)...421，再把后面的n - 1个元素反过来，得到3124...(n-1)n，就得到第三列的第一个。\n\n第三列的最后一个是3n(n-1)...421, 把n(n-1)...421中最小的与第一个互换，但因为1，2已经出现过了，所以把倒数第3个元素(自然是4)与第一个互换，得到4n(n-1)...321，再将后面n - 1个反过来排，得到4123...(n - 1)n，正好是第4列的第一个元素。\n\n于是我们可以得到一个递归的做法，从1234...n起，用一个递归的程序\n1\\. i = n\n2\\. 对后面n - 1个进行排列(递归的)\n3\\. 把第i位与第1位互换\n4\\. i减去1​\n5\\. 把后面的n - 1位反过来排\n6\\. 回到第2步\n当i到第一位时程序结束。\n\n需要注意的一点是，排序结束后，数组元素的位置是逆置的，要保证不改变数组元素，我们需要将数组进行一个逆置。\n``` java\npackage chapter3;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class Permutions {\n\tpublic static List<List<Integer>> permute(int[] nums) {\n\t\tList<List<Integer>> result = new ArrayList<List<Integer>>();\n\t\tif (nums.length == 0)\n\t\t\treturn result;\n\t\tpermute(nums, 0, result);\n\t\treverse(nums, 0, nums.length - 1); //after permutation, we need to reverse array\n\t\treturn result;\n\t}\n\tpublic static void swap(int[] nums, int i, int j) {\n\t\tint temp = nums[i];\n\t\tnums[i] = nums[j];\n\t\tnums[j] = temp;\n\t}\n\tpublic static void reverse(int[] nums, int begin, int end) {\n\t\twhile (begin < end) {\n\t\t\tswap(nums, begin, end);\n\t\t\tbegin++;\n\t\t\tend--;\n\t\t}\n\t}\n\tpublic static void permute(int[] nums, int start, List<List<Integer>> result) {\n\t\tif (start == nums.length - 1) {\n\t\t\tList<Integer> temp = new ArrayList<Integer>();\n\t\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\t\ttemp.add(nums[i]);\n\t\t\t}\n\t\t\tresult.add(temp);\n\t\t\treturn;\n\t\t}\n\t\tint i = nums.length;\n\t\twhile (i > start) {\n\t\t\tpermute(nums, start + 1, result);\n\t\t\tswap(nums, start, i - 1);\n\t\t\ti--;\n\t\t\tif (i <= start)\n\t\t\t\tbreak;\n\t\t\treverse(nums, start + 1, nums.length - 1);\t\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 3, 4};\n\t\tList<List<Integer>> result = permute(nums);\n\t\tfor (List<Integer> list: result) {\n\t\t\tfor (Integer i: list) {\n\t\t\t\tSystem.out.print(i);\n\t\t\t}\n\t\t\tSystem.out.println(\"\");\n\t\t}\n\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\tSystem.out.print(nums[i] + \" \");\n\t\t}\n\t}\n}\n```","slug":"产生所有排列--字典顺序","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mi00ho26s6mr0pbiqz"},{"title":"产生所有排列--字典顺序(非递归解)","id":"1070","date":"2015-11-02T13:42:50.000Z","_content":"\n编写一个程序，用字典顺序列出n个元素的所有排列(Permutation).​\n说明:\n下面是一个n = 4，用字典顺序列出来的所有排列，一共为4! = 24个。\n1234 2134 3124 4123\n1243 2143 3142 4132\n1324 2314 3214 4213\n1342 2341 3241 4231\n1423 2413 3412 4312\n1432 2431 3421 4321​\n\n在[产生所有排列--字典顺序](http://program.dengshilong.org/2015/10/31/%E4%BA%A7%E7%94%9F%E6%89%80%E6%9C%89%E6%8E%92%E5%88%97-%E5%AD%97%E5%85%B8%E9%A1%BA%E5%BA%8F/)中，用了递归的方法求解字典排列，这里使用非递归的方法。据Hall和Knuth的考证，200多年前(1812年)Fischer和Kruse在一本书中就提到了这个方法.\n\nstep 1: 从右往左找，找到第一个i使得nums[i] < nums[i + 1]\nstep 2: 从右往左找，找到第一个j使得nums[i] < nums[j]\nstep 3: 交换nums[i]与nums[j]\nstep 4: 将nums[i + 1],...nums[n]反转\n在step 1时，如果找不到满足条件的i, 则结束程序。\n\n例如153642,\n从右往左找，找到第一个 i = 2 使得nums[i] < nums[i + 1] 即3 < 6\n从右往左找，找到第一个 j = 3 使得nums[i] < nums[j] 即 3 < 4\n交换nums[i]和nums[j], 得到154632\n将nums[i + ],..nums[n]反转，即将632反转，得到154236\n所以154236就是153642的下一个排列。\n\n如此从要求12...n的字典排列，可以从12,...n开始，一直用求下一个排列的方法列出所有排列。\n\n``` java\npackage chapter3;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class Permutation {\n\tpublic static List<List<Integer>> permute(int[] nums) {\n\t\tList<List<Integer>> result = new ArrayList<List<Integer>>();\n\t\tif (nums.length == 0)\n\t\t\treturn result;\n\t\twhile (true) {\n\t\t\tList<Integer> temp = new ArrayList<Integer>();\n\t\t\tfor (int t: nums) {\n\t\t\t\ttemp.add(t);\t\t\n\t\t\t}\n\t\t\tresult.add(temp);\n\t\t\tint i = nums.length - 2;\n\t\t\twhile (i >= 0 && nums[i] > nums[i + 1]) \n\t\t\t\ti--;\n\t\t\tif (i < 0)\n\t\t\t\tbreak;\n\n\t\t\tint j = nums.length - 1;\n\t\t\twhile (j > i && nums[i] > nums[j])\n\t\t\t\tj--;\n\t\t\tswap(nums, i, j);\n\t\t\treverse(nums, i + 1, nums.length - 1);\n\t\t}\n\t\treverse(nums, 0, nums.length - 1);\n\t\treturn result;\n\t}\n\tpublic static void swap(int[] nums, int i, int j) {\n\t\tint temp = nums[i];\n\t\tnums[i] = nums[j];\n\t\tnums[j] = temp;\n\t}\n\tpublic static void reverse(int[] nums, int begin, int end) {\n\t\twhile (begin < end) {\n\t\t\tswap(nums, begin, end);\n\t\t\tbegin++;\n\t\t\tend--;\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 3, 4};\n\t\tList<List<Integer>> result = permute(nums);\n\t\tfor (List<Integer> list: result) {\n\t\t\tfor (Integer i: list) {\n\t\t\t\tSystem.out.print(i);\n\t\t\t}\n\t\t\tSystem.out.println(\"\");\n\t\t}\n\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\tSystem.out.print(nums[i] + \" \");\n\t\t}\t\n\t}\n}\n```","source":"_posts/产生所有排列--字典顺序(非递归解).md","raw":"title: 产生所有排列--字典顺序(非递归解)\ntags:\n  - C名题百则\nid: 1070\ncategories:\n  - 算法\ndate: 2015-11-02 21:42:50\n---\n\n编写一个程序，用字典顺序列出n个元素的所有排列(Permutation).​\n说明:\n下面是一个n = 4，用字典顺序列出来的所有排列，一共为4! = 24个。\n1234 2134 3124 4123\n1243 2143 3142 4132\n1324 2314 3214 4213\n1342 2341 3241 4231\n1423 2413 3412 4312\n1432 2431 3421 4321​\n\n在[产生所有排列--字典顺序](http://program.dengshilong.org/2015/10/31/%E4%BA%A7%E7%94%9F%E6%89%80%E6%9C%89%E6%8E%92%E5%88%97-%E5%AD%97%E5%85%B8%E9%A1%BA%E5%BA%8F/)中，用了递归的方法求解字典排列，这里使用非递归的方法。据Hall和Knuth的考证，200多年前(1812年)Fischer和Kruse在一本书中就提到了这个方法.\n\nstep 1: 从右往左找，找到第一个i使得nums[i] < nums[i + 1]\nstep 2: 从右往左找，找到第一个j使得nums[i] < nums[j]\nstep 3: 交换nums[i]与nums[j]\nstep 4: 将nums[i + 1],...nums[n]反转\n在step 1时，如果找不到满足条件的i, 则结束程序。\n\n例如153642,\n从右往左找，找到第一个 i = 2 使得nums[i] < nums[i + 1] 即3 < 6\n从右往左找，找到第一个 j = 3 使得nums[i] < nums[j] 即 3 < 4\n交换nums[i]和nums[j], 得到154632\n将nums[i + ],..nums[n]反转，即将632反转，得到154236\n所以154236就是153642的下一个排列。\n\n如此从要求12...n的字典排列，可以从12,...n开始，一直用求下一个排列的方法列出所有排列。\n\n``` java\npackage chapter3;\n\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class Permutation {\n\tpublic static List<List<Integer>> permute(int[] nums) {\n\t\tList<List<Integer>> result = new ArrayList<List<Integer>>();\n\t\tif (nums.length == 0)\n\t\t\treturn result;\n\t\twhile (true) {\n\t\t\tList<Integer> temp = new ArrayList<Integer>();\n\t\t\tfor (int t: nums) {\n\t\t\t\ttemp.add(t);\t\t\n\t\t\t}\n\t\t\tresult.add(temp);\n\t\t\tint i = nums.length - 2;\n\t\t\twhile (i >= 0 && nums[i] > nums[i + 1]) \n\t\t\t\ti--;\n\t\t\tif (i < 0)\n\t\t\t\tbreak;\n\n\t\t\tint j = nums.length - 1;\n\t\t\twhile (j > i && nums[i] > nums[j])\n\t\t\t\tj--;\n\t\t\tswap(nums, i, j);\n\t\t\treverse(nums, i + 1, nums.length - 1);\n\t\t}\n\t\treverse(nums, 0, nums.length - 1);\n\t\treturn result;\n\t}\n\tpublic static void swap(int[] nums, int i, int j) {\n\t\tint temp = nums[i];\n\t\tnums[i] = nums[j];\n\t\tnums[j] = temp;\n\t}\n\tpublic static void reverse(int[] nums, int begin, int end) {\n\t\twhile (begin < end) {\n\t\t\tswap(nums, begin, end);\n\t\t\tbegin++;\n\t\t\tend--;\n\t\t}\n\t}\n\n\tpublic static void main(String[] args) {\n\t\tint[] nums = {1, 2, 3, 4};\n\t\tList<List<Integer>> result = permute(nums);\n\t\tfor (List<Integer> list: result) {\n\t\t\tfor (Integer i: list) {\n\t\t\t\tSystem.out.print(i);\n\t\t\t}\n\t\t\tSystem.out.println(\"\");\n\t\t}\n\t\tfor (int i = 0; i < nums.length; i++) {\n\t\t\tSystem.out.print(nums[i] + \" \");\n\t\t}\t\n\t}\n}\n```","slug":"产生所有排列--字典顺序(非递归解)","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mk00hr26s659xsguzc"},{"title":"产生匹配括号的字符串","id":"1106","date":"2015-12-07T08:42:40.000Z","_content":"\n请写一个程序，输入一个正整数的值，然后列出所有有n个做括号与n个右括号正确地组成的字符串；当然，正确的左、右括号一定个数一样多。\n\n说明：\n所谓由括号正确地组成的字符串，指的是如果有一个左括号，那么在它的右边就一定有一个与它相匹配的右括号。(())、()(),就是仅有的两个由两个左括号和两个右括号正确地组成的字符串；((()))、(()())、(())()、()(())、()()()是仅有的5个由3个左括号和3个右括号正确地组成的字符串。\n\n如何产生这样的字符串呢？下面就是一个有用的想法：如果在产生的过程中已经产生了若干左、右括号，为了要把产生的行为完成，还欠R个左括号、L个右括号，那么有没有办法找出产生下一个括号时L与R的关系呢？记住，递归是一个不容忽视的利器。\n​\n解法：\n假设还有left个左括号和right个右括号等待匹配，根据left与right的大小可以分三种情况\n1.当 left == right 时，此时只能继续放左括号\n2.当 left < right时，可以有两个选择， 继续放一个左括号或者继续放一个有括号。\n放左括号时需要判断left是否大于0，只有left大于0时,才能继续放左括号。\n放右括号时则不需要判断。\n3.当left > right时，此时没有意义。\n\n写成Java程序如下：\n```\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class GenerateParenthesis {\n\tpublic static List<String> generateParenthesis(int n) {\n\t\tList<String> result = new ArrayList<String>();\n\t\tgenerateParenthesis(n, n , n, \"\", result);\n\t\treturn result;\n\t}\n\tprivate static void generateParenthesis(int left, int right, int n, \n\t\t\tString s, List<String> result) {\n\n\t\tif (s.length() == n * 2) {\n\t\t\tresult.add(s);\n\t\t} else {\n\t\t\tif (left == right) {\n\t\t\t\tgenerateParenthesis(left - 1, right, n , s + \"(\", result);\n\t\t\t} else if (left < right) {\n\t\t\t\tif (left > 0) {\n\t\t\t\t\tgenerateParenthesis(left - 1, right, n , s + \"(\", result);\n\t\t\t\t}\n\t\t\t\tgenerateParenthesis(left, right - 1, n, s + \")\", result);\n\t\t\t} \n\t\t}\t\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<String> result = generateParenthesis(3);\n\t\tfor (String s: result) {\n\t\t\tSystem.out.println(s);\n\t\t}\n\t}\n}\n```\n还可以对程序进行优化，因为递归过程会产生许多字符串，可以用数组来解决这个问题。修改程序如下：\n```\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class GenerateParenthesis {\n\tpublic static List<String> generateParenthesis(int n) {\n\t\tList<String> result = new ArrayList<String>();\n\t\tchar[] str = new char[n * 2];\n\t\tgenerateParenthesis(n, n , str, 0, result);\n\t\treturn result;\n\t}\n\tprivate static void generateParenthesis(int left, int right, char[] str, \n\t\t\tint length, List<String> result) {\n\n\t\tif (length == str.length) {\n\t\t\tresult.add(String.valueOf(str));\n\t\t} else {\n\t\t\tif (left == right) {\n\t\t\t\tstr[length] = '(';\n\t\t\t\tgenerateParenthesis(left - 1, right, str, length + 1, result);\n\t\t\t} else if (left < right) {\n\t\t\t\tif (left > 0) {\n\t\t\t\t\tstr[length] = '(';\n\t\t\t\t\tgenerateParenthesis(left - 1, right, str, length + 1, result);\n\t\t\t\t}\n\t\t\t\tstr[length] = ')';\n\t\t\t\tgenerateParenthesis(left, right - 1, str, length + 1, result);\n\t\t\t} \n\t\t}\t\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<String> result = generateParenthesis(3);\n\t\tfor (String s: result) {\n\t\t\tSystem.out.println(s);\n\t\t}\n\t}\n}\n\n```\n","source":"_posts/产生匹配括号的字符串.md","raw":"title: 产生匹配括号的字符串\ntags:\n  - C名题百则\nid: 1106\ncategories:\n  - 算法\ndate: 2015-12-07 16:42:40\n---\n\n请写一个程序，输入一个正整数的值，然后列出所有有n个做括号与n个右括号正确地组成的字符串；当然，正确的左、右括号一定个数一样多。\n\n说明：\n所谓由括号正确地组成的字符串，指的是如果有一个左括号，那么在它的右边就一定有一个与它相匹配的右括号。(())、()(),就是仅有的两个由两个左括号和两个右括号正确地组成的字符串；((()))、(()())、(())()、()(())、()()()是仅有的5个由3个左括号和3个右括号正确地组成的字符串。\n\n如何产生这样的字符串呢？下面就是一个有用的想法：如果在产生的过程中已经产生了若干左、右括号，为了要把产生的行为完成，还欠R个左括号、L个右括号，那么有没有办法找出产生下一个括号时L与R的关系呢？记住，递归是一个不容忽视的利器。\n​\n解法：\n假设还有left个左括号和right个右括号等待匹配，根据left与right的大小可以分三种情况\n1.当 left == right 时，此时只能继续放左括号\n2.当 left < right时，可以有两个选择， 继续放一个左括号或者继续放一个有括号。\n放左括号时需要判断left是否大于0，只有left大于0时,才能继续放左括号。\n放右括号时则不需要判断。\n3.当left > right时，此时没有意义。\n\n写成Java程序如下：\n```\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class GenerateParenthesis {\n\tpublic static List<String> generateParenthesis(int n) {\n\t\tList<String> result = new ArrayList<String>();\n\t\tgenerateParenthesis(n, n , n, \"\", result);\n\t\treturn result;\n\t}\n\tprivate static void generateParenthesis(int left, int right, int n, \n\t\t\tString s, List<String> result) {\n\n\t\tif (s.length() == n * 2) {\n\t\t\tresult.add(s);\n\t\t} else {\n\t\t\tif (left == right) {\n\t\t\t\tgenerateParenthesis(left - 1, right, n , s + \"(\", result);\n\t\t\t} else if (left < right) {\n\t\t\t\tif (left > 0) {\n\t\t\t\t\tgenerateParenthesis(left - 1, right, n , s + \"(\", result);\n\t\t\t\t}\n\t\t\t\tgenerateParenthesis(left, right - 1, n, s + \")\", result);\n\t\t\t} \n\t\t}\t\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<String> result = generateParenthesis(3);\n\t\tfor (String s: result) {\n\t\t\tSystem.out.println(s);\n\t\t}\n\t}\n}\n```\n还可以对程序进行优化，因为递归过程会产生许多字符串，可以用数组来解决这个问题。修改程序如下：\n```\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class GenerateParenthesis {\n\tpublic static List<String> generateParenthesis(int n) {\n\t\tList<String> result = new ArrayList<String>();\n\t\tchar[] str = new char[n * 2];\n\t\tgenerateParenthesis(n, n , str, 0, result);\n\t\treturn result;\n\t}\n\tprivate static void generateParenthesis(int left, int right, char[] str, \n\t\t\tint length, List<String> result) {\n\n\t\tif (length == str.length) {\n\t\t\tresult.add(String.valueOf(str));\n\t\t} else {\n\t\t\tif (left == right) {\n\t\t\t\tstr[length] = '(';\n\t\t\t\tgenerateParenthesis(left - 1, right, str, length + 1, result);\n\t\t\t} else if (left < right) {\n\t\t\t\tif (left > 0) {\n\t\t\t\t\tstr[length] = '(';\n\t\t\t\t\tgenerateParenthesis(left - 1, right, str, length + 1, result);\n\t\t\t\t}\n\t\t\t\tstr[length] = ')';\n\t\t\t\tgenerateParenthesis(left, right - 1, str, length + 1, result);\n\t\t\t} \n\t\t}\t\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<String> result = generateParenthesis(3);\n\t\tfor (String s: result) {\n\t\t\tSystem.out.println(s);\n\t\t}\n\t}\n}\n\n```\n","slug":"产生匹配括号的字符串","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mn00hu26s6f2xtdgk2"},{"title":"产生Gray码","id":"1053","date":"2015-10-29T08:40:43.000Z","_content":"\n编写一个程序，用Gray码(Gray Code)的顺序列出一个集合的所有子集。\n\n什么是Gray码? nbit的Gray码是一连串共有2的n次方个元素的数列，每一个元素都有nbit,而且任何相邻的两个元素之间都只有1bit的值不同。例如，\n两个bit的Gray码:\n00 01 11 10 是一组Gray码\n3个bit的Gray码:\n000 001 011 010 110 111 101 100 是一组Gray码\n但是Gray码并不是惟一的，把他循环排列或是用反过来的顺序写，也会得到一组Gray码；比如说，如果把3bitGray码的最后3个元素放在前面去，就会得到:\n111 101 100 000 001 011 010 110 也是一组Gray码\n\n产生Gray码的方法很多，这里这介绍其中一种。\n将2bit Gray码列出\n00 \n01\n11\n10\n将3bit Gray码列出\n000\n001\n011\n010\n110\n111\n101\n100\n观察3bit Gray码可以发现，它可以由2bit Gray码来得到。\n3bit Gray码的前四个由2bit Gray码从第一个到最后一个在最前面的加上0得到\n3bit Gray码的后四个 可以将2bit Gray从最后一个到第一个在最前面加上1得到\n写成代码如下\n``` java\npublic class GrayCode {\n\tpublic static List<Integer> grayCode(int n) {\n\t     List<Integer> result = new ArrayList<Integer>();\n\t     if (n == 0) {\n\t    \t result.add(0);\n\t     } else {\n\t    \t List<Integer> temp = grayCode(n-1);\n\t    \t for (Integer i: temp) {\n\t    \t\t result.add(i);\n\t    \t }\n\t    \t for (int i = temp.size() - 1; i >= 0; i--) {\n\t    \t\t result.add(temp.get(i) + (1 << (n - 1)));\n\t    \t }\n\t     }\n\t     return result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<Integer> result = grayCode(1);\n\t\tfor (Integer i: result) {\n\t\t\tSystem.out.println(i);\n\t\t}\n\t}\n}\n```","source":"_posts/产生Gray码.md","raw":"title: 产生Gray码\ntags:\n  - C名题百则\nid: 1053\ncategories:\n  - 算法\ndate: 2015-10-29 16:40:43\n---\n\n编写一个程序，用Gray码(Gray Code)的顺序列出一个集合的所有子集。\n\n什么是Gray码? nbit的Gray码是一连串共有2的n次方个元素的数列，每一个元素都有nbit,而且任何相邻的两个元素之间都只有1bit的值不同。例如，\n两个bit的Gray码:\n00 01 11 10 是一组Gray码\n3个bit的Gray码:\n000 001 011 010 110 111 101 100 是一组Gray码\n但是Gray码并不是惟一的，把他循环排列或是用反过来的顺序写，也会得到一组Gray码；比如说，如果把3bitGray码的最后3个元素放在前面去，就会得到:\n111 101 100 000 001 011 010 110 也是一组Gray码\n\n产生Gray码的方法很多，这里这介绍其中一种。\n将2bit Gray码列出\n00 \n01\n11\n10\n将3bit Gray码列出\n000\n001\n011\n010\n110\n111\n101\n100\n观察3bit Gray码可以发现，它可以由2bit Gray码来得到。\n3bit Gray码的前四个由2bit Gray码从第一个到最后一个在最前面的加上0得到\n3bit Gray码的后四个 可以将2bit Gray从最后一个到第一个在最前面加上1得到\n写成代码如下\n``` java\npublic class GrayCode {\n\tpublic static List<Integer> grayCode(int n) {\n\t     List<Integer> result = new ArrayList<Integer>();\n\t     if (n == 0) {\n\t    \t result.add(0);\n\t     } else {\n\t    \t List<Integer> temp = grayCode(n-1);\n\t    \t for (Integer i: temp) {\n\t    \t\t result.add(i);\n\t    \t }\n\t    \t for (int i = temp.size() - 1; i >= 0; i--) {\n\t    \t\t result.add(temp.get(i) + (1 << (n - 1)));\n\t    \t }\n\t     }\n\t     return result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tList<Integer> result = grayCode(1);\n\t\tfor (Integer i: result) {\n\t\t\tSystem.out.println(i);\n\t\t}\n\t}\n}\n```","slug":"产生Gray码","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mp00hx26s69iih61hg"},{"title":"两数组最短距离","id":"1037","date":"2015-10-22T07:35:45.000Z","_content":"\n已知两个元素从小到大排列的数组x[]与y[],请编写一个程序算出两个数组元素彼此之间差的绝对值最小的一个树，此值称为数组的距离。\n\n说明： 如果x[i]与y[i]是两个元素，那么 |x[i] - y[i]| 就是这两个元素之间的距离，所有这些距离的最小值，称为数组的距离。比如说x[]有1，3，5，7，9， y[]有2，6，8，那么最短距离就是1，因为x[0]与y[0]、 x[1]与y[0]、x[2]与y[1]、x[3]与y[1]、还有x[4]与y[2]的距离都是1。\n\n依然是利用数组已经排好序的特性。\n``` java\npublic class MinDist {\n\tpublic static int minDist(int[] x, int[] y) {\n\t\tint result = Integer.MAX_VALUE;\n\t\tint i = 0;\n\t\tint j = 0;\n\t\twhile (i < x.length && j < y.length) {\t\n\t\t\tif (x[i] >= y[j]) {\n\t\t\t\tresult = Math.min(result, x[i] - y[j]);\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\tresult = Math.min(result, y[j] - x[i]);\n\t\t\t\ti++;\n\t\t\t}\t\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] x = {1, 3, 5, 7, 9};\n\t\tint[] y = {2, 6, 8};\n\t\tSystem.out.println(minDist(x, y));\n\t}\n}\n```","source":"_posts/两数组最短距离.md","raw":"title: 两数组最短距离\ntags:\n  - C名题百则\nid: 1037\ncategories:\n  - 算法\ndate: 2015-10-22 15:35:45\n---\n\n已知两个元素从小到大排列的数组x[]与y[],请编写一个程序算出两个数组元素彼此之间差的绝对值最小的一个树，此值称为数组的距离。\n\n说明： 如果x[i]与y[i]是两个元素，那么 |x[i] - y[i]| 就是这两个元素之间的距离，所有这些距离的最小值，称为数组的距离。比如说x[]有1，3，5，7，9， y[]有2，6，8，那么最短距离就是1，因为x[0]与y[0]、 x[1]与y[0]、x[2]与y[1]、x[3]与y[1]、还有x[4]与y[2]的距离都是1。\n\n依然是利用数组已经排好序的特性。\n``` java\npublic class MinDist {\n\tpublic static int minDist(int[] x, int[] y) {\n\t\tint result = Integer.MAX_VALUE;\n\t\tint i = 0;\n\t\tint j = 0;\n\t\twhile (i < x.length && j < y.length) {\t\n\t\t\tif (x[i] >= y[j]) {\n\t\t\t\tresult = Math.min(result, x[i] - y[j]);\n\t\t\t\tj++;\n\t\t\t} else {\n\t\t\t\tresult = Math.min(result, y[j] - x[i]);\n\t\t\t\ti++;\n\t\t\t}\t\n\t\t}\n\t\treturn result;\n\t}\n\tpublic static void main(String[] args) {\n\t\tint[] x = {1, 3, 5, 7, 9};\n\t\tint[] y = {2, 6, 8};\n\t\tSystem.out.println(minDist(x, y));\n\t}\n}\n```","slug":"两数组最短距离","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mq00i026s6jf6g0xug"},{"title":"vps上部署Hexo","date":"2015-12-11T12:38:09.000Z","_content":"Hexo一般都是部署到github上去，只是我有vps，干吗不用。\n\n对于部署到vps上，本来是想使用Hexo server，然后用Nginx做反向代理。后来想想，这样耗费资源，于是在网上找到[在VPS上部署hexo](http://blog.berry10086.com/Tech/deploy-hexo-to-vps/)，直接将生成的页面给Nginx服务器，既节省资源，访问速度又更快。只是我还是想通过git管理Hexo代码，就像以前写[MV小站](http://lemonbean.info/)那样。可是对于git不熟悉，上次也没有做笔记。于是在网上找到[VPS上(debian8 jessie)部署hexo(Nginx代理+git部署)](http://blog.15-cm.com/2015/06/05/deploy-hexo-on-vps/)，正是我想要的。具体可以参考这篇，这里只记录遇到的问题。\n\n## 设置ssh密钥登陆vps失败\n用ssh-keygen生成密钥之后，将公钥id_rsa.pub的内容复制到vps上的authorized_keys里，一直无法登陆。最后在[linux ssh 使用深度解析（key登录详解）](http://blog.lizhigang.net/archives/249)中找到了解答，原来是authorized_keys文件权限的缘故，这个文件必须设置为600，ssh key登陆才会通过。查看日志文件/var/log/secure可以得道一些帮助。\n\n## git push时无法通过\n在master上执行git config receive.denyCurrentBranch ignore即可。\n\n## Hexo生成的css文件没有更新\n不知道什么情况，有时候有更新，有时候又没有更新。所以干脆先执行hexo clean后再执行hexo g。另外，git hooks很实用。\n\n## 在git仓库里添加hooks\n在.git/hooks目录里，参考post-receive脚本,添加如下内容\n```\nGIT_REPO=/home/dengsl/program/nodejs/blog\n DEPLOY_DIR=/home/dengsl/program/html/blog/note\n\n # Get the latest commit subject\n SUBJECT=$(git log -1 --pretty=format:\"%s\")\n\n cd $GIT_REPO\n env -i git reset --hard\n\n #update or deploy\n IF_DEPLOY=$( echo $SUBJECT | grep 'deploy')\n if [ -z \"$IF_DEPLOY\" ]; then\n     echo >&2 \"Success. Repo update only\"\n     exit 0;\n fi\n\n # Check the deploy dir whether it exists\n if [ ! -d $DEPLOY_DIR ] ; then\n echo >&2 \"fatal: post-receive: DEPLOY_DIR_NOT_EXIST: \\\"$DEPLOY_DIR\\\"\"\n exit 1\n fi\n\n #deploy static site\n hexo clean\n hexo g\n cp -r public/* $DEPLOY_DIR\n```\n\n现在就可以通过git来发布页面，很有意思。\n\n \n","source":"_posts/vps上部署Hexo.md","raw":"title: vps上部署Hexo\ndate: 2015-12-11 20:38:09\ntags: Hexo\ncategories: 软件安装\n---\nHexo一般都是部署到github上去，只是我有vps，干吗不用。\n\n对于部署到vps上，本来是想使用Hexo server，然后用Nginx做反向代理。后来想想，这样耗费资源，于是在网上找到[在VPS上部署hexo](http://blog.berry10086.com/Tech/deploy-hexo-to-vps/)，直接将生成的页面给Nginx服务器，既节省资源，访问速度又更快。只是我还是想通过git管理Hexo代码，就像以前写[MV小站](http://lemonbean.info/)那样。可是对于git不熟悉，上次也没有做笔记。于是在网上找到[VPS上(debian8 jessie)部署hexo(Nginx代理+git部署)](http://blog.15-cm.com/2015/06/05/deploy-hexo-on-vps/)，正是我想要的。具体可以参考这篇，这里只记录遇到的问题。\n\n## 设置ssh密钥登陆vps失败\n用ssh-keygen生成密钥之后，将公钥id_rsa.pub的内容复制到vps上的authorized_keys里，一直无法登陆。最后在[linux ssh 使用深度解析（key登录详解）](http://blog.lizhigang.net/archives/249)中找到了解答，原来是authorized_keys文件权限的缘故，这个文件必须设置为600，ssh key登陆才会通过。查看日志文件/var/log/secure可以得道一些帮助。\n\n## git push时无法通过\n在master上执行git config receive.denyCurrentBranch ignore即可。\n\n## Hexo生成的css文件没有更新\n不知道什么情况，有时候有更新，有时候又没有更新。所以干脆先执行hexo clean后再执行hexo g。另外，git hooks很实用。\n\n## 在git仓库里添加hooks\n在.git/hooks目录里，参考post-receive脚本,添加如下内容\n```\nGIT_REPO=/home/dengsl/program/nodejs/blog\n DEPLOY_DIR=/home/dengsl/program/html/blog/note\n\n # Get the latest commit subject\n SUBJECT=$(git log -1 --pretty=format:\"%s\")\n\n cd $GIT_REPO\n env -i git reset --hard\n\n #update or deploy\n IF_DEPLOY=$( echo $SUBJECT | grep 'deploy')\n if [ -z \"$IF_DEPLOY\" ]; then\n     echo >&2 \"Success. Repo update only\"\n     exit 0;\n fi\n\n # Check the deploy dir whether it exists\n if [ ! -d $DEPLOY_DIR ] ; then\n echo >&2 \"fatal: post-receive: DEPLOY_DIR_NOT_EXIST: \\\"$DEPLOY_DIR\\\"\"\n exit 1\n fi\n\n #deploy static site\n hexo clean\n hexo g\n cp -r public/* $DEPLOY_DIR\n```\n\n现在就可以通过git来发布页面，很有意思。\n\n \n","slug":"vps上部署Hexo","published":1,"updated":"2016-04-04T02:26:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ms00i326s6qdc5ymma"},{"title":"solr非存储字段变成存储字段解决代码","id":"961","date":"2014-11-19T14:22:13.000Z","_content":"\n看来这一段小代码还是有点用的，还是开源出来吧，免得再造轮子。注意，修改时基于Solr1.4,其它版本进行相应修改即可。\n\n主要修改了两个类IndexWriter, SegmentMerger.添加辅助类ByteUtil,TypeUtil，Constant。\n\n修改类IndexWriter:\n在方法private int mergeMiddle(MergePolicy.OneMerge merge)里，\n 将SegmentReader初始化 SegmentReader reader = merge.readers[i] =  readerPool.get(info, merge.mergeDocStores,MERGE_READ_BUFFER_SIZE, -1);\n 修改成\n``` java\n       String temp = System\n               .getProperty(Constant.DOCUMENT_MERGE_OPTION);\n       boolean documentMerge =  temp != null && temp.equals(\"true\") ? true\n               : false;\n       if (documentMerge) {\n           merge.readers[i] = readerPool.get(info, merge.mergeDocStores,\n                   MERGE_READ_BUFFER_SIZE,\n                   IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n       } else {\n           merge.readers[i] = readerPool.get(info, merge.mergeDocStores,\n                   MERGE_READ_BUFFER_SIZE,\n                   -1);\n       }\n       SegmentReader reader = merge.readers[i];\n```\n 这是因为如果需要读FieldCache,则需要加载内存，否则会报错。而readerPool.get这个函数内有这样一个判断\n``` java\n      if (termsIndexDivisor != -1 && !sr.termsIndexLoaded()) {\n         // If this reader was originally opened because we\n         // needed to merge it, we didn't load the terms\n         // index.  But now, if the caller wants the terms\n         // index (eg because it's doing deletes, or an NRT\n         // reader is being opened) we ask the reader to\n         // load its terms index.\n         sr.loadTermsIndex(termsIndexDivisor);\n       }\n```\n    设置第四个参数为IndexReader.DEFAULT_TERMS_INDEX_DIVISOR，SegmentReader就会增加索引\n修改类SegmentMerger:\n在mergeFields函数里,将copyFieldsWithDeletions和copyFieldsNoDeletions增加一个参数 boolean documentMerge\n 参数的值由如下语句得到\n``` java\n String temp = System.getProperty(Constant.DOCUMENT_MERGE_OPTION);\n boolean documentMerge =  temp != null && temp.equals(\"true\") ? true : false;\n```\n\n 函数copyFieldsWithDeletions和copyFieldsNoDeletions是对应的，这里只拿copyFieldsNoDeletions举例。\n 在copyFieldsNoDeletions里，读取FieldCache的主要工作在以下这个判断语句里完成.\n``` java\n           if (documentMerge) {\n               //Update Dengshilong 2014-09-25\n               //here is where  documentMerge and read FieldCache actually do\n               //read fields and types from start parameters\n               //for every field ,read value from FieldCache , \n               //for numerical field use the correspond byte transform method to build a Field\n               String fieldNamesStr = System\n                       .getProperty(Constant.DOCUMENT_MERGE_FIELDS);\n               String typesStr = System\n                       .getProperty(Constant.DOCUMENT_MERGE_TYPES);\n               String[] fieldNames = fieldNamesStr.split(\",\");\n               String[] types = typesStr.split(\",\");\n               for (; docCount < maxDoc; docCount++) {\n                   // NOTE: it's very important to first assign to doc then\n                   // pass it to\n                   // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n                   Document doc = reader.document(docCount,\n                           fieldSelectorMerge);\n                   Map typeMap = TypeUtil.TYPE_MAP;\n                   for (int i = 0; i < fieldNames.length; i++) {\n                       String fieldName = fieldNames[i];\n                       String type = types[i];\n                       Fieldable field = (Fieldable) doc\n                               .getFieldable(fieldName);\n                       if (field == null) {\n                           Types t = (Types) TypeUtil.TYPE_MAP.get(type);\n                           switch(t) {\n                           case INTEGER:\n                               int[] vi = FieldCache.DEFAULT.getInts(reader, fieldName);\n                               Field fi = new Field(fieldName, ByteUtil.toArr(vi[docCount]), Store.YES);\n                               doc.add(fi);\n                               break;\n                           case LONG:\n                               long[] vl = FieldCache.DEFAULT.getLongs(reader, fieldName);\n                               Field fl = new Field(fieldName, ByteUtil.toArr(vl[docCount]), Store.YES);\n                               doc.add(fl);\n                               break;\n                           case FLOAT:\n                               float[] vf = FieldCache.DEFAULT.getFloats(reader, fieldName);\n                               Field ff = new Field(fieldName, ByteUtil.toArr(vf[docCount]), Store.YES);\n                               doc.add(ff);\n                               break;\n                           case DOUBLE:\n                               double[] vd = FieldCache.DEFAULT.getDoubles(reader, fieldName);\n                               Field fd = new Field(fieldName, ByteUtil.toArr(vd[docCount]), Store.YES);\n                               doc.add(fd);\n                               break; \n                           }\n                       } else {\n                           continue;\n                       }    \n                   }\n\n                   fieldsWriter.addDocument(doc);\n                   checkAbort.work(300); \n               }\n           }\n```\n增加类ByteUtil用于int,double等数值型转化为byte[]数组;\n``` java\npackage org.apache.lucene.util;\n//The transform method is copy from TrieField.java\npublic class ByteUtil {\n    public static int toInt(byte[] arr) {\n        return (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n    }\n\n    public static long toLong(byte[] arr) {\n        int high = (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n        int low = (arr[4] << 24) | ((arr[5] & 0xff) << 16)\n                | ((arr[6] & 0xff) << 8) | (arr[7] & 0xff);\n        return (((long) high) << 32) | (low & 0x0ffffffffL);\n    }\n    public static float toFloat(byte[] arr) {\n        return Float.intBitsToFloat(toInt(arr));\n    }\n    public static double toDouble(byte[] arr) {\n        return Double.longBitsToDouble(toLong(arr));\n    }\n\n    public static byte[] toArr(int val) {\n        byte[] arr = new byte[4];\n        arr[0] = (byte) (val >>> 24);\n        arr[1] = (byte) (val >>> 16);\n        arr[2] = (byte) (val >>> 8);\n        arr[3] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(long val) {\n        byte[] arr = new byte[8];\n        arr[0] = (byte) (val >>> 56);\n        arr[1] = (byte) (val >>> 48);\n        arr[2] = (byte) (val >>> 40);\n        arr[3] = (byte) (val >>> 32);\n        arr[4] = (byte) (val >>> 24);\n        arr[5] = (byte) (val >>> 16);\n        arr[6] = (byte) (val >>> 8);\n        arr[7] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(float val) {\n        return toArr(Float.floatToRawIntBits(val));\n    }\n\n    public static byte[] toArr(double val) {\n        return toArr(Double.doubleToRawLongBits(val));\n    }\n}\n```\n增加类TypesUtil，定义了INTEGER等类型常量\n``` java\npackage org.apache.lucene.util;\nimport java.util.HashMap;\nimport java.util.Map;\n//the types is copy form TrieField.java\npublic class TypeUtil {\n    public enum Types {\n        INTEGER,\n        LONG,\n        FLOAT,\n        DOUBLE,\n   }\n   public final static Map TYPE_MAP = new HashMap() { {    \n        put(\"int\", Types.INTEGER);    \n        put(\"tint\", Types.INTEGER);\n        put(\"long\", Types.LONG); \n        put(\"tlong\", Types.LONG);\n        put(\"float\", Types.FLOAT);\n        put(\"tfloat\", Types.FLOAT);\n        put(\"double\", Types.DOUBLE);\n        put(\"tdouble\", Types.DOUBLE);\n   }}; \n}\n```\n增加类Constant,定义了三个常量\n``` java\npackage org.apache.lucene.util;\npublic class Constant {\n  //add for documentMerge\n  public final static String DOCUMENT_MERGE_OPTION = \"search.index.documentMerge\";\n  public final static String DOCUMENT_MERGE_FIELDS = \"search.index.documentMerge.fields\";\n  public final static String DOCUMENT_MERGE_TYPES = \"search.index.documentMerge.types\";\n}\n```\n使用：\n在solr启动脚本中,添加如下参数\nsearch.index.documentMerge 为true时表示开启强制文档合并,其它值时表示不开启\nsearch.index.documentMerge.fields 需要读取的字段，字段之间用逗号隔开\nsearch.index.documentMerge.types 读取字段的类型,类型间用逗号隔开,这里的类型要与上面的字段一一对应起来\n举个例子：\n\n要对PublishTime,ContentLength进行读取,而它们的字段类型分别为tint,int于是添加如下参数\n-Dsearch.index.documentMerge=true -Dsearch.index.documentMerge.fields=PublishTim,ContentLength\n -Dsearch.index.documentMerge.types=tint,int","source":"_posts/solr非存储字段变成存储字段解决代码.md","raw":"title: solr非存储字段变成存储字段解决代码\ntags:\n  - fieldcache\n  - solr\nid: 961\ncategories:\n  - 搜索引擎\ndate: 2014-11-19 22:22:13\n---\n\n看来这一段小代码还是有点用的，还是开源出来吧，免得再造轮子。注意，修改时基于Solr1.4,其它版本进行相应修改即可。\n\n主要修改了两个类IndexWriter, SegmentMerger.添加辅助类ByteUtil,TypeUtil，Constant。\n\n修改类IndexWriter:\n在方法private int mergeMiddle(MergePolicy.OneMerge merge)里，\n 将SegmentReader初始化 SegmentReader reader = merge.readers[i] =  readerPool.get(info, merge.mergeDocStores,MERGE_READ_BUFFER_SIZE, -1);\n 修改成\n``` java\n       String temp = System\n               .getProperty(Constant.DOCUMENT_MERGE_OPTION);\n       boolean documentMerge =  temp != null && temp.equals(\"true\") ? true\n               : false;\n       if (documentMerge) {\n           merge.readers[i] = readerPool.get(info, merge.mergeDocStores,\n                   MERGE_READ_BUFFER_SIZE,\n                   IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);\n       } else {\n           merge.readers[i] = readerPool.get(info, merge.mergeDocStores,\n                   MERGE_READ_BUFFER_SIZE,\n                   -1);\n       }\n       SegmentReader reader = merge.readers[i];\n```\n 这是因为如果需要读FieldCache,则需要加载内存，否则会报错。而readerPool.get这个函数内有这样一个判断\n``` java\n      if (termsIndexDivisor != -1 && !sr.termsIndexLoaded()) {\n         // If this reader was originally opened because we\n         // needed to merge it, we didn't load the terms\n         // index.  But now, if the caller wants the terms\n         // index (eg because it's doing deletes, or an NRT\n         // reader is being opened) we ask the reader to\n         // load its terms index.\n         sr.loadTermsIndex(termsIndexDivisor);\n       }\n```\n    设置第四个参数为IndexReader.DEFAULT_TERMS_INDEX_DIVISOR，SegmentReader就会增加索引\n修改类SegmentMerger:\n在mergeFields函数里,将copyFieldsWithDeletions和copyFieldsNoDeletions增加一个参数 boolean documentMerge\n 参数的值由如下语句得到\n``` java\n String temp = System.getProperty(Constant.DOCUMENT_MERGE_OPTION);\n boolean documentMerge =  temp != null && temp.equals(\"true\") ? true : false;\n```\n\n 函数copyFieldsWithDeletions和copyFieldsNoDeletions是对应的，这里只拿copyFieldsNoDeletions举例。\n 在copyFieldsNoDeletions里，读取FieldCache的主要工作在以下这个判断语句里完成.\n``` java\n           if (documentMerge) {\n               //Update Dengshilong 2014-09-25\n               //here is where  documentMerge and read FieldCache actually do\n               //read fields and types from start parameters\n               //for every field ,read value from FieldCache , \n               //for numerical field use the correspond byte transform method to build a Field\n               String fieldNamesStr = System\n                       .getProperty(Constant.DOCUMENT_MERGE_FIELDS);\n               String typesStr = System\n                       .getProperty(Constant.DOCUMENT_MERGE_TYPES);\n               String[] fieldNames = fieldNamesStr.split(\",\");\n               String[] types = typesStr.split(\",\");\n               for (; docCount < maxDoc; docCount++) {\n                   // NOTE: it's very important to first assign to doc then\n                   // pass it to\n                   // termVectorsWriter.addAllDocVectors; see LUCENE-1282\n                   Document doc = reader.document(docCount,\n                           fieldSelectorMerge);\n                   Map typeMap = TypeUtil.TYPE_MAP;\n                   for (int i = 0; i < fieldNames.length; i++) {\n                       String fieldName = fieldNames[i];\n                       String type = types[i];\n                       Fieldable field = (Fieldable) doc\n                               .getFieldable(fieldName);\n                       if (field == null) {\n                           Types t = (Types) TypeUtil.TYPE_MAP.get(type);\n                           switch(t) {\n                           case INTEGER:\n                               int[] vi = FieldCache.DEFAULT.getInts(reader, fieldName);\n                               Field fi = new Field(fieldName, ByteUtil.toArr(vi[docCount]), Store.YES);\n                               doc.add(fi);\n                               break;\n                           case LONG:\n                               long[] vl = FieldCache.DEFAULT.getLongs(reader, fieldName);\n                               Field fl = new Field(fieldName, ByteUtil.toArr(vl[docCount]), Store.YES);\n                               doc.add(fl);\n                               break;\n                           case FLOAT:\n                               float[] vf = FieldCache.DEFAULT.getFloats(reader, fieldName);\n                               Field ff = new Field(fieldName, ByteUtil.toArr(vf[docCount]), Store.YES);\n                               doc.add(ff);\n                               break;\n                           case DOUBLE:\n                               double[] vd = FieldCache.DEFAULT.getDoubles(reader, fieldName);\n                               Field fd = new Field(fieldName, ByteUtil.toArr(vd[docCount]), Store.YES);\n                               doc.add(fd);\n                               break; \n                           }\n                       } else {\n                           continue;\n                       }    \n                   }\n\n                   fieldsWriter.addDocument(doc);\n                   checkAbort.work(300); \n               }\n           }\n```\n增加类ByteUtil用于int,double等数值型转化为byte[]数组;\n``` java\npackage org.apache.lucene.util;\n//The transform method is copy from TrieField.java\npublic class ByteUtil {\n    public static int toInt(byte[] arr) {\n        return (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n    }\n\n    public static long toLong(byte[] arr) {\n        int high = (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n        int low = (arr[4] << 24) | ((arr[5] & 0xff) << 16)\n                | ((arr[6] & 0xff) << 8) | (arr[7] & 0xff);\n        return (((long) high) << 32) | (low & 0x0ffffffffL);\n    }\n    public static float toFloat(byte[] arr) {\n        return Float.intBitsToFloat(toInt(arr));\n    }\n    public static double toDouble(byte[] arr) {\n        return Double.longBitsToDouble(toLong(arr));\n    }\n\n    public static byte[] toArr(int val) {\n        byte[] arr = new byte[4];\n        arr[0] = (byte) (val >>> 24);\n        arr[1] = (byte) (val >>> 16);\n        arr[2] = (byte) (val >>> 8);\n        arr[3] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(long val) {\n        byte[] arr = new byte[8];\n        arr[0] = (byte) (val >>> 56);\n        arr[1] = (byte) (val >>> 48);\n        arr[2] = (byte) (val >>> 40);\n        arr[3] = (byte) (val >>> 32);\n        arr[4] = (byte) (val >>> 24);\n        arr[5] = (byte) (val >>> 16);\n        arr[6] = (byte) (val >>> 8);\n        arr[7] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(float val) {\n        return toArr(Float.floatToRawIntBits(val));\n    }\n\n    public static byte[] toArr(double val) {\n        return toArr(Double.doubleToRawLongBits(val));\n    }\n}\n```\n增加类TypesUtil，定义了INTEGER等类型常量\n``` java\npackage org.apache.lucene.util;\nimport java.util.HashMap;\nimport java.util.Map;\n//the types is copy form TrieField.java\npublic class TypeUtil {\n    public enum Types {\n        INTEGER,\n        LONG,\n        FLOAT,\n        DOUBLE,\n   }\n   public final static Map TYPE_MAP = new HashMap() { {    \n        put(\"int\", Types.INTEGER);    \n        put(\"tint\", Types.INTEGER);\n        put(\"long\", Types.LONG); \n        put(\"tlong\", Types.LONG);\n        put(\"float\", Types.FLOAT);\n        put(\"tfloat\", Types.FLOAT);\n        put(\"double\", Types.DOUBLE);\n        put(\"tdouble\", Types.DOUBLE);\n   }}; \n}\n```\n增加类Constant,定义了三个常量\n``` java\npackage org.apache.lucene.util;\npublic class Constant {\n  //add for documentMerge\n  public final static String DOCUMENT_MERGE_OPTION = \"search.index.documentMerge\";\n  public final static String DOCUMENT_MERGE_FIELDS = \"search.index.documentMerge.fields\";\n  public final static String DOCUMENT_MERGE_TYPES = \"search.index.documentMerge.types\";\n}\n```\n使用：\n在solr启动脚本中,添加如下参数\nsearch.index.documentMerge 为true时表示开启强制文档合并,其它值时表示不开启\nsearch.index.documentMerge.fields 需要读取的字段，字段之间用逗号隔开\nsearch.index.documentMerge.types 读取字段的类型,类型间用逗号隔开,这里的类型要与上面的字段一一对应起来\n举个例子：\n\n要对PublishTime,ContentLength进行读取,而它们的字段类型分别为tint,int于是添加如下参数\n-Dsearch.index.documentMerge=true -Dsearch.index.documentMerge.fields=PublishTim,ContentLength\n -Dsearch.index.documentMerge.types=tint,int","slug":"solr非存储字段变成存储字段解决代码","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4mv00i726s6wh9k1s5z"},{"title":"solr非存储字段变成存储字段","id":"917","date":"2014-09-25T15:01:28.000Z","_content":"\n试想这样一种情形，一个publish_time，原先是只索引不保存，运行了很长一段时间后，发现需要返回这个字段，于是改成既索引又保存。这样新进来的数据就可以返回这个字段的值，可是原先保存的数据将无法返回这个字段的值，因为没有保存。那如何解决这个问题？\n\n一个解决的办法是将数据重新跑一遍，重建索引，这样所有的数据都可以返回publish_time这个字段。想想还有没有其它办法，看到建了索引，这样还是有办法可以拿到数据，一个解决的办法是读fiedcache. 索引加载时，会在fieldcache里记录字段信息，这样可以提高字段查询的速度。事实上，在上述例子中，进行publish_time字段查询时，就可以拿到所有数据的publish_time字段信息,而这些信息就是来自于fieldcache.\n\n于是找到了一个切入点，在进行段合并时，将之前没有保存的字段信息从fieldcache中读出，写到新的段中，这样新生成的段中,所有数据都会有publish_time字段信息。\n\n于是问题的关键就变成了如何处理在段合并时，读取fieldcache信息，并且增加到新段中.从《Lucene原理与代码分析》中可以知道，段合并主要是在SegmentMerger中完成,具体是在copyFieldsWithDeletions和copyFieldsNoDeletions中。看名字就可以知道这两个函数是对应的，所以只要讨论其中一个就行了。在合并时主要分两种情况，一种是合并的段所有字段的顺序和个数都是一样的，这样只要将段数据复制到新段中即可，另一种则需要像添加一篇新文档一样将段中的文档一篇篇添加，具体体现就在fieldsWriter.addDocument(doc);这句。\n\n对于后一情况，需要从fieldcache中读取之前没有保存的字段，如FieldCache.DEFAULT.getInts(reader, fieldName)，这里的reader是一个SegmentReader实例, fieldName则是字段名,这样就可以得到字段的值,。而文档已经由Document doc = reader.document(docCount,  fieldSelectorMerge)读出，之后构建一个Field将它添加到文档中，并将文档添加到段中即可.\n\n需要注意的是,reader一定要加载索引，否则会报，terms index was not loaded when this reader was created错误.\n\n还有就是,对于int,double等数值型数据,需要调用Field(String name, byte[] value)方法，也就是先将int,double等转化成byte[]数组，之后再构建。具体转化方法参见[int,double等转化成byte数组](http://program.dengshilong.org/2014/09/24/intdouble%E7%AD%89%E8%BD%AC%E5%8C%96%E6%88%90byte%E6%95%B0%E7%BB%84/).","source":"_posts/solr非存储字段变成存储字段.md","raw":"title: solr非存储字段变成存储字段\ntags:\n  - fieldcache\n  - solr\n  - 段合并\nid: 917\ncategories:\n  - 搜索引擎\ndate: 2014-09-25 23:01:28\n---\n\n试想这样一种情形，一个publish_time，原先是只索引不保存，运行了很长一段时间后，发现需要返回这个字段，于是改成既索引又保存。这样新进来的数据就可以返回这个字段的值，可是原先保存的数据将无法返回这个字段的值，因为没有保存。那如何解决这个问题？\n\n一个解决的办法是将数据重新跑一遍，重建索引，这样所有的数据都可以返回publish_time这个字段。想想还有没有其它办法，看到建了索引，这样还是有办法可以拿到数据，一个解决的办法是读fiedcache. 索引加载时，会在fieldcache里记录字段信息，这样可以提高字段查询的速度。事实上，在上述例子中，进行publish_time字段查询时，就可以拿到所有数据的publish_time字段信息,而这些信息就是来自于fieldcache.\n\n于是找到了一个切入点，在进行段合并时，将之前没有保存的字段信息从fieldcache中读出，写到新的段中，这样新生成的段中,所有数据都会有publish_time字段信息。\n\n于是问题的关键就变成了如何处理在段合并时，读取fieldcache信息，并且增加到新段中.从《Lucene原理与代码分析》中可以知道，段合并主要是在SegmentMerger中完成,具体是在copyFieldsWithDeletions和copyFieldsNoDeletions中。看名字就可以知道这两个函数是对应的，所以只要讨论其中一个就行了。在合并时主要分两种情况，一种是合并的段所有字段的顺序和个数都是一样的，这样只要将段数据复制到新段中即可，另一种则需要像添加一篇新文档一样将段中的文档一篇篇添加，具体体现就在fieldsWriter.addDocument(doc);这句。\n\n对于后一情况，需要从fieldcache中读取之前没有保存的字段，如FieldCache.DEFAULT.getInts(reader, fieldName)，这里的reader是一个SegmentReader实例, fieldName则是字段名,这样就可以得到字段的值,。而文档已经由Document doc = reader.document(docCount,  fieldSelectorMerge)读出，之后构建一个Field将它添加到文档中，并将文档添加到段中即可.\n\n需要注意的是,reader一定要加载索引，否则会报，terms index was not loaded when this reader was created错误.\n\n还有就是,对于int,double等数值型数据,需要调用Field(String name, byte[] value)方法，也就是先将int,double等转化成byte[]数组，之后再构建。具体转化方法参见[int,double等转化成byte数组](http://program.dengshilong.org/2014/09/24/intdouble%E7%AD%89%E8%BD%AC%E5%8C%96%E6%88%90byte%E6%95%B0%E7%BB%84/).","slug":"solr非存储字段变成存储字段","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4my00id26s6fhufzqkc"},{"title":"solr分布式搜索时设置分页的一个错误 ","id":"905","date":"2014-09-19T13:16:58.000Z","_content":"\n最近在做一个站内搜索功能,有用到一个分页功能.搜索时会传两个参数pageId和pageSize 用来指定页号与每页的条数.solr已经提供了start和rows两个参数,于是将分页参数与之对应起来,在component初始化时写了如下代码:\n``` java\nString pidStr = req.getParams().get(PAGE_ID);\nif ( pidStr != null ) { \n      int pageId = req.getParams().getInt(PAGE_ID, 0);\n      int pageSize = req.getParams().getInt(PAGE_SIZE, 10);\n      pageId = (pageId > -1) ? pageId : 0; \n      pageSize = (pageSize > 0 ) ? pageSize : 10; \n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(CommonParams.START, pageId * pageSize);\n      params.set(CommonParams.ROWS, pageSize);\n      params.set(CommonParams.WT, \"json\");\n      params.set(CommonParams.OMIT_HEADER, \"true\");\n      req.setParams(params);\n}\n```\n可是一直得不到正确的结果，在后台输出日志,发现start和rows在设置了上面的值后，start和rows会用来构建新的查询,在新的查询中start会变为0,而rows会变成start与rows的和，可是之后start和rows又会变成原先的值，于是得不到想要的结果。\n\n举个例子,假设要搜第三页,每页10条,则可设置pageId为2,pageSize为10,于是start被设置成20,rows被设置成10,之后start和rows会被用于生成向shard发送的请求,start被设置为0,rows设置为30.问题在于这个请求发出之后start的值又变成了20,rows变成了10,百思不得其解.\n\n跟踪代码到createMainQuery函数,看到如下代码：\n``` java\nif (rb.shards_start > -1) {\n    // if the client set shards.start set this explicitly\n    sreq.params.set(CommonParams.START, rb.shards_start);\n} else {\n    sreq.params.set(CommonParams.START, \"0\");\n}\nif (rb.shards_rows > -1) {\n    // if the client set shards.rows set this explicity\n    sreq.params.set(CommonParams.ROWS, rb.shards_rows);\n} else {\n    sreq.params.set(CommonParams.ROWS, rb.getSortSpec().getOffset()\n            + rb.getSortSpec().getCount());\n}\n```\n打印日志rb.shards_start与rb.shards_rows都为-1,于是start变为0,row变成30,这是正确的,那么关键点就是要找出start和rows何时变成20与10，跟踪程序找不到原因。看后台日志,发现初始化每次都会执行两次,然后想到分布式，才渐渐明白问题的原因.\n\n在一次分布式查询中,solr的leader会接受请求，然后对请求进行解析，之后重新构建请求，将新的请求发给各个Shard,Shard做非分布式查询之后,将结果发给leader,之后leader汇总各个Shard的响应,进行最后的处理(如做offset等),问题是leader和Shard都是同一份代码,而且初始化部分每个Shard接收leader的请求后都要执行,于是start和rows又被重新设置了.在上面的例子中,start和rows在Shard中分别被设置成20和10了,只会Shard做非分布式查询,这样Shard只会返回10条数据给leader，这显然不是想要的.\n\n之后发现,在leader构建的新的请求中,会添加isShard=true参数,于是可以修改代码如下:\n``` java\nboolean isShard = req.getParams().getBool(ShardParams.IS_SHARD, false);\nif ( pidStr != null && !isShard) { //分布式时，只有leader才需要执行这里\n```\n之后结果就是正确的。到这里，才有点明白分布式程序，真不好写.","source":"_posts/solr分布式搜索时设置分页的一个错误.md","raw":"title: 'solr分布式搜索时设置分页的一个错误 '\ntags:\n  - solr\n  - 分布式\n  - 分页\nid: 905\ncategories:\n  - 搜索引擎\ndate: 2014-09-19 21:16:58\n---\n\n最近在做一个站内搜索功能,有用到一个分页功能.搜索时会传两个参数pageId和pageSize 用来指定页号与每页的条数.solr已经提供了start和rows两个参数,于是将分页参数与之对应起来,在component初始化时写了如下代码:\n``` java\nString pidStr = req.getParams().get(PAGE_ID);\nif ( pidStr != null ) { \n      int pageId = req.getParams().getInt(PAGE_ID, 0);\n      int pageSize = req.getParams().getInt(PAGE_SIZE, 10);\n      pageId = (pageId > -1) ? pageId : 0; \n      pageSize = (pageSize > 0 ) ? pageSize : 10; \n      ModifiableSolrParams params = new ModifiableSolrParams(req.getParams());\n      params.set(CommonParams.START, pageId * pageSize);\n      params.set(CommonParams.ROWS, pageSize);\n      params.set(CommonParams.WT, \"json\");\n      params.set(CommonParams.OMIT_HEADER, \"true\");\n      req.setParams(params);\n}\n```\n可是一直得不到正确的结果，在后台输出日志,发现start和rows在设置了上面的值后，start和rows会用来构建新的查询,在新的查询中start会变为0,而rows会变成start与rows的和，可是之后start和rows又会变成原先的值，于是得不到想要的结果。\n\n举个例子,假设要搜第三页,每页10条,则可设置pageId为2,pageSize为10,于是start被设置成20,rows被设置成10,之后start和rows会被用于生成向shard发送的请求,start被设置为0,rows设置为30.问题在于这个请求发出之后start的值又变成了20,rows变成了10,百思不得其解.\n\n跟踪代码到createMainQuery函数,看到如下代码：\n``` java\nif (rb.shards_start > -1) {\n    // if the client set shards.start set this explicitly\n    sreq.params.set(CommonParams.START, rb.shards_start);\n} else {\n    sreq.params.set(CommonParams.START, \"0\");\n}\nif (rb.shards_rows > -1) {\n    // if the client set shards.rows set this explicity\n    sreq.params.set(CommonParams.ROWS, rb.shards_rows);\n} else {\n    sreq.params.set(CommonParams.ROWS, rb.getSortSpec().getOffset()\n            + rb.getSortSpec().getCount());\n}\n```\n打印日志rb.shards_start与rb.shards_rows都为-1,于是start变为0,row变成30,这是正确的,那么关键点就是要找出start和rows何时变成20与10，跟踪程序找不到原因。看后台日志,发现初始化每次都会执行两次,然后想到分布式，才渐渐明白问题的原因.\n\n在一次分布式查询中,solr的leader会接受请求，然后对请求进行解析，之后重新构建请求，将新的请求发给各个Shard,Shard做非分布式查询之后,将结果发给leader,之后leader汇总各个Shard的响应,进行最后的处理(如做offset等),问题是leader和Shard都是同一份代码,而且初始化部分每个Shard接收leader的请求后都要执行,于是start和rows又被重新设置了.在上面的例子中,start和rows在Shard中分别被设置成20和10了,只会Shard做非分布式查询,这样Shard只会返回10条数据给leader，这显然不是想要的.\n\n之后发现,在leader构建的新的请求中,会添加isShard=true参数,于是可以修改代码如下:\n``` java\nboolean isShard = req.getParams().getBool(ShardParams.IS_SHARD, false);\nif ( pidStr != null && !isShard) { //分布式时，只有leader才需要执行这里\n```\n之后结果就是正确的。到这里，才有点明白分布式程序，真不好写.","slug":"solr分布式搜索时设置分页的一个错误","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4n100ij26s6p77n7hpq"},{"title":"smarty使用的注意点","id":"727","date":"2014-05-15T14:09:11.000Z","_content":"\n因为不会写MVC，所以只好使用模版，而在PHP中，一般使用Smarty.以下是自己在使用过程中，遇到的一些问题，以及需要注意的地方。\n1.一般评论都是通过一个textarea输入，在显示的时候需要将换行幅\\n替换成标签,当尝试使用replace : '\\n' : '\n''时，一直不可行，后来才知道，原来有nl2br这个函数。\n\n2.对于使用addslashes过滤的内容，则需要使用stripslashes将添加的\\去掉。\n\n{% raw %}\n3.对于left_delimiter和right_delimiter的选择，我的经验是{{和}}比较好，对于<{和}>最好不用，否则会遇到很多问题。使用判断语句如{{if}} {{elseif}} {{else}} {{/if}}时，千万不能在{{和关键字中留出空格，否则会出错。如写成{{ /if }} {{ else }}这些都会出错.\n{% endraw %}\n","source":"_posts/smarty使用的注意点.md","raw":"title: smarty使用的注意点\ntags:\n  - smarty\n  - 换行\nid: 727\ncategories:\n  - PHP\ndate: 2014-05-15 22:09:11\n---\n\n因为不会写MVC，所以只好使用模版，而在PHP中，一般使用Smarty.以下是自己在使用过程中，遇到的一些问题，以及需要注意的地方。\n1.一般评论都是通过一个textarea输入，在显示的时候需要将换行幅\\n替换成标签,当尝试使用replace : '\\n' : '\n''时，一直不可行，后来才知道，原来有nl2br这个函数。\n\n2.对于使用addslashes过滤的内容，则需要使用stripslashes将添加的\\去掉。\n\n{% raw %}\n3.对于left_delimiter和right_delimiter的选择，我的经验是{{和}}比较好，对于<{和}>最好不用，否则会遇到很多问题。使用判断语句如{{if}} {{elseif}} {{else}} {{/if}}时，千万不能在{{和关键字中留出空格，否则会出错。如写成{{ /if }} {{ else }}这些都会出错.\n{% endraw %}\n","slug":"smarty使用的注意点","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4n400iq26s6zwbowo4z"},{"title":"shell的一些特殊变量","id":"707","date":"2014-04-27T14:44:43.000Z","_content":"\n有些时候，想让脚步运行在后台中，而且只存在一个这样的脚步，这时一种可行的方法是将脚步的运行的进程ID写在一个文件中，当再次运行这个脚步时，去读取这个文件，读出ID，如果这个ID有进程在运行，就退出。这时需要知道进程ID，而在shell中，它是一个特殊变量，也就是$$.当运行shell脚步时，$$就是输出进程ID。\n\n而有些时候，在shell中会编写一些函数，并返回结果，这是需要一个变量保存函数运行结果。这个变量就是$?.\n\n而又有些时候，在shell中想知道运行脚步的名字，这个变量就是$0.\n\n还有许多很有用的特殊变量，只是我不知道还有哪些。google之后可以知道，只是很好奇的是，这些人是怎么知道这些变量的呢？\n","source":"_posts/shell的一些特殊变量.md","raw":"title: shell的一些特殊变量\ntags:\n  - shell\nid: 707\ncategories:\n  - shell\ndate: 2014-04-27 22:44:43\n---\n\n有些时候，想让脚步运行在后台中，而且只存在一个这样的脚步，这时一种可行的方法是将脚步的运行的进程ID写在一个文件中，当再次运行这个脚步时，去读取这个文件，读出ID，如果这个ID有进程在运行，就退出。这时需要知道进程ID，而在shell中，它是一个特殊变量，也就是$$.当运行shell脚步时，$$就是输出进程ID。\n\n而有些时候，在shell中会编写一些函数，并返回结果，这是需要一个变量保存函数运行结果。这个变量就是$?.\n\n而又有些时候，在shell中想知道运行脚步的名字，这个变量就是$0.\n\n还有许多很有用的特殊变量，只是我不知道还有哪些。google之后可以知道，只是很好奇的是，这些人是怎么知道这些变量的呢？\n","slug":"shell的一些特殊变量","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4n700ix26s65ack2bj5"},{"title":"sed替换文件内容","id":"752","date":"2014-05-27T05:55:14.000Z","_content":"\n使用sed -i 's/text/test/' *.sh将当前目录下(不包括子目录)，所有shell脚本的text替换为test, 其中-i参数是指示需要进行文件内替换，也就是改变文件的内容。\n\n如果需要将子目录的也替换，则可以与find命令结合使用,使用find . -name \"*.sh\" | xargs sed -i 's/text/test/'  将当前目录下(包括子目录)，所有shell脚本的text替换为test,\n","source":"_posts/sed替换文件内容.md","raw":"title: sed替换文件内容\ntags:\n  - find\n  - sed\n  - 子目录\nid: 752\ncategories:\n  - shell\ndate: 2014-05-27 13:55:14\n---\n\n使用sed -i 's/text/test/' *.sh将当前目录下(不包括子目录)，所有shell脚本的text替换为test, 其中-i参数是指示需要进行文件内替换，也就是改变文件的内容。\n\n如果需要将子目录的也替换，则可以与find命令结合使用,使用find . -name \"*.sh\" | xargs sed -i 's/text/test/'  将当前目录下(包括子目录)，所有shell脚本的text替换为test,\n","slug":"sed替换文件内容","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4nb00j126s68v6ogdl4"},{"title":"mysqli_fetch_all函数","id":"681","date":"2014-04-13T13:15:45.000Z","_content":"\n许多情况下，都需要将mysql的查询结果转成一个数组，这个就可以遍历数组来显示，查询结果。在我的开发环境里，我使用mysqli_fetch_all函数,使用方法如下\n\n``` php\n$result = mysqli_query($con, $sql);\n$posts =  mysqli_fetch_all($result, MYSQLI_ASSOC);\n```\n\n加上MYSQLI_ASSOC是为了使返回的是关联数组,之后就可以遍历$posts数组。当将这段代码放到线上环境时，发现没有结果，最后才知道原来是mysqli_fetch_all函数无法使用。 google之后才知道,mysqli_fetch_all这个函数只存在于mysqlnd中，也就是PHP的原生MySQL驱动中。原来链接MySQL存在两套驱动,一套是libmysql,一套是mysqlnd。本来mysqlnd是不存在的,后来因为mysql到了Oracle手上之后,驱动的认证就有些问题了,于是PHP开发组自己开发了一套mysql驱动。\n\n可是在linux下，安装mysqli时还是默认使用libmysql，所以要么就得重新安装mysqli模块,使用mysqlnd驱动安装，或者自己来实现mysqli_fetch_all的功能。暂时先自己实现类似的功能。\n``` php\n$result = mysqli_query($con, $sql);\n$posts = array();\nwhile($row = mysqli_fetch_array($result)) {\n    $posts[] = $row;\n}\n```\n\n","source":"_posts/mysqli_fetch_all函数.md","raw":"title: mysqli_fetch_all函数\ntags:\n  - mysqli\n  - mysqli_fetch_all\n  - mysqlnd\nid: 681\ncategories:\n  - PHP\ndate: 2014-04-13 21:15:45\n---\n\n许多情况下，都需要将mysql的查询结果转成一个数组，这个就可以遍历数组来显示，查询结果。在我的开发环境里，我使用mysqli_fetch_all函数,使用方法如下\n\n``` php\n$result = mysqli_query($con, $sql);\n$posts =  mysqli_fetch_all($result, MYSQLI_ASSOC);\n```\n\n加上MYSQLI_ASSOC是为了使返回的是关联数组,之后就可以遍历$posts数组。当将这段代码放到线上环境时，发现没有结果，最后才知道原来是mysqli_fetch_all函数无法使用。 google之后才知道,mysqli_fetch_all这个函数只存在于mysqlnd中，也就是PHP的原生MySQL驱动中。原来链接MySQL存在两套驱动,一套是libmysql,一套是mysqlnd。本来mysqlnd是不存在的,后来因为mysql到了Oracle手上之后,驱动的认证就有些问题了,于是PHP开发组自己开发了一套mysql驱动。\n\n可是在linux下，安装mysqli时还是默认使用libmysql，所以要么就得重新安装mysqli模块,使用mysqlnd驱动安装，或者自己来实现mysqli_fetch_all的功能。暂时先自己实现类似的功能。\n``` php\n$result = mysqli_query($con, $sql);\n$posts = array();\nwhile($row = mysqli_fetch_array($result)) {\n    $posts[] = $row;\n}\n```\n\n","slug":"mysqli_fetch_all函数","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ng00j926s6qrjirv0r"},{"title":"junit找不到方法","id":"977","date":"2014-12-13T03:39:20.000Z","_content":"\n最近迷上了单元测试，在写单元测试时，提示一下错误：\njava.lang.NoSuchMethodError: junit.framework.ComparisonFailure.getExpected()Ljava/lang/String;\n\n莫名其妙的，assertFalse怎么可能没有。后来才知道，原来是版本冲突了，因为添加了好多个junit的jar本，而Eclipse只找到最低版本的，将一些低版本的jar去掉就好了。\n\n添加jar这个问题真是蛋疼，在Eclipse里对引用的jar一个目录一个目录的添加，还要肉眼去把低版本的删除，真是麻烦。","source":"_posts/junit找不到方法.md","raw":"title: junit找不到方法\ntags:\n  - junit\nid: 977\ncategories:\n  - Java\ndate: 2014-12-13 11:39:20\n---\n\n最近迷上了单元测试，在写单元测试时，提示一下错误：\njava.lang.NoSuchMethodError: junit.framework.ComparisonFailure.getExpected()Ljava/lang/String;\n\n莫名其妙的，assertFalse怎么可能没有。后来才知道，原来是版本冲突了，因为添加了好多个junit的jar本，而Eclipse只找到最低版本的，将一些低版本的jar去掉就好了。\n\n添加jar这个问题真是蛋疼，在Eclipse里对引用的jar一个目录一个目录的添加，还要肉眼去把低版本的删除，真是麻烦。","slug":"junit找不到方法","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4nk00jh26s6zz5fd8p0"},{"title":"int,double等转化成byte数组","id":"913","date":"2014-09-24T14:23:09.000Z","_content":"\n最近需要用到这个功能，本来想自己写，怕写错了，上网找了一下，都没找到合适的。看了solr与源码中的TrieField.java,有这一部分的代码，copy到这里。\n``` java\npublic class ByteUtil {\n    public static int toInt(byte[] arr) {\n        return (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n    }\n\n    public static long toLong(byte[] arr) {\n        int high = (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n        int low = (arr[4] << 24) | ((arr[5] & 0xff) << 16)\n                | ((arr[6] & 0xff) << 8) | (arr[7] & 0xff);\n        return (((long) high) << 32) | (low & 0x0ffffffffL);\n    }\n\n    public static float toFloat(byte[] arr) {\n        return Float.intBitsToFloat(toInt(arr));\n    }\n\n    public static double toDouble(byte[] arr) {\n        return Double.longBitsToDouble(toLong(arr));\n    }\n\n    public static byte[] toArr(int val) {\n        byte[] arr = new byte[4];\n        arr[0] = (byte) (val >>> 24);\n        arr[1] = (byte) (val >>> 16);\n        arr[2] = (byte) (val >>> 8);\n        arr[3] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(long val) {\n        byte[] arr = new byte[8];\n        arr[0] = (byte) (val >>> 56);\n        arr[1] = (byte) (val >>> 48);\n        arr[2] = (byte) (val >>> 40);\n        arr[3] = (byte) (val >>> 32);\n        arr[4] = (byte) (val >>> 24);\n        arr[5] = (byte) (val >>> 16);\n        arr[6] = (byte) (val >>> 8);\n        arr[7] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(float val) {\n        return toArr(Float.floatToRawIntBits(val));\n    }\n\n    public static byte[] toArr(double val) {\n        return toArr(Double.doubleToRawLongBits(val));\n    }\n}\n```","source":"_posts/int,double等转化成byte数组.md","raw":"title: 'int,double等转化成byte数组'\ntags:\n  - byte数组\n  - java\n  - 转换\nid: 913\ncategories:\n  - Java\ndate: 2014-09-24 22:23:09\n---\n\n最近需要用到这个功能，本来想自己写，怕写错了，上网找了一下，都没找到合适的。看了solr与源码中的TrieField.java,有这一部分的代码，copy到这里。\n``` java\npublic class ByteUtil {\n    public static int toInt(byte[] arr) {\n        return (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n    }\n\n    public static long toLong(byte[] arr) {\n        int high = (arr[0] << 24) | ((arr[1] & 0xff) << 16)\n                | ((arr[2] & 0xff) << 8) | (arr[3] & 0xff);\n        int low = (arr[4] << 24) | ((arr[5] & 0xff) << 16)\n                | ((arr[6] & 0xff) << 8) | (arr[7] & 0xff);\n        return (((long) high) << 32) | (low & 0x0ffffffffL);\n    }\n\n    public static float toFloat(byte[] arr) {\n        return Float.intBitsToFloat(toInt(arr));\n    }\n\n    public static double toDouble(byte[] arr) {\n        return Double.longBitsToDouble(toLong(arr));\n    }\n\n    public static byte[] toArr(int val) {\n        byte[] arr = new byte[4];\n        arr[0] = (byte) (val >>> 24);\n        arr[1] = (byte) (val >>> 16);\n        arr[2] = (byte) (val >>> 8);\n        arr[3] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(long val) {\n        byte[] arr = new byte[8];\n        arr[0] = (byte) (val >>> 56);\n        arr[1] = (byte) (val >>> 48);\n        arr[2] = (byte) (val >>> 40);\n        arr[3] = (byte) (val >>> 32);\n        arr[4] = (byte) (val >>> 24);\n        arr[5] = (byte) (val >>> 16);\n        arr[6] = (byte) (val >>> 8);\n        arr[7] = (byte) (val);\n        return arr;\n    }\n\n    public static byte[] toArr(float val) {\n        return toArr(Float.floatToRawIntBits(val));\n    }\n\n    public static byte[] toArr(double val) {\n        return toArr(Double.doubleToRawLongBits(val));\n    }\n}\n```","slug":"int,double等转化成byte数组","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4nm00jl26s608tmpb4g"},{"title":"find查找目录下的所有shell脚本","id":"750","date":"2014-05-27T05:47:28.000Z","_content":"\n使用命令find . -name *.sh查找当前目录下的所有shell脚本，提示find: 路径必须在表达式之前\n\n之后改成find . -name \"*.sh\",可行。find结合sed就可以将需要的文件进行替换。","source":"_posts/find查找目录下的所有shell脚本.md","raw":"title: find查找目录下的所有shell脚本\ntags:\n  - find\n  - shell\nid: 750\ncategories:\n  - shell\ndate: 2014-05-27 13:47:28\n---\n\n使用命令find . -name *.sh查找当前目录下的所有shell脚本，提示find: 路径必须在表达式之前\n\n之后改成find . -name \"*.sh\",可行。find结合sed就可以将需要的文件进行替换。","slug":"find查找目录下的所有shell脚本","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4np00jt26s6pb8k5vmp"},{"title":"crontab定时运行脚本","id":"642","date":"2014-03-25T05:14:43.000Z","_content":"\n在Linux上经常需要定时运行某个脚本，这是crontab就派上用场了。对于如何使用crontab,一般google。事实上，我一直很好奇的是，网上那些人关于crontab的知识到底从哪里得来的，知道man crontab后我才知道，原来他们也是看的手册。\nman crontab后，没有关于如何编写crontab任务的说明，看到see also crontab(5)后,执行man 5 crontab,发现这里有说明如何编写crontab任务。这样以后就不需要遇到一个问题，就上网找，直接看手册就好了。\n\n一般说来，都是仿照晚上的例子写，如这里[http://www.blogjava.net/xiaomage234/archive/2007/12/26/170490.html](http://www.blogjava.net/xiaomage234/archive/2007/12/26/170490.html)后来才发现，给出的例子中有一个坑。\n* */1 * * * /usr/local/apache/bin/apachectl restart\n每小时重启apache\n这个例子中说每小时重启apache，试着写了之后，才发现每一分钟都会重启。仔细分析后才发现原因,因为第一列是分钟的位置,而使用*号，则代表0-59分钟，于是在一个小时里，0-59分钟都会重启apache,等到59分钟重启apache后，已经过了一小时，于是又回到0分钟，于是apache又重启了。\n\n所以以后遇到位置的命令时，不要立马上网找，可以先看看手册的说明。或者找一个靠谱的网页看，后来才发现[http://www.centos.bz/2011/03/auto-run-task-crontab/](http://www.centos.bz/2011/03/auto-run-task-crontab/)这里写的比较靠谱。在找这些命令使用过程中发现，网上这般人经常抄来抄去的，浪费别人的时间，太无聊了。","source":"_posts/crontab定时运行脚本.md","raw":"title: crontab定时运行脚本\ntags:\n  - crontab\n  - shell\nid: 642\ncategories:\n  - shell\ndate: 2014-03-25 13:14:43\n---\n\n在Linux上经常需要定时运行某个脚本，这是crontab就派上用场了。对于如何使用crontab,一般google。事实上，我一直很好奇的是，网上那些人关于crontab的知识到底从哪里得来的，知道man crontab后我才知道，原来他们也是看的手册。\nman crontab后，没有关于如何编写crontab任务的说明，看到see also crontab(5)后,执行man 5 crontab,发现这里有说明如何编写crontab任务。这样以后就不需要遇到一个问题，就上网找，直接看手册就好了。\n\n一般说来，都是仿照晚上的例子写，如这里[http://www.blogjava.net/xiaomage234/archive/2007/12/26/170490.html](http://www.blogjava.net/xiaomage234/archive/2007/12/26/170490.html)后来才发现，给出的例子中有一个坑。\n* */1 * * * /usr/local/apache/bin/apachectl restart\n每小时重启apache\n这个例子中说每小时重启apache，试着写了之后，才发现每一分钟都会重启。仔细分析后才发现原因,因为第一列是分钟的位置,而使用*号，则代表0-59分钟，于是在一个小时里，0-59分钟都会重启apache,等到59分钟重启apache后，已经过了一小时，于是又回到0分钟，于是apache又重启了。\n\n所以以后遇到位置的命令时，不要立马上网找，可以先看看手册的说明。或者找一个靠谱的网页看，后来才发现[http://www.centos.bz/2011/03/auto-run-task-crontab/](http://www.centos.bz/2011/03/auto-run-task-crontab/)这里写的比较靠谱。在找这些命令使用过程中发现，网上这般人经常抄来抄去的，浪费别人的时间，太无聊了。","slug":"crontab定时运行脚本","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4nu00jx26s6tll8lgw9"},{"title":"cannot import name detail_route错误","date":"2016-04-14T12:17:02.000Z","_content":"在看[Django-rest-framework2](http://tomchristie.github.io/rest-framework-2-docs/)时，看到Tutorial 6: ViewSets & Routers，执行`from rest_framework.decorators import detail_route`时，报cannot import name detail_route错误\n\n查看decorators.py源码，发现原因是从2.4.0才有这个方法，而公司用的是2.3.14，所以没有。\n\n在view里添加detail_route的代码\n```\ndef detail_route(methods=['get'], **kwargs):\n    \"\"\" \n    Used to mark a method on a ViewSet that should be routed for detail requests.\n    \"\"\"\n    def decorator(func):\n        func.bind_to_methods = methods\n        func.detail = True\n        func.kwargs = kwargs\n        return func\n    return decorator\n```\n\n","source":"_posts/cannot-import-name-detail-route错误.md","raw":"title: cannot import name detail_route错误\ndate: 2016-04-14 20:17:02\ntags: \n    - Django\ncategories: \n    - Python\n---\n在看[Django-rest-framework2](http://tomchristie.github.io/rest-framework-2-docs/)时，看到Tutorial 6: ViewSets & Routers，执行`from rest_framework.decorators import detail_route`时，报cannot import name detail_route错误\n\n查看decorators.py源码，发现原因是从2.4.0才有这个方法，而公司用的是2.3.14，所以没有。\n\n在view里添加detail_route的代码\n```\ndef detail_route(methods=['get'], **kwargs):\n    \"\"\" \n    Used to mark a method on a ViewSet that should be routed for detail requests.\n    \"\"\"\n    def decorator(func):\n        func.bind_to_methods = methods\n        func.detail = True\n        func.kwargs = kwargs\n        return func\n    return decorator\n```\n\n","slug":"cannot-import-name-detail-route错误","published":1,"updated":"2016-04-14T12:25:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ny00k226s6z95elcyp"},{"title":"Wordpress迁移到Hexo遇到的问题","date":"2015-12-11T07:53:24.000Z","_content":"因为在这个学习笔记里要贴一些代码，可是Wordpress的编辑器对于代码支持不够好，会改变代码格式，于是决定迁移到对代码支持更好的Hexo.Hexo是用Node.js写的博客系统，类似与Octpress，台湾人写的，很不错。\n\n对于如何搭建Hexo，以及如何迁移Wordpress,可以看[官方文档](https://hexo.io/zh-cn/)。这里主要说说迁移过程遇到的问题。\n## npm和hexo命令安装后在新开的终端中不能使用\n使用nvm安装npm后，在新开的终端中npm命令不能使用，执行nvm install 4后又可以使用。考虑过之后，发现是没有将npm命令所在的bin目录加到PATH中。执行which npm, 找到npm所在的bin目录, 在用户的.bashrc文件中,将它就加入PATH中即可。如下\nexport PATH=/home/long/.nvm/versions/node/v4.2.3/bin:$PATH\n\n## Template render error: unexpected token: / \n在[https://github.com/hexojs/hexo/issues/1439](https://github.com/hexojs/hexo/issues/1439)也有类似的问题，原来hexo变量是用两个{和两个}包含起来, 而在一些编程语言中，二维数组会出现用两个{和两个}的情况，所以冲突了。于是修改hexo-migrator-wordpress插件,到存放hexo-migrator-wordpress插件的目录(从博客的根目录进入到node_modules/hexo-migrator-wordpress)下,打开index.js, 增加一个函数\n```\nfunction replaceTwoBrace(str){\n    str = str.replace(/{{/g, '{ {');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面增加一行`content = replaceTwoBrace(content);`,解决问题。\n\n## 文件名问题\n生成的文件名如下例子 \ne8-af-ad-e8-a8-80-e7-89-b9-e6-80-a7-e8-bf-98-e6-98-af-e6-9c-89-e5-bf-85-e8-a6-81-e5-ad-a6-e4-b9-a0-e7-9a-84.md\ne8-bd-af-e8-bf-9e-e6-8e-a5-e5-92-8c-e7-a1-ac-e8-bf-9e-e6-8e-a5.md\ne8-bf-bd-e8-b8-aaquery-too-complex-not-enough-stack-e9-94-99-e8-af-af.md\n我想这是将URL转化过来的结果，因为URL中，中文是UTF-8编码。这里之所以有问题是因为这样的文件名生成的URL和以前在Wordpress中不一样，这样之前在搜索引擎索引的文章就不能访问了，因为URL变了。想通过修改hexo-migrator-wordpress插件来解决,打开index.js, 在128行附近的`post.create(data, next);`, 之后看到`post = hexo.post;`, 然后进入node_modules/hexo/lib/hexo目录，在post.js里看到`fs.writeFile(path, content)`，想通过改这里来解决。后来想想，写个Python脚本,从内容的第一行，也就是title字段抽取出标题也可以解决。于是写了个Python脚本, changePostURL.py\n```\nimport os,sys\n\ndef getTitle(firstLine):\n    strs = ':'.join(firstLine.split(':')[1:])\n    strs = strs.replace(\"'\", '') \n    strs = strs.strip()\n    title = '-'.join(strs.split(' '))\n    return title\nif __name__ == \"__main__\":\n    dirName = sys.argv[1]\n    for root,dirs,fileNames in os.walk(dirName):\n        for fileName in fileNames:\n            print fileName \n            print root\n            fileName = os.path.join(root, fileName)\n            f = open(fileName)\n            firstLine = f.readline()\n            title = getTitle(firstLine)\n            print title\n            content = firstLine + f.read()\n            f.close()\n            newname = title + '.md'\n            print newname\n            os.rename(fileName, os.path.join(root,newname))\n```\n执行`python changePostURL.py source/_posts/`搞定\n\n## HTML实体问题\n在转化出来的文件内容中，有&gt;和&lt;等实体，我想是因为Wordpress编辑器进行了转化。虽然最后的显示结果没有问题，但在Markdown中，我还是希望看到>和<等,于是在hexo-migrator-wordpress中再添加一个函数.\n```\nfunction replaceHTMLEntity(str){\n    str = str.replace(/amp;/g, '');\n    str = str.replace(/&lt;/g, '<');\n    str = str.replace(/&gt;/g, '>');\n    str = str.replace(/&quot;/g, '\"');\n    str = str.replace(/&#92;/g, '\\\\');\n    str = str.replace(/&#48;/g, '0');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面添加一行,`content = replaceHTMLEntity(content);`，解决问题\n\n## 代码标签问题\n在Wordpress中，我使用Syntax Highlighter进行代码高亮时，在代码块的前后需要添加相应的标签来高亮，如Java程序需要添加[java],[/java], 而在Markdown中这些标签就不需要了，需要对它进行替换。添加一个函数\n```\nfunction replaceCodeTag(str){\n    str = str.replace(/\\[python\\]/gi, '```');\n    str = str.replace(/\\[\\/python\\]/gi, '```');\n    str = str.replace(/\\[java\\]/gi, '```');\n    str = str.replace(/\\[\\/java\\]/gi, '```');\n    str = str.replace(/\\[php\\]/gi, '```');\n    str = str.replace(/\\[\\/php\\]/gi, '```');\n    str = str.replace(/\\[c\\]/gi, '```');\n    str = str.replace(/\\[\\/c\\]/gi, '```');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面添加一行,`content = replaceCodeTag(content);`，解决问题\n","source":"_posts/Wordpress迁移到Hexo遇到的问题.md","raw":"title: Wordpress迁移到Hexo遇到的问题\ndate: 2015-12-11 15:53:24\ntags: \n - Hexo\n - Wordpress\ncategories:\n - 软件安装\n---\n因为在这个学习笔记里要贴一些代码，可是Wordpress的编辑器对于代码支持不够好，会改变代码格式，于是决定迁移到对代码支持更好的Hexo.Hexo是用Node.js写的博客系统，类似与Octpress，台湾人写的，很不错。\n\n对于如何搭建Hexo，以及如何迁移Wordpress,可以看[官方文档](https://hexo.io/zh-cn/)。这里主要说说迁移过程遇到的问题。\n## npm和hexo命令安装后在新开的终端中不能使用\n使用nvm安装npm后，在新开的终端中npm命令不能使用，执行nvm install 4后又可以使用。考虑过之后，发现是没有将npm命令所在的bin目录加到PATH中。执行which npm, 找到npm所在的bin目录, 在用户的.bashrc文件中,将它就加入PATH中即可。如下\nexport PATH=/home/long/.nvm/versions/node/v4.2.3/bin:$PATH\n\n## Template render error: unexpected token: / \n在[https://github.com/hexojs/hexo/issues/1439](https://github.com/hexojs/hexo/issues/1439)也有类似的问题，原来hexo变量是用两个{和两个}包含起来, 而在一些编程语言中，二维数组会出现用两个{和两个}的情况，所以冲突了。于是修改hexo-migrator-wordpress插件,到存放hexo-migrator-wordpress插件的目录(从博客的根目录进入到node_modules/hexo-migrator-wordpress)下,打开index.js, 增加一个函数\n```\nfunction replaceTwoBrace(str){\n    str = str.replace(/{{/g, '{ {');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面增加一行`content = replaceTwoBrace(content);`,解决问题。\n\n## 文件名问题\n生成的文件名如下例子 \ne8-af-ad-e8-a8-80-e7-89-b9-e6-80-a7-e8-bf-98-e6-98-af-e6-9c-89-e5-bf-85-e8-a6-81-e5-ad-a6-e4-b9-a0-e7-9a-84.md\ne8-bd-af-e8-bf-9e-e6-8e-a5-e5-92-8c-e7-a1-ac-e8-bf-9e-e6-8e-a5.md\ne8-bf-bd-e8-b8-aaquery-too-complex-not-enough-stack-e9-94-99-e8-af-af.md\n我想这是将URL转化过来的结果，因为URL中，中文是UTF-8编码。这里之所以有问题是因为这样的文件名生成的URL和以前在Wordpress中不一样，这样之前在搜索引擎索引的文章就不能访问了，因为URL变了。想通过修改hexo-migrator-wordpress插件来解决,打开index.js, 在128行附近的`post.create(data, next);`, 之后看到`post = hexo.post;`, 然后进入node_modules/hexo/lib/hexo目录，在post.js里看到`fs.writeFile(path, content)`，想通过改这里来解决。后来想想，写个Python脚本,从内容的第一行，也就是title字段抽取出标题也可以解决。于是写了个Python脚本, changePostURL.py\n```\nimport os,sys\n\ndef getTitle(firstLine):\n    strs = ':'.join(firstLine.split(':')[1:])\n    strs = strs.replace(\"'\", '') \n    strs = strs.strip()\n    title = '-'.join(strs.split(' '))\n    return title\nif __name__ == \"__main__\":\n    dirName = sys.argv[1]\n    for root,dirs,fileNames in os.walk(dirName):\n        for fileName in fileNames:\n            print fileName \n            print root\n            fileName = os.path.join(root, fileName)\n            f = open(fileName)\n            firstLine = f.readline()\n            title = getTitle(firstLine)\n            print title\n            content = firstLine + f.read()\n            f.close()\n            newname = title + '.md'\n            print newname\n            os.rename(fileName, os.path.join(root,newname))\n```\n执行`python changePostURL.py source/_posts/`搞定\n\n## HTML实体问题\n在转化出来的文件内容中，有&gt;和&lt;等实体，我想是因为Wordpress编辑器进行了转化。虽然最后的显示结果没有问题，但在Markdown中，我还是希望看到>和<等,于是在hexo-migrator-wordpress中再添加一个函数.\n```\nfunction replaceHTMLEntity(str){\n    str = str.replace(/amp;/g, '');\n    str = str.replace(/&lt;/g, '<');\n    str = str.replace(/&gt;/g, '>');\n    str = str.replace(/&quot;/g, '\"');\n    str = str.replace(/&#92;/g, '\\\\');\n    str = str.replace(/&#48;/g, '0');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面添加一行,`content = replaceHTMLEntity(content);`，解决问题\n\n## 代码标签问题\n在Wordpress中，我使用Syntax Highlighter进行代码高亮时，在代码块的前后需要添加相应的标签来高亮，如Java程序需要添加[java],[/java], 而在Markdown中这些标签就不需要了，需要对它进行替换。添加一个函数\n```\nfunction replaceCodeTag(str){\n    str = str.replace(/\\[python\\]/gi, '```');\n    str = str.replace(/\\[\\/python\\]/gi, '```');\n    str = str.replace(/\\[java\\]/gi, '```');\n    str = str.replace(/\\[\\/java\\]/gi, '```');\n    str = str.replace(/\\[php\\]/gi, '```');\n    str = str.replace(/\\[\\/php\\]/gi, '```');\n    str = str.replace(/\\[c\\]/gi, '```');\n    str = str.replace(/\\[\\/c\\]/gi, '```');\n    return str;\n};\n```\n之后在`content = tomd(content).replace(/\\r\\n/g, '\\n');`前面添加一行,`content = replaceCodeTag(content);`，解决问题\n","slug":"Wordpress迁移到Hexo遇到的问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4o200k626s6mia3myn6"},{"title":"Ubuntu中打开PDF文件","id":"842","date":"2014-07-20T02:07:30.000Z","_content":"\n习惯在命令行下工作，都忘记用什么软件打开PDF了，才发现是用evince打开。\n\n于是在命令行下执行evince 文件名即可打开，例如要打开ex1.pdf,则执行evince ex1.pdf","source":"_posts/Ubuntu中打开PDF文件.md","raw":"title: Ubuntu中打开PDF文件\ntags:\n  - evince\n  - pdf\nid: 842\ncategories:\n  - shell\ndate: 2014-07-20 10:07:30\n---\n\n习惯在命令行下工作，都忘记用什么软件打开PDF了，才发现是用evince打开。\n\n于是在命令行下执行evince 文件名即可打开，例如要打开ex1.pdf,则执行evince ex1.pdf","slug":"Ubuntu中打开PDF文件","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ob00kb26s6w78742dj"},{"title":"TCP建立连接时的三次握手","id":"710","date":"2014-04-27T23:57:35.000Z","_content":"\nTCP建立连接时一般要发送三次包，也就是俗称的三次握手。首先客户端向服务器端发送一个建立连接请求，告诉服务器自己的序列号；服务器收到这个请求包后，进行确认，同时告诉客户端自己的序列号；之后客户端对这个包进行确认。如果一切正常，三次握手就已经完成。\n\n在网络状况不好的时候，如果在发送的过程中任意一个包丢失会怎样呢？\n\n首先来看看第一个包。这种情况显而易见，如果客户端建立连接的请求包丢失，那么服务器端根本不知道有这么一个请求，客户端只有重新发送这个包。\n\n再来看看第二个包。这种情况也是显而易见，如果服务器的确认包丢失，那么客户端无法知道服务器是否收到这个请求，此时服务器端必须再次发送这个确认包。\n\n最后来看看第三个包。这种情况就不是那么显而易见了。如果客户端的确认包丢失，一个明显的解决办法是客户端再次发送这个确认包，然而这是不可行的，因为即使再次发送，客户端依然不知道服务器端是否收到这个确认包。解决的办法是服务器端再次发送三次握手的第二个包。这样就可以说明服务器端没有收到客户端的确认包，所以它需要再次发送第二个包，当客户端再次收到这个包时，也就知道自己此前发送的确认包丢失了，于是再次发送确认包。","source":"_posts/TCP建立连接时的三次握手.md","raw":"title: TCP建立连接时的三次握手\ntags:\n  - TCP\n  - 三次握手\nid: 710\ncategories:\n  - 网络编程\ndate: 2014-04-28 07:57:35\n---\n\nTCP建立连接时一般要发送三次包，也就是俗称的三次握手。首先客户端向服务器端发送一个建立连接请求，告诉服务器自己的序列号；服务器收到这个请求包后，进行确认，同时告诉客户端自己的序列号；之后客户端对这个包进行确认。如果一切正常，三次握手就已经完成。\n\n在网络状况不好的时候，如果在发送的过程中任意一个包丢失会怎样呢？\n\n首先来看看第一个包。这种情况显而易见，如果客户端建立连接的请求包丢失，那么服务器端根本不知道有这么一个请求，客户端只有重新发送这个包。\n\n再来看看第二个包。这种情况也是显而易见，如果服务器的确认包丢失，那么客户端无法知道服务器是否收到这个请求，此时服务器端必须再次发送这个确认包。\n\n最后来看看第三个包。这种情况就不是那么显而易见了。如果客户端的确认包丢失，一个明显的解决办法是客户端再次发送这个确认包，然而这是不可行的，因为即使再次发送，客户端依然不知道服务器端是否收到这个确认包。解决的办法是服务器端再次发送三次握手的第二个包。这样就可以说明服务器端没有收到客户端的确认包，所以它需要再次发送第二个包，当客户端再次收到这个包时，也就知道自己此前发送的确认包丢失了，于是再次发送确认包。","slug":"TCP建立连接时的三次握手","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4oe00kh26s6wag5x4na"},{"title":"Sphinx更新属性无法为负值","id":"929","date":"2014-10-19T04:36:08.000Z","_content":"\n离职已经三个多月了，关于Sphinx的知识都快忘的差不多了，所以得赶紧记下来，以备不时之需。\n\n离职前，在Sphinx-for-Chinese讨论组里异常活跃，很热心帮助群里的人解决问题。其中有个问题就是属性更新时无法设置为负值。于是看看Sphinx的更新属性流程。从searchd.cpp的main函数开始,到ServiceMain，TickPreforked,HandleClient,HandleClientSphinx,HandleCommandUpdate在这里看到\n``` c\nARRAY_FOREACH ( i, tUpd.m_dAttrs )\n    {\n        tUpd.m_dAttrs[i] = tReq.GetString().ToLower().Leak();\n        tUpd.m_dTypes[i] = SPH_ATTR_INTEGER;\n        if ( iVer>=0x102 )\n        {     \n            if ( tReq.GetDword() )\n            {     \n                tUpd.m_dTypes[i] = SPH_ATTR_UINT32SET;\n                bMvaUpdate = true;\n            }     \n        }     \n    }\n```\n也就是说，这里默认是SPH_ATTR_INTEGER，而在Sphinx里，这个是无符号整型。因为在后面的一个判断语句里，有如下句子\n``` c\n} else\n{     \n       tUpd.m_dPool.Add ( tReq.GetDword() );\n} \n```  \n查看GetDword()，就可以知道返回的是无符号整型。\n\n之后跳转到DoCommandUpdate,UpdateAttributes\n在其中发现这样一句话：\n// this is a hack\n // Query parser tries to detect an attribute type. And this is wrong because, we should\n // take attribute type from schema. Probably we'll rewrite updates in future but\n // for now this fix just works.\n // Fixes cases like UPDATE float_attr=1 WHERE id=1;\n也就是说，Sphinx更新属性时，没有去读取配置文件。而只是根据上面代码中的设定去读取更新信息，所以没有办法读取负数。一个主要的原因是，Sphinx没有32位整型数据的概念，只有32位无符号整型的概念。\n\n因为这样，你也许会尝试将要更为负值的字段设置成64位整型，因为这个是有正负的，可是尝试之后还是不行。这是因为在代码里，没有根据配置文件去读数据，所以它还是按照上面的设定去读数据，这样还是无符号的。所以对于这个问题，还有待Sphinx的开发人员去解决.\n\n太久没用vim看代码了,连ctags的跳转是ctrl + ] 和ctrl + o都快忘记了。","source":"_posts/Sphinx更新属性无法为负值.md","raw":"title: Sphinx更新属性无法为负值\ntags:\n  - Sphinx\n  - 更新\n  - 负值\nid: 929\ncategories:\n  - 搜索引擎\ndate: 2014-10-19 12:36:08\n---\n\n离职已经三个多月了，关于Sphinx的知识都快忘的差不多了，所以得赶紧记下来，以备不时之需。\n\n离职前，在Sphinx-for-Chinese讨论组里异常活跃，很热心帮助群里的人解决问题。其中有个问题就是属性更新时无法设置为负值。于是看看Sphinx的更新属性流程。从searchd.cpp的main函数开始,到ServiceMain，TickPreforked,HandleClient,HandleClientSphinx,HandleCommandUpdate在这里看到\n``` c\nARRAY_FOREACH ( i, tUpd.m_dAttrs )\n    {\n        tUpd.m_dAttrs[i] = tReq.GetString().ToLower().Leak();\n        tUpd.m_dTypes[i] = SPH_ATTR_INTEGER;\n        if ( iVer>=0x102 )\n        {     \n            if ( tReq.GetDword() )\n            {     \n                tUpd.m_dTypes[i] = SPH_ATTR_UINT32SET;\n                bMvaUpdate = true;\n            }     \n        }     \n    }\n```\n也就是说，这里默认是SPH_ATTR_INTEGER，而在Sphinx里，这个是无符号整型。因为在后面的一个判断语句里，有如下句子\n``` c\n} else\n{     \n       tUpd.m_dPool.Add ( tReq.GetDword() );\n} \n```  \n查看GetDword()，就可以知道返回的是无符号整型。\n\n之后跳转到DoCommandUpdate,UpdateAttributes\n在其中发现这样一句话：\n// this is a hack\n // Query parser tries to detect an attribute type. And this is wrong because, we should\n // take attribute type from schema. Probably we'll rewrite updates in future but\n // for now this fix just works.\n // Fixes cases like UPDATE float_attr=1 WHERE id=1;\n也就是说，Sphinx更新属性时，没有去读取配置文件。而只是根据上面代码中的设定去读取更新信息，所以没有办法读取负数。一个主要的原因是，Sphinx没有32位整型数据的概念，只有32位无符号整型的概念。\n\n因为这样，你也许会尝试将要更为负值的字段设置成64位整型，因为这个是有正负的，可是尝试之后还是不行。这是因为在代码里，没有根据配置文件去读数据，所以它还是按照上面的设定去读数据，这样还是无符号的。所以对于这个问题，还有待Sphinx的开发人员去解决.\n\n太久没用vim看代码了,连ctags的跳转是ctrl + ] 和ctrl + o都快忘记了。","slug":"Sphinx更新属性无法为负值","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4oh00ko26s6y7ra7n0m"},{"title":"Sphinx使用一元分词","id":"694","date":"2014-04-14T05:19:15.000Z","_content":"\n之前说过用Sphinx给同事搭建搜索服务，可是他提了一个要求，也就是文本中有牛皮癣这个词，搜牛皮时也要能搜到牛皮癣，这个要求在经过分词后是不可以完成的。于是只好去寻求一元分词和二元分词的办法。\n在[http://lutaf.com/157.htm](http://lutaf.com/157.htm) 这里看到，“sphinx只要把min_word_len设置为1,并配置charset_table,默认就是单字切分 ”于是试着配置，结果不行。于是只好看文档，在文档中找到，默认情况下，Sphinx已经支持一元分词。\n只需设置\ncharset_type = utf-8 ，\n ngram_len = 1，\nngram_chars = U+3000..U+2FA1F\n这样，再次搜牛皮时，就可以搜到牛皮癣了。\n","source":"_posts/Sphinx使用一元分词.md","raw":"title: Sphinx使用一元分词\ntags:\n  - Sphinx\n  - Sphinx-for-chinese\n  - 一元分词\nid: 694\ncategories:\n  - 搜索引擎\ndate: 2014-04-14 13:19:15\n---\n\n之前说过用Sphinx给同事搭建搜索服务，可是他提了一个要求，也就是文本中有牛皮癣这个词，搜牛皮时也要能搜到牛皮癣，这个要求在经过分词后是不可以完成的。于是只好去寻求一元分词和二元分词的办法。\n在[http://lutaf.com/157.htm](http://lutaf.com/157.htm) 这里看到，“sphinx只要把min_word_len设置为1,并配置charset_table,默认就是单字切分 ”于是试着配置，结果不行。于是只好看文档，在文档中找到，默认情况下，Sphinx已经支持一元分词。\n只需设置\ncharset_type = utf-8 ，\n ngram_len = 1，\nngram_chars = U+3000..U+2FA1F\n这样，再次搜牛皮时，就可以搜到牛皮癣了。\n","slug":"Sphinx使用一元分词","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ok00ku26s6hp6d9hpr"},{"title":"Sphinx-for-Chinese的分词细粒度问题解决代码","id":"910","date":"2014-10-19T09:12:44.000Z","_content":"\n感觉上，这段代码不贴上来，仿佛欠别人钱似的。趁现在还有些精力，以后很长一段时间都不会接触Sphinx了，赶紧把这件事给做了。\n具体为什么这样改，可以看前面的文章。以下修改是基于sphinx-for-chinese-2.2.1-dev-r4311版本，之需要修改sphinx.cpp即可。\n\n在2296行后面添加如下代码：\n``` c\nstruct CSphWord\n{\n    BYTE m_sAccum[3 * SPH_MAX_WORD_LEN + 3];\n    int length;\n    const BYTE *m_pTokenStart;\n    const BYTE *m_pTokenEnd;\n};\nclass ISphWords\n{\npublic:\n    int Length () const\n    {\n        return m_dData.GetLength();\n    }\n\n    const CSphWord * First () const\n    {\n        return m_dData.Begin();\n    }\n\n    const CSphWord * Last () const\n    {\n        return &m_dData.Last();\n    }\n    void Clean() {\n        m_dData.Reset();\n    }     \n\n    void AddWord ( BYTE * word, int length, const BYTE *start, const BYTE *end)\n    {\n            CSphWord & tWord = m_dData.Add();\n            memcpy(tWord.m_sAccum, word, length);\n            tWord.length = length;\n            tWord.m_pTokenStart = start;\n            tWord.m_pTokenEnd = end;\n    }\n\npublic:\n    CSphVector<CSphWord> m_dData;\n};\n```\n\n在2296行,`virtual int GetMaxCodepointLength () const { return m_tLC.GetMaxCodepointLength(); }`后面添加如下方法成员：\n```\n cvirtual BYTE *              ProcessParsedWord();\n```\n在2303行，`Darts::DoubleArray::result_pair_type    m_pResultPair[256];`后面添加如下数据成员：\n``` c\n/*****add by luodongshan for indexer*****/\n        int totalParsedWordsNum; //总共需要处理的词\n        int processedParsedWordsNum; //已经处理的词\n        int isIndexer; //是否开启细粒度分词\n        bool needMoreParser; //需要更细粒度分词\n        const char * m_pTempCur;\n        char  m_BestWord[3 * SPH_MAX_WORD_LEN + 3];\n        int m_iBestWordLength;\n        ISphWords m_Words;\n        CSphWord *current;\n        bool isParserEnd;\n```\n在6448行，m_bHasBlend = false;后面添加如下初始化代码：\n``` c\n        char *penv = getenv(\"IS_INDEX\");\n        if (penv != NULL) {\n                isIndexer = 1;\n        } else {\n                isIndexer = 0;\n        }     \n        needMoreParser = false;\n        current = NULL;\n        isParserEnd = false;\n```\n在6743后面添加新增方法成员ProcessParsedWord的实现：\n``` c\ntemplate < bool IS_QUERY >\nBYTE * CSphTokenizer_UTF8Chinese<IS_QUERY>::ProcessParsedWord() {\n    for (; current != NULL && current <= m_Words.Last(); ) {\n        memcpy(m_sAccum, current->m_sAccum, current->length);\n        m_pTokenStart = current->m_pTokenStart;\n        m_pTokenEnd = current->m_pTokenEnd;\n        current++;\n        return m_sAccum;\n    }\n    isParserEnd = false;\n    m_Words.Clean();\n    current = NULL;\n    return NULL;\n}\n```\n在6785行， `bool bGotSoft = false; // hey Beavis he said soft huh huhhuh `后面增加如下代码：\n``` c\n        if (isIndexer && isParserEnd) { //使用MMSEG分词结束，处理细粒度分词得到的词\n                return ProcessParsedWord();\n        }  \n```\n在6791行， int iNum;后面增加如下代码：\n``` c\n        /***add by dengsl 2014/06/24****/\n        if(isIndexer && needMoreParser) { //对最优匹配进行细粒度分词\n                while (m_pTempCur < m_BestWord + m_iBestWordLength) {\n                        if(processedParsedWordsNum == totalParsedWordsNum) { //此位置的前缀词已处理完，跳到下一位置\n                                size_t minWordLength = m_pResultPair[0].length;\n                                for(int i = 1; i < totalParsedWordsNum; i++) {\n                                        if(m_pResultPair[i].length < minWordLength) {\n                                                minWordLength = m_pResultPair[i].length;\n                                        }     \n                                }     \n                                m_pTempCur += minWordLength;\n                                m_pText=(Darts::DoubleArray::key_type *)(m_pCur + (m_pTempCur - m_BestWord));\n                                iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-(m_pCur+(m_pTempCur-m_BestWord)));\n                                totalParsedWordsNum = iNum;\n                                processedParsedWordsNum = 0;\n                        } else {\n                                iWordLength = m_pResultPair[processedParsedWordsNum].length;\n                                processedParsedWordsNum++;\n                                if (m_pTempCur == m_BestWord && iWordLength == m_iBestWordLength) {\n                                        continue;\n                                }     \n                                memcpy(m_sAccum, m_pText, iWordLength);\n                                m_sAccum[iWordLength] = '\\0';\n                                if( 3 * SPH_MAX_WORD_LEN + 3 >= iWordLength + 2) {\n                                        m_sAccum[iWordLength + 1] = '\\0';\n                                        if(m_pTokenEnd == m_pBufferMax) { //是结尾，保存结尾符标志\n                                                m_sAccum[iWordLength + 1] = 1;\n                                        }     \n                                }     \n                                m_Words.AddWord(m_sAccum, iWordLength + 2, m_pCur + (m_pTempCur - m_BestWord), m_pCur + (m_pTempCur - m_BestWord) + iWordLength);\n                        }     \n                }     \n                m_pCur += m_iBestWordLength;\n                needMoreParser = false;\n                iWordLength = 0;\n                current = const_cast< CSphWord * > ( m_Words.First() );\n        }     \n        /***add end by dengsl 2014/06/24****/\n```\n在6832行，iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-m_pCur);后面增加如下代码：\n``` c\n                /***add by dengsl 2014/06/24****/\n                if(isIndexer && iNum > 1) {\n                        m_iBestWordLength=getBestWordLength(m_pText, m_pBufferMax-m_pCur);\n                        memcpy(m_sAccum, m_pText, m_iBestWordLength);\n                        m_sAccum[m_iBestWordLength]='\\0';\n                        m_pTokenStart = m_pCur;\n                        m_pTokenEnd = m_pCur + m_iBestWordLength;\n\n                        totalParsedWordsNum = iNum;\n                        needMoreParser = true;\n                        processedParsedWordsNum = 0;\n                        memcpy(m_BestWord, m_pText, m_iBestWordLength);\n                        m_BestWord[m_iBestWordLength]='\\0';\n                        m_pTempCur = m_BestWord;\n                        if( 3 * SPH_MAX_WORD_LEN + 3 >= m_iBestWordLength + 2) {\n                                m_sAccum[m_iBestWordLength + 1] = '\\0';\n                                if(m_pTokenEnd == m_pBufferMax) { //是结尾，保存结尾符标志\n                                        m_sAccum[m_iBestWordLength + 1] = 1;\n                                }     \n                        }     \n                        return m_sAccum;\n                }     \n                /***add by dengsl 2014/06/24****/\n```\n在6903行，将\n``` c\nreturn NULL;\n```\n修改为\n``` c\n/* dengsl */\nisParserEnd = true;\nreturn ProcessParsedWord();\n```\n在6914行，将\n``` c\n if_const ( IS_BLEND && !BlendAdjust ( pCur ) )\n     return NULL;\n```\n修改成：\n``` c\n/* dengsl */\nif_const ( IS_BLEND && !BlendAdjust ( pCur ) ) {\n    isParserEnd = true;\n    return ProcessParsedWord();\n}  \n```\n在27210行，m_tHits.AddHit ( uDocid, iWord, m_tState.m_iHitPos );后面增加如下代码：\n``` c\n        ///add by luodongshan 20140626\n            if(sWord != NULL) {\n                int sWord_len = strlen((char*)sWord);\n                if(sWord_len + 2 <= 3 * SPH_MAX_WORD_LEN + 3 && sWord[sWord_len + 1] == 1 &&\n                        getenv(\"IS_INDEX\") != NULL && !bSkipEndMarker )  {\n                    CSphWordHit * pHit = const_cast < CSphWordHit * > ( m_tHits.Last() );\n                    HITMAN::SetEndMarker ( &pHit->m_iWordPos );\n\n                }     \n            }     \n            ///add by luodongshan 20140626 end\n```\n将过上面的修改，重新编译源码，之后设置环境变量IS_INDEX,即运行export IS_INDEX=1,就可以支持细粒度的划分。\n\n一个需要注意的地方是,对于searchd,也变成细粒度分词了，这并不是我们想要的，所以对于searchd，需要使用未修改代码的searchd.因为我们想建索引时细粒度，搜索时粗粒度。\n\n之所以要这样，是因为如果不这样处理，很多结果会搜出来了。如有文章内容分别为中大酒店，中大假日酒店。如果搜索时也是细粒度，则有中大，酒店，中，大，大酒店，酒，店等查询词，而大酒店只在中大酒店中存在，所以只会搜出中大酒店，这并不是我们想要的。\n","source":"_posts/Sphinx-for-Chinese的分词细粒度问题解决代码.md","raw":"title: Sphinx-for-Chinese的分词细粒度问题解决代码\ntags:\n  - Sphinx-for-chinese\n  - 分词\n  - 细粒度\nid: 910\ncategories:\n  - 搜索引擎\ndate: 2014-10-19 17:12:44\n---\n\n感觉上，这段代码不贴上来，仿佛欠别人钱似的。趁现在还有些精力，以后很长一段时间都不会接触Sphinx了，赶紧把这件事给做了。\n具体为什么这样改，可以看前面的文章。以下修改是基于sphinx-for-chinese-2.2.1-dev-r4311版本，之需要修改sphinx.cpp即可。\n\n在2296行后面添加如下代码：\n``` c\nstruct CSphWord\n{\n    BYTE m_sAccum[3 * SPH_MAX_WORD_LEN + 3];\n    int length;\n    const BYTE *m_pTokenStart;\n    const BYTE *m_pTokenEnd;\n};\nclass ISphWords\n{\npublic:\n    int Length () const\n    {\n        return m_dData.GetLength();\n    }\n\n    const CSphWord * First () const\n    {\n        return m_dData.Begin();\n    }\n\n    const CSphWord * Last () const\n    {\n        return &m_dData.Last();\n    }\n    void Clean() {\n        m_dData.Reset();\n    }     \n\n    void AddWord ( BYTE * word, int length, const BYTE *start, const BYTE *end)\n    {\n            CSphWord & tWord = m_dData.Add();\n            memcpy(tWord.m_sAccum, word, length);\n            tWord.length = length;\n            tWord.m_pTokenStart = start;\n            tWord.m_pTokenEnd = end;\n    }\n\npublic:\n    CSphVector<CSphWord> m_dData;\n};\n```\n\n在2296行,`virtual int GetMaxCodepointLength () const { return m_tLC.GetMaxCodepointLength(); }`后面添加如下方法成员：\n```\n cvirtual BYTE *              ProcessParsedWord();\n```\n在2303行，`Darts::DoubleArray::result_pair_type    m_pResultPair[256];`后面添加如下数据成员：\n``` c\n/*****add by luodongshan for indexer*****/\n        int totalParsedWordsNum; //总共需要处理的词\n        int processedParsedWordsNum; //已经处理的词\n        int isIndexer; //是否开启细粒度分词\n        bool needMoreParser; //需要更细粒度分词\n        const char * m_pTempCur;\n        char  m_BestWord[3 * SPH_MAX_WORD_LEN + 3];\n        int m_iBestWordLength;\n        ISphWords m_Words;\n        CSphWord *current;\n        bool isParserEnd;\n```\n在6448行，m_bHasBlend = false;后面添加如下初始化代码：\n``` c\n        char *penv = getenv(\"IS_INDEX\");\n        if (penv != NULL) {\n                isIndexer = 1;\n        } else {\n                isIndexer = 0;\n        }     \n        needMoreParser = false;\n        current = NULL;\n        isParserEnd = false;\n```\n在6743后面添加新增方法成员ProcessParsedWord的实现：\n``` c\ntemplate < bool IS_QUERY >\nBYTE * CSphTokenizer_UTF8Chinese<IS_QUERY>::ProcessParsedWord() {\n    for (; current != NULL && current <= m_Words.Last(); ) {\n        memcpy(m_sAccum, current->m_sAccum, current->length);\n        m_pTokenStart = current->m_pTokenStart;\n        m_pTokenEnd = current->m_pTokenEnd;\n        current++;\n        return m_sAccum;\n    }\n    isParserEnd = false;\n    m_Words.Clean();\n    current = NULL;\n    return NULL;\n}\n```\n在6785行， `bool bGotSoft = false; // hey Beavis he said soft huh huhhuh `后面增加如下代码：\n``` c\n        if (isIndexer && isParserEnd) { //使用MMSEG分词结束，处理细粒度分词得到的词\n                return ProcessParsedWord();\n        }  \n```\n在6791行， int iNum;后面增加如下代码：\n``` c\n        /***add by dengsl 2014/06/24****/\n        if(isIndexer && needMoreParser) { //对最优匹配进行细粒度分词\n                while (m_pTempCur < m_BestWord + m_iBestWordLength) {\n                        if(processedParsedWordsNum == totalParsedWordsNum) { //此位置的前缀词已处理完，跳到下一位置\n                                size_t minWordLength = m_pResultPair[0].length;\n                                for(int i = 1; i < totalParsedWordsNum; i++) {\n                                        if(m_pResultPair[i].length < minWordLength) {\n                                                minWordLength = m_pResultPair[i].length;\n                                        }     \n                                }     \n                                m_pTempCur += minWordLength;\n                                m_pText=(Darts::DoubleArray::key_type *)(m_pCur + (m_pTempCur - m_BestWord));\n                                iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-(m_pCur+(m_pTempCur-m_BestWord)));\n                                totalParsedWordsNum = iNum;\n                                processedParsedWordsNum = 0;\n                        } else {\n                                iWordLength = m_pResultPair[processedParsedWordsNum].length;\n                                processedParsedWordsNum++;\n                                if (m_pTempCur == m_BestWord && iWordLength == m_iBestWordLength) {\n                                        continue;\n                                }     \n                                memcpy(m_sAccum, m_pText, iWordLength);\n                                m_sAccum[iWordLength] = '\\0';\n                                if( 3 * SPH_MAX_WORD_LEN + 3 >= iWordLength + 2) {\n                                        m_sAccum[iWordLength + 1] = '\\0';\n                                        if(m_pTokenEnd == m_pBufferMax) { //是结尾，保存结尾符标志\n                                                m_sAccum[iWordLength + 1] = 1;\n                                        }     \n                                }     \n                                m_Words.AddWord(m_sAccum, iWordLength + 2, m_pCur + (m_pTempCur - m_BestWord), m_pCur + (m_pTempCur - m_BestWord) + iWordLength);\n                        }     \n                }     \n                m_pCur += m_iBestWordLength;\n                needMoreParser = false;\n                iWordLength = 0;\n                current = const_cast< CSphWord * > ( m_Words.First() );\n        }     \n        /***add end by dengsl 2014/06/24****/\n```\n在6832行，iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-m_pCur);后面增加如下代码：\n``` c\n                /***add by dengsl 2014/06/24****/\n                if(isIndexer && iNum > 1) {\n                        m_iBestWordLength=getBestWordLength(m_pText, m_pBufferMax-m_pCur);\n                        memcpy(m_sAccum, m_pText, m_iBestWordLength);\n                        m_sAccum[m_iBestWordLength]='\\0';\n                        m_pTokenStart = m_pCur;\n                        m_pTokenEnd = m_pCur + m_iBestWordLength;\n\n                        totalParsedWordsNum = iNum;\n                        needMoreParser = true;\n                        processedParsedWordsNum = 0;\n                        memcpy(m_BestWord, m_pText, m_iBestWordLength);\n                        m_BestWord[m_iBestWordLength]='\\0';\n                        m_pTempCur = m_BestWord;\n                        if( 3 * SPH_MAX_WORD_LEN + 3 >= m_iBestWordLength + 2) {\n                                m_sAccum[m_iBestWordLength + 1] = '\\0';\n                                if(m_pTokenEnd == m_pBufferMax) { //是结尾，保存结尾符标志\n                                        m_sAccum[m_iBestWordLength + 1] = 1;\n                                }     \n                        }     \n                        return m_sAccum;\n                }     \n                /***add by dengsl 2014/06/24****/\n```\n在6903行，将\n``` c\nreturn NULL;\n```\n修改为\n``` c\n/* dengsl */\nisParserEnd = true;\nreturn ProcessParsedWord();\n```\n在6914行，将\n``` c\n if_const ( IS_BLEND && !BlendAdjust ( pCur ) )\n     return NULL;\n```\n修改成：\n``` c\n/* dengsl */\nif_const ( IS_BLEND && !BlendAdjust ( pCur ) ) {\n    isParserEnd = true;\n    return ProcessParsedWord();\n}  \n```\n在27210行，m_tHits.AddHit ( uDocid, iWord, m_tState.m_iHitPos );后面增加如下代码：\n``` c\n        ///add by luodongshan 20140626\n            if(sWord != NULL) {\n                int sWord_len = strlen((char*)sWord);\n                if(sWord_len + 2 <= 3 * SPH_MAX_WORD_LEN + 3 && sWord[sWord_len + 1] == 1 &&\n                        getenv(\"IS_INDEX\") != NULL && !bSkipEndMarker )  {\n                    CSphWordHit * pHit = const_cast < CSphWordHit * > ( m_tHits.Last() );\n                    HITMAN::SetEndMarker ( &pHit->m_iWordPos );\n\n                }     \n            }     \n            ///add by luodongshan 20140626 end\n```\n将过上面的修改，重新编译源码，之后设置环境变量IS_INDEX,即运行export IS_INDEX=1,就可以支持细粒度的划分。\n\n一个需要注意的地方是,对于searchd,也变成细粒度分词了，这并不是我们想要的，所以对于searchd，需要使用未修改代码的searchd.因为我们想建索引时细粒度，搜索时粗粒度。\n\n之所以要这样，是因为如果不这样处理，很多结果会搜出来了。如有文章内容分别为中大酒店，中大假日酒店。如果搜索时也是细粒度，则有中大，酒店，中，大，大酒店，酒，店等查询词，而大酒店只在中大酒店中存在，所以只会搜出中大酒店，这并不是我们想要的。\n","slug":"Sphinx-for-Chinese的分词细粒度问题解决代码","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4oo00l026s64chh0ujv"},{"title":"Sphinx-for-Chinese的分词细粒度问题","id":"769","date":"2014-06-28T14:31:51.000Z","_content":"\n假如使用Sphinx来做搜索引擎，就一定会遇到分词问题。对于中文，有两个选择，选择1是使用Sphinx自带的一元分词，选择2是使用CoreSeek或者Sphinx-for-Chinese，这两个都使用了mmseg来进行分词。据我了解,CoreSeek在支持细粒度的分词，而Sphinx-for-Chinese不支持。而公司使用的是Sphinx-for-Chinese,所以就遇到了分词的粒度问题。\n\n根据产品人员的反馈，有许多这样的例子。例如搜索西海或者海岸时，搜不到大华西海岸酒店，搜索兵马俑时，搜不到秦始皇兵马俑博物馆,搜索肯尼亚时搜不到肯尼亚山。这都是因为Sphinx-for-Chinese使用mmseg得到最优结果后，就不在进行细分的结果。拿大华西海岸酒店这个例子来说，词典里有大华，西海岸，酒店，华西，西海，海岸这些词，根据mmseg得到的最优分词结果，分成大华+西海岸+酒店，这个分词的结果也是正确的，可是搜索西海，海岸就搜不到它的。问过Sphinx-for-Chinese的开发人员后，要想支持更细粒度的分词，只有修改源码。\n\n在组长划出一条线，需要在哪一部分代码后，一个最简单的想法是，对于mmseg中每一步得到的最优结果，都进行更细粒度的划分。例如上面的例子，对于西海岸进行更细粒度划分后，就可以得到西海和海岸，这样搜索西海和海岸时，就可以搜索到。于是立马动手写，折腾一个上午后，果然可以搜到了，这样就达到了同城旅游中酒店搜索的效果了。可是搜索华西还是搜不到，而携程则可以搜到，在携程里，搜索西也可以搜到它。仔细考虑后，在原来的代码里只需要很少的修改就可以做到搜索华西是也可以搜到它，搜索效果已经超过了同程旅游。在增加单字索引后，搜索效果和携程相当接近。\n\n相信许多使用Sphinx-for-Chinese都会遇到类似的问题，也都将用各自的办法解决这个问题。这里将这一部分代码开源，也算是对开源事业的一点点贡献。事实上，需要修改的地方并不是很多。这里我使用的是sphinx-for-chinese-2.2.1-dev-r4311版本,相信其它版本也可以进行类似的修改。需要修改的文件只有一个，那就是sphinx.cpp。\n\n在2244行附近，class CSphTokenizer_UTF8Chinese : public CSphTokenizer_UTF8_Base这个类中,增加以下数据成员\n``` c\nint m_totalParsedWordsNum; //总共得到的分词结果\nint m_processedParsedWordsNum; //已经处理的分词个数\nint m_isIndexer; //标示是否是indexer程序\nbool m_needMoreParser; //标示是否需要更细粒度分词\nconst char * m_pTempCur; //标示在m_BestWord中的位置\nchar m_BestWord[3 * SPH_MAX_WORD_LEN + 3]; //记录使用mmseg得到的最优分词结果\nint m_iBestWordLength; //最优分词结果的长度\n```\n\n在6404行附近CSphTokenizer_UTF8Chinese<IS_QUERY>::CSphTokenizer_UTF8Chinese ()这个构造函数中，增加以下语句进行初始化。\n``` c\n char *penv = getenv(\"IS_INDEXER\");\n        if (penv != NULL) {\n                m_isIndexer = 1;\n        } else {\n                m_isIndexer = 0;\n        }\n        m_needMoreParser = false;\n```\n在6706行附近BYTE * CSphTokenizer_UTF8Chinese<IS_QUERY>::GetToken ()函数中int iNum;语句后面增加如下语句\n``` c\n       if(m_isIndexer && m_needMoreParser) { //对最优结果进行进一步细分\n                while (m_pTempCur < m_BestWord + m_iBestWordLength) {\n                        if(m_processedParsedWordsNum == m_totalParsedWordsNum) {\n                                size_t minWordLength = m_pResultPair[0].length;\n                                for(int i = 1; i < m_totalParsedWordsNum; i++) {\n                                        if(m_pResultPair[i].length < minWordLength) {\n                                                minWordLength = m_pResultPair[i].length;\n                                        }\n                                }\n                                m_pTempCur += minWordLength;\n                                m_pText=(Darts::DoubleArray::key_type *)(m_pCur + (m_pTempCur - m_BestWord));\n                                iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-(m_pCur+(m_pTempCur-m_Best\nWord)));\n                                m_totalParsedWordsNum = iNum;\n                                m_processedParsedWordsNum = 0;\n                        } else {\n                                iWordLength = m_pResultPair[m_processedParsedWordsNum].length;\n                                m_processedParsedWordsNum++;\n                                if (m_pTempCur == m_BestWord && iWordLength == m_iBestWordLength) { //是最优分词结果,跳过\n                                        continue;\n                                }\n                                memcpy(m_sAccum, m_pText, iWordLength);\n                                m_sAccum[iWordLength]='\\0';\n\n                                m_pTokenStart = m_pCur + (m_pTempCur - m_BestWord);\n                                m_pTokenEnd = m_pCur + (m_pTempCur - m_BestWord) + iWordLength;\n                                return m_sAccum;\n                        }\n                }\n                m_pCur += m_iBestWordLength;\n                m_needMoreParser = false;\n                iWordLength = 0;\n        }\n```\n在 iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-m_pCur);语句后面，增加如下语句 \n``` c\n            if(m_isIndexer && iNum > 1) {\n                        m_iBestWordLength=getBestWordLength(m_pText, m_pBufferMax-m_pCur); //使用mmseg得到最优分词结果\n                        memcpy(m_sAccum, m_pText, m_iBestWordLength);\n                        m_sAccum[m_iBestWordLength]='\\0';\n                        m_pTokenStart = m_pCur;\n                        m_pTokenEnd = m_pCur + m_iBestWordLength;\n\n                        m_totalParsedWordsNum = iNum;\n                        m_needMoreParser = true;\n                        m_processedParsedWordsNum = 0;\n                        memcpy(m_BestWord, m_pText, m_iBestWordLength);\n                        m_BestWord[m_iBestWordLength]='\\0';\n                        m_pTempCur = m_BestWord;\n                        return m_sAccum;\n                }\n```\n需要修改的地方就这么多。重新编译，生成后indexer后,设置环境变量,export IS_INDEXER=1，重建索引即可。这里需要注意的一点是，必须使用修改代码之前的searchd，这样才会符合我们的需求，如果使用修改代码之后的searchd,搜索西海时，会分成西海，西，海，然后去搜索，这就不是我们想要的。\n\n对于代码，有几个关键的地方需要分明的。\n1.GetToken函数\n这个行数每次返回一个词，也就是分词的结果，返回前，需要设置m_pTokenStart和m_pTokenEnd,标示这个词在内容中的开始位置和结束位置。当返回值为NULL时，标示分词结束\n\n2.m_pCur\n这个用来标示当前的指针在内容的偏移位置，前面说到的设置m_pTokenStart和m_pTokenEnd就需要用到这个值\n\n3.commonPrefixSearch函数\n调用这个函数会返回所有共同前缀的词，结果保存在m_pResultPair中。例如m_pText当前位置是西，则会返回西，西海，西海岸这三个有共同前缀的词。\n\n4.getBestWordLength函数\n这个函数使用mmseg算法，得到下次分词最优结果的长度。例如m_pText当前位置是西，最优分词结果是西海岸，而在utf-8中，一个字为三个字节，所以函数返回8。\n\n因为代码简单，所以就不细说了。这个修改，唯一不足的是，无法做到精确匹配。也是说，假设两个地点，一个是北京，一个是北京大学，搜索北京时，无法保证北京是排在第一个，即使它和搜索词精确匹配。这是因为在对北京进行更细粒度分词时，将北京分成北京,北,京这个三个词，这样破坏了Sphinx用来判断精确匹配的一些设置。为了纠正这个错误，组长和我又写了一些代码，这部分新增的代码就没有上面那部分好理解了，同时写的也有一些别扭。","source":"_posts/Sphinx-for-Chinese的分词细粒度问题.md","raw":"title: Sphinx-for-Chinese的分词细粒度问题\ntags:\n  - mmseg\n  - Sphinx-for-chinese\n  - 分词\n  - 粒度\nid: 769\ncategories:\n  - 搜索引擎\ndate: 2014-06-28 22:31:51\n---\n\n假如使用Sphinx来做搜索引擎，就一定会遇到分词问题。对于中文，有两个选择，选择1是使用Sphinx自带的一元分词，选择2是使用CoreSeek或者Sphinx-for-Chinese，这两个都使用了mmseg来进行分词。据我了解,CoreSeek在支持细粒度的分词，而Sphinx-for-Chinese不支持。而公司使用的是Sphinx-for-Chinese,所以就遇到了分词的粒度问题。\n\n根据产品人员的反馈，有许多这样的例子。例如搜索西海或者海岸时，搜不到大华西海岸酒店，搜索兵马俑时，搜不到秦始皇兵马俑博物馆,搜索肯尼亚时搜不到肯尼亚山。这都是因为Sphinx-for-Chinese使用mmseg得到最优结果后，就不在进行细分的结果。拿大华西海岸酒店这个例子来说，词典里有大华，西海岸，酒店，华西，西海，海岸这些词，根据mmseg得到的最优分词结果，分成大华+西海岸+酒店，这个分词的结果也是正确的，可是搜索西海，海岸就搜不到它的。问过Sphinx-for-Chinese的开发人员后，要想支持更细粒度的分词，只有修改源码。\n\n在组长划出一条线，需要在哪一部分代码后，一个最简单的想法是，对于mmseg中每一步得到的最优结果，都进行更细粒度的划分。例如上面的例子，对于西海岸进行更细粒度划分后，就可以得到西海和海岸，这样搜索西海和海岸时，就可以搜索到。于是立马动手写，折腾一个上午后，果然可以搜到了，这样就达到了同城旅游中酒店搜索的效果了。可是搜索华西还是搜不到，而携程则可以搜到，在携程里，搜索西也可以搜到它。仔细考虑后，在原来的代码里只需要很少的修改就可以做到搜索华西是也可以搜到它，搜索效果已经超过了同程旅游。在增加单字索引后，搜索效果和携程相当接近。\n\n相信许多使用Sphinx-for-Chinese都会遇到类似的问题，也都将用各自的办法解决这个问题。这里将这一部分代码开源，也算是对开源事业的一点点贡献。事实上，需要修改的地方并不是很多。这里我使用的是sphinx-for-chinese-2.2.1-dev-r4311版本,相信其它版本也可以进行类似的修改。需要修改的文件只有一个，那就是sphinx.cpp。\n\n在2244行附近，class CSphTokenizer_UTF8Chinese : public CSphTokenizer_UTF8_Base这个类中,增加以下数据成员\n``` c\nint m_totalParsedWordsNum; //总共得到的分词结果\nint m_processedParsedWordsNum; //已经处理的分词个数\nint m_isIndexer; //标示是否是indexer程序\nbool m_needMoreParser; //标示是否需要更细粒度分词\nconst char * m_pTempCur; //标示在m_BestWord中的位置\nchar m_BestWord[3 * SPH_MAX_WORD_LEN + 3]; //记录使用mmseg得到的最优分词结果\nint m_iBestWordLength; //最优分词结果的长度\n```\n\n在6404行附近CSphTokenizer_UTF8Chinese<IS_QUERY>::CSphTokenizer_UTF8Chinese ()这个构造函数中，增加以下语句进行初始化。\n``` c\n char *penv = getenv(\"IS_INDEXER\");\n        if (penv != NULL) {\n                m_isIndexer = 1;\n        } else {\n                m_isIndexer = 0;\n        }\n        m_needMoreParser = false;\n```\n在6706行附近BYTE * CSphTokenizer_UTF8Chinese<IS_QUERY>::GetToken ()函数中int iNum;语句后面增加如下语句\n``` c\n       if(m_isIndexer && m_needMoreParser) { //对最优结果进行进一步细分\n                while (m_pTempCur < m_BestWord + m_iBestWordLength) {\n                        if(m_processedParsedWordsNum == m_totalParsedWordsNum) {\n                                size_t minWordLength = m_pResultPair[0].length;\n                                for(int i = 1; i < m_totalParsedWordsNum; i++) {\n                                        if(m_pResultPair[i].length < minWordLength) {\n                                                minWordLength = m_pResultPair[i].length;\n                                        }\n                                }\n                                m_pTempCur += minWordLength;\n                                m_pText=(Darts::DoubleArray::key_type *)(m_pCur + (m_pTempCur - m_BestWord));\n                                iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-(m_pCur+(m_pTempCur-m_Best\nWord)));\n                                m_totalParsedWordsNum = iNum;\n                                m_processedParsedWordsNum = 0;\n                        } else {\n                                iWordLength = m_pResultPair[m_processedParsedWordsNum].length;\n                                m_processedParsedWordsNum++;\n                                if (m_pTempCur == m_BestWord && iWordLength == m_iBestWordLength) { //是最优分词结果,跳过\n                                        continue;\n                                }\n                                memcpy(m_sAccum, m_pText, iWordLength);\n                                m_sAccum[iWordLength]='\\0';\n\n                                m_pTokenStart = m_pCur + (m_pTempCur - m_BestWord);\n                                m_pTokenEnd = m_pCur + (m_pTempCur - m_BestWord) + iWordLength;\n                                return m_sAccum;\n                        }\n                }\n                m_pCur += m_iBestWordLength;\n                m_needMoreParser = false;\n                iWordLength = 0;\n        }\n```\n在 iNum = m_tDa.commonPrefixSearch(m_pText, m_pResultPair, 256, m_pBufferMax-m_pCur);语句后面，增加如下语句 \n``` c\n            if(m_isIndexer && iNum > 1) {\n                        m_iBestWordLength=getBestWordLength(m_pText, m_pBufferMax-m_pCur); //使用mmseg得到最优分词结果\n                        memcpy(m_sAccum, m_pText, m_iBestWordLength);\n                        m_sAccum[m_iBestWordLength]='\\0';\n                        m_pTokenStart = m_pCur;\n                        m_pTokenEnd = m_pCur + m_iBestWordLength;\n\n                        m_totalParsedWordsNum = iNum;\n                        m_needMoreParser = true;\n                        m_processedParsedWordsNum = 0;\n                        memcpy(m_BestWord, m_pText, m_iBestWordLength);\n                        m_BestWord[m_iBestWordLength]='\\0';\n                        m_pTempCur = m_BestWord;\n                        return m_sAccum;\n                }\n```\n需要修改的地方就这么多。重新编译，生成后indexer后,设置环境变量,export IS_INDEXER=1，重建索引即可。这里需要注意的一点是，必须使用修改代码之前的searchd，这样才会符合我们的需求，如果使用修改代码之后的searchd,搜索西海时，会分成西海，西，海，然后去搜索，这就不是我们想要的。\n\n对于代码，有几个关键的地方需要分明的。\n1.GetToken函数\n这个行数每次返回一个词，也就是分词的结果，返回前，需要设置m_pTokenStart和m_pTokenEnd,标示这个词在内容中的开始位置和结束位置。当返回值为NULL时，标示分词结束\n\n2.m_pCur\n这个用来标示当前的指针在内容的偏移位置，前面说到的设置m_pTokenStart和m_pTokenEnd就需要用到这个值\n\n3.commonPrefixSearch函数\n调用这个函数会返回所有共同前缀的词，结果保存在m_pResultPair中。例如m_pText当前位置是西，则会返回西，西海，西海岸这三个有共同前缀的词。\n\n4.getBestWordLength函数\n这个函数使用mmseg算法，得到下次分词最优结果的长度。例如m_pText当前位置是西，最优分词结果是西海岸，而在utf-8中，一个字为三个字节，所以函数返回8。\n\n因为代码简单，所以就不细说了。这个修改，唯一不足的是，无法做到精确匹配。也是说，假设两个地点，一个是北京，一个是北京大学，搜索北京时，无法保证北京是排在第一个，即使它和搜索词精确匹配。这是因为在对北京进行更细粒度分词时，将北京分成北京,北,京这个三个词，这样破坏了Sphinx用来判断精确匹配的一些设置。为了纠正这个错误，组长和我又写了一些代码，这部分新增的代码就没有上面那部分好理解了，同时写的也有一些别扭。","slug":"Sphinx-for-Chinese的分词细粒度问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4or00l726s63yi8qs67"},{"title":"Sphinx-for-Chinese的分词细粒度问题(续)","id":"781","date":"2014-07-08T13:11:45.000Z","_content":"\n在[Sphinx-for-Chinese的分词细粒度问题](http://program.dengshilong.org/2014/06/28/sphinx-for-chinese的分词细粒度问题/)中说过，为了解决分词的粒度问题，我们对Sphinx-for-Chinese的代码进行了一些修改，而针对精确匹配我们也写了一些额外的代码，虽然这一部分的代码并不是很好看，但毕竟解决了问题，所以也想对这一部分进行说明，因为相信其他人也会遇到类似的问题，这里可以提供一个参考的解决方案。\n\n所谓精确匹配，也就是搜索的词语搜索的字段完全相同。例如假设有三个标题,中大，中大酒店，中大假日酒店，则搜索中大时，与中大完全匹配。一般情况下，我们都希望精确匹配的内容排在前面，此时还需要设置排序方法为SPH_RANK_SPH04。\n\n依然以sphinx-for-chinese-2.2.1-dev-r4311为例，在sphinxsearch.cpp中6282行附近，找到RankerState_ProximityBM25Exact_fn，这里就是sph04的实现。看到数据成员m_uExactHit，知道这个与精确匹配有关，在这段代码里看到HITMAN::IsEnd，于是猜测在某个地方有SetEnd,在sphinx.cpp中27144行附近找到CSphSource_Document::BuildRegularHits方法，在这里找到了，\nCSphWordHit * pHit = const_cast < CSphWordHit * > ( m_tHits.Last() );\nHITMAN::SetEndMarker ( &pHit->m_iWordPos );\n于是我们想，在进行细粒度分词时，中大将被分成，中大、中、大三个词。只要有某种办法，将中大这个词也使用SetEndMarker就可以达到所要的目的，于是增加了一些代码。\n\n这之后，搜索中大时，中大这个标题确实排在了前面，可是问题又出现了，在搜索中大酒店时，中大酒店这个标题并没有排在前面，中大酒店与中大假日酒店的权重是相同的。分析了原因，搜索中大酒店时，将被分成中大+酒店，而中大假日酒店中，正好也包含中大和酒店，并且酒店也是排在末尾，于是这两个的权重是一样的。于是我们只好再看看m_uExactHit的计算，发现IsEnd并不是唯一的条件，于是相信为细分以前，索引中大酒店时，分词的词是中大、酒店，而细分后变成了中大、中、大、大酒店、酒店、酒、店，于是我们猜测，如果将分词按照原先的方法分一次，之后再一起返回细粒度的分词，可能可以达到目的。这样的结果就是分词返回的是中大、酒店、中、大、大酒店、酒、店。于是按照这个想法，又增加了一些代码。果然这次搜索中大酒店时，中大酒店排在了前面，并且权重比中大假日酒店高。","source":"_posts/Sphinx-for-Chinese的分词细粒度问题(续).md","raw":"title: Sphinx-for-Chinese的分词细粒度问题(续)\ntags:\n  - Sphinx-for-chinese\n  - SPH_RANK_SPH04\n  - 分词粒度\n  - 精确匹配\nid: 781\ncategories:\n  - 搜索引擎\ndate: 2014-07-08 21:11:45\n---\n\n在[Sphinx-for-Chinese的分词细粒度问题](http://program.dengshilong.org/2014/06/28/sphinx-for-chinese的分词细粒度问题/)中说过，为了解决分词的粒度问题，我们对Sphinx-for-Chinese的代码进行了一些修改，而针对精确匹配我们也写了一些额外的代码，虽然这一部分的代码并不是很好看，但毕竟解决了问题，所以也想对这一部分进行说明，因为相信其他人也会遇到类似的问题，这里可以提供一个参考的解决方案。\n\n所谓精确匹配，也就是搜索的词语搜索的字段完全相同。例如假设有三个标题,中大，中大酒店，中大假日酒店，则搜索中大时，与中大完全匹配。一般情况下，我们都希望精确匹配的内容排在前面，此时还需要设置排序方法为SPH_RANK_SPH04。\n\n依然以sphinx-for-chinese-2.2.1-dev-r4311为例，在sphinxsearch.cpp中6282行附近，找到RankerState_ProximityBM25Exact_fn，这里就是sph04的实现。看到数据成员m_uExactHit，知道这个与精确匹配有关，在这段代码里看到HITMAN::IsEnd，于是猜测在某个地方有SetEnd,在sphinx.cpp中27144行附近找到CSphSource_Document::BuildRegularHits方法，在这里找到了，\nCSphWordHit * pHit = const_cast < CSphWordHit * > ( m_tHits.Last() );\nHITMAN::SetEndMarker ( &pHit->m_iWordPos );\n于是我们想，在进行细粒度分词时，中大将被分成，中大、中、大三个词。只要有某种办法，将中大这个词也使用SetEndMarker就可以达到所要的目的，于是增加了一些代码。\n\n这之后，搜索中大时，中大这个标题确实排在了前面，可是问题又出现了，在搜索中大酒店时，中大酒店这个标题并没有排在前面，中大酒店与中大假日酒店的权重是相同的。分析了原因，搜索中大酒店时，将被分成中大+酒店，而中大假日酒店中，正好也包含中大和酒店，并且酒店也是排在末尾，于是这两个的权重是一样的。于是我们只好再看看m_uExactHit的计算，发现IsEnd并不是唯一的条件，于是相信为细分以前，索引中大酒店时，分词的词是中大、酒店，而细分后变成了中大、中、大、大酒店、酒店、酒、店，于是我们猜测，如果将分词按照原先的方法分一次，之后再一起返回细粒度的分词，可能可以达到目的。这样的结果就是分词返回的是中大、酒店、中、大、大酒店、酒、店。于是按照这个想法，又增加了一些代码。果然这次搜索中大酒店时，中大酒店排在了前面，并且权重比中大假日酒店高。","slug":"Sphinx-for-Chinese的分词细粒度问题(续)","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ou00lf26s6dipl1s9h"},{"title":"Spark初体验","date":"2016-04-26T14:15:55.000Z","_content":"因为Oryx推荐引擎需要用到Spark, 所以开始了解Spark, \n\n按照[使用Spark MLlib给豆瓣用户推荐电影](http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/)写了一个[Python版本](https://github.com/dengshilong/douban_recommender), 算是有了一个初步了解。只是不知道推荐效果怎样，关键是不好测试效果。\n\n使用的过程中遇到一个问题\n\n### org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://localhost:9000/user/long/README.md\n这是在执行[官方文档例子quickstart例子](http://spark.apache.org/docs/latest/quick-start.html)时遇到，\n```\n>>> textFile = sc.textFile(&quot;README.md&quot;)\n>>> textFile.count()\n```\n一直想不通，后来想到在测试Oryx的例子时，在conf/spark-env.sh里配置了HADOOP_CONF_DIR，把它注释掉即可。\n\n而之所以之前配置了HADOOP_CONF_DIR, 是因为在执行Oryx的例子时，会使用bin/spark-submit --master yarn-client提交，此时如果没有配置HADOOP_CONF_DIR, 会报Exception in thread \"main\" java.lang.Exception: When running with master 'yarn-client' either HADOOP_CONF_DIR or YARN_CONF_DIR must be set in the environment.错误。\n\n参考文章\n* http://spark.apache.org/docs/latest/\n* https://www.codementor.io/spark/tutorial/building-a-recommender-with-apache-spark-python-example-app-part1\n* http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/\n","source":"_posts/Spark初体验.md","raw":"title: Spark初体验\ndate: 2016-04-26 22:15:55\ntags:\n    - Spark\ncategories:\n    - 大数据\n---\n因为Oryx推荐引擎需要用到Spark, 所以开始了解Spark, \n\n按照[使用Spark MLlib给豆瓣用户推荐电影](http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/)写了一个[Python版本](https://github.com/dengshilong/douban_recommender), 算是有了一个初步了解。只是不知道推荐效果怎样，关键是不好测试效果。\n\n使用的过程中遇到一个问题\n\n### org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://localhost:9000/user/long/README.md\n这是在执行[官方文档例子quickstart例子](http://spark.apache.org/docs/latest/quick-start.html)时遇到，\n```\n>>> textFile = sc.textFile(&quot;README.md&quot;)\n>>> textFile.count()\n```\n一直想不通，后来想到在测试Oryx的例子时，在conf/spark-env.sh里配置了HADOOP_CONF_DIR，把它注释掉即可。\n\n而之所以之前配置了HADOOP_CONF_DIR, 是因为在执行Oryx的例子时，会使用bin/spark-submit --master yarn-client提交，此时如果没有配置HADOOP_CONF_DIR, 会报Exception in thread \"main\" java.lang.Exception: When running with master 'yarn-client' either HADOOP_CONF_DIR or YARN_CONF_DIR must be set in the environment.错误。\n\n参考文章\n* http://spark.apache.org/docs/latest/\n* https://www.codementor.io/spark/tutorial/building-a-recommender-with-apache-spark-python-example-app-part1\n* http://colobu.com/2015/11/30/movie-recommendation-for-douban-users-by-spark-mllib/\n","slug":"Spark初体验","published":1,"updated":"2016-04-26T14:17:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4oy00lo26s62qr1ozgd"},{"title":"Solr索引升级错误","id":"952","date":"2014-11-08T07:53:58.000Z","_content":"\n最近需要将Solr从1.4升级到4.8，于是需要将索引数据进行升级，而1.4无法直接升级到4.8，需要经过如下转化。从1.4升级到3.6，3.6升级到4.0，4.0升级到4.8。有几个引擎的数据升级很顺利，可是也有那么几个引擎的数据升级过程中出现了错误。\n\n错误都出现在4.0升级到4.8时。调用栈如下：\nCaused by: java.lang.IllegalArgumentException: maxValue must be non-negative (got: -1)\n        at org.apache.lucene.util.packed.PackedInts.bitsRequired(PackedInts.java:1180)\n        at org.apache.lucene.codecs.lucene41.ForUtil.bitsRequired(ForUtil.java:243)\n        at org.apache.lucene.codecs.lucene41.ForUtil.writeBlock(ForUtil.java:164)\n        at org.apache.lucene.codecs.lucene41.Lucene41PostingsWriter.addPosition(Lucene41PostingsWriter.java:368)\n        at org.apache.lucene.codecs.PostingsConsumer.merge(PostingsConsumer.java:123)\n        at org.apache.lucene.codecs.TermsConsumer.merge(TermsConsumer.java:164)\n        at org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:72)\n        at org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:389)\n        at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:112)\n        at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4132)\n        at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3728)\n        at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n        at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)\n\n看代码后，在PostingsConsumer 120行附近，final int position = postingsEnum.nextPosition();，这个position是负的，所以报错。看这附近的代码，知道是对索引词的在文档中的位置信息进行压缩。可是词在文档中的位置不应该是负的，于是报错。问题是，为什么这里会出现负的位置，只能解释是数据问题。一个解决的办法是跳过为负的位置，如此升级确实成功了，只是不知道有没有什么副作用。","source":"_posts/Solr索引升级错误.md","raw":"title: Solr索引升级错误\ntags:\n  - solr\n  - 升级\n  - 索引\nid: 952\ncategories:\n  - 搜索引擎\ndate: 2014-11-08 15:53:58\n---\n\n最近需要将Solr从1.4升级到4.8，于是需要将索引数据进行升级，而1.4无法直接升级到4.8，需要经过如下转化。从1.4升级到3.6，3.6升级到4.0，4.0升级到4.8。有几个引擎的数据升级很顺利，可是也有那么几个引擎的数据升级过程中出现了错误。\n\n错误都出现在4.0升级到4.8时。调用栈如下：\nCaused by: java.lang.IllegalArgumentException: maxValue must be non-negative (got: -1)\n        at org.apache.lucene.util.packed.PackedInts.bitsRequired(PackedInts.java:1180)\n        at org.apache.lucene.codecs.lucene41.ForUtil.bitsRequired(ForUtil.java:243)\n        at org.apache.lucene.codecs.lucene41.ForUtil.writeBlock(ForUtil.java:164)\n        at org.apache.lucene.codecs.lucene41.Lucene41PostingsWriter.addPosition(Lucene41PostingsWriter.java:368)\n        at org.apache.lucene.codecs.PostingsConsumer.merge(PostingsConsumer.java:123)\n        at org.apache.lucene.codecs.TermsConsumer.merge(TermsConsumer.java:164)\n        at org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:72)\n        at org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:389)\n        at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:112)\n        at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4132)\n        at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3728)\n        at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)\n        at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)\n\n看代码后，在PostingsConsumer 120行附近，final int position = postingsEnum.nextPosition();，这个position是负的，所以报错。看这附近的代码，知道是对索引词的在文档中的位置信息进行压缩。可是词在文档中的位置不应该是负的，于是报错。问题是，为什么这里会出现负的位置，只能解释是数据问题。一个解决的办法是跳过为负的位置，如此升级确实成功了，只是不知道有没有什么副作用。","slug":"Solr索引升级错误","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4p100lt26s6w64x22ch"},{"title":"Solr索引升级","id":"984","date":"2014-12-27T02:27:18.000Z","_content":"\n相信现在很多人还在用Solr1.4,因为Solr1.4许多时候还是满足需求了。可是总有一天会想升级，因为新版本中的一些功能和特性让使用Solr更加方便。而如果要从Solr1.4升级到Solr4.8,可以经过Solr1.4->Solr3.6->Solr4.0->Solr4.8这个步骤.\n\n从Solr1.4->Solr3.6，去官网下载Solr3.6,使用需要升级的索引搭建起Solr引擎，执行curl 'http://localhost:8983/solr/update?optimize=true&maxSegments=1&waitFlush=false' 即可\n\n从Solr3.6->Solr4.0,去官网下载Solr4.0, 将lucene-core-4.0.jar拷贝到某一目录下，如：lib4.0/lucene-core-4.0.jar(注意，可能需要其它的包如：slf-api和log-back相关包，同样拷贝到lib4.0目录下), 之后执行java -cp \"lib4.0/*\" org.apache.lucene.index.IndexUpgrader -verbose index/, 这里 index目录存放着Solr3.6索引文件。\n\n从Solr4.0->Solr4.8, 去官网下载Solr4.8,将lucene-core-4.8拷贝到某一目录下, 如：lib4.0/lucene-core-4.8.jar,之后执行../jdk1.7/bin/java -cp \"lib4.8/*\" org.apache.lucene.index.IndexUpgrader -delete-prior-commits -verbose index/，这里因为Solr4.8需要用到jdk1.7，所以执行java命令时，必须是jdk1.7。\n","source":"_posts/Solr索引升级.md","raw":"title: Solr索引升级\ntags:\n  - solr\n  - 索引\nid: 984\ncategories:\n  - 搜索引擎\ndate: 2014-12-27 10:27:18\n---\n\n相信现在很多人还在用Solr1.4,因为Solr1.4许多时候还是满足需求了。可是总有一天会想升级，因为新版本中的一些功能和特性让使用Solr更加方便。而如果要从Solr1.4升级到Solr4.8,可以经过Solr1.4->Solr3.6->Solr4.0->Solr4.8这个步骤.\n\n从Solr1.4->Solr3.6，去官网下载Solr3.6,使用需要升级的索引搭建起Solr引擎，执行curl 'http://localhost:8983/solr/update?optimize=true&maxSegments=1&waitFlush=false' 即可\n\n从Solr3.6->Solr4.0,去官网下载Solr4.0, 将lucene-core-4.0.jar拷贝到某一目录下，如：lib4.0/lucene-core-4.0.jar(注意，可能需要其它的包如：slf-api和log-back相关包，同样拷贝到lib4.0目录下), 之后执行java -cp \"lib4.0/*\" org.apache.lucene.index.IndexUpgrader -verbose index/, 这里 index目录存放着Solr3.6索引文件。\n\n从Solr4.0->Solr4.8, 去官网下载Solr4.8,将lucene-core-4.8拷贝到某一目录下, 如：lib4.0/lucene-core-4.8.jar,之后执行../jdk1.7/bin/java -cp \"lib4.8/*\" org.apache.lucene.index.IndexUpgrader -delete-prior-commits -verbose index/，这里因为Solr4.8需要用到jdk1.7，所以执行java命令时，必须是jdk1.7。\n","slug":"Solr索引升级","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4p400lz26s680kim30c"},{"title":"Solr查询词提取","id":"972","date":"2014-12-04T13:28:02.000Z","_content":"\n最近因为负责一个小功能，所以想尽力做好它。于是对会经常看看用户的查询，看看这些查询的结果是否满足需要，于是需要对这些查询词进行提取。本来还想用Python来写的，后来想想shell才是做这事的最佳方法，于是先从grep开始。\n\nsolr的日志中,query都是跟在‘q=’后面，且参数间用&隔开，于是执行如下命令，\ngrep -o 'q=.*\\&' solr.log\n得到如下结果\nq=磐安&macro.skip=0&qt=macro&wt=json&\nq=磐安+财政&macro.skip=0&qt=macro&wt=json&\nq=保定+财政&macro.skip=0&qt=macro&wt=json&\nq=磐安+财政&macro.skip=0&qt=macro&wt=json&\nq=财政+长春&macro.skip=0&qt=macro&wt=json&\nq=财政+长沙&macro.skip=0&qt=macro&wt=json&\nq=存款收入&macro.skip=0&qt=macro&wt=json&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=利率走势&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=行业经济&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=区域宏观&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=中国宏观&\n\n之后就是截取query部分，这时awk就派上用场了。先用&分割，得到第一段，之后用=分割，得到第二段\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'\n结果如下：\n磐安\n磐安+财政\n保定+财政\n磐安+财政\n财政+长春\n财政+长沙\n存款收入\n存款收入\n存款收入\n存款收入\n存款收入\n\n之后想统计每个查询词的次数，此时先用sort排序，之后用uniq -c来统计，\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'  |sort | uniq -c\n结果如下：\n1 保定+财政\n5 存款收入\n1 磐安\n2 磐安+财政\n1 财政+长春\n1 财政+长沙\n\n而我希望按查询次数从高到低排列，于是再用sort -rn\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'  |sort | uniq -c | sort -rn\n结果如下：\n5 存款收入\n2 磐安+财政 \n1 财政+长沙\n1 财政+长春\n1 磐安\n1 保定+财政\n\n一行代码搞定。一句话，管道实在是太方便了，linux也是如此。","source":"_posts/Solr查询词提取.md","raw":"title: Solr查询词提取\ntags:\n  - awk\n  - grep\n  - sort\n  - uniq\nid: 972\ncategories:\n  - shell\ndate: 2014-12-04 21:28:02\n---\n\n最近因为负责一个小功能，所以想尽力做好它。于是对会经常看看用户的查询，看看这些查询的结果是否满足需要，于是需要对这些查询词进行提取。本来还想用Python来写的，后来想想shell才是做这事的最佳方法，于是先从grep开始。\n\nsolr的日志中,query都是跟在‘q=’后面，且参数间用&隔开，于是执行如下命令，\ngrep -o 'q=.*\\&' solr.log\n得到如下结果\nq=磐安&macro.skip=0&qt=macro&wt=json&\nq=磐安+财政&macro.skip=0&qt=macro&wt=json&\nq=保定+财政&macro.skip=0&qt=macro&wt=json&\nq=磐安+财政&macro.skip=0&qt=macro&wt=json&\nq=财政+长春&macro.skip=0&qt=macro&wt=json&\nq=财政+长沙&macro.skip=0&qt=macro&wt=json&\nq=存款收入&macro.skip=0&qt=macro&wt=json&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=利率走势&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=行业经济&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=区域宏观&\nq=存款收入&qt=macro&wt=json&macro.groupOffset=0&macro.groupNames=中国宏观&\n\n之后就是截取query部分，这时awk就派上用场了。先用&分割，得到第一段，之后用=分割，得到第二段\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'\n结果如下：\n磐安\n磐安+财政\n保定+财政\n磐安+财政\n财政+长春\n财政+长沙\n存款收入\n存款收入\n存款收入\n存款收入\n存款收入\n\n之后想统计每个查询词的次数，此时先用sort排序，之后用uniq -c来统计，\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'  |sort | uniq -c\n结果如下：\n1 保定+财政\n5 存款收入\n1 磐安\n2 磐安+财政\n1 财政+长春\n1 财政+长沙\n\n而我希望按查询次数从高到低排列，于是再用sort -rn\ngrep -o 'q=.*\\&' solr.log | grep -v 'module2:' | grep -v 'solrconfig.xml' | awk -F '&' '{print $1}' | awk -F '=' '{print $2}'  |sort | uniq -c | sort -rn\n结果如下：\n5 存款收入\n2 磐安+财政 \n1 财政+长沙\n1 财政+长春\n1 磐安\n1 保定+财政\n\n一行代码搞定。一句话，管道实在是太方便了，linux也是如此。","slug":"Solr查询词提取","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4p600m326s64bd8i4tz"},{"title":"Solr权限控制solrj认证","id":"1000","date":"2015-01-22T11:44:28.000Z","_content":"\n在上篇中，我们通过在jetty中配置，是update需要进行用户名和密码认证，这篇中我们继续介绍如何在solrj中调用update\n\n*测试添加文档 \n先尝试使用solrj,编写测试程序 \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrInputDocume doc1 = new SolrInputDocument(); \nserver.add(docs); \n```\n提示401错误,添加用户名和密码: \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nHttpClientUtil.setBasicAuth((DefaultHttpClient) server.getHttpClient(), \"index\", \"update\"); \nSolrInputDocume doc1 = new SolrInputDocument(); \nserver.add(docs); \n```\n提示 NonRepeatableRequestException, Cannot retry request with a non-repeatable request entity. 想跟踪过去,看看错误出自哪里,没办法调到源代码,于是尝试查询. \n*测试查询文档 \n将etc/webdefault.xml中对<url-pattern>/update/*</url-pattern>的限制改成,<url-pattern>/select/*</url-pattern>,编写查询代码, \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrQuery query = new SolrQuery(); \nString q = \"*:*\"; \nquery.setQuery(q); \n```\n提示401错误,添加用户名和密码: \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrQuery query = new SolrQuery(); \nString q = \"*:*\"; \nquery.setQuery(q); \n```\n查询成功, \n\n*问题解决 \n不明白原因,只是猜测post的信息不能反复使用,在setBasicAuth前面有一段说明, \"Currently this is not preemtive authentication. So it is not currently possible to do a post request while using this setting.\",意思就是认证过程不是最先进行的,所以现在不能用于post,可是认证过程可以用于get,于是察看get的执行过程,发现它先执行一次,发现要认证,于是再执行一次,而第二次执行时会先执行认证过程. 对于post过程,如果 可以执行同样的过程,那就可以达到目的,关键问题是\"Cannot retry request with a non-repeatable request entity\",于是查看solr-4470是如何实现的,看到HttpSolrServer里代码如下: \n ``` java\n if (contentStream[0] instanceof RequestWriter.LazyContentStream) {\n    post.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {\n      @Override\n      public Header getContentType() {\n        return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n      }\n\n      @Override\n      public boolean isRepeatable() {\n        return false;\n      }\n\n    });\n  } else {\n    post.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {\n      @Override\n      public Header getContentType() {\n        return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n      }\n\n      @Override\n      public boolean isRepeatable() {\n        return false;\n      }\n    });\n  }\n ```\n修改成 \n ``` java\n HttpEntity entity = new InputStreamEntity(contentStream[0].getStream(), -1) {\n     @Override\n     public Header getContentType() {\n         return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n     }\n     @Override\n     public boolean isRepeatable() {\n         return false;\n     }  \n };\n entity = new BufferedHttpEntity(entity);\n ```\n\n在生产环境中，可以添加参数控制是否需要entity = new BufferedHttpEntity(entity);和HttpClientUtil.setBasicAuth((DefaultHttpClient) server.getHttpClient(), \"index\", \"update\");这两句\n","source":"_posts/Solr权限控制solrj认证.md","raw":"title: Solr权限控制solrj认证\ntags:\n  - security\n  - solr\n  - solrj\nid: 1000\ncategories:\n  - 搜索引擎\ndate: 2015-01-22 19:44:28\n---\n\n在上篇中，我们通过在jetty中配置，是update需要进行用户名和密码认证，这篇中我们继续介绍如何在solrj中调用update\n\n*测试添加文档 \n先尝试使用solrj,编写测试程序 \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrInputDocume doc1 = new SolrInputDocument(); \nserver.add(docs); \n```\n提示401错误,添加用户名和密码: \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nHttpClientUtil.setBasicAuth((DefaultHttpClient) server.getHttpClient(), \"index\", \"update\"); \nSolrInputDocume doc1 = new SolrInputDocument(); \nserver.add(docs); \n```\n提示 NonRepeatableRequestException, Cannot retry request with a non-repeatable request entity. 想跟踪过去,看看错误出自哪里,没办法调到源代码,于是尝试查询. \n*测试查询文档 \n将etc/webdefault.xml中对<url-pattern>/update/*</url-pattern>的限制改成,<url-pattern>/select/*</url-pattern>,编写查询代码, \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrQuery query = new SolrQuery(); \nString q = \"*:*\"; \nquery.setQuery(q); \n```\n提示401错误,添加用户名和密码: \n``` java\nString url = \"http://localhost:8989/solr\"; \nHttpSolrServer server = new HttpSolrServer(url); \nSolrQuery query = new SolrQuery(); \nString q = \"*:*\"; \nquery.setQuery(q); \n```\n查询成功, \n\n*问题解决 \n不明白原因,只是猜测post的信息不能反复使用,在setBasicAuth前面有一段说明, \"Currently this is not preemtive authentication. So it is not currently possible to do a post request while using this setting.\",意思就是认证过程不是最先进行的,所以现在不能用于post,可是认证过程可以用于get,于是察看get的执行过程,发现它先执行一次,发现要认证,于是再执行一次,而第二次执行时会先执行认证过程. 对于post过程,如果 可以执行同样的过程,那就可以达到目的,关键问题是\"Cannot retry request with a non-repeatable request entity\",于是查看solr-4470是如何实现的,看到HttpSolrServer里代码如下: \n ``` java\n if (contentStream[0] instanceof RequestWriter.LazyContentStream) {\n    post.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {\n      @Override\n      public Header getContentType() {\n        return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n      }\n\n      @Override\n      public boolean isRepeatable() {\n        return false;\n      }\n\n    });\n  } else {\n    post.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {\n      @Override\n      public Header getContentType() {\n        return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n      }\n\n      @Override\n      public boolean isRepeatable() {\n        return false;\n      }\n    });\n  }\n ```\n修改成 \n ``` java\n HttpEntity entity = new InputStreamEntity(contentStream[0].getStream(), -1) {\n     @Override\n     public Header getContentType() {\n         return new BasicHeader(\"Content-Type\", contentStream[0].getContentType());\n     }\n     @Override\n     public boolean isRepeatable() {\n         return false;\n     }  \n };\n entity = new BufferedHttpEntity(entity);\n ```\n\n在生产环境中，可以添加参数控制是否需要entity = new BufferedHttpEntity(entity);和HttpClientUtil.setBasicAuth((DefaultHttpClient) server.getHttpClient(), \"index\", \"update\");这两句\n","slug":"Solr权限控制solrj认证","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pa00mc26s6bok0vbe0"},{"title":"Solr权限控制","id":"994","date":"2015-01-20T13:47:37.000Z","_content":"\n有些情况下，想给Solr增加权限控制，这样就不会被随意更新和删除。关于这点，在[https://wiki.apache.org/solr/SolrSecurity](https://wiki.apache.org/solr/SolrSecurity)有详细的描述。觉得最坑人的一点是Solr-4470还没resolved。不管它，先使用Jetty添加权限控制\n\n下载已经编译好的solr-4.8.0,进入example目录\n编辑etc/webdefault.xml,添加如下内容:\n```\n<security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Solr authenticated application</web-resource-name>\n      <url-pattern>/update/*</url-pattern>\n    </web-resource-collection>\n    <auth-constraint>\n      <role-name>update-role</role-name>\n    </auth-constraint>\n  </security-constraint>\n\n  <login-config>\n    <auth-method>BASIC</auth-method>\n    <realm-name>Solr Update</realm-name>\n  </login-config>\n\n```\n编辑 etc/jetty.xml, 添加如下内容：\n```\n <Call name=\"addBean\">\n      <Arg>\n        <New class=\"org.eclipse.jetty.security.HashLoginService\">\n          <Set name=\"name\">Solr Update</Set>\n          <Set name=\"config\"><SystemProperty name=\"jetty.home\" default=\".\"/>/etc/realm.properties</Set>\n          <Set name=\"refreshInterval\">0</Set>\n        </New>\n      </Arg>\n    </Call>\n```\n增加 etc/realm.properties,写入如下内容，也就是用户名，密码以及角色：\n```\nindex: update, update-role\n```\n启动solr,到exampledocs目录下执行./post.sh solr.xml,返回401错误，说明未认证。修改post.sh,在调用curl时加上用户名和密码，如下：\ncurl --user index:update $URL --data-binary @$f -H 'Content-type:application/xml'\n\n再次执行./post.sh solr.xml,执行成功，到solr后台查看,可以看到添加文件成功,说明认证设置成功\n","source":"_posts/Solr权限控制.md","raw":"title: Solr权限控制\ntags:\n  - security\n  - solr\nid: 994\ncategories:\n  - 搜索引擎\ndate: 2015-01-20 21:47:37\n---\n\n有些情况下，想给Solr增加权限控制，这样就不会被随意更新和删除。关于这点，在[https://wiki.apache.org/solr/SolrSecurity](https://wiki.apache.org/solr/SolrSecurity)有详细的描述。觉得最坑人的一点是Solr-4470还没resolved。不管它，先使用Jetty添加权限控制\n\n下载已经编译好的solr-4.8.0,进入example目录\n编辑etc/webdefault.xml,添加如下内容:\n```\n<security-constraint>\n    <web-resource-collection>\n      <web-resource-name>Solr authenticated application</web-resource-name>\n      <url-pattern>/update/*</url-pattern>\n    </web-resource-collection>\n    <auth-constraint>\n      <role-name>update-role</role-name>\n    </auth-constraint>\n  </security-constraint>\n\n  <login-config>\n    <auth-method>BASIC</auth-method>\n    <realm-name>Solr Update</realm-name>\n  </login-config>\n\n```\n编辑 etc/jetty.xml, 添加如下内容：\n```\n <Call name=\"addBean\">\n      <Arg>\n        <New class=\"org.eclipse.jetty.security.HashLoginService\">\n          <Set name=\"name\">Solr Update</Set>\n          <Set name=\"config\"><SystemProperty name=\"jetty.home\" default=\".\"/>/etc/realm.properties</Set>\n          <Set name=\"refreshInterval\">0</Set>\n        </New>\n      </Arg>\n    </Call>\n```\n增加 etc/realm.properties,写入如下内容，也就是用户名，密码以及角色：\n```\nindex: update, update-role\n```\n启动solr,到exampledocs目录下执行./post.sh solr.xml,返回401错误，说明未认证。修改post.sh,在调用curl时加上用户名和密码，如下：\ncurl --user index:update $URL --data-binary @$f -H 'Content-type:application/xml'\n\n再次执行./post.sh solr.xml,执行成功，到solr后台查看,可以看到添加文件成功,说明认证设置成功\n","slug":"Solr权限控制","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pe00mj26s67v6in4of"},{"title":"Solr分布式请求stage理解","id":"940","date":"2014-10-20T12:52:51.000Z","_content":"\n从QueryComponent可以知道，一个分布式solr请求从发起请求到对响应的结果进行处理会经历许多的stage.\n\n对于分布式普通请求，从private int regularDistributedProcess(ResponseBuilder rb)的实现中可以看到，会经历ResponseBuilder.STAGE_PARSE_QUERY,ResponseBuilder.STAGE_EXECUTE_QUERY,ResponseBuilder.STAGE_GET_FIELDS,ResponseBuilder.STAGE_DONE等stage。从private void handleRegularResponses(ResponseBuilder rb, ShardRequest sreq)，分布式普通请求有ShardRequest.PURPOSE_GET_TOP_IDS，ShardRequest.PURPOSE_GET_FIELDS两次响应\n\n对于分布式group请求,从private int groupedDistributedProcess(ResponseBuilder rb)的实现中可以看到，则会经历ResponseBuilder.STAGE_PARSE_QUERY，ResponseBuilder.STAGE_TOP_GROUPS，ResponseBuilder.STAGE_EXECUTE_QUERY，ResponseBuilder.STAGE_GET_FIELDS，ResponseBuilder.STAGE_DONE等stage。从private void handleGroupedResponses(ResponseBuilder rb, ShardRequest sreq)可以看到，分布式group请求有ShardRequest.PURPOSE_GET_TOP_GROUPS,ShardRequest.PURPOSE_GET_TOP_IDS,ShardRequest.PURPOSE_GET_FIELDS三次响应.\n\n对于不同的请求和响应，有相应的类或者方法来实现。当然也可以自己实现相应的类或者方法来处理。即便是QueryComponent也可以自己定义，只需要实现相应的接口即可。\n\n对于private int regularDistributedProcess(ResponseBuilder rb),一个可能的实现是：\n``` java\n private int regularDistributedProcess(ResponseBuilder rb) {\n        ComponentDistributedStage cdStage = stages.getCDStage(rb.stage);\n        int nextState = ResponseBuilder.STAGE_DONE;\n        if (cdStage != null) {\n            cdStage.distributedProcess(rb, this);\n            if (stages.containsNextState(rb.stage))\n                nextState = stages.getNextState(rb.stage);\n        }\n        return nextState;\n    }\n```\n这里stages是一个Map,保存相应stage的实现类，父类型为ComponentDistributedStage。具体实现一个stage时，实现相应的接口即可。","source":"_posts/Solr分布式请求stage理解.md","raw":"title: Solr分布式请求stage理解\ntags:\n  - solr\n  - stage\n  - 分布式\nid: 940\ncategories:\n  - 搜索引擎\ndate: 2014-10-20 20:52:51\n---\n\n从QueryComponent可以知道，一个分布式solr请求从发起请求到对响应的结果进行处理会经历许多的stage.\n\n对于分布式普通请求，从private int regularDistributedProcess(ResponseBuilder rb)的实现中可以看到，会经历ResponseBuilder.STAGE_PARSE_QUERY,ResponseBuilder.STAGE_EXECUTE_QUERY,ResponseBuilder.STAGE_GET_FIELDS,ResponseBuilder.STAGE_DONE等stage。从private void handleRegularResponses(ResponseBuilder rb, ShardRequest sreq)，分布式普通请求有ShardRequest.PURPOSE_GET_TOP_IDS，ShardRequest.PURPOSE_GET_FIELDS两次响应\n\n对于分布式group请求,从private int groupedDistributedProcess(ResponseBuilder rb)的实现中可以看到，则会经历ResponseBuilder.STAGE_PARSE_QUERY，ResponseBuilder.STAGE_TOP_GROUPS，ResponseBuilder.STAGE_EXECUTE_QUERY，ResponseBuilder.STAGE_GET_FIELDS，ResponseBuilder.STAGE_DONE等stage。从private void handleGroupedResponses(ResponseBuilder rb, ShardRequest sreq)可以看到，分布式group请求有ShardRequest.PURPOSE_GET_TOP_GROUPS,ShardRequest.PURPOSE_GET_TOP_IDS,ShardRequest.PURPOSE_GET_FIELDS三次响应.\n\n对于不同的请求和响应，有相应的类或者方法来实现。当然也可以自己实现相应的类或者方法来处理。即便是QueryComponent也可以自己定义，只需要实现相应的接口即可。\n\n对于private int regularDistributedProcess(ResponseBuilder rb),一个可能的实现是：\n``` java\n private int regularDistributedProcess(ResponseBuilder rb) {\n        ComponentDistributedStage cdStage = stages.getCDStage(rb.stage);\n        int nextState = ResponseBuilder.STAGE_DONE;\n        if (cdStage != null) {\n            cdStage.distributedProcess(rb, this);\n            if (stages.containsNextState(rb.stage))\n                nextState = stages.getNextState(rb.stage);\n        }\n        return nextState;\n    }\n```\n这里stages是一个Map,保存相应stage的实现类，父类型为ComponentDistributedStage。具体实现一个stage时，实现相应的接口即可。","slug":"Solr分布式请求stage理解","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pg00mn26s6vw9prq4o"},{"title":"Solr分布式group查询过程","id":"926","date":"2014-10-18T03:45:09.000Z","_content":"\n最近因为需要在分布式group查询时自定义自己的排序，因为在许多应用中都需要定义针对应用的排序规则。例如在用户名时，需要针对name,添加最匹配原则最左侧优先,最短优先等排序规则。而要使用这些规则， 一个前提条件是，先要拿到这个字段的值。可是在Solr提供的api中，无法定义这样精细的规则，所以必须修改代码才能支持.\n\n在此之前，要了解分布式group查询的过程.当进行分布式group查询时,从QueryComponent中，可以知道,leader会向shard发送三次请求,分别对应三个阶段 ResponseBuilder.STAGE_TOP_GROUPS，ResponseBuilder.STAGE_EXECUTE_QUERY，ResponseBuilder.STAGE_GET_FIELDS三个阶段。\n\n第一个阶段也可称为firstPhase,主要是得到字段的分组信息，也就是得到字段有哪些分组,请求的构造在 SearchGroupsRequestFactory中.在shard中，对这次请求作出响应是在QueryComponent中的process函数 内，if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) 中完成的，查询得到的结果由SearchGroupsResultTransformer的transform进行转换。对于shard返回的结 果，leader在SearchGroupShardResponseProcessor中进行处理.\n\n第二个阶段也可称为secondPhase,这个阶段主要是得到每个分组内的文档id,在这个阶段,leader会将上一阶段得到的分组 信息发给shard,请求的构造在TopGroupsShardRequestFactory中.在shard中,对这次请求作出响应是在 QueryComponent中的process函数内，else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false))中完成，查询得到的结果由TopGroupsResultTransformer的transform函数进行转换。对于shard返回的 结果,leader在TopGroupsShardResponseProcessor中进行处理\n\n第三个阶段主要是得到文档的字段信息，在这个阶段，leader会将最终结果中的文档id发送给shard,请求的构造在 StoredFieldsShardRequestFactory中.在shard中，对这次请求作出响应是在QueryComponent中的 process函数内,String ids = params.get(ShardParams.IDS);语句后的if (ids != null)中。对于shard返回的结果,leader是在StoredFieldsShardResponseProcessor中. \n\n分布式group查询的过程差不多就这样，以后再介绍如何定义自己的排序。","source":"_posts/Solr分布式group查询过程.md","raw":"title: Solr分布式group查询过程\ntags:\n  - group查询\n  - solr\n  - 分布式\nid: 926\ncategories:\n  - 搜索引擎\ndate: 2014-10-18 11:45:09\n---\n\n最近因为需要在分布式group查询时自定义自己的排序，因为在许多应用中都需要定义针对应用的排序规则。例如在用户名时，需要针对name,添加最匹配原则最左侧优先,最短优先等排序规则。而要使用这些规则， 一个前提条件是，先要拿到这个字段的值。可是在Solr提供的api中，无法定义这样精细的规则，所以必须修改代码才能支持.\n\n在此之前，要了解分布式group查询的过程.当进行分布式group查询时,从QueryComponent中，可以知道,leader会向shard发送三次请求,分别对应三个阶段 ResponseBuilder.STAGE_TOP_GROUPS，ResponseBuilder.STAGE_EXECUTE_QUERY，ResponseBuilder.STAGE_GET_FIELDS三个阶段。\n\n第一个阶段也可称为firstPhase,主要是得到字段的分组信息，也就是得到字段有哪些分组,请求的构造在 SearchGroupsRequestFactory中.在shard中，对这次请求作出响应是在QueryComponent中的process函数 内，if (params.getBool(GroupParams.GROUP_DISTRIBUTED_FIRST, false)) 中完成的，查询得到的结果由SearchGroupsResultTransformer的transform进行转换。对于shard返回的结 果，leader在SearchGroupShardResponseProcessor中进行处理.\n\n第二个阶段也可称为secondPhase,这个阶段主要是得到每个分组内的文档id,在这个阶段,leader会将上一阶段得到的分组 信息发给shard,请求的构造在TopGroupsShardRequestFactory中.在shard中,对这次请求作出响应是在 QueryComponent中的process函数内，else if (params.getBool(GroupParams.GROUP_DISTRIBUTED_SECOND, false))中完成，查询得到的结果由TopGroupsResultTransformer的transform函数进行转换。对于shard返回的 结果,leader在TopGroupsShardResponseProcessor中进行处理\n\n第三个阶段主要是得到文档的字段信息，在这个阶段，leader会将最终结果中的文档id发送给shard,请求的构造在 StoredFieldsShardRequestFactory中.在shard中，对这次请求作出响应是在QueryComponent中的 process函数内,String ids = params.get(ShardParams.IDS);语句后的if (ids != null)中。对于shard返回的结果,leader是在StoredFieldsShardResponseProcessor中. \n\n分布式group查询的过程差不多就这样，以后再介绍如何定义自己的排序。","slug":"Solr分布式group查询过程","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pk00mt26s6sgwto2ti"},{"title":"Solr从MySQL导数据","date":"2016-04-04T06:07:18.000Z","_content":"本来打算用Solr来搭建搜索服务，而公司的数据放在MySQL数据里，于是在文档里找到DataImportHandler,参考[https://wiki.apache.org/solr/DataImportHandler](https://wiki.apache.org/solr/DataImportHandler), 这里以导入Wordpress数据为例\n## 在conf目录下新建data-config.xml\n\ndata-config.xml的内容为\n```\n<dataConfig>\n  <dataSource type=\"JdbcDataSource\" \n              driver=\"com.mysql.jdbc.Driver\"\n              url=\"jdbc:mysql://localhost/blog\" \n              user=\"blog\" \n              password=\"12345678\"/>\n  <document>\n    <entity name=\"post\" pk=\"ID\"\n            query=\"select ID,post_title,post_content from wp_posts where post_status='publish'\"\n            deltaImportQuery=\"select ID,post_title,post_content from wp_posts where ID='${dih.delta.ID}'\"\n            deltaQuery=\"select ID from wp_posts where post_status='publish' and post_modified_gmt > '${dih.last_index_time}'\">\n      <field column=\"ID\" name=\"id\"/>\n      <field column=\"post_title\" name=\"title\"/>\n      <field column=\"post_content\" name=\"content\"/>\n    </entity>\n  </document>\n</dataConfig>\n```\n## 配置schema.xml\n```\n <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n<field name=\"title\" type=\"text_general\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n<field name=\"content\" type=\"text_general\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n```\n## 修改solrconfig.xml\n在solrconfig.xml增加\n`<lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-dataimporthandler-.*\\.jar\" />`,这样就不会报solr.Dataimport Class not found error.\n* 添加jdbc连接mysql\n\n在server/lib里添加mysql-connector-java-5.1.38.jar，我这里下载到的是5.1.38,其它版本的也可以。\n\n* 新建core.properties\n\n在blog目录下新建core.properties文件，内容为\n```\n#Written by CorePropertiesLocator\n#Wed Mar 23 10:55:00 UTC 2016\nnumShards=1\ncollection.configName=blog\n#name=blog_shard1_replica1\nshard=shard1\ncollection=blog\ncoreNodeName=core_node1\n```\n* 启动Solr\n\nbin/solr start -s server/solr/blog启动Solr\n\n## 执行全量索引\n命令为`http://127.0.0.1:8983/solr/blog/dataimport?command=full-import`\n## 执行增量索引\n命令为`http://127.0.0.1:8983/solr/blog/dataimport?command=delta-import`\n\n\n## 遇到的问题\n* nohup: can't detach from console: Inappropriate ioctl for device\n\n这个问题时在搭建SolrCloud时遇到的，在这里不妨说说。在启动zookeeper时，遇到这个问题，网上说时因为在tmux里启动的缘故，于是新开一个终端,启动zookeeper,这次正常启动。\n* /Users/long/program/java/solr-5.5.0/solr/server/logs/solr.log: No such file or directory\n\n执行命令`bin/solr start -s server/solr/blog`时出现这个错误，莫名奇妙的，我想依然是不能在tmux里执行shell, 于是新开一个终端再次执行，这次正常启动\n","source":"_posts/Solr从MySQL导数据.md","raw":"title: Solr从MySQL导数据\ndate: 2016-04-04 14:07:18\ntags: \n    - Solr\ncategories:\n    - 搜索引擎\n---\n本来打算用Solr来搭建搜索服务，而公司的数据放在MySQL数据里，于是在文档里找到DataImportHandler,参考[https://wiki.apache.org/solr/DataImportHandler](https://wiki.apache.org/solr/DataImportHandler), 这里以导入Wordpress数据为例\n## 在conf目录下新建data-config.xml\n\ndata-config.xml的内容为\n```\n<dataConfig>\n  <dataSource type=\"JdbcDataSource\" \n              driver=\"com.mysql.jdbc.Driver\"\n              url=\"jdbc:mysql://localhost/blog\" \n              user=\"blog\" \n              password=\"12345678\"/>\n  <document>\n    <entity name=\"post\" pk=\"ID\"\n            query=\"select ID,post_title,post_content from wp_posts where post_status='publish'\"\n            deltaImportQuery=\"select ID,post_title,post_content from wp_posts where ID='${dih.delta.ID}'\"\n            deltaQuery=\"select ID from wp_posts where post_status='publish' and post_modified_gmt > '${dih.last_index_time}'\">\n      <field column=\"ID\" name=\"id\"/>\n      <field column=\"post_title\" name=\"title\"/>\n      <field column=\"post_content\" name=\"content\"/>\n    </entity>\n  </document>\n</dataConfig>\n```\n## 配置schema.xml\n```\n <field name=\"id\" type=\"string\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n<field name=\"title\" type=\"text_general\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n<field name=\"content\" type=\"text_general\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" /> \n```\n## 修改solrconfig.xml\n在solrconfig.xml增加\n`<lib dir=\"${solr.install.dir:../../../..}/dist/\" regex=\"solr-dataimporthandler-.*\\.jar\" />`,这样就不会报solr.Dataimport Class not found error.\n* 添加jdbc连接mysql\n\n在server/lib里添加mysql-connector-java-5.1.38.jar，我这里下载到的是5.1.38,其它版本的也可以。\n\n* 新建core.properties\n\n在blog目录下新建core.properties文件，内容为\n```\n#Written by CorePropertiesLocator\n#Wed Mar 23 10:55:00 UTC 2016\nnumShards=1\ncollection.configName=blog\n#name=blog_shard1_replica1\nshard=shard1\ncollection=blog\ncoreNodeName=core_node1\n```\n* 启动Solr\n\nbin/solr start -s server/solr/blog启动Solr\n\n## 执行全量索引\n命令为`http://127.0.0.1:8983/solr/blog/dataimport?command=full-import`\n## 执行增量索引\n命令为`http://127.0.0.1:8983/solr/blog/dataimport?command=delta-import`\n\n\n## 遇到的问题\n* nohup: can't detach from console: Inappropriate ioctl for device\n\n这个问题时在搭建SolrCloud时遇到的，在这里不妨说说。在启动zookeeper时，遇到这个问题，网上说时因为在tmux里启动的缘故，于是新开一个终端,启动zookeeper,这次正常启动。\n* /Users/long/program/java/solr-5.5.0/solr/server/logs/solr.log: No such file or directory\n\n执行命令`bin/solr start -s server/solr/blog`时出现这个错误，莫名奇妙的，我想依然是不能在tmux里执行shell, 于是新开一个终端再次执行，这次正常启动\n","slug":"Solr从MySQL导数据","published":1,"updated":"2016-04-04T06:08:45.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4po00mz26s6jdrymye0"},{"title":"Solr in Action笔记二","id":"957","date":"2014-11-16T11:56:07.000Z","_content":"\n初识Solr\n\n1.安装Solr,\n方法一，下载源码，编译，安装，这个单独介绍\n方法二，下载二进制文件，解压，即可。\n\n2.启动Solr\n进入example目录,允许 java -jar start.jar，默认监听8983端口，访问http://localhost:8983/solr看看是否启动。\n若端口被占用，修改启动端口即可，java -Djetty.port=8080 -jar start.jar 。\n\n3.查询\nSolr后台，查询表单的参数意义示例\n字段 值 意义\nq iPod 查询词\nfq manu:Belkin 过滤，只显示manu中有Belkin的结果\nsort price asc 排序，价格从低到高排列\nstart 0 分页参数,相当于mysql中的offset,即从第几条结果开始显示\nrows 10 分页参数,想到与mysql中的limit,即总共显示几条结果\nfl name,price,features,score 需要显示的字段\ndf text 默认搜索字段，对于没有制定搜索字段的查询，默认查询text字段\nwt xml 返回结果显示格式，还有json,csv等多种格式供选择\n\n4.相关性排序\n可以对查询词进行加权，改变排序结果，如查询词“iPod power\"变成\"iPod power^2\"，则power的权重是iPod的两倍\n\n5.分页\n使用start和rows参数，每页显示条数尽量小，因为需要都去返回字段的值，条数越多，速度越慢\n\n6.排序\n对返回结果使用如 price asc等进行排序\n\n7.提供的搜索组件\ndismax 如何翻译，待查\nedismax 如何翻译，待查\nhl 高亮\nfacet 平面搜索\nspatial 地理位置搜索\nspellchecking 拼写检查","source":"_posts/Solr-in-Action笔记二.md","raw":"title: Solr in Action笔记二\ntags:\n  - solr\nid: 957\ncategories:\n  - 搜索引擎\ndate: 2014-11-16 19:56:07\n---\n\n初识Solr\n\n1.安装Solr,\n方法一，下载源码，编译，安装，这个单独介绍\n方法二，下载二进制文件，解压，即可。\n\n2.启动Solr\n进入example目录,允许 java -jar start.jar，默认监听8983端口，访问http://localhost:8983/solr看看是否启动。\n若端口被占用，修改启动端口即可，java -Djetty.port=8080 -jar start.jar 。\n\n3.查询\nSolr后台，查询表单的参数意义示例\n字段 值 意义\nq iPod 查询词\nfq manu:Belkin 过滤，只显示manu中有Belkin的结果\nsort price asc 排序，价格从低到高排列\nstart 0 分页参数,相当于mysql中的offset,即从第几条结果开始显示\nrows 10 分页参数,想到与mysql中的limit,即总共显示几条结果\nfl name,price,features,score 需要显示的字段\ndf text 默认搜索字段，对于没有制定搜索字段的查询，默认查询text字段\nwt xml 返回结果显示格式，还有json,csv等多种格式供选择\n\n4.相关性排序\n可以对查询词进行加权，改变排序结果，如查询词“iPod power\"变成\"iPod power^2\"，则power的权重是iPod的两倍\n\n5.分页\n使用start和rows参数，每页显示条数尽量小，因为需要都去返回字段的值，条数越多，速度越慢\n\n6.排序\n对返回结果使用如 price asc等进行排序\n\n7.提供的搜索组件\ndismax 如何翻译，待查\nedismax 如何翻译，待查\nhl 高亮\nfacet 平面搜索\nspatial 地理位置搜索\nspellchecking 拼写检查","slug":"Solr-in-Action笔记二","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pr00n226s64munergq"},{"title":"Solr in Action笔记三","id":"979","date":"2014-12-14T14:12:05.000Z","_content":"\nSolr关键概念\n\n1.反向索引\n2.检索词和布尔查询：\n并查询：\n+new +house 或者\nnew AND house\n或查询：\nnew house 或者\nnew OR house\n排除查询:\nnew house –rental 或者\nnew house NOT rental\n短语查询：\n“new home” OR “new house”\n3 bedrooms” AND “walk in closet” AND “granite countertops”\n分组查询：\nNew AND (house OR (home NOT improvement NOT depot NOT grown))\n(+(buying purchasing -renting) +(home house residence –(+property -bedroom)))\n\n对于短语查询，之所以可以实现，是因为在反向索引中保存了词在文档中的位置信息。\n\n3.模糊查询\n通配符查询：\n如果需要查询以offic开头的词，只需要查询 offic*\n如果要使用通配符在开头的查询，如 *ing,则需要将ReversedWildcardFilterFactory添加到字段分析链中\n\n范围查询：\nyearsOld:[18 TO 21] 18 <= x <= 21\nyearsOld:{18 TO 21} 18 < x < 21\nyearsOld:[18 TO 21} 18 <= x < 21\ncreated:[2012-02-01T00:00.0Z TO 2012-08-02T00:00.0Z]\n\n编辑距离查询：\nadministrator~ 默认编辑距离为1\nadministrator~1 编辑距离为1\nadministrator~2  编辑距离为2\n\n临近查询：\n“chief officer”~1 距离为1\n例如: “chief executive officer”, “officer chief”\n\n4.相关性：\nSolr默认相关性，距离看文档\n\n5.准确率和召回率\n准确率说的是一次查询中，查询结果有多少是相关的比率\n召回率说的是一次查询中，有多少相关结果被返回的比率\n\n一般来说，搜索引擎都是尽量在二者中寻求一个平衡\n\n6.Solr的一些局限\nSolr无法执行想数据库查询那样复杂的查询\n当更新一个跨越很多个文档的字段时，Solr将很麻烦\n对于返回许多文档的查询，Solr的性能将会下降","source":"_posts/Solr-in-Action笔记三.md","raw":"title: Solr in Action笔记三\ntags:\n  - solr\nid: 979\ncategories:\n  - 搜索引擎\ndate: 2014-12-14 22:12:05\n---\n\nSolr关键概念\n\n1.反向索引\n2.检索词和布尔查询：\n并查询：\n+new +house 或者\nnew AND house\n或查询：\nnew house 或者\nnew OR house\n排除查询:\nnew house –rental 或者\nnew house NOT rental\n短语查询：\n“new home” OR “new house”\n3 bedrooms” AND “walk in closet” AND “granite countertops”\n分组查询：\nNew AND (house OR (home NOT improvement NOT depot NOT grown))\n(+(buying purchasing -renting) +(home house residence –(+property -bedroom)))\n\n对于短语查询，之所以可以实现，是因为在反向索引中保存了词在文档中的位置信息。\n\n3.模糊查询\n通配符查询：\n如果需要查询以offic开头的词，只需要查询 offic*\n如果要使用通配符在开头的查询，如 *ing,则需要将ReversedWildcardFilterFactory添加到字段分析链中\n\n范围查询：\nyearsOld:[18 TO 21] 18 <= x <= 21\nyearsOld:{18 TO 21} 18 < x < 21\nyearsOld:[18 TO 21} 18 <= x < 21\ncreated:[2012-02-01T00:00.0Z TO 2012-08-02T00:00.0Z]\n\n编辑距离查询：\nadministrator~ 默认编辑距离为1\nadministrator~1 编辑距离为1\nadministrator~2  编辑距离为2\n\n临近查询：\n“chief officer”~1 距离为1\n例如: “chief executive officer”, “officer chief”\n\n4.相关性：\nSolr默认相关性，距离看文档\n\n5.准确率和召回率\n准确率说的是一次查询中，查询结果有多少是相关的比率\n召回率说的是一次查询中，有多少相关结果被返回的比率\n\n一般来说，搜索引擎都是尽量在二者中寻求一个平衡\n\n6.Solr的一些局限\nSolr无法执行想数据库查询那样复杂的查询\n当更新一个跨越很多个文档的字段时，Solr将很麻烦\n对于返回许多文档的查询，Solr的性能将会下降","slug":"Solr-in-Action笔记三","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pt00n526s6uhlgsce3"},{"title":"Solr in Action笔记一","id":"954","date":"2014-11-11T16:23:03.000Z","_content":"\nSolr in Action是本好书，决定复习一遍。\n\n为什么需要搜索引擎，或者说搜索引擎有什么特别的地方，需要在应用中用到它？\n\n搜索引擎有四个主要特征：\n\n1.文本为中心。\n\n当用户需要在文本中查找所需要的信息时，基本上就需要用到搜索引擎了。\n\n2.读多写少\n搜索引擎的结果为了读做了很多优化，相应的，写数据就会变得慢一些。当应用读多写少，用搜索引擎是比较合适的，而如果写多读少，则应考虑其它方案。\n\n3.面向文档\n搜索引擎的一条记录成为一个文档，这个文档是一个整体，不需要依赖其它信息。\n\n4.灵活的模式\n意思是说，引擎中的记录不要求结构都一样，每条记录所具有的字段可以不同\n\n搜索的基本应用：\n1.关键词查询\n2.相关性排序\n相关性排序是搜索引擎区别与其它查询的重要特征，相关性排序也是一个非常重要的研究方向。\n\nSolr是什么？\n简单来说,Solr就是Lucene的一个外壳。底层，Solr使用Lucene来索引和查询数据，外层，Solr提供灵活的配置文件，避免像Lucene那样编写代码来定义字段类型。此外，Solr还提供一些功能，如高亮，缓存，分布式等。\n\n为什么选择Solr?\n因为Solr在稳定性，可扩展性，容错性三个方面都做的非常出色。","source":"_posts/Solr-in-Action笔记一.md","raw":"title: Solr in Action笔记一\ntags:\n  - solr\nid: 954\ncategories:\n  - 搜索引擎\ndate: 2014-11-12 00:23:03\n---\n\nSolr in Action是本好书，决定复习一遍。\n\n为什么需要搜索引擎，或者说搜索引擎有什么特别的地方，需要在应用中用到它？\n\n搜索引擎有四个主要特征：\n\n1.文本为中心。\n\n当用户需要在文本中查找所需要的信息时，基本上就需要用到搜索引擎了。\n\n2.读多写少\n搜索引擎的结果为了读做了很多优化，相应的，写数据就会变得慢一些。当应用读多写少，用搜索引擎是比较合适的，而如果写多读少，则应考虑其它方案。\n\n3.面向文档\n搜索引擎的一条记录成为一个文档，这个文档是一个整体，不需要依赖其它信息。\n\n4.灵活的模式\n意思是说，引擎中的记录不要求结构都一样，每条记录所具有的字段可以不同\n\n搜索的基本应用：\n1.关键词查询\n2.相关性排序\n相关性排序是搜索引擎区别与其它查询的重要特征，相关性排序也是一个非常重要的研究方向。\n\nSolr是什么？\n简单来说,Solr就是Lucene的一个外壳。底层，Solr使用Lucene来索引和查询数据，外层，Solr提供灵活的配置文件，避免像Lucene那样编写代码来定义字段类型。此外，Solr还提供一些功能，如高亮，缓存，分布式等。\n\n为什么选择Solr?\n因为Solr在稳定性，可扩展性，容错性三个方面都做的非常出色。","slug":"Solr-in-Action笔记一","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4pv00n826s698fiqabc"},{"title":"SlopeOne算法","date":"2016-05-05T12:54:38.000Z","_content":"最近公司说要做智能推荐，于是想起了协同过滤，想到了Slope One算法，虽然以前看过这个算法，但没有记笔记，这次只好从头看起，好在Slope One比较容易。\n\n\n在[Wiki](https://en.wikipedia.org/wiki/Slope_One)上看了介绍，印象中有人用Python写了一个非常简洁的版本，于是在网上找。在[这里](http://www.serpentine.com/blog/2006/12/12/collaborative-filtering-made-easy/)找到详细说明，在[这里](https://github.com/kek/slopeone/blob/master/slope_one.py)找到代码。\n\n| u\\v | i   | i |\n| ----|:---:| -:|\n| u1  | 3   | 2 |\n| u2  | 4   | 2 |\n| u3  | 5   | ? |\n\n对于上表中,使用 Slope One算法来预测用户u3对j 的评分具体过程是这样的:首先计算项目i和j的偏差,即((3 – 2) + (4 – 2)) / 2 = 1.5,之后预测用户u3对j的评分就可以这样计算5 – 1.5 = 3.5。\n\n之后自己写了一个[版本](https://github.com/dengshilong/recommender/blob/master/src/main/SlopeOne.py)。\n","source":"_posts/SlopeOne算法.md","raw":"title: SlopeOne算法\ndate: 2016-05-05 20:54:38\ntags: 推荐系统\ncategories: 大数据\n---\n最近公司说要做智能推荐，于是想起了协同过滤，想到了Slope One算法，虽然以前看过这个算法，但没有记笔记，这次只好从头看起，好在Slope One比较容易。\n\n\n在[Wiki](https://en.wikipedia.org/wiki/Slope_One)上看了介绍，印象中有人用Python写了一个非常简洁的版本，于是在网上找。在[这里](http://www.serpentine.com/blog/2006/12/12/collaborative-filtering-made-easy/)找到详细说明，在[这里](https://github.com/kek/slopeone/blob/master/slope_one.py)找到代码。\n\n| u\\v | i   | i |\n| ----|:---:| -:|\n| u1  | 3   | 2 |\n| u2  | 4   | 2 |\n| u3  | 5   | ? |\n\n对于上表中,使用 Slope One算法来预测用户u3对j 的评分具体过程是这样的:首先计算项目i和j的偏差,即((3 – 2) + (4 – 2)) / 2 = 1.5,之后预测用户u3对j的评分就可以这样计算5 – 1.5 = 3.5。\n\n之后自己写了一个[版本](https://github.com/dengshilong/recommender/blob/master/src/main/SlopeOne.py)。\n","slug":"SlopeOne算法","published":1,"updated":"2016-05-05T12:59:44.000Z","_id":"cinuar4q100nb26s6m90bmg09","comments":1,"layout":"post","photos":[],"link":""},{"title":"Screen-会话管理工具","id":"901","date":"2014-09-04T14:47:33.000Z","_content":"\n工作一年后,才知道有Screen这个东西,太不应该了,也许真是环境影响人.\n\n今天遇到问题,导师过来指导,看我的SecureCRT开着很多个会话,没有用Screen,于是提醒可以用这个.之前在公司的wiki上看到过介绍,本以为就是SecureCRT,原来是一个管理会话工具,有了它之后,就不需要再开很多个会话,然后关闭了.会话间的切换也可以很方便的用快捷键命令,而不是鼠标,因为鼠标极其影响效率.\n\n用了公司一个员工的配置\nhardstatus alwayslastline \"%{=b}%{b}%-w%{.BW}%10>%n*%t%{-}%+w%< %=%{kG}%C%A, %Y-%m-%d\"\nscreen -t local1 0 bash\nscreen -t local2 1 bash\nscreen -t local3 2 bash\nscreen -t local4 3 bash\nscreen -t local5 4 bash\n\nselect 0\n\nvim ~/.screenrc,复制上面内容.之后就可以使用Screen了.一些常用命令如下:\nc-a : Ctrl + a\nscreen -S name #开一个session\nscreen -S name -X quit #杀死session\nc-a c #创建一个窗口\nc-a n #next 窗口\nc-a p #previous 窗口\nc-a A #为窗口命名\nc-a d #detach screen\nc-a #跳转到number的窗口\nscreen -ls #查看窗口\nscreen -r name #连接一个session\nscreen -x name #共享session\n<span style=\"color: #000000;\">可以参考</span>[http://hunsefee.diandian.com/post/2010-10-28/7319178](http://hunsefee.diandian.com/post/2010-10-28/7319178)","source":"_posts/Screen-会话管理工具.md","raw":"title: Screen-会话管理工具\ntags:\n  - Screen\nid: 901\ncategories:\n  - 软件安装\ndate: 2014-09-04 22:47:33\n---\n\n工作一年后,才知道有Screen这个东西,太不应该了,也许真是环境影响人.\n\n今天遇到问题,导师过来指导,看我的SecureCRT开着很多个会话,没有用Screen,于是提醒可以用这个.之前在公司的wiki上看到过介绍,本以为就是SecureCRT,原来是一个管理会话工具,有了它之后,就不需要再开很多个会话,然后关闭了.会话间的切换也可以很方便的用快捷键命令,而不是鼠标,因为鼠标极其影响效率.\n\n用了公司一个员工的配置\nhardstatus alwayslastline \"%{=b}%{b}%-w%{.BW}%10>%n*%t%{-}%+w%< %=%{kG}%C%A, %Y-%m-%d\"\nscreen -t local1 0 bash\nscreen -t local2 1 bash\nscreen -t local3 2 bash\nscreen -t local4 3 bash\nscreen -t local5 4 bash\n\nselect 0\n\nvim ~/.screenrc,复制上面内容.之后就可以使用Screen了.一些常用命令如下:\nc-a : Ctrl + a\nscreen -S name #开一个session\nscreen -S name -X quit #杀死session\nc-a c #创建一个窗口\nc-a n #next 窗口\nc-a p #previous 窗口\nc-a A #为窗口命名\nc-a d #detach screen\nc-a #跳转到number的窗口\nscreen -ls #查看窗口\nscreen -r name #连接一个session\nscreen -x name #共享session\n<span style=\"color: #000000;\">可以参考</span>[http://hunsefee.diandian.com/post/2010-10-28/7319178](http://hunsefee.diandian.com/post/2010-10-28/7319178)","slug":"Screen-会话管理工具","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4q400nf26s6md0ea01o"},{"title":"Python筛法求素数的优化","id":"882","date":"2014-08-16T13:13:21.000Z","_content":"\n在pythontip上做题时,有这样一道题，\n给你一个正整数N(1 <= N <= 10000000)，求{1,2,3,...,N}中质数的个数。\n如N=3， 输出2.\n也就是求N以内质数的个数。\n刚开始用以前写的筛法写了一个最初版本，\n``` python\nN = 10000000\nprimes = [True for i in xrange(N + 1)] \nprimes[0] = primes[1] = False\nfor i in xrange(2, N + 1): \n    if not primes[i]:\n        continue\n    n = i * i \n    while n < N + 1:\n        primes[n] = False\n        n += i\nprint len([i for i in xrange(N + 1) if primes[i]])\n```\n发现超时，用time模块的clock测试,用了16s.之后一步一步优化，先将len([i for i in xrange(N + 1) if primes[i]])这句改成primes.count(True)时间缩短到14s,之后看了讨论组里的讨论,将\n``` python\nn = i * i \n    while n < N + 1:\n        primes[n] = False\n        n += i\n```\n这部分改成\n``` python\nprimes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n```\n时间没有明显的变化，因为看到[False] * ((N - i * i) / i + 1)，于是将[True for i in xrange(N + 1)] 这行改成[True] * (N + 1) ，速度明显加快，只用了4s,经过这样优化后，程序变成了\n``` python\nN = 10000000\nprimes = [True] * (N + 1) \nprimes[0] = primes[1] = False\nfor i in xrange(2, N + 1): \n    if not primes[i]:\n        continue\n    primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\nprint primes.count(True)\n```\n之后想办法将for循环去掉。于是将它改成\n``` python\ni = 2\nwhile i * i <= N:\n    if primes[i]:\n        primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n    i += 1\n```\n最终为\n``` python\nN = 10000000\nprimes = [True] * (N + 1) \nprimes[0] = primes[1] = False\ni = 2\nwhile i * i <= N:\n    if primes[i]:\n        primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n    i += 1\nprint primes.count(True)\n```\n时间跑到了2s以内，提交后通过了。\n\n之后将之前求素数的程序[筛法得到素数](http://program.dengshilong.org/2014/07/15/%E7%AD%9B%E6%B3%95%E5%BE%97%E5%88%B0%E7%B4%A0%E6%95%B0/)进行修改,得到\n``` python\ndef getPrimes(n):\n    primes = [True] * (n + 1)\n    primes[0] = primes[1] = False\n    i = 2\n    while i * i <= n:\n        if primes[i]:\n            primes[i * i:n + 1:i] = [False] * ((n - i * i) / i + 1)\n        i += 1\n    return [i for i in xrange(n + 1) if primes[i]]\n```\n​\n","source":"_posts/Python筛法求素数的优化.md","raw":"title: Python筛法求素数的优化\ntags:\n  - 列表解析\n  - 筛法\n  - 素数\nid: 882\ncategories:\n  - 算法\ndate: 2014-08-16 21:13:21\n---\n\n在pythontip上做题时,有这样一道题，\n给你一个正整数N(1 <= N <= 10000000)，求{1,2,3,...,N}中质数的个数。\n如N=3， 输出2.\n也就是求N以内质数的个数。\n刚开始用以前写的筛法写了一个最初版本，\n``` python\nN = 10000000\nprimes = [True for i in xrange(N + 1)] \nprimes[0] = primes[1] = False\nfor i in xrange(2, N + 1): \n    if not primes[i]:\n        continue\n    n = i * i \n    while n < N + 1:\n        primes[n] = False\n        n += i\nprint len([i for i in xrange(N + 1) if primes[i]])\n```\n发现超时，用time模块的clock测试,用了16s.之后一步一步优化，先将len([i for i in xrange(N + 1) if primes[i]])这句改成primes.count(True)时间缩短到14s,之后看了讨论组里的讨论,将\n``` python\nn = i * i \n    while n < N + 1:\n        primes[n] = False\n        n += i\n```\n这部分改成\n``` python\nprimes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n```\n时间没有明显的变化，因为看到[False] * ((N - i * i) / i + 1)，于是将[True for i in xrange(N + 1)] 这行改成[True] * (N + 1) ，速度明显加快，只用了4s,经过这样优化后，程序变成了\n``` python\nN = 10000000\nprimes = [True] * (N + 1) \nprimes[0] = primes[1] = False\nfor i in xrange(2, N + 1): \n    if not primes[i]:\n        continue\n    primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\nprint primes.count(True)\n```\n之后想办法将for循环去掉。于是将它改成\n``` python\ni = 2\nwhile i * i <= N:\n    if primes[i]:\n        primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n    i += 1\n```\n最终为\n``` python\nN = 10000000\nprimes = [True] * (N + 1) \nprimes[0] = primes[1] = False\ni = 2\nwhile i * i <= N:\n    if primes[i]:\n        primes[i * i:N + 1:i] = [False] * ((N - i * i) / i + 1)\n    i += 1\nprint primes.count(True)\n```\n时间跑到了2s以内，提交后通过了。\n\n之后将之前求素数的程序[筛法得到素数](http://program.dengshilong.org/2014/07/15/%E7%AD%9B%E6%B3%95%E5%BE%97%E5%88%B0%E7%B4%A0%E6%95%B0/)进行修改,得到\n``` python\ndef getPrimes(n):\n    primes = [True] * (n + 1)\n    primes[0] = primes[1] = False\n    i = 2\n    while i * i <= n:\n        if primes[i]:\n            primes[i * i:n + 1:i] = [False] * ((n - i * i) / i + 1)\n        i += 1\n    return [i for i in xrange(n + 1) if primes[i]]\n```\n​\n","slug":"Python筛法求素数的优化","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4q800nj26s60b7ar14x"},{"title":"PyCharm安装vim插件","date":"2016-04-15T02:17:04.000Z","_content":"google \"pycharm vim\", 第一条指向[https://confluence.jetbrains.com/display/PYH/Configuring+PyCharm+to+work+as+a+Vim+editor](https://confluence.jetbrains.com/display/PYH/Configuring+PyCharm+to+work+as+a+Vim+editor)这里，但没有找到我想要的，于是自己在PyCharm里找，终于找到了，记下来。\n\nPyCharm->Preference->Plugins->Install JetBrains plugin, 之后搜索vim找到ideavim, 安装后重启，进入PyCharm已经可以和vim一样编辑代码。\n\n但是连行号都没有，于是想到要给ideavim加个配置文件，可是要加到哪里？打开[http://blog.csdn.net/u010211892/article/details/43274699](http://blog.csdn.net/u010211892/article/details/43274699)看到\n```\ncp ~/.vimrc ~/.ideavimrc \n```\n对啊，vim是.vimrc, ideavim就是.ideavimrc, 没想到啊。\n","source":"_posts/PyCharm安装vim插件.md","raw":"title: PyCharm安装vim插件\ndate: 2016-04-15 10:17:04\ntags: \n    - PyCharm\n    -  vim\ncategories:\n    - Python\n---\ngoogle \"pycharm vim\", 第一条指向[https://confluence.jetbrains.com/display/PYH/Configuring+PyCharm+to+work+as+a+Vim+editor](https://confluence.jetbrains.com/display/PYH/Configuring+PyCharm+to+work+as+a+Vim+editor)这里，但没有找到我想要的，于是自己在PyCharm里找，终于找到了，记下来。\n\nPyCharm->Preference->Plugins->Install JetBrains plugin, 之后搜索vim找到ideavim, 安装后重启，进入PyCharm已经可以和vim一样编辑代码。\n\n但是连行号都没有，于是想到要给ideavim加个配置文件，可是要加到哪里？打开[http://blog.csdn.net/u010211892/article/details/43274699](http://blog.csdn.net/u010211892/article/details/43274699)看到\n```\ncp ~/.vimrc ~/.ideavimrc \n```\n对啊，vim是.vimrc, ideavim就是.ideavimrc, 没想到啊。\n","slug":"PyCharm安装vim插件","published":1,"updated":"2016-04-15T02:24:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qb00np26s6drm10y2z"},{"title":"POJ2524-Ubiquitous Religions","id":"857","date":"2014-08-13T04:21:09.000Z","_content":"\n连并查集都忘记是怎么回事了，实在是不应该。还是复习一下为妙。\npoj2524这一题是并差集的简单应用，先从这题开始。\n\nThere are so many different religions in the world today that it is difficult to keep track of them all. You are interested in finding out how many different religions students in your university believe in.\n\nYou know that there are n students in your university (0 < n <= 50000). It is infeasible for you to ask every student their religious beliefs. Furthermore, many students are not comfortable expressing their beliefs. One way to avoid these problems is to ask m (0 <= m <= n(n-1)/2) pairs of students and ask them whether they believe in the same religion (e.g. they may know if they both attend the same church). From this data, you may not know what each person believes in, but you can get an idea of the upper bound of how many different religions can be possibly represented on campus. You may assume that each student subscribes to at most one religion.\n\ninput:\nThe input consists of a number of cases. Each case starts with a line specifying the integers n and m. The next m lines each consists of two integers i and j, specifying that students i and j believe in the same religion. The students are numbered 1 to n. The end of input is specified by a line in which n = m = 0.\n\noutput:\nFor each test case, print on a single line the case number (starting with 1) followed by the maximum number of different religions that the students in the university believe in.\n\nsample input\n10 9\n1 2\n1 3\n1 4\n1 5\n1 6\n1 7\n1 8\n1 9\n1 10\n10 4\n2 3\n4 5\n4 8\n5 8\n0 0\nsample output\nCase 1: 1\nCase 2: 7\n题目描述\n​世界上有许多不同的宗教，要记录全部是很困难的。你有兴趣找出在你所在的大学，有多少不同宗教信仰的学生。\n\n你所在的大学有n个学生(0 < n <= 50000).问遍所有学生的宗教信仰是不实际的。并且，一些学生对于表达他们的信仰会觉得不舒服。一个避免这些问题的解决办法是问m(0 <= m <= n(n-1)/2)对学生，他们是否属于同一个宗教(也就是他们同时出现在相同的教堂).从这些数据里，你不能知道每一个人的信仰，但是可以知道校园里宗教数量的一个上界。你可以假设一个学生至多属于一个宗教。\n\n输入：\n输入中包含一些测试用例。每个例子由一行包含整数n和m开始。接下来的m行由两个整数i和j组成,i和j属于同一个宗教.学生从1到n编号.输入的结束由一行n = m = 0标示.\n\n输出：\n每一个测试用例，输出一个数字标示第几个测试用例(从1开始)跟着是这所大学的所有学生可能的最大宗教信仰数。\n\n``` c\n#include <stdio.h>\n#include <iostream>\nusing namespace std;\nconst int MAX=50001;\nint father[MAX];\nint rank[MAX];\nvoid make_set(int x) {\n    father[x] = x;\n    rank[x] = 1;\n}\nint find_set(int x) {\n    if (x != father[x]) {\n        father[x] = find_set(father[x]);\n    }\n    return father[x];\n}\nvoid union_set(int x, int y) {\n    int fx = find_set(x);\n    int fy = find_set(y);\n    if (fx == fy)\n        return;\n    if (rank[fx] > rank[fy]) {\n        father[fy] = fx;\n        rank[fx] += rank[fy] ;\n    } else {\n        rank[fy] += rank[fx];\n        father[fx] = fy;\n    }\n}\nint main() {\n    int n, m, a, b;\n    int test_case = 0;\n    while (true) {\n        scanf(\"%d %d\", &n, &m);\n        if (n == 0 && m == 0) {\n            break;\n        }\n        test_case++;\n        for (int i = 1; i <= n; i++) {\n            make_set(i);\n        }\n        while (m--) {\n            scanf(\"%d %d\", &a, &b);\n            union_set(a, b);\n        }\n        int count = 0;\n        for (int i = 1; i <= n; i++) {\n            if (i == father[i]) {\n                count++;\n            }\n        }\n        printf(\"Case %d: %d\\n\", test_case, count);\n    }\n    return 0;\n}\n```","source":"_posts/POJ2524-Ubiquitous-Religions.md","raw":"title: POJ2524-Ubiquitous Religions\ntags:\n  - 并查集\nid: 857\ncategories:\n  - 数据结构\ndate: 2014-08-13 12:21:09\n---\n\n连并查集都忘记是怎么回事了，实在是不应该。还是复习一下为妙。\npoj2524这一题是并差集的简单应用，先从这题开始。\n\nThere are so many different religions in the world today that it is difficult to keep track of them all. You are interested in finding out how many different religions students in your university believe in.\n\nYou know that there are n students in your university (0 < n <= 50000). It is infeasible for you to ask every student their religious beliefs. Furthermore, many students are not comfortable expressing their beliefs. One way to avoid these problems is to ask m (0 <= m <= n(n-1)/2) pairs of students and ask them whether they believe in the same religion (e.g. they may know if they both attend the same church). From this data, you may not know what each person believes in, but you can get an idea of the upper bound of how many different religions can be possibly represented on campus. You may assume that each student subscribes to at most one religion.\n\ninput:\nThe input consists of a number of cases. Each case starts with a line specifying the integers n and m. The next m lines each consists of two integers i and j, specifying that students i and j believe in the same religion. The students are numbered 1 to n. The end of input is specified by a line in which n = m = 0.\n\noutput:\nFor each test case, print on a single line the case number (starting with 1) followed by the maximum number of different religions that the students in the university believe in.\n\nsample input\n10 9\n1 2\n1 3\n1 4\n1 5\n1 6\n1 7\n1 8\n1 9\n1 10\n10 4\n2 3\n4 5\n4 8\n5 8\n0 0\nsample output\nCase 1: 1\nCase 2: 7\n题目描述\n​世界上有许多不同的宗教，要记录全部是很困难的。你有兴趣找出在你所在的大学，有多少不同宗教信仰的学生。\n\n你所在的大学有n个学生(0 < n <= 50000).问遍所有学生的宗教信仰是不实际的。并且，一些学生对于表达他们的信仰会觉得不舒服。一个避免这些问题的解决办法是问m(0 <= m <= n(n-1)/2)对学生，他们是否属于同一个宗教(也就是他们同时出现在相同的教堂).从这些数据里，你不能知道每一个人的信仰，但是可以知道校园里宗教数量的一个上界。你可以假设一个学生至多属于一个宗教。\n\n输入：\n输入中包含一些测试用例。每个例子由一行包含整数n和m开始。接下来的m行由两个整数i和j组成,i和j属于同一个宗教.学生从1到n编号.输入的结束由一行n = m = 0标示.\n\n输出：\n每一个测试用例，输出一个数字标示第几个测试用例(从1开始)跟着是这所大学的所有学生可能的最大宗教信仰数。\n\n``` c\n#include <stdio.h>\n#include <iostream>\nusing namespace std;\nconst int MAX=50001;\nint father[MAX];\nint rank[MAX];\nvoid make_set(int x) {\n    father[x] = x;\n    rank[x] = 1;\n}\nint find_set(int x) {\n    if (x != father[x]) {\n        father[x] = find_set(father[x]);\n    }\n    return father[x];\n}\nvoid union_set(int x, int y) {\n    int fx = find_set(x);\n    int fy = find_set(y);\n    if (fx == fy)\n        return;\n    if (rank[fx] > rank[fy]) {\n        father[fy] = fx;\n        rank[fx] += rank[fy] ;\n    } else {\n        rank[fy] += rank[fx];\n        father[fx] = fy;\n    }\n}\nint main() {\n    int n, m, a, b;\n    int test_case = 0;\n    while (true) {\n        scanf(\"%d %d\", &n, &m);\n        if (n == 0 && m == 0) {\n            break;\n        }\n        test_case++;\n        for (int i = 1; i <= n; i++) {\n            make_set(i);\n        }\n        while (m--) {\n            scanf(\"%d %d\", &a, &b);\n            union_set(a, b);\n        }\n        int count = 0;\n        for (int i = 1; i <= n; i++) {\n            if (i == father[i]) {\n                count++;\n            }\n        }\n        printf(\"Case %d: %d\\n\", test_case, count);\n    }\n    return 0;\n}\n```","slug":"POJ2524-Ubiquitous-Religions","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qf00nv26s6p13wfz6q"},{"title":"POJ2001-Shortest Prefixes","id":"868","date":"2014-08-14T08:49:30.000Z","_content":"\nTrie又称为前缀树或字典树，它有许多重要用途，如搜索提示，以及作为AC自动机的基础。POJ2001-最短前缀这题是Trie的基础应用。\n**Description**\nA prefix of a string is a substring starting at the beginning of the given string. The prefixes of \"carbon\" are: \"c\", \"ca\", \"car\", \"carb\", \"carbo\", and \"carbon\". Note that the empty string is not considered a prefix in this problem, but every non-empty string is considered to be a prefix of itself. In everyday language, we tend to abbreviate words by prefixes. For example, \"carbohydrate\" is commonly abbreviated by \"carb\". In this problem, given a set of words, you will find for each word the shortest prefix that uniquely identifies the word it represents.\n\nIn the sample input below, \"carbohydrate\" can be abbreviated to \"carboh\", but it cannot be abbreviated to \"carbo\" (or anything shorter) because there are other words in the list that begin with \"carbo\".\n\nAn exact match will override a prefix match. For example, the prefix \"car\" matches the given word \"car\" exactly. Therefore, it is understood without ambiguity that \"car\" is an abbreviation for \"car\" , not for \"carriage\" or any of the other words in the list that begins with \"car\".\n**Input**\nThe input contains at least two, but no more than 1000 lines. Each line contains one word consisting of 1 to 20 lower case letters.\n**Output**\nThe output contains the same number of lines as the input. Each line of the output contains the word from the corresponding line of the input, followed by one blank space, and the shortest prefix that uniquely (without ambiguity) identifies this word.\n**Sample Input**\ncarbohydrate\ncart\ncarburetor\ncaramel\ncaribou\ncarbonic\ncartilage\ncarbon\ncarriage\ncarton\ncar\ncarbonate\n**Sample Output**\ncarbohydrate carboh\ncart cart\ncarburetor carbu\ncaramel cara\ncaribou cari\ncarbonic carboni\ncartilage carti\ncarbon carbon\ncarriage carr\ncarton carto\ncar car\ncarbonate carbona\n​​​​​**描述**\n一个字符串的前缀是从头开始的字符串的子串。\"carbon\"的前缀有：\"c\",\"ca\",\"car\",\"carb\",\"carbo\"和\"carbon\".注意在这个问题中空串不认为是前缀，但是每个非空字符串自身可以认为是一个前缀。在日常用于中，我们倾向于用前缀来缩写词。例如，“carbohydrate\"常缩写成\"carb\".在这个问题中，我们给出一系列单词，要求能够唯一标识单词的最短前缀。\n\n例如在下面的例子中，\"carbohydrate\"可以缩写成\"carboh\",但是它不能缩写成\"carbo\"(或者更短),因为在这些词中，还有一个词是由\"carbo\"开始的.\n\n精确匹配将覆盖前缀匹配。例如，前缀\"car\"精确匹配单词\"car\".因此,”car\"可以毫无歧义的认为是\"car\"的简写,而不是\"carriage\"的，或者其它一些由\"car\"作为前缀的单词.\n**输入：**\n输入至少包含两个，不超过1000行，每行宝行一个由1到20个字母组成的单词。\n**输出：**\n输出包含与输入相同的行数。每一行输出由对应的输入组成，跟着一个空格，之后是唯一(无歧义)标示单词的最短前缀.\n**示例输入：**\ncarbohydrate\ncart\ncarburetor\ncaramel\ncaribou\ncarbonic\ncartilage\ncarbon\ncarriage\ncarton\ncar\ncarbonate\n**示例输出：**\ncarbohydrate carboh\ncart cart\ncarburetor carbu\ncaramel cara\ncaribou cari\ncarbonic carboni\ncartilage carti\ncarbon carbon\ncarriage carr\ncarton carto\ncar car\ncarbonate carbona\n解答：\n在节点中增加一个time字段来记录路径被经过的次数，如果time=1,则只出现一次，说明可以用来标示单词，作为最短前缀。\n代码如下：\n\n``` c\n#include\n#include\n#include\nusing namespace std;\nconst int NUM = 26;\nconst int MAX = 1000;\nconst int LENGTH = 21;\nchar words[MAX][LENGTH];\nstruct NODE {\n    int time;\n    NODE *next[NUM];\n    NODE () {\n        time = 0;\n        memset(next, 0, sizeof(next));\n    }\n};\n\nvoid insert(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s != '\\0') {\n        int index = *s - 'a';\n        if (!cur->next[index]) {\n            cur->next[index] = new NODE();\n            cur = cur->next[index];\n            cur->time = 1;\n        } else {\n            cur = cur->next[index];\n            (cur->time)++;\n        }\n        s++;\n    }\n}\nvoid search(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s != '\\0') {\n        int index = *s - 'a';\n        cur = cur->next[index];\n        if (cur->time != 1) {\n            printf(\"%c\", *s);\n            s++;\n        } else {\n            printf(\"%c\", *s);\n            break;\n        }\n    }\n    printf(\"\\n\");\n}\nint main() {\n    int total = 0;\n    NODE * root = new NODE();\n    while (scanf(\"%s\", words[total]) != EOF) {\n        insert(root, words[total]);\n        total++;\n    }\n    for (int i = 0; i < total; i++) {\n        printf(\"%s \", words[i]);\n        search(root, words[i]);\n    }\n    return 0;\n}\n```","source":"_posts/POJ2001-Shortest-Prefixes.md","raw":"title: POJ2001-Shortest Prefixes\ntags:\n  - trie\n  - 前缀树\n  - 字典树\nid: 868\ncategories:\n  - 数据结构\ndate: 2014-08-14 16:49:30\n---\n\nTrie又称为前缀树或字典树，它有许多重要用途，如搜索提示，以及作为AC自动机的基础。POJ2001-最短前缀这题是Trie的基础应用。\n**Description**\nA prefix of a string is a substring starting at the beginning of the given string. The prefixes of \"carbon\" are: \"c\", \"ca\", \"car\", \"carb\", \"carbo\", and \"carbon\". Note that the empty string is not considered a prefix in this problem, but every non-empty string is considered to be a prefix of itself. In everyday language, we tend to abbreviate words by prefixes. For example, \"carbohydrate\" is commonly abbreviated by \"carb\". In this problem, given a set of words, you will find for each word the shortest prefix that uniquely identifies the word it represents.\n\nIn the sample input below, \"carbohydrate\" can be abbreviated to \"carboh\", but it cannot be abbreviated to \"carbo\" (or anything shorter) because there are other words in the list that begin with \"carbo\".\n\nAn exact match will override a prefix match. For example, the prefix \"car\" matches the given word \"car\" exactly. Therefore, it is understood without ambiguity that \"car\" is an abbreviation for \"car\" , not for \"carriage\" or any of the other words in the list that begins with \"car\".\n**Input**\nThe input contains at least two, but no more than 1000 lines. Each line contains one word consisting of 1 to 20 lower case letters.\n**Output**\nThe output contains the same number of lines as the input. Each line of the output contains the word from the corresponding line of the input, followed by one blank space, and the shortest prefix that uniquely (without ambiguity) identifies this word.\n**Sample Input**\ncarbohydrate\ncart\ncarburetor\ncaramel\ncaribou\ncarbonic\ncartilage\ncarbon\ncarriage\ncarton\ncar\ncarbonate\n**Sample Output**\ncarbohydrate carboh\ncart cart\ncarburetor carbu\ncaramel cara\ncaribou cari\ncarbonic carboni\ncartilage carti\ncarbon carbon\ncarriage carr\ncarton carto\ncar car\ncarbonate carbona\n​​​​​**描述**\n一个字符串的前缀是从头开始的字符串的子串。\"carbon\"的前缀有：\"c\",\"ca\",\"car\",\"carb\",\"carbo\"和\"carbon\".注意在这个问题中空串不认为是前缀，但是每个非空字符串自身可以认为是一个前缀。在日常用于中，我们倾向于用前缀来缩写词。例如，“carbohydrate\"常缩写成\"carb\".在这个问题中，我们给出一系列单词，要求能够唯一标识单词的最短前缀。\n\n例如在下面的例子中，\"carbohydrate\"可以缩写成\"carboh\",但是它不能缩写成\"carbo\"(或者更短),因为在这些词中，还有一个词是由\"carbo\"开始的.\n\n精确匹配将覆盖前缀匹配。例如，前缀\"car\"精确匹配单词\"car\".因此,”car\"可以毫无歧义的认为是\"car\"的简写,而不是\"carriage\"的，或者其它一些由\"car\"作为前缀的单词.\n**输入：**\n输入至少包含两个，不超过1000行，每行宝行一个由1到20个字母组成的单词。\n**输出：**\n输出包含与输入相同的行数。每一行输出由对应的输入组成，跟着一个空格，之后是唯一(无歧义)标示单词的最短前缀.\n**示例输入：**\ncarbohydrate\ncart\ncarburetor\ncaramel\ncaribou\ncarbonic\ncartilage\ncarbon\ncarriage\ncarton\ncar\ncarbonate\n**示例输出：**\ncarbohydrate carboh\ncart cart\ncarburetor carbu\ncaramel cara\ncaribou cari\ncarbonic carboni\ncartilage carti\ncarbon carbon\ncarriage carr\ncarton carto\ncar car\ncarbonate carbona\n解答：\n在节点中增加一个time字段来记录路径被经过的次数，如果time=1,则只出现一次，说明可以用来标示单词，作为最短前缀。\n代码如下：\n\n``` c\n#include\n#include\n#include\nusing namespace std;\nconst int NUM = 26;\nconst int MAX = 1000;\nconst int LENGTH = 21;\nchar words[MAX][LENGTH];\nstruct NODE {\n    int time;\n    NODE *next[NUM];\n    NODE () {\n        time = 0;\n        memset(next, 0, sizeof(next));\n    }\n};\n\nvoid insert(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s != '\\0') {\n        int index = *s - 'a';\n        if (!cur->next[index]) {\n            cur->next[index] = new NODE();\n            cur = cur->next[index];\n            cur->time = 1;\n        } else {\n            cur = cur->next[index];\n            (cur->time)++;\n        }\n        s++;\n    }\n}\nvoid search(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s != '\\0') {\n        int index = *s - 'a';\n        cur = cur->next[index];\n        if (cur->time != 1) {\n            printf(\"%c\", *s);\n            s++;\n        } else {\n            printf(\"%c\", *s);\n            break;\n        }\n    }\n    printf(\"\\n\");\n}\nint main() {\n    int total = 0;\n    NODE * root = new NODE();\n    while (scanf(\"%s\", words[total]) != EOF) {\n        insert(root, words[total]);\n        total++;\n    }\n    for (int i = 0; i < total; i++) {\n        printf(\"%s \", words[i]);\n        search(root, words[i]);\n    }\n    return 0;\n}\n```","slug":"POJ2001-Shortest-Prefixes","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qh00nz26s65e065m7o"},{"title":"Octave中的for循环","id":"844","date":"2014-07-20T02:56:32.000Z","_content":"\n之前就选修过Angrew Ng的机器学习,但是那是一味的只追求进度，所以收获甚微，于是这次又重新选修了这门课。\n\n这么课程使用Octave语言，这可以说是Matlab的开源版本，使用这种高阶语言，可以让我们更专注于算法层面。今天在实现sigmoid函数时，老是出错。原来是忘记了在每个for循环之后加上end. 还有一点需要说明的是,在Octave中，数组是从1开始的。\n```\nx = [1 2; 3 4]\ng = zeros(size(x));\nfor i = 1:size(x,1)\n    for j = 1:size(x,2)\n        g(i,j) = 1 / (1 + e ^ (-x(i, j)));\n    end \nend\ng\n```\n","source":"_posts/Octave中的for循环.md","raw":"title: Octave中的for循环\ntags:\n  - octave\nid: 844\ncategories:\n  - 机器学习\ndate: 2014-07-20 10:56:32\n---\n\n之前就选修过Angrew Ng的机器学习,但是那是一味的只追求进度，所以收获甚微，于是这次又重新选修了这门课。\n\n这么课程使用Octave语言，这可以说是Matlab的开源版本，使用这种高阶语言，可以让我们更专注于算法层面。今天在实现sigmoid函数时，老是出错。原来是忘记了在每个for循环之后加上end. 还有一点需要说明的是,在Octave中，数组是从1开始的。\n```\nx = [1 2; 3 4]\ng = zeros(size(x));\nfor i = 1:size(x,1)\n    for j = 1:size(x,2)\n        g(i,j) = 1 / (1 + e ^ (-x(i, j)));\n    end \nend\ng\n```\n","slug":"Octave中的for循环","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ql00o726s6fdumg49d"},{"title":"N后问题递归解","id":"1059","date":"2015-10-30T07:49:43.000Z","_content":"\n8后问题(Eight Queen Problem)是指在一个8 * 8的西洋棋盘上要如何放置8个皇后棋且不会互相吃到对方；皇后棋可以吃掉任何它所在的那一列、那一行，以及那两个对角线(米字形)上的任何棋子。请写一个程序，读入一个值n表示棋盘的大小，然后求出n * n格棋盘上放n个皇后棋且不会相互吃掉对方的所有解答。\n\n说明。这是广义的N后问题，因为所要求的是“所有”解答，而不单是其中的一组，对大多数会运用递归的人来说，这个题目反而容易做些。这一类型题目的揭发通常要用到回溯(Backtrack)的技巧--不管用递归还是不用递归都是如此，虽然会浪费时间，但多半会找到答案。\n\n依据题意，写了一个递归的方法，判断是否能放置皇后时有点麻烦，应该有更简便的方法。\n``` java\n import java.util.Arrays;\n\npublic class NQueens {\n\tpublic static int totalNQueens(int n) {\n        boolean[][] board = new boolean[n][n];\n        return totalNQueens(0, n, board);\n    }\n\t//check if queen can put on board[row][col]\n\tprivate static boolean canPutCheck(int row, int col, int n, boolean[][] board) {\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tif (board[row][i]) //row\n\t\t\t\treturn false;\n\t\t\tif (board[i][col]) //col\n\t\t\t\treturn false;\n\t\t}\n\t\t//diagonal\n\t\tint i = 0;\n\t\twhile (row + i < n && col + i < n) {\n\t\t\tif (board[row + i][col +i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\ti = 0;\n\t\twhile (row - i >= 0 && col - i >= 0) {\n\t\t\tif (board[row - i][col - i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\t//back diagonal\n\t\ti = 0;\n\t\twhile (row + i < n && col - i >= 0) {\n\t\t\tif (board[row + i][col - i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\ti = 0;\n\t\twhile (row - i >= 0 && col + i < n) {\n\t\t\tif (board[row - i][col + i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\treturn true;\n\n\t}\n\tprivate static int totalNQueens(int row, int n, boolean[][] board) {\n\t\tif (row == n) { \n\t\t\treturn 1;\n\t\t}\n\t\tint count = 0;\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (canPutCheck(row, j, n, board)) {\n\t\t\t\tboard[row][j] = true;\n\t\t\t\tcount += totalNQueens(row + 1, n, board);\n\t\t\t\tboard[row][j] = false; //backtrack\n\t\t\t}\n\t\t}\n\t\treturn count;\n\n\t}\n\tpublic static void main(String[] args) {\n\t\tfor (int i = 4; i < 10; i++)\n\t\t\tSystem.out.println(i + \" \" + totalNQueens(i));\n\t}\n}\n\n```","source":"_posts/N后问题递归解.md","raw":"title: N后问题递归解\ntags:\n  - C名题百则\nid: 1059\ncategories:\n  - 算法\ndate: 2015-10-30 15:49:43\n---\n\n8后问题(Eight Queen Problem)是指在一个8 * 8的西洋棋盘上要如何放置8个皇后棋且不会互相吃到对方；皇后棋可以吃掉任何它所在的那一列、那一行，以及那两个对角线(米字形)上的任何棋子。请写一个程序，读入一个值n表示棋盘的大小，然后求出n * n格棋盘上放n个皇后棋且不会相互吃掉对方的所有解答。\n\n说明。这是广义的N后问题，因为所要求的是“所有”解答，而不单是其中的一组，对大多数会运用递归的人来说，这个题目反而容易做些。这一类型题目的揭发通常要用到回溯(Backtrack)的技巧--不管用递归还是不用递归都是如此，虽然会浪费时间，但多半会找到答案。\n\n依据题意，写了一个递归的方法，判断是否能放置皇后时有点麻烦，应该有更简便的方法。\n``` java\n import java.util.Arrays;\n\npublic class NQueens {\n\tpublic static int totalNQueens(int n) {\n        boolean[][] board = new boolean[n][n];\n        return totalNQueens(0, n, board);\n    }\n\t//check if queen can put on board[row][col]\n\tprivate static boolean canPutCheck(int row, int col, int n, boolean[][] board) {\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tif (board[row][i]) //row\n\t\t\t\treturn false;\n\t\t\tif (board[i][col]) //col\n\t\t\t\treturn false;\n\t\t}\n\t\t//diagonal\n\t\tint i = 0;\n\t\twhile (row + i < n && col + i < n) {\n\t\t\tif (board[row + i][col +i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\ti = 0;\n\t\twhile (row - i >= 0 && col - i >= 0) {\n\t\t\tif (board[row - i][col - i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\t//back diagonal\n\t\ti = 0;\n\t\twhile (row + i < n && col - i >= 0) {\n\t\t\tif (board[row + i][col - i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\ti = 0;\n\t\twhile (row - i >= 0 && col + i < n) {\n\t\t\tif (board[row - i][col + i])\n\t\t\t\treturn false;\n\t\t\ti++;\n\t\t}\n\t\treturn true;\n\n\t}\n\tprivate static int totalNQueens(int row, int n, boolean[][] board) {\n\t\tif (row == n) { \n\t\t\treturn 1;\n\t\t}\n\t\tint count = 0;\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (canPutCheck(row, j, n, board)) {\n\t\t\t\tboard[row][j] = true;\n\t\t\t\tcount += totalNQueens(row + 1, n, board);\n\t\t\t\tboard[row][j] = false; //backtrack\n\t\t\t}\n\t\t}\n\t\treturn count;\n\n\t}\n\tpublic static void main(String[] args) {\n\t\tfor (int i = 4; i < 10; i++)\n\t\t\tSystem.out.println(i + \" \" + totalNQueens(i));\n\t}\n}\n\n```","slug":"N后问题递归解","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qo00oc26s6kz7feo2t"},{"title":"MySQL的timestamp类型 ","id":"677","date":"2014-04-12T07:03:30.000Z","_content":"\n在数据库应用中，时间字段是极为常用的，而timestamp因为有一个很好的特性，所以经常用到。例如将timestamp设置为NOT NULL DEFAULT CURRENT_TIMESTAMP时，在数据第一次插入时，时间会自动设置为当前时间。\n\n而如果再加上ON UPDATE CURRENT_TIMESTAMP，也就是将timestamp类型设置为 NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP，这样在更新数据时，就会自动更新为当前时间。如此，就没有必要在更新数据时，使用now函数。\n\n最近在做一个项目，令我意外的是，一个同事竟然不知道有这个类型，所以在更新数据时，他要使用now函数。他说在数据结构设计时，不会关心具体数据库提供的特性。即便如此，我还是认为，数据结构设计还是要接地气的。","source":"_posts/MySQL的timestamp类型.md","raw":"title: 'MySQL的timestamp类型 '\ntags:\n  - MySQL\n  - timestamp\n  - 自动更新\nid: 677\ncategories:\n  - 数据库\ndate: 2014-04-12 15:03:30\n---\n\n在数据库应用中，时间字段是极为常用的，而timestamp因为有一个很好的特性，所以经常用到。例如将timestamp设置为NOT NULL DEFAULT CURRENT_TIMESTAMP时，在数据第一次插入时，时间会自动设置为当前时间。\n\n而如果再加上ON UPDATE CURRENT_TIMESTAMP，也就是将timestamp类型设置为 NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP，这样在更新数据时，就会自动更新为当前时间。如此，就没有必要在更新数据时，使用now函数。\n\n最近在做一个项目，令我意外的是，一个同事竟然不知道有这个类型，所以在更新数据时，他要使用now函数。他说在数据结构设计时，不会关心具体数据库提供的特性。即便如此，我还是认为，数据结构设计还是要接地气的。","slug":"MySQL的timestamp类型","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qr00of26s69p7g1dfl"},{"title":"MMSEG分词","id":"786","date":"2014-07-08T15:44:38.000Z","_content":"\n很早之前就知道MMSEG分词算法，网上也有各种语言的实现。最近了解Sphinx-for-Chinese的分词后，才知道它也是使用的MMSEG，并且CoreSeek也是使用的MMSEG。也许MMSEG是互联网上使用知名度最高的分词算法了吧，因为它简单并且高效。\n\n更进一步了解后，知道MMSEG是台湾人蔡志浩提出来的。蔡志浩是一位心理学教师，在美国伊利诺伊读博士期间，选修了语言学，在这个过程中，随手写了MMSEG。看蔡志浩网站，总是很舒心，因为蔡老师的文笔很好，总会用通俗的语言把问题讲清楚，而且蔡老师的博客涉及范围极广，设计，心理，写作，社会观察，旅游等等。也正是因为他的博客，我才用实名建立自己的博客。以下回归正题。\n\nMMSEG总的说来就是四个规则。\n1.最长匹配原则\n2.最大平均长度\n3.最小长度方差\n4.最大单字单词的语素自由度\n\n算法步骤：\n1.选定一个分词个数，得到可行的分词情形\n2.利用4条原则得到最优分词可能\n3.得到最优分词的第一个词，回到步骤1继续分词\n\n举个例子最好理解。下面是要对“研究生命起源的原因主要是因为它的重要性”进行分词。\n1.首先选定分词个数为3，则可以得到可行的分词情形如下：\n研 究 生\n研 究 生命\n研究 生命 起\n研究 生命 起源\n研究生 命 起\n研究生 命 起源\n2.利用4条原则得到最优分词可能\n运用第1条原则后，可以得到最优分词可能为一下两条\n研究 生命 起源\n研究生 命 起源\n运用第2条原则，这两个结果相同\n运用第3条原则，可以得到最优的结果为\n研究 生命 起源\n3.从最优结果中得到第一个词，也就是“研究”，之后对“生命起源的原因主要是因为它的重要性”运用相同的步骤进行分词\n\n有必要对原则4进行解释，这条原则说的是单字的成为语素的自由度。当分到”主要是因为“就会用到。对于”主要是因为“\n第1步骤中得到：\n主 要 是\n主 要是 因为\n主要 是 因\n主要 是 因为\n第2步骤中，由前三条原则，只剩下一下两个\n主要 是 因为\n主 要是 因为\n之后再运用第4条原则，这里单字”是“为独立语素的可能比”主“要大，所以最优结果为\n主要 是 因为\n\n见过的MMSEG算法实现中，素心如何天上月的[http://yongsun.me/2013/06/simple-implementation-of-mmseg-with-python/](http://yongsun.me/2013/06/simple-implementation-of-mmseg-with-python/)无疑是最简明清晰的。Python确实不错，短短100行就把算法的精髓展示出来，并且几乎可以不用写注释了。模仿他的实现，写了一遍。\n\n``` python\n#coding:utf-8\nfrom collections import defaultdict\nimport codecs\nfrom math import log\n\nclass Trie(object):\n    class TrieNode():\n        def __init__(self):\n            self.value = 0\n            self.trans = {}\n    def __init__(self):\n        self.root = self.TrieNode()\n    def add(self, word, value=1):\n        cur = self.root\n        for ch in word:\n            try:\n                cur = cur.trans[ch]\n            except:\n                cur.trans[ch] = self.TrieNode()\n                cur = cur.trans[ch]\n        cur.value = value\n    def _walk(self, node, ch):\n        if ch in node.trans:\n            node = node.trans[ch]\n            return node, node.value\n        else:\n            return None, 0\n    def match_all(self, s):\n        ret = []\n        cur = self.root\n        for ch in s:\n            cur, value = self._walk(cur, ch)\n            if not cur:\n                break\n            if value:\n                ret.append(value)\n        return ret\n\nclass Dict(Trie):\n    def __init__(self, filename):\n        super(Dict, self).__init__()\n        self.load(filename)\n\n    def load(self, filename):\n        with codecs.open(filename, \"r\", \"utf-8\") as f:\n            for line in f:\n                word = line.strip()\n                self.add(word, word)\nclass CharFreq(defaultdict):\n    def __init__(self, filename):\n        super(CharFreq, self).__init__(lambda: 1)\n        self.load(filename)\n    def load(self, filename):\n        with codecs.open(filename, \"r\", \"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                word, freq = line.split(' ')\n                self[word] = freq\nclass MMSEG():\n    class Chunk():\n        def __init__(self, words, chars):\n            self.words = words\n            self.lens = map(lambda x: len(x), words)\n            self.length = sum(self.lens)\n            self.average = self.length * 1.0 / len(words)\n            self.variance = sum(map(lambda x: (x - self.average) ** 2, self.lens)) / len(words)\n            self.free = sum(log(float(chars[w])) for w in self.words if len(w) == 1)\n        def __lt__(self, other):\n            return (self.length, self.average, -self.variance, self.free) < (other.length, other.average, -other.variance, other.free)\n    def __init__(self, dic, chars):\n        self.dic = dic\n        self.chars = chars\n    def __get_chunks(self, s, depth=3):\n        ret = []\n        def __get_chunk(self, s, num, seg):\n            if not num or not s:\n                if seg:\n                    ret.append(self.Chunk(seg, self.chars))\n                return\n            else:\n                m = self.dic.match_all(s)\n                if not m:\n                    __get_chunk(self, s[1:], num - 1, seg + [s[0]])\n                else:\n                    for w in m:\n                        __get_chunk(self, s[len(w):], num - 1, seg + [w])\n        __get_chunk(self, s, depth, [])\n        return ret\n    def segment(self, s):\n        while s:\n            chunks = self.__get_chunks(s)\n            best = max(chunks)\n            yield best.words[0]\n            s = s[len(best.words[0]):]\n\nif __name__ == \"__main__\":\n    dic = Dict(\"dict.txt\")\n    chars = CharFreq('chars.txt')\n    mmseg = MMSEG(dic, chars)\n    print ' '.join(mmseg.segment(u\"北京欢迎你\"))\n    print ' '.join(mmseg.segment(u\"研究生命起源的原因主要是因为它的重要性\"))\n    print ' '.join(mmseg.segment(u'开发票'))\n    print ' '.join(mmseg.segment(u'武松杀嫂雕塑是艺术，还是恶俗？大家怎么看的？'))\n    print ' '.join(mmseg.segment(u'陈明真做客《麻辣天后宫》的那期视频哪里有？'))\n    print ' '.join(mmseg.segment(u'压缩技术是解决网络传输负担的 有效技术。数据压缩有无损压缩和有损压缩两种。在搜索引擎中用到的压缩技术属于无损压缩。接下来，我们将先讲解各种倒排索引压缩算法，然后来分析搜索引擎技术中词典和倒排表的压缩。'))\n```\n用到的两个文件[dict.txt](http://program.dengshilong.org/wp-content/uploads/2014/07/dict.txt)和[chars.txt](http://program.dengshilong.org/wp-content/uploads/2014/07/chars.txt)\n","source":"_posts/MMSEG分词.md","raw":"title: MMSEG分词\ntags:\n  - mmseg\n  - Python\n  - 分词\nid: 786\ncategories:\n  - 搜索引擎\ndate: 2014-07-08 23:44:38\n---\n\n很早之前就知道MMSEG分词算法，网上也有各种语言的实现。最近了解Sphinx-for-Chinese的分词后，才知道它也是使用的MMSEG，并且CoreSeek也是使用的MMSEG。也许MMSEG是互联网上使用知名度最高的分词算法了吧，因为它简单并且高效。\n\n更进一步了解后，知道MMSEG是台湾人蔡志浩提出来的。蔡志浩是一位心理学教师，在美国伊利诺伊读博士期间，选修了语言学，在这个过程中，随手写了MMSEG。看蔡志浩网站，总是很舒心，因为蔡老师的文笔很好，总会用通俗的语言把问题讲清楚，而且蔡老师的博客涉及范围极广，设计，心理，写作，社会观察，旅游等等。也正是因为他的博客，我才用实名建立自己的博客。以下回归正题。\n\nMMSEG总的说来就是四个规则。\n1.最长匹配原则\n2.最大平均长度\n3.最小长度方差\n4.最大单字单词的语素自由度\n\n算法步骤：\n1.选定一个分词个数，得到可行的分词情形\n2.利用4条原则得到最优分词可能\n3.得到最优分词的第一个词，回到步骤1继续分词\n\n举个例子最好理解。下面是要对“研究生命起源的原因主要是因为它的重要性”进行分词。\n1.首先选定分词个数为3，则可以得到可行的分词情形如下：\n研 究 生\n研 究 生命\n研究 生命 起\n研究 生命 起源\n研究生 命 起\n研究生 命 起源\n2.利用4条原则得到最优分词可能\n运用第1条原则后，可以得到最优分词可能为一下两条\n研究 生命 起源\n研究生 命 起源\n运用第2条原则，这两个结果相同\n运用第3条原则，可以得到最优的结果为\n研究 生命 起源\n3.从最优结果中得到第一个词，也就是“研究”，之后对“生命起源的原因主要是因为它的重要性”运用相同的步骤进行分词\n\n有必要对原则4进行解释，这条原则说的是单字的成为语素的自由度。当分到”主要是因为“就会用到。对于”主要是因为“\n第1步骤中得到：\n主 要 是\n主 要是 因为\n主要 是 因\n主要 是 因为\n第2步骤中，由前三条原则，只剩下一下两个\n主要 是 因为\n主 要是 因为\n之后再运用第4条原则，这里单字”是“为独立语素的可能比”主“要大，所以最优结果为\n主要 是 因为\n\n见过的MMSEG算法实现中，素心如何天上月的[http://yongsun.me/2013/06/simple-implementation-of-mmseg-with-python/](http://yongsun.me/2013/06/simple-implementation-of-mmseg-with-python/)无疑是最简明清晰的。Python确实不错，短短100行就把算法的精髓展示出来，并且几乎可以不用写注释了。模仿他的实现，写了一遍。\n\n``` python\n#coding:utf-8\nfrom collections import defaultdict\nimport codecs\nfrom math import log\n\nclass Trie(object):\n    class TrieNode():\n        def __init__(self):\n            self.value = 0\n            self.trans = {}\n    def __init__(self):\n        self.root = self.TrieNode()\n    def add(self, word, value=1):\n        cur = self.root\n        for ch in word:\n            try:\n                cur = cur.trans[ch]\n            except:\n                cur.trans[ch] = self.TrieNode()\n                cur = cur.trans[ch]\n        cur.value = value\n    def _walk(self, node, ch):\n        if ch in node.trans:\n            node = node.trans[ch]\n            return node, node.value\n        else:\n            return None, 0\n    def match_all(self, s):\n        ret = []\n        cur = self.root\n        for ch in s:\n            cur, value = self._walk(cur, ch)\n            if not cur:\n                break\n            if value:\n                ret.append(value)\n        return ret\n\nclass Dict(Trie):\n    def __init__(self, filename):\n        super(Dict, self).__init__()\n        self.load(filename)\n\n    def load(self, filename):\n        with codecs.open(filename, \"r\", \"utf-8\") as f:\n            for line in f:\n                word = line.strip()\n                self.add(word, word)\nclass CharFreq(defaultdict):\n    def __init__(self, filename):\n        super(CharFreq, self).__init__(lambda: 1)\n        self.load(filename)\n    def load(self, filename):\n        with codecs.open(filename, \"r\", \"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                word, freq = line.split(' ')\n                self[word] = freq\nclass MMSEG():\n    class Chunk():\n        def __init__(self, words, chars):\n            self.words = words\n            self.lens = map(lambda x: len(x), words)\n            self.length = sum(self.lens)\n            self.average = self.length * 1.0 / len(words)\n            self.variance = sum(map(lambda x: (x - self.average) ** 2, self.lens)) / len(words)\n            self.free = sum(log(float(chars[w])) for w in self.words if len(w) == 1)\n        def __lt__(self, other):\n            return (self.length, self.average, -self.variance, self.free) < (other.length, other.average, -other.variance, other.free)\n    def __init__(self, dic, chars):\n        self.dic = dic\n        self.chars = chars\n    def __get_chunks(self, s, depth=3):\n        ret = []\n        def __get_chunk(self, s, num, seg):\n            if not num or not s:\n                if seg:\n                    ret.append(self.Chunk(seg, self.chars))\n                return\n            else:\n                m = self.dic.match_all(s)\n                if not m:\n                    __get_chunk(self, s[1:], num - 1, seg + [s[0]])\n                else:\n                    for w in m:\n                        __get_chunk(self, s[len(w):], num - 1, seg + [w])\n        __get_chunk(self, s, depth, [])\n        return ret\n    def segment(self, s):\n        while s:\n            chunks = self.__get_chunks(s)\n            best = max(chunks)\n            yield best.words[0]\n            s = s[len(best.words[0]):]\n\nif __name__ == \"__main__\":\n    dic = Dict(\"dict.txt\")\n    chars = CharFreq('chars.txt')\n    mmseg = MMSEG(dic, chars)\n    print ' '.join(mmseg.segment(u\"北京欢迎你\"))\n    print ' '.join(mmseg.segment(u\"研究生命起源的原因主要是因为它的重要性\"))\n    print ' '.join(mmseg.segment(u'开发票'))\n    print ' '.join(mmseg.segment(u'武松杀嫂雕塑是艺术，还是恶俗？大家怎么看的？'))\n    print ' '.join(mmseg.segment(u'陈明真做客《麻辣天后宫》的那期视频哪里有？'))\n    print ' '.join(mmseg.segment(u'压缩技术是解决网络传输负担的 有效技术。数据压缩有无损压缩和有损压缩两种。在搜索引擎中用到的压缩技术属于无损压缩。接下来，我们将先讲解各种倒排索引压缩算法，然后来分析搜索引擎技术中词典和倒排表的压缩。'))\n```\n用到的两个文件[dict.txt](http://program.dengshilong.org/wp-content/uploads/2014/07/dict.txt)和[chars.txt](http://program.dengshilong.org/wp-content/uploads/2014/07/chars.txt)\n","slug":"MMSEG分词","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qv00oo26s6odqra38x"},{"title":"Lucene编写Analyzer","date":"2015-12-23T04:01:07.000Z","_content":"在有些应用中，需要针对应用的特征编写Analyzer，这里以Lucene5.0为例。在许多中文搜索应用，往往需要对文本进行分词，而用单字分词不能满足条件，所以需要使用其它分词，而MMSEG是其中一种。\n\n从网上找到了chenbl写的[mmseg4j](https://github.com/chenlb/mmseg4j-core)，学会如何使用mmseg4j后，开始编写Analyzer。查看[Analysis包](https://lucene.apache.org/core/5_4_0/core/org/apache/lucene/analysis/package-summary.html#package_description)的介绍后，发现主要是实现一个Tokenizer，然后在Analyzer中调用即可。于是编写了如下MMSegAnalyzer,\n```\npublic class MMSegAnalyzer extends Analyzer {\n    public MMSegAnalyzer() {\n    }\n    @Override\n    protected TokenStreamComponents createComponents(String fieldName) {\n        // TODO Auto-generated method stub\n        return new TokenStreamComponents(new MMSegTokenizer());\n    }\n}\n```\n之后编写MMSegTokenizer,\n```\npublic class MMSegTokenizer extends Tokenizer {\n    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n    Dictionary dic;\n    Seg seg;\n    MMSeg mmSeg;\n\n    public MMSegTokenizer() {\n        dic = Dictionary.getInstance();\n        seg = new ComplexSeg(dic);\n        mmSeg = new MMSeg(input, seg);\n    }\n\n    @Override\n    public boolean incrementToken() throws IOException {\n        clearAttributes();\n        // TODO Auto-generated method stub\n        Word word = null;\n        while((word = mmSeg.next())!=null) {\n            termAtt.copyBuffer(word.getSen(), word.getWordOffset(), word.getLength());\n            offsetAtt.setOffset(word.getStartOffset(), word.getEndOffset());\n            return true;\n        }\n        return false;\n    }\n    @Override\n    public void close() throws IOException {\n        super.close();\n    }\n\n    @Override\n    public void reset() throws IOException {\n        super.reset();\n    }\n}\n```\n其中\n```\nprivate final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\nprivate final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n```\n这两个属性是用来设置Token的内容和文本的偏移位置。\n然后使用《Lucene in Action2》第四章中提到的AnalyzerDemo.java来进行测试，发现抛出异常java.lang.IllegalStateException: TokenStream contract violation，\n查看TokenStream类后,知道reset函数是在incrementToken函数之前调用，主要是完成一些初始化工作。猜测是MMSeg有一些初始化工作没有完成，然后查看MMSeg类，发现有个reset函数，正是完成一些初始化工作。\n于是修改修改MMSegTokenizer的reset函数，如下:\n```\npublic class MMSegTokenizer extends Tokenizer {\n    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n    Dictionary dic;\n    Seg seg;\n    MMSeg mmSeg;\n\n    public MMSegTokenizer() {\n        dic = Dictionary.getInstance();\n        seg = new ComplexSeg(dic);\n        mmSeg = new MMSeg(input, seg);\n    }\n\n    @Override\n    public boolean incrementToken() throws IOException {\n        clearAttributes();\n        // TODO Auto-generated method stub\n        Word word = null;\n        while((word = mmSeg.next())!=null) {\n            termAtt.copyBuffer(word.getSen(), word.getWordOffset(), word.getLength());\n            offsetAtt.setOffset(word.getStartOffset(), word.getEndOffset());\n            return true;\n        }\n        return false;\n    }\n    @Override\n    public void close() throws IOException {\n        super.close();\n    }\n\n    @Override\n    public void reset() throws IOException {\n        super.reset();\n        mmSeg.reset(input);\n    }\n}\n```\nMMSegAnalyzer可以进行分词了。之后看mmseg4j的实现，才发现要实现一个高效的MMSEG分词并不是一件容易的事。\n","source":"_posts/Lucene编写Analyzer.md","raw":"title: Lucene编写Analyzer\ndate: 2015-12-23 12:01:07\ntags: Lucene\ncategories: Lucene\n---\n在有些应用中，需要针对应用的特征编写Analyzer，这里以Lucene5.0为例。在许多中文搜索应用，往往需要对文本进行分词，而用单字分词不能满足条件，所以需要使用其它分词，而MMSEG是其中一种。\n\n从网上找到了chenbl写的[mmseg4j](https://github.com/chenlb/mmseg4j-core)，学会如何使用mmseg4j后，开始编写Analyzer。查看[Analysis包](https://lucene.apache.org/core/5_4_0/core/org/apache/lucene/analysis/package-summary.html#package_description)的介绍后，发现主要是实现一个Tokenizer，然后在Analyzer中调用即可。于是编写了如下MMSegAnalyzer,\n```\npublic class MMSegAnalyzer extends Analyzer {\n    public MMSegAnalyzer() {\n    }\n    @Override\n    protected TokenStreamComponents createComponents(String fieldName) {\n        // TODO Auto-generated method stub\n        return new TokenStreamComponents(new MMSegTokenizer());\n    }\n}\n```\n之后编写MMSegTokenizer,\n```\npublic class MMSegTokenizer extends Tokenizer {\n    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n    Dictionary dic;\n    Seg seg;\n    MMSeg mmSeg;\n\n    public MMSegTokenizer() {\n        dic = Dictionary.getInstance();\n        seg = new ComplexSeg(dic);\n        mmSeg = new MMSeg(input, seg);\n    }\n\n    @Override\n    public boolean incrementToken() throws IOException {\n        clearAttributes();\n        // TODO Auto-generated method stub\n        Word word = null;\n        while((word = mmSeg.next())!=null) {\n            termAtt.copyBuffer(word.getSen(), word.getWordOffset(), word.getLength());\n            offsetAtt.setOffset(word.getStartOffset(), word.getEndOffset());\n            return true;\n        }\n        return false;\n    }\n    @Override\n    public void close() throws IOException {\n        super.close();\n    }\n\n    @Override\n    public void reset() throws IOException {\n        super.reset();\n    }\n}\n```\n其中\n```\nprivate final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\nprivate final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n```\n这两个属性是用来设置Token的内容和文本的偏移位置。\n然后使用《Lucene in Action2》第四章中提到的AnalyzerDemo.java来进行测试，发现抛出异常java.lang.IllegalStateException: TokenStream contract violation，\n查看TokenStream类后,知道reset函数是在incrementToken函数之前调用，主要是完成一些初始化工作。猜测是MMSeg有一些初始化工作没有完成，然后查看MMSeg类，发现有个reset函数，正是完成一些初始化工作。\n于是修改修改MMSegTokenizer的reset函数，如下:\n```\npublic class MMSegTokenizer extends Tokenizer {\n    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);\n    Dictionary dic;\n    Seg seg;\n    MMSeg mmSeg;\n\n    public MMSegTokenizer() {\n        dic = Dictionary.getInstance();\n        seg = new ComplexSeg(dic);\n        mmSeg = new MMSeg(input, seg);\n    }\n\n    @Override\n    public boolean incrementToken() throws IOException {\n        clearAttributes();\n        // TODO Auto-generated method stub\n        Word word = null;\n        while((word = mmSeg.next())!=null) {\n            termAtt.copyBuffer(word.getSen(), word.getWordOffset(), word.getLength());\n            offsetAtt.setOffset(word.getStartOffset(), word.getEndOffset());\n            return true;\n        }\n        return false;\n    }\n    @Override\n    public void close() throws IOException {\n        super.close();\n    }\n\n    @Override\n    public void reset() throws IOException {\n        super.reset();\n        mmSeg.reset(input);\n    }\n}\n```\nMMSegAnalyzer可以进行分词了。之后看mmseg4j的实现，才发现要实现一个高效的MMSEG分词并不是一件容易的事。\n","slug":"Lucene编写Analyzer","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4qy00ou26s6ragxb04f"},{"title":"Lucene索引文件格式","id":"959","date":"2014-11-19T13:56:33.000Z","_content":"\n随着对Solr的进一步深入，自然就想了解Lucene的索引文件格式。之前写的段合并小工具不知怎么不起作用了(后来发现是没有更新代码)，于是把觉先的《Lucene源码剖析》又翻出来看，顺便看了一下 Lucene索引格式。Solr使用的是1.4的，查看文件格式，与Lucene2.9的文件格式相差不大，依然有参考价值。\n\n到索引目录下查看，一共有如下几种文件格式。对照[http://lucene.apache.org/core/2_9_4/fileformats.html](http://lucene.apache.org/core/2_9_4/fileformats.html)，知道每一种格式的大概用途。\nsegments.gen, segments_N Segments File 主要保存索引段信息\n.fnm Fields 域的元数据信息文件，保存域信息\n.fdx Field Index 域数据索引文件，保存指向域数据文件的指针，方便快速访问域数据文件\n.fdt Field Data 域数据文件，保存每个文档的字段,域的真正值就是在这里保存\n.tis Term Infos 词典文件,记录索引词的信息\n.tii Term Info Index 词典索引文件，记录到tis文件的指向，主要是为了加快访问词典文件\n.frq Frequencies 文档号与词频文件，记录索引词在文档中的词频\n.prx Positions 词位置信息文件，记录索引词的位置信息\n.nrm Norms 标准化因子文件，记录文档和域的权重\n.tvx Term Vector Index 词向量索引文件，保存到词向量文档文件和词向量域文件的指针\n.tvd Term Vector Documents 词向量文档文件，记录文档第一个域与其它域的偏移\n.tvf Term Vector Fields 词向量域文件，记录域级别的词向量\n.del Deleted Document 记录哪个文档被删除\n\n还有.cfs文件，也即是Compound File，当将所有索引文件合成一个文件时才会出现，主要是减少文件句柄。\nwrite.lock,用来互斥的写索引文件。\n而.tvx,tvd,tvf只有在启用词向量时才会出现。\n","source":"_posts/Lucene索引文件格式.md","raw":"title: Lucene索引文件格式\ntags:\n  - Lucene\n  - 索引\nid: 959\ncategories:\n  - Lucene\ndate: 2014-11-19 21:56:33\n---\n\n随着对Solr的进一步深入，自然就想了解Lucene的索引文件格式。之前写的段合并小工具不知怎么不起作用了(后来发现是没有更新代码)，于是把觉先的《Lucene源码剖析》又翻出来看，顺便看了一下 Lucene索引格式。Solr使用的是1.4的，查看文件格式，与Lucene2.9的文件格式相差不大，依然有参考价值。\n\n到索引目录下查看，一共有如下几种文件格式。对照[http://lucene.apache.org/core/2_9_4/fileformats.html](http://lucene.apache.org/core/2_9_4/fileformats.html)，知道每一种格式的大概用途。\nsegments.gen, segments_N Segments File 主要保存索引段信息\n.fnm Fields 域的元数据信息文件，保存域信息\n.fdx Field Index 域数据索引文件，保存指向域数据文件的指针，方便快速访问域数据文件\n.fdt Field Data 域数据文件，保存每个文档的字段,域的真正值就是在这里保存\n.tis Term Infos 词典文件,记录索引词的信息\n.tii Term Info Index 词典索引文件，记录到tis文件的指向，主要是为了加快访问词典文件\n.frq Frequencies 文档号与词频文件，记录索引词在文档中的词频\n.prx Positions 词位置信息文件，记录索引词的位置信息\n.nrm Norms 标准化因子文件，记录文档和域的权重\n.tvx Term Vector Index 词向量索引文件，保存到词向量文档文件和词向量域文件的指针\n.tvd Term Vector Documents 词向量文档文件，记录文档第一个域与其它域的偏移\n.tvf Term Vector Fields 词向量域文件，记录域级别的词向量\n.del Deleted Document 记录哪个文档被删除\n\n还有.cfs文件，也即是Compound File，当将所有索引文件合成一个文件时才会出现，主要是减少文件句柄。\nwrite.lock,用来互斥的写索引文件。\n而.tvx,tvd,tvf只有在启用词向量时才会出现。\n","slug":"Lucene索引文件格式","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4r100oz26s6yduu1wd3"},{"title":"Lucene入门例子","id":"896","date":"2014-08-27T13:27:13.000Z","_content":"\n开始Lucene之路,从官网下了最新的4.9.0,从先从小例子开始.\n建索引\n``` java\npackage org.dsl;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig.OpenMode;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.store.FSDirectory;\nimport org.apache.lucene.util.Version;\nimport java.io.File;\nimport java.io.IOException;\npublic class Index {\n    public static void main(String[] args) throws IOException {\n        String INDEX_DIR = \"e:\\\\index\";\n        Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_4_9);\n        IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_4_9, analyzer);\n        IndexWriter writer = null;\n        iwc.setOpenMode(OpenMode.CREATE);\n        iwc.setUseCompoundFile(false);\n        try {\n            writer = new IndexWriter(FSDirectory.open(new File(INDEX_DIR)), iwc);\n            Document doc = new Document();\n            doc.add(new TextField(\"title\", \"who are you, you are a man\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"A long way to go there. Please drive a car\", Field.Store.NO));\n            writer.addDocument(doc);\n            doc = new Document();\n            doc.add(new TextField(\"title\", \"are you sure\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"He is a good man. He is a driver\", Field.Store.NO));\n            writer.addDocument(doc);\n            writer.commit();\n            writer.close();\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }\n\n}\n```\n搜索\n``` java\npackage org.dsl;\nimport java.io.File;\nimport java.util.Date;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.FSDirectory;\npublic class Search {\n    private Search() {}\n    public static void main(String[] args) throws Exception {\n        String index = \"e:\\\\index\";\n        IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));\n        IndexSearcher searcher = new IndexSearcher(reader);\n        String queryString = \"driver\";\n        Query query = new TermQuery(new Term(\"content\", queryString));\n        System.out.println(\"Searching for: \" + query.toString());\n        Date start = new Date();\n        TopDocs results = searcher.search(query, null, 100);\n        Date end = new Date();\n        System.out.println(\"Time: \"+(end.getTime()-start.getTime())+\"ms\");\n        ScoreDoc[] hits = results.scoreDocs;\n        int numTotalHits = results.totalHits;\n        System.out.println(numTotalHits + \" total matching documents\");\n        for (int i = 0; i < hits.length; i++) {\n            String output = \"\";\n            Document doc = searcher.doc(hits[i].doc);\n            output += \"doc=\"+hits[i].doc+\" score=\"+hits[i].score;\n            String title = doc.get(\"title\");\n            if (title != null) {\n                output += \" \" + title;\n            }\n            System.out.println(output);\n        }\n        reader.close();\n    }\n}\n```\n","source":"_posts/Lucene入门例子.md","raw":"title: Lucene入门例子\ntags:\n  - Lucene\nid: 896\ncategories:\n  - Lucene\ndate: 2014-08-27 21:27:13\n---\n\n开始Lucene之路,从官网下了最新的4.9.0,从先从小例子开始.\n建索引\n``` java\npackage org.dsl;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig.OpenMode;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.store.FSDirectory;\nimport org.apache.lucene.util.Version;\nimport java.io.File;\nimport java.io.IOException;\npublic class Index {\n    public static void main(String[] args) throws IOException {\n        String INDEX_DIR = \"e:\\\\index\";\n        Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_4_9);\n        IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_4_9, analyzer);\n        IndexWriter writer = null;\n        iwc.setOpenMode(OpenMode.CREATE);\n        iwc.setUseCompoundFile(false);\n        try {\n            writer = new IndexWriter(FSDirectory.open(new File(INDEX_DIR)), iwc);\n            Document doc = new Document();\n            doc.add(new TextField(\"title\", \"who are you, you are a man\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"A long way to go there. Please drive a car\", Field.Store.NO));\n            writer.addDocument(doc);\n            doc = new Document();\n            doc.add(new TextField(\"title\", \"are you sure\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"He is a good man. He is a driver\", Field.Store.NO));\n            writer.addDocument(doc);\n            writer.commit();\n            writer.close();\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }\n\n}\n```\n搜索\n``` java\npackage org.dsl;\nimport java.io.File;\nimport java.util.Date;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.FSDirectory;\npublic class Search {\n    private Search() {}\n    public static void main(String[] args) throws Exception {\n        String index = \"e:\\\\index\";\n        IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));\n        IndexSearcher searcher = new IndexSearcher(reader);\n        String queryString = \"driver\";\n        Query query = new TermQuery(new Term(\"content\", queryString));\n        System.out.println(\"Searching for: \" + query.toString());\n        Date start = new Date();\n        TopDocs results = searcher.search(query, null, 100);\n        Date end = new Date();\n        System.out.println(\"Time: \"+(end.getTime()-start.getTime())+\"ms\");\n        ScoreDoc[] hits = results.scoreDocs;\n        int numTotalHits = results.totalHits;\n        System.out.println(numTotalHits + \" total matching documents\");\n        for (int i = 0; i < hits.length; i++) {\n            String output = \"\";\n            Document doc = searcher.doc(hits[i].doc);\n            output += \"doc=\"+hits[i].doc+\" score=\"+hits[i].score;\n            String title = doc.get(\"title\");\n            if (title != null) {\n                output += \" \" + title;\n            }\n            System.out.println(output);\n        }\n        reader.close();\n    }\n}\n```\n","slug":"Lucene入门例子","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4r400p326s680etg6jd"},{"title":"Lucene中扩展codec功能","id":"991","date":"2015-01-16T13:04:44.000Z","_content":"\n从Lucene4.0开始，提供了扩展codec功能，这个功能主要是留给想自己定义索引格式的开发者。\n在此之前，有必要了解codec主要的作用，codec相关的类主要作用是读写索引。 而通过实现FilterCodec，可以很方便的定义自己的codec。 这个方便主要是可以将许多读写索引部分交给已有的codec实现，而只实现自己需要改进的部分。当然如果这样还不能满足需求 可以重新写一个codec。 \n\n写个简单的例子更容易懂，\n在Codec.java中，可以看到，读写索引主要实现以下几个方法 \n``` java\n /** Encodes/decodes postings */\n  public abstract PostingsFormat postingsFormat();\n\n  /** Encodes/decodes docvalues */\n  public abstract DocValuesFormat docValuesFormat();\n\n  /** Encodes/decodes stored fields */\n  public abstract StoredFieldsFormat storedFieldsFormat();\n\n  /** Encodes/decodes term vectors */\n  public abstract TermVectorsFormat termVectorsFormat();\n\n  /** Encodes/decodes field infos file */\n  public abstract FieldInfosFormat fieldInfosFormat();\n\n  /** Encodes/decodes segment info file */\n  public abstract SegmentInfoFormat segmentInfoFormat();\n\n  /** Encodes/decodes document normalization values */\n  public abstract NormsFormat normsFormat();\n\n  /** Encodes/decodes live docs */\n  public abstract LiveDocsFormat liveDocsFormat();\n```\n一个纯文本保存索引的codec是SimpleTextCodec,这个codec的主要目的是用来学习\n\n下面定义自己的codec\n``` java\npublic class HexinCodec extends FilterCodec {\n    final private FieldInfosFormat myTermFieldInfoFormat;\n    public HexinCodec() {\n        super(\"HexinCodec\", new Lucene46Codec());\n        myTermFieldInfoFormat = new SimpleTextFieldInfosFormat();\n    }\n    public FieldInfosFormat fieldInfosFormat() {\n        return myTermFieldInfoFormat;\n    }\n}\n```\n最后，还是让上面的例子跑起来，首先下载Lucene4.8.0的源码，之后在codecs/src/java下新建包org.apache.lucene.codecs.hexin,\n在这个包下面新建类HexinCodec.java,复制上面的代码。\n之后编写测试用的建索引程序Index.java \n``` java\npackage org.hexin;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.codecs.Codec;\nimport org.apache.lucene.codecs.hexin.HexinCodec;\nimport org.apache.lucene.codecs.lucene46.Lucene46Codec;\nimport org.apache.lucene.codecs.simpletext.SimpleTextCodec;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig.OpenMode;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.store.FSDirectory;\nimport org.apache.lucene.util.Version;\n\nimport java.io.File;\nimport java.io.IOException;\npublic class Index {\n    public static void main(String[] args) throws IOException {\n        //Codec codec = new SimpleTextCodec();\n        Codec codec = new HexinCodec();\n        //Codec codec = new Lucene46Codec();\n        String INDEX_DIR = \"e:\\\\index\";\n        Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_48);\n        IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_48, analyzer);\n        iwc.setCodec(codec);\n        IndexWriter writer = null;\n        iwc.setOpenMode(OpenMode.CREATE);\n        iwc.setUseCompoundFile(false);\n        try {\n            writer = new IndexWriter(FSDirectory.open(new File(INDEX_DIR)), iwc);\n            Document doc = new Document();\n            doc.add(new TextField(\"title\", \"who are you, you are a man\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"A long way to go there. Please drive a car\", Field.Store.NO));\n            writer.addDocument(doc);\n            doc = new Document();\n            doc.add(new TextField(\"title\", \"are you sure\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"He is a good man. He is a driver\", Field.Store.NO));\n            writer.addDocument(doc);\n            writer.commit();\n            writer.close();\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }  \n}\n```\n编写测试用的搜索例子Search.java \n``` java\npackage org.hexin;\nimport java.io.File; \nimport java.util.Date;\n\nimport org.apache.lucene.codecs.Codec;\nimport org.apache.lucene.codecs.simpletext.SimpleTextCodec;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.FSDirectory;\npublic class Search {\n    private Search() {}\n    public static void main(String[] args) throws Exception {\n\n        String index = \"e:\\\\index\";\n        IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));\n        IndexSearcher searcher = new IndexSearcher(reader);\n        String queryString = \"driver\";\n        Query query = new TermQuery(new Term(\"content\", queryString));\n        System.out.println(\"Searching for: \" + query.toString());\n        Date start = new Date();\n        TopDocs results = searcher.search(query, null, 100);\n        Date end = new Date();\n        System.out.println(\"Time: \"+(end.getTime()-start.getTime())+\"ms\");\n        ScoreDoc[] hits = results.scoreDocs;\n        int numTotalHits = results.totalHits;\n        System.out.println(numTotalHits + \" total matching documents\");\n        for (int i = 0; i < hits.length; i++) {\n            String output = \"\";\n            Document doc = searcher.doc(hits[i].doc);\n            output += \"doc=\"+hits[i].doc+\" score=\"+hits[i].score;\n            String title = doc.get(\"title\");\n            if (title != null) {\n                output += \" \" + title;\n            }\n            System.out.println(output);\n        }\n        reader.close();\n    }\n}\n```\n\n在Eclipse中运行Index.java,此时会报错\nA SPI class of type org.apache.lucene.codecs.Codec with name 'Lucene46' does not exist. You need to add the corresponding \nJAR file supporting this SPI to your classpath.The current classpath supports the following names:[]\n\n问过定坤后，知道一个解决的办法是去官网下载已经编译过的Lucene二进制包,将其中的META-INF拷贝到core/src/java目录下，写上下面两行\norg.apache.lucene.codecs.simpletext.SimpleTextCodec\norg.apache.lucene.codecs.hexin.HexinCodec\n此时即可运行通过。查看索引文件，有一个fld结尾的文件，其内容为文本文件,保存着字段值,这个文件就是通过SimpleTextCodec写入的，\n而其它文件则是通过Lucene46Codec写入的。\n","source":"_posts/Lucene中扩展codec功能.md","raw":"title: Lucene中扩展codec功能\ntags:\n  - codec\n  - Lucene\nid: 991\ncategories:\n  - Lucene\ndate: 2015-01-16 21:04:44\n---\n\n从Lucene4.0开始，提供了扩展codec功能，这个功能主要是留给想自己定义索引格式的开发者。\n在此之前，有必要了解codec主要的作用，codec相关的类主要作用是读写索引。 而通过实现FilterCodec，可以很方便的定义自己的codec。 这个方便主要是可以将许多读写索引部分交给已有的codec实现，而只实现自己需要改进的部分。当然如果这样还不能满足需求 可以重新写一个codec。 \n\n写个简单的例子更容易懂，\n在Codec.java中，可以看到，读写索引主要实现以下几个方法 \n``` java\n /** Encodes/decodes postings */\n  public abstract PostingsFormat postingsFormat();\n\n  /** Encodes/decodes docvalues */\n  public abstract DocValuesFormat docValuesFormat();\n\n  /** Encodes/decodes stored fields */\n  public abstract StoredFieldsFormat storedFieldsFormat();\n\n  /** Encodes/decodes term vectors */\n  public abstract TermVectorsFormat termVectorsFormat();\n\n  /** Encodes/decodes field infos file */\n  public abstract FieldInfosFormat fieldInfosFormat();\n\n  /** Encodes/decodes segment info file */\n  public abstract SegmentInfoFormat segmentInfoFormat();\n\n  /** Encodes/decodes document normalization values */\n  public abstract NormsFormat normsFormat();\n\n  /** Encodes/decodes live docs */\n  public abstract LiveDocsFormat liveDocsFormat();\n```\n一个纯文本保存索引的codec是SimpleTextCodec,这个codec的主要目的是用来学习\n\n下面定义自己的codec\n``` java\npublic class HexinCodec extends FilterCodec {\n    final private FieldInfosFormat myTermFieldInfoFormat;\n    public HexinCodec() {\n        super(\"HexinCodec\", new Lucene46Codec());\n        myTermFieldInfoFormat = new SimpleTextFieldInfosFormat();\n    }\n    public FieldInfosFormat fieldInfosFormat() {\n        return myTermFieldInfoFormat;\n    }\n}\n```\n最后，还是让上面的例子跑起来，首先下载Lucene4.8.0的源码，之后在codecs/src/java下新建包org.apache.lucene.codecs.hexin,\n在这个包下面新建类HexinCodec.java,复制上面的代码。\n之后编写测试用的建索引程序Index.java \n``` java\npackage org.hexin;\nimport org.apache.lucene.analysis.Analyzer;\nimport org.apache.lucene.analysis.standard.StandardAnalyzer;\nimport org.apache.lucene.codecs.Codec;\nimport org.apache.lucene.codecs.hexin.HexinCodec;\nimport org.apache.lucene.codecs.lucene46.Lucene46Codec;\nimport org.apache.lucene.codecs.simpletext.SimpleTextCodec;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.lucene.document.TextField;\nimport org.apache.lucene.index.IndexWriter;\nimport org.apache.lucene.index.IndexWriterConfig.OpenMode;\nimport org.apache.lucene.index.IndexWriterConfig;\nimport org.apache.lucene.store.FSDirectory;\nimport org.apache.lucene.util.Version;\n\nimport java.io.File;\nimport java.io.IOException;\npublic class Index {\n    public static void main(String[] args) throws IOException {\n        //Codec codec = new SimpleTextCodec();\n        Codec codec = new HexinCodec();\n        //Codec codec = new Lucene46Codec();\n        String INDEX_DIR = \"e:\\\\index\";\n        Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_48);\n        IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_48, analyzer);\n        iwc.setCodec(codec);\n        IndexWriter writer = null;\n        iwc.setOpenMode(OpenMode.CREATE);\n        iwc.setUseCompoundFile(false);\n        try {\n            writer = new IndexWriter(FSDirectory.open(new File(INDEX_DIR)), iwc);\n            Document doc = new Document();\n            doc.add(new TextField(\"title\", \"who are you, you are a man\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"A long way to go there. Please drive a car\", Field.Store.NO));\n            writer.addDocument(doc);\n            doc = new Document();\n            doc.add(new TextField(\"title\", \"are you sure\", Field.Store.YES));\n            doc.add(new TextField(\"content\", \"He is a good man. He is a driver\", Field.Store.NO));\n            writer.addDocument(doc);\n            writer.commit();\n            writer.close();\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n    }  \n}\n```\n编写测试用的搜索例子Search.java \n``` java\npackage org.hexin;\nimport java.io.File; \nimport java.util.Date;\n\nimport org.apache.lucene.codecs.Codec;\nimport org.apache.lucene.codecs.simpletext.SimpleTextCodec;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.index.DirectoryReader;\nimport org.apache.lucene.index.IndexReader;\nimport org.apache.lucene.index.Term;\nimport org.apache.lucene.search.IndexSearcher;\nimport org.apache.lucene.search.Query;\nimport org.apache.lucene.search.TermQuery;\nimport org.apache.lucene.search.ScoreDoc;\nimport org.apache.lucene.search.TopDocs;\nimport org.apache.lucene.store.FSDirectory;\npublic class Search {\n    private Search() {}\n    public static void main(String[] args) throws Exception {\n\n        String index = \"e:\\\\index\";\n        IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(index)));\n        IndexSearcher searcher = new IndexSearcher(reader);\n        String queryString = \"driver\";\n        Query query = new TermQuery(new Term(\"content\", queryString));\n        System.out.println(\"Searching for: \" + query.toString());\n        Date start = new Date();\n        TopDocs results = searcher.search(query, null, 100);\n        Date end = new Date();\n        System.out.println(\"Time: \"+(end.getTime()-start.getTime())+\"ms\");\n        ScoreDoc[] hits = results.scoreDocs;\n        int numTotalHits = results.totalHits;\n        System.out.println(numTotalHits + \" total matching documents\");\n        for (int i = 0; i < hits.length; i++) {\n            String output = \"\";\n            Document doc = searcher.doc(hits[i].doc);\n            output += \"doc=\"+hits[i].doc+\" score=\"+hits[i].score;\n            String title = doc.get(\"title\");\n            if (title != null) {\n                output += \" \" + title;\n            }\n            System.out.println(output);\n        }\n        reader.close();\n    }\n}\n```\n\n在Eclipse中运行Index.java,此时会报错\nA SPI class of type org.apache.lucene.codecs.Codec with name 'Lucene46' does not exist. You need to add the corresponding \nJAR file supporting this SPI to your classpath.The current classpath supports the following names:[]\n\n问过定坤后，知道一个解决的办法是去官网下载已经编译过的Lucene二进制包,将其中的META-INF拷贝到core/src/java目录下，写上下面两行\norg.apache.lucene.codecs.simpletext.SimpleTextCodec\norg.apache.lucene.codecs.hexin.HexinCodec\n此时即可运行通过。查看索引文件，有一个fld结尾的文件，其内容为文本文件,保存着字段值,这个文件就是通过SimpleTextCodec写入的，\n而其它文件则是通过Lucene46Codec写入的。\n","slug":"Lucene中扩展codec功能","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4r600p626s6627ru215"},{"title":"Linux挂载U盘","id":"836","date":"2014-07-17T02:54:14.000Z","_content":"\n挂载U盘\nmount -t auto /dev/sdb1 /mnt/usb\n如果在mnt目录下不存在usb目录 则先执行 mkdir /mnt/usb,其中/mnt/usb为挂载目录,也可以使用将U盘挂载到其它目录\n\n之后卸载U盘\numount /mnt/usb\n\n如果是文件名中包含中文，还会遇到乱码问题，所以还要加上-o iocharset=utf8","source":"_posts/Linux挂载U盘.md","raw":"title: Linux挂载U盘\ntags:\n  - Linux\n  - U盘\nid: 836\ncategories:\n  - shell\ndate: 2014-07-17 10:54:14\n---\n\n挂载U盘\nmount -t auto /dev/sdb1 /mnt/usb\n如果在mnt目录下不存在usb目录 则先执行 mkdir /mnt/usb,其中/mnt/usb为挂载目录,也可以使用将U盘挂载到其它目录\n\n之后卸载U盘\numount /mnt/usb\n\n如果是文件名中包含中文，还会遇到乱码问题，所以还要加上-o iocharset=utf8","slug":"Linux挂载U盘","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4r900pb26s6maskh2ev"},{"title":"Java创建线程","date":"2015-12-21T12:44:03.000Z","_content":"在Java中创建线程有两中方法，一种是实现Runnable接口，一种是继承Thread类\n## 实现Runnable接口\n1. 将任务代码迁移到实现Runnable接口的类的run方法中\n```\nclass MyRunnable implements Runnable {\n    public void run() {\n        task code\n    }\n}\n```\n2. 创建一个类对象:\nRunnable r = new MyRunnable()\n3. 由Runnable创建一个Thread对象\nThread t = new Thread(r)\n4. 启动线程\nt.start()\n完整例子如下:\n```\npublic class MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId());\n        \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Runnable r = new MyRunnable();\n            Thread t = new Thread(r);\n            t.start();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 8\nChild: 9\nChild: 10\nChild: 11\nParent: 1\nChild: 12\n这里不能直接调用run方法，因为这样不会创建新的线程:\n```\npublic class MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId());\n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Runnable r = new MyRunnable();\n//          Thread t = new Thread(r);\n//          t.start();\n            r.run();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nParent: 1\n可以看到id都是一样的,也就是这里没有创建新的线程.\n## 继承Thread类\n```\nclass MyThread extends Thread {\n    public void run() {\n        task code\n    }\n} \n```\n完整例子如下:\n```\npublic class MyThread extends Thread {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId()); \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Thread t = new MyThread();\n            t.start();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 8\nChild: 9\nChild: 10\nChild: 11\nParent: 1\nChild: 12\n这里不能直接调用t.run()，因为这样不会创建新的线程\n```\npublic class MyThread extends Thread {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId()); \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Thread t = new MyThread();\n//          t.start();\n            t.run();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n结果如下：\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nParent: 1\n可以看到id都是一样的。\n查看Thread类的源码就会发现问题的所在.\n```\npublic synchronized void start() {\n        /**\n         * This method is not invoked for the main method thread or \"system\"\n         * group threads created/set up by the VM. Any new functionality added\n         * to this method in the future may have to also be added to the VM.\n         *\n         * A zero status value corresponds to state \"NEW\".\n         */\n        if (threadStatus != 0)\n            throw new IllegalThreadStateException();\n\n        /* Notify the group that this thread is about to be started\n         * so that it can be added to the group's list of threads\n         * and the group's unstarted count can be decremented. */\n        group.add(this);\n\n        boolean started = false;\n        try {\n            start0();\n            started = true;\n        } finally {\n            try {\n                if (!started) {\n                    group.threadStartFailed(this);\n                }\n            } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n            }\n        }\n    }\n\n    private native void start0();\n```\n在start方法中调用native方法start0()，虽然看不到它的具体实现，但可以推测这里创建了新的线程，然后调用run方法。而run方法中，则没有创建线程相关的代码\n```\npublic void run() {\n    if (target != null) {\n        target.run();\n    }\n}\n```\n关于两种方法的区别，可以看[http://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread](http://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread), 推荐使用实现Runnable接口的方法。\n","source":"_posts/Java创建线程.md","raw":"title: Java创建线程\ndate: 2015-12-21 20:44:03\ntags: 线程\ncategories: Java\n---\n在Java中创建线程有两中方法，一种是实现Runnable接口，一种是继承Thread类\n## 实现Runnable接口\n1. 将任务代码迁移到实现Runnable接口的类的run方法中\n```\nclass MyRunnable implements Runnable {\n    public void run() {\n        task code\n    }\n}\n```\n2. 创建一个类对象:\nRunnable r = new MyRunnable()\n3. 由Runnable创建一个Thread对象\nThread t = new Thread(r)\n4. 启动线程\nt.start()\n完整例子如下:\n```\npublic class MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId());\n        \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Runnable r = new MyRunnable();\n            Thread t = new Thread(r);\n            t.start();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 8\nChild: 9\nChild: 10\nChild: 11\nParent: 1\nChild: 12\n这里不能直接调用run方法，因为这样不会创建新的线程:\n```\npublic class MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId());\n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Runnable r = new MyRunnable();\n//          Thread t = new Thread(r);\n//          t.start();\n            r.run();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nParent: 1\n可以看到id都是一样的,也就是这里没有创建新的线程.\n## 继承Thread类\n```\nclass MyThread extends Thread {\n    public void run() {\n        task code\n    }\n} \n```\n完整例子如下:\n```\npublic class MyThread extends Thread {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId()); \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Thread t = new MyThread();\n            t.start();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n输出结果如下：\nChild: 8\nChild: 9\nChild: 10\nChild: 11\nParent: 1\nChild: 12\n这里不能直接调用t.run()，因为这样不会创建新的线程\n```\npublic class MyThread extends Thread {\n    @Override\n    public void run() {\n        System.out.println(\"Child: \" + Thread.currentThread().getId()); \n    }\n    public static void main(String[] arg) {\n        for (int i = 0; i < 5; i++) {\n            Thread t = new MyThread();\n//          t.start();\n            t.run();\n        }\n        System.out.println(\"Parent: \" + Thread.currentThread().getId());\n    }\n}\n```\n结果如下：\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nChild: 1\nParent: 1\n可以看到id都是一样的。\n查看Thread类的源码就会发现问题的所在.\n```\npublic synchronized void start() {\n        /**\n         * This method is not invoked for the main method thread or \"system\"\n         * group threads created/set up by the VM. Any new functionality added\n         * to this method in the future may have to also be added to the VM.\n         *\n         * A zero status value corresponds to state \"NEW\".\n         */\n        if (threadStatus != 0)\n            throw new IllegalThreadStateException();\n\n        /* Notify the group that this thread is about to be started\n         * so that it can be added to the group's list of threads\n         * and the group's unstarted count can be decremented. */\n        group.add(this);\n\n        boolean started = false;\n        try {\n            start0();\n            started = true;\n        } finally {\n            try {\n                if (!started) {\n                    group.threadStartFailed(this);\n                }\n            } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n            }\n        }\n    }\n\n    private native void start0();\n```\n在start方法中调用native方法start0()，虽然看不到它的具体实现，但可以推测这里创建了新的线程，然后调用run方法。而run方法中，则没有创建线程相关的代码\n```\npublic void run() {\n    if (target != null) {\n        target.run();\n    }\n}\n```\n关于两种方法的区别，可以看[http://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread](http://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread), 推荐使用实现Runnable接口的方法。\n","slug":"Java创建线程","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rd00ph26s6aa5bhxk4"},{"title":"Hadoop Yarn安装","date":"2016-04-20T09:13:06.000Z","_content":"这里使用Hadoop 2.7.2, 在Mac上安装， 如果按照[官方文档](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation)一步步来，是可以安装成功的。但如果漏了一些步骤，就会出现问题。\n\n\n\n## Input path does not exist\n最后查找日志，发现原因是\n`/bin/bash: /bin/java: No such file or directory`\n\n解决办法是将JAVA_HOME加入到etc/hadoop/hadoop-env.sh即可\n\n## org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible \n原因是多次运行`bin/hdfs namenode -format`, 导致namenode的version和datanode的version不一致。\n\n解决办法是修改datanode的version.\n具体参考[http://blog.csdn.net/wanghai__/article/details/5752199](http://blog.csdn.net/wanghai__/article/details/5752199)\n","source":"_posts/Hadoop-Yarn安装.md","raw":"title: Hadoop Yarn安装\ndate: 2016-04-20 17:13:06\ntags: \n    - Hadoop\n    - Yarn\ncategories:\n    - 软件安装\n    \n---\n这里使用Hadoop 2.7.2, 在Mac上安装， 如果按照[官方文档](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation)一步步来，是可以安装成功的。但如果漏了一些步骤，就会出现问题。\n\n\n\n## Input path does not exist\n最后查找日志，发现原因是\n`/bin/bash: /bin/java: No such file or directory`\n\n解决办法是将JAVA_HOME加入到etc/hadoop/hadoop-env.sh即可\n\n## org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible \n原因是多次运行`bin/hdfs namenode -format`, 导致namenode的version和datanode的version不一致。\n\n解决办法是修改datanode的version.\n具体参考[http://blog.csdn.net/wanghai__/article/details/5752199](http://blog.csdn.net/wanghai__/article/details/5752199)\n","slug":"Hadoop-Yarn安装","published":1,"updated":"2016-04-20T09:14:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rg00pl26s6vqktnddf"},{"title":"HDU2222-Keywords Search","id":"873","date":"2014-08-16T03:12:23.000Z","_content":"\nAC自动机作为多模式匹配的经典方法，在关键词过滤中有重要应用，在我看来，AC自动机主要是这样几个步骤，第一步是先建立关键词的trie数，第二步是构建自动机，建立关键词之间的联系，第三步是利用第二步构建的自动机进行检索。HDU2222-关键词搜索是AC自动机的一个简单应用。关于AC自动机的资料，可以看这里[http://www.notonlysuccess.com/index.php/aho-corasick-automaton/](http://www.notonlysuccess.com/index.php/aho-corasick-automaton/).\n**问题描述**\n现在，搜索引擎如谷歌，百度等已经走进每个人的生活。\nWiskey也想在他的图片检索系统中实现这个功能。\n每一张图片有一段描述，当用户输入关键字查找图片时，系统会将这些关键字与图片的描述进行匹配，然后显示与这些关键字最匹配的图片。\n为了简化用题，这里给你出一段图片的描述，和一些关键字，请你告诉我​将匹配多少个关键字。\n**输入**\n第一行是一个整数，它的意思是有多少个测试用例。\n每一个测试用例包含整数N，它的意思是有多少个关键字。(N <= 10000)\n每一个关键字是由'a'-'z'的字符组成，长度不超过50.\n用例的最后一行​是描述，长度不超过1000000.\n**示例输入**\n1\n5\nshe\nhe\nsay\nshr\nher\nyasherhs\n**示例输出**\n3\n\n解法：\nAC自动机的简单应用。有一个坑是，输入中关键词存在重复时，要计算多次。\n\n代码如下\n``` c\n#include <iostream>\n#include <stdio.h>\n#include <string.h>\n#include <queue>\nusing namespace std;\nconst int NUM = 26;\nstruct NODE {\n    int cnt;\n    NODE *fail;\n    NODE *next[NUM];\n    NODE () {\n        cnt = 0;\n        fail = NULL;\n        memset(next, 0, sizeof(next));\n    }\n};\n\nvoid insert(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s) {\n        int index = *s - 'a';\n        if (!cur->next[index]) {\n            cur->next[index] = new NODE();\n        }\n        cur = cur->next[index];\n        s++;\n    }\n    cur->cnt++;\n} \nvoid ac_build(NODE *root) {\n    queue <NODE *> q;\n    NODE *cur;\n    root->fail = NULL;\n    for (int i = 0; i < NUM; i++) {\n        if (root->next[i]) {\n            root->next[i]->fail = root;\n            q.push(root->next[i]);\n        }\n    } \n    while (!q.empty()) {\n        cur = q.front();\n        q.pop();\n        for (int i = 0; i < NUM; i++) {\n            if (cur->next[i]) {\n                q.push(cur->next[i]);\n                NODE *temp = cur->fail;\n                while (temp) {\n                    if (temp->next[i]) {\n                        cur->next[i]->fail = temp->next[i];\n                        break;\n                    }\n                    temp = temp->fail;\n                }\n                if (temp == NULL) {\n                    cur->next[i]->fail = root;\n                }\n            }\n        }\n    }\n}\nint ac_find(NODE *root, char *s) {\n    int sum = 0;\n    NODE *cur = root;\n    while (*s) {\n        int index = *s - 'a';\n        while (cur->next[index] == NULL && cur != root) {\n            cur = cur->fail;\n        }\n        cur = (cur->next[index] == NULL) ? root : cur->next[index]; \n        NODE *temp = cur;\n        while (temp != root && temp->cnt != -1) {  \n            sum += temp->cnt;\n            temp->cnt = -1;\n            temp = temp->fail;\n        }\n        s++;\n    }\n    return sum;\n}\nint main() {\n    int ncase, n;\n    char word[51];\n    char desc[1000001];\n    scanf(\"%d\", &ncase);\n    while (ncase--) {\n        NODE *root = new NODE();\n        scanf(\"%d\", &n);\n        for (int i = 0; i < n; i++) {\n            scanf(\"%s\", word);\n            insert(root, word);\n        }\n        scanf(\"%s\", desc);\n        ac_build(root);\n        int res = ac_find(root, desc);\n        printf(\"%d\\n\", res);\n    }\n    return 0;\n}\n```\n","source":"_posts/HDU2222-Keywords-Search.md","raw":"title: HDU2222-Keywords Search\ntags:\n  - AC自动机\nid: 873\ncategories:\n  - 算法\ndate: 2014-08-16 11:12:23\n---\n\nAC自动机作为多模式匹配的经典方法，在关键词过滤中有重要应用，在我看来，AC自动机主要是这样几个步骤，第一步是先建立关键词的trie数，第二步是构建自动机，建立关键词之间的联系，第三步是利用第二步构建的自动机进行检索。HDU2222-关键词搜索是AC自动机的一个简单应用。关于AC自动机的资料，可以看这里[http://www.notonlysuccess.com/index.php/aho-corasick-automaton/](http://www.notonlysuccess.com/index.php/aho-corasick-automaton/).\n**问题描述**\n现在，搜索引擎如谷歌，百度等已经走进每个人的生活。\nWiskey也想在他的图片检索系统中实现这个功能。\n每一张图片有一段描述，当用户输入关键字查找图片时，系统会将这些关键字与图片的描述进行匹配，然后显示与这些关键字最匹配的图片。\n为了简化用题，这里给你出一段图片的描述，和一些关键字，请你告诉我​将匹配多少个关键字。\n**输入**\n第一行是一个整数，它的意思是有多少个测试用例。\n每一个测试用例包含整数N，它的意思是有多少个关键字。(N <= 10000)\n每一个关键字是由'a'-'z'的字符组成，长度不超过50.\n用例的最后一行​是描述，长度不超过1000000.\n**示例输入**\n1\n5\nshe\nhe\nsay\nshr\nher\nyasherhs\n**示例输出**\n3\n\n解法：\nAC自动机的简单应用。有一个坑是，输入中关键词存在重复时，要计算多次。\n\n代码如下\n``` c\n#include <iostream>\n#include <stdio.h>\n#include <string.h>\n#include <queue>\nusing namespace std;\nconst int NUM = 26;\nstruct NODE {\n    int cnt;\n    NODE *fail;\n    NODE *next[NUM];\n    NODE () {\n        cnt = 0;\n        fail = NULL;\n        memset(next, 0, sizeof(next));\n    }\n};\n\nvoid insert(NODE *root, char *s) {\n    NODE *cur = root;\n    while (*s) {\n        int index = *s - 'a';\n        if (!cur->next[index]) {\n            cur->next[index] = new NODE();\n        }\n        cur = cur->next[index];\n        s++;\n    }\n    cur->cnt++;\n} \nvoid ac_build(NODE *root) {\n    queue <NODE *> q;\n    NODE *cur;\n    root->fail = NULL;\n    for (int i = 0; i < NUM; i++) {\n        if (root->next[i]) {\n            root->next[i]->fail = root;\n            q.push(root->next[i]);\n        }\n    } \n    while (!q.empty()) {\n        cur = q.front();\n        q.pop();\n        for (int i = 0; i < NUM; i++) {\n            if (cur->next[i]) {\n                q.push(cur->next[i]);\n                NODE *temp = cur->fail;\n                while (temp) {\n                    if (temp->next[i]) {\n                        cur->next[i]->fail = temp->next[i];\n                        break;\n                    }\n                    temp = temp->fail;\n                }\n                if (temp == NULL) {\n                    cur->next[i]->fail = root;\n                }\n            }\n        }\n    }\n}\nint ac_find(NODE *root, char *s) {\n    int sum = 0;\n    NODE *cur = root;\n    while (*s) {\n        int index = *s - 'a';\n        while (cur->next[index] == NULL && cur != root) {\n            cur = cur->fail;\n        }\n        cur = (cur->next[index] == NULL) ? root : cur->next[index]; \n        NODE *temp = cur;\n        while (temp != root && temp->cnt != -1) {  \n            sum += temp->cnt;\n            temp->cnt = -1;\n            temp = temp->fail;\n        }\n        s++;\n    }\n    return sum;\n}\nint main() {\n    int ncase, n;\n    char word[51];\n    char desc[1000001];\n    scanf(\"%d\", &ncase);\n    while (ncase--) {\n        NODE *root = new NODE();\n        scanf(\"%d\", &n);\n        for (int i = 0; i < n; i++) {\n            scanf(\"%s\", word);\n            insert(root, word);\n        }\n        scanf(\"%s\", desc);\n        ac_build(root);\n        int res = ac_find(root, desc);\n        printf(\"%d\\n\", res);\n    }\n    return 0;\n}\n```\n","slug":"HDU2222-Keywords-Search","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rj00pr26s6r04w8ehd"},{"title":"Elasticsearch源码分析-查询","date":"2016-04-16T08:04:59.000Z","_content":"在[Elasticsearch源码分析-启动](http://program.dengshilong.org/2016/04/15/Elasticsearch源码分析-启动/)里简单了解Elasticsearch的启动过程，这里来看看查询过程。\n\n## 接收请求\n从启动篇里知道HttpRequestHandler，进入这个类查看，看到messageReceived, 进入NettyHttpRequest, 看到String uri = request.getUri(); 看到这里没有日志输出，一直纳闷为什么Elasticsearch没有请求url输出，于是加上日志\n```\ntry {\n    logger.info(\"query uri {}\", URLDecoder.decode(uri, \"UTF-8\"));\n} catch (java.io.UnsupportedEncodingException e) {\n    logger.info(\"query uri {}\", uri);\n}\n```\n之后日志里就有请求的uri了。看到RestUtils.decodeQueryString(uri, pathEndPos + 1, params), 知道请求参数是在这里完成解析。\n\n查看serverTransport.dispatchRequest,进入httpServerAdapter.dispatchRequest(request, channel)，这里要知道httpServerAdapter的具体对象，查看\n```\npublic void httpServerAdapter(HttpServerAdapter httpServerAdapter) {\n    this.httpServerAdapter = httpServerAdapter;\n}\n```\n被哪个函数调用，跳到HttpServer.java, 打开server.internalDispatchRequest(request, channel); 之后到了restController.dispatchRequest(request, channel);\n    \n最终请求的处理由restController.dispatchRequest(request, channel);完成\n\n## 请求处理\n进入RestController的dispatchRequest方法, 进入executeHandler方法, 在getHandler(request)里，根据不同的请求方法，返回不同的handler,然后调用handler里的handleRequest方法处理请求，这里以GET方法为例。\n\n对于不同的动作，都可以使用GET方法，如curl -XGET /index/type/id, curl -XGET /index/type/_search, 这里以/index/type/_search这查询为例。\n\n在RestSearchAction.java里，有语句`controller.registerHandler(GET, \"/{index}/{type}/_search\", this);`, 所以执行curl -XGET /index/type/_search时，得到的handler就是RestSearchAction, 并执行这个类里的handleRequest方法。\n\n进入RestSearchAction.java里的handleRequest方法，先是执行RestSearchAction.parseSearchRequest(searchRequest, request, parseFieldMatcher, null)，这个方法主要对查询参数进行设置，之后调用client.search(searchRequest, new RestStatusToXContentListener<SearchResponse>(channel))进行查询。\n\n### client类型\n现在要弄清楚client的具体类型, 在Node初始化里，有modules.add(new NodeClientModule())这句，打开查看，有bind(Client.class).to(NodeClient.class).asEagerSingleton()，所以这里的client具体类型是NodeClient, 而NodeClent继承自AbstractClient,\n\n然后看查询调用过程client.search ->client.execute->client.doExecute->transportAction.execute, 最终还是由transportAction来完成实际的查询\n\n值得注意的一点是client. execute是execute(SearchAction.INSTANCE, request, listener);\n\n### transportAction类型\n在Node初始化时，有modules.add(new ActionModule(false))，进入ActionModule.java查看，有registerAction(SearchAction.INSTANCE, TransportSearchAction.class);所以transportAction是TransportSearchAction类型。\n\n### 具体执行\ntransportAction.execute最终会调用transportAction.doExecute, 这里是进入TransportSearchAction.java的doExecute,这里会对search_type进行判断\n\n对于search_type, 是由RestSearchAction.java里的searchRequest.searchType(searchType)语句设定，默认是SearchType.DEFAULT, 也就是SearchType.QUERY_THEN_FETCH\n\n### query阶段\n由此新建了一个SearchQueryThenFetchAsyncAction实例，之后searchAsyncAction.start();开始查询。在父类AbstractSearchAsyncAction的start()函数里,\n```\nfor (final ShardIterator shardIt : shardsIts) {\n    shardIndex++;\n    final ShardRouting shard = shardIt.nextOrNull();\n    if (shard != null) {\n        performFirstPhase(shardIndex, shardIt, shard);\n    } else {\n        // really, no shards active in this group                 \n        onFirstPhaseResult(shardIndex, null, null, shardIt, new NoShardAvailableActionException(shardIt.shardId()));\n    }\n}\n```\n对每一个shard调用performFirstPhase,\n\n查看performFirstPhase, 最终会调用sendExecuteFirstPhase,并添加了ActionListener, 如果成功则执行onResponse里的onFirstPhaseResult, 在onFirstPhaseResult里有个判断, if (xTotalOps == expectedTotalOps)，当所有shard都执行完后，执行innerMoveToSecondPhase, 最终执行moveToSecondPhase\n\n### fetch阶段\n在moveToSecondPhase里, sortedShardList = searchPhaseController.sortDocs(useScroll, firstResults)对第一阶段的结果进行合并，之后对每个shard里入选到topN的doc进行fetch,即执行executeFetch(entry.index, queryResult.shardTarget(), counter, fetchSearchRequest, node)，\n\n在executeFetch里, \n```\nif (counter.decrementAndGet() == 0) {\n    finishHim();\n}\n```\n当所有需要执行的shard都结束后，执行finishHim()，标志着查询结束。\n\n在finishHim里，\n```\nfinal InternalSearchResponse internalResponse = searchPhaseController.merge(sortedShardList, firstResults,fetchResults, request);\n```\n对fetch阶段Shard返回的结果进行合并.\n```\nlistener.onResponse(new SearchResponse(internalResponse, scrollId, expectedSuccessfulOps,successfulOps.get(), buildTookInMillis(), buildShardFailures()))\n```\n设置返回的SearchResponse对象.\n\n## 请求结果返回\n在TransportAction调用execute时，有添加Actionlistener, \n```\npublic void onResponse(Response response) {\n    taskManager.unregister(task);\n    listener.onResponse(response);\n}\n```\n这里的Response就是上面返回的SearchResponse, 而listener可以在RestSearchAction中找到, 是RestStatusToXContentListener<SearchResponse>(channel).\n\nRestStatusToXContentListener继承RestResponseListener, RestResponseListener继承RestActionListener, 最终onResponse方法会调用RestStatusToXContentListener中的buildResponse, 也就调用了SearchResponse中的toXContent方法。\n\n到此，大致了解Elasticsearch的查询过程。目前，我修改JSON返回格式，就是修改SearchResponse的toXContent方法。\n","source":"_posts/Elasticsearch源码分析-查询.md","raw":"title: Elasticsearch源码分析-查询\ndate: 2016-04-16 16:04:59\ntags: Elasticsearch\ncategories: 搜索引擎\n---\n在[Elasticsearch源码分析-启动](http://program.dengshilong.org/2016/04/15/Elasticsearch源码分析-启动/)里简单了解Elasticsearch的启动过程，这里来看看查询过程。\n\n## 接收请求\n从启动篇里知道HttpRequestHandler，进入这个类查看，看到messageReceived, 进入NettyHttpRequest, 看到String uri = request.getUri(); 看到这里没有日志输出，一直纳闷为什么Elasticsearch没有请求url输出，于是加上日志\n```\ntry {\n    logger.info(\"query uri {}\", URLDecoder.decode(uri, \"UTF-8\"));\n} catch (java.io.UnsupportedEncodingException e) {\n    logger.info(\"query uri {}\", uri);\n}\n```\n之后日志里就有请求的uri了。看到RestUtils.decodeQueryString(uri, pathEndPos + 1, params), 知道请求参数是在这里完成解析。\n\n查看serverTransport.dispatchRequest,进入httpServerAdapter.dispatchRequest(request, channel)，这里要知道httpServerAdapter的具体对象，查看\n```\npublic void httpServerAdapter(HttpServerAdapter httpServerAdapter) {\n    this.httpServerAdapter = httpServerAdapter;\n}\n```\n被哪个函数调用，跳到HttpServer.java, 打开server.internalDispatchRequest(request, channel); 之后到了restController.dispatchRequest(request, channel);\n    \n最终请求的处理由restController.dispatchRequest(request, channel);完成\n\n## 请求处理\n进入RestController的dispatchRequest方法, 进入executeHandler方法, 在getHandler(request)里，根据不同的请求方法，返回不同的handler,然后调用handler里的handleRequest方法处理请求，这里以GET方法为例。\n\n对于不同的动作，都可以使用GET方法，如curl -XGET /index/type/id, curl -XGET /index/type/_search, 这里以/index/type/_search这查询为例。\n\n在RestSearchAction.java里，有语句`controller.registerHandler(GET, \"/{index}/{type}/_search\", this);`, 所以执行curl -XGET /index/type/_search时，得到的handler就是RestSearchAction, 并执行这个类里的handleRequest方法。\n\n进入RestSearchAction.java里的handleRequest方法，先是执行RestSearchAction.parseSearchRequest(searchRequest, request, parseFieldMatcher, null)，这个方法主要对查询参数进行设置，之后调用client.search(searchRequest, new RestStatusToXContentListener<SearchResponse>(channel))进行查询。\n\n### client类型\n现在要弄清楚client的具体类型, 在Node初始化里，有modules.add(new NodeClientModule())这句，打开查看，有bind(Client.class).to(NodeClient.class).asEagerSingleton()，所以这里的client具体类型是NodeClient, 而NodeClent继承自AbstractClient,\n\n然后看查询调用过程client.search ->client.execute->client.doExecute->transportAction.execute, 最终还是由transportAction来完成实际的查询\n\n值得注意的一点是client. execute是execute(SearchAction.INSTANCE, request, listener);\n\n### transportAction类型\n在Node初始化时，有modules.add(new ActionModule(false))，进入ActionModule.java查看，有registerAction(SearchAction.INSTANCE, TransportSearchAction.class);所以transportAction是TransportSearchAction类型。\n\n### 具体执行\ntransportAction.execute最终会调用transportAction.doExecute, 这里是进入TransportSearchAction.java的doExecute,这里会对search_type进行判断\n\n对于search_type, 是由RestSearchAction.java里的searchRequest.searchType(searchType)语句设定，默认是SearchType.DEFAULT, 也就是SearchType.QUERY_THEN_FETCH\n\n### query阶段\n由此新建了一个SearchQueryThenFetchAsyncAction实例，之后searchAsyncAction.start();开始查询。在父类AbstractSearchAsyncAction的start()函数里,\n```\nfor (final ShardIterator shardIt : shardsIts) {\n    shardIndex++;\n    final ShardRouting shard = shardIt.nextOrNull();\n    if (shard != null) {\n        performFirstPhase(shardIndex, shardIt, shard);\n    } else {\n        // really, no shards active in this group                 \n        onFirstPhaseResult(shardIndex, null, null, shardIt, new NoShardAvailableActionException(shardIt.shardId()));\n    }\n}\n```\n对每一个shard调用performFirstPhase,\n\n查看performFirstPhase, 最终会调用sendExecuteFirstPhase,并添加了ActionListener, 如果成功则执行onResponse里的onFirstPhaseResult, 在onFirstPhaseResult里有个判断, if (xTotalOps == expectedTotalOps)，当所有shard都执行完后，执行innerMoveToSecondPhase, 最终执行moveToSecondPhase\n\n### fetch阶段\n在moveToSecondPhase里, sortedShardList = searchPhaseController.sortDocs(useScroll, firstResults)对第一阶段的结果进行合并，之后对每个shard里入选到topN的doc进行fetch,即执行executeFetch(entry.index, queryResult.shardTarget(), counter, fetchSearchRequest, node)，\n\n在executeFetch里, \n```\nif (counter.decrementAndGet() == 0) {\n    finishHim();\n}\n```\n当所有需要执行的shard都结束后，执行finishHim()，标志着查询结束。\n\n在finishHim里，\n```\nfinal InternalSearchResponse internalResponse = searchPhaseController.merge(sortedShardList, firstResults,fetchResults, request);\n```\n对fetch阶段Shard返回的结果进行合并.\n```\nlistener.onResponse(new SearchResponse(internalResponse, scrollId, expectedSuccessfulOps,successfulOps.get(), buildTookInMillis(), buildShardFailures()))\n```\n设置返回的SearchResponse对象.\n\n## 请求结果返回\n在TransportAction调用execute时，有添加Actionlistener, \n```\npublic void onResponse(Response response) {\n    taskManager.unregister(task);\n    listener.onResponse(response);\n}\n```\n这里的Response就是上面返回的SearchResponse, 而listener可以在RestSearchAction中找到, 是RestStatusToXContentListener<SearchResponse>(channel).\n\nRestStatusToXContentListener继承RestResponseListener, RestResponseListener继承RestActionListener, 最终onResponse方法会调用RestStatusToXContentListener中的buildResponse, 也就调用了SearchResponse中的toXContent方法。\n\n到此，大致了解Elasticsearch的查询过程。目前，我修改JSON返回格式，就是修改SearchResponse的toXContent方法。\n","slug":"Elasticsearch源码分析-查询","published":1,"updated":"2016-04-16T08:35:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rm00pv26s6kzixwfho"},{"title":"Elasticsearch源码分析-启动","date":"2016-04-15T12:06:06.000Z","_content":"## 前言\n刚开始使用Elasticsearch时，我只需要修改Elasticsearch的_search这个查询的返回格式，使之与django-rest-framework的返回结果一致，凭着修改Solr的JSONResponseWriter返回结果的经验，在没有研究Elasticsearch源码的情况下，很快找到了org.elasticsearch.action.search.SearchResponse类，并进行修改，虽然遇到一些问题，但最终还是达到了目的。最近需要修改[top hits aggregations](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html)的返回结果，于是开始看源码。\n## 准备工作\n### 修改日志\n* 修改config下的logging.yml, 将所有INFO替换为DEBUG，\n* 将`conversionPattern: \"[%d{ISO8601}][%-5p][%-25c]: %.10000m%n\"` 改为`conversionPattern: \"[%d{ISO8601}][%-5p][%l]: %.10000m%n\"`以便查看到更多的日志，这里建议生产环境中也这样设置，这个更容易查找错误\n### 查看程序入口\n查看bin目录下的启动脚本elasticsearch, 知道程序入口是org.elasticsearch.bootstrap.Elasticsearch\n## 深入代码\n* 进入Bootstrap.java的init方法,    `Environment environment = initialSettings(foreground);`加载环境配置,\n* 进入`INSTANCE.setup(true, settings, environment);`，`JarHell.checkJarHell();`完成jar hell检查, 跟踪`node = nodeBuilder.build();`，发现是这里新建Node，并完成初始化\n### Node初始化\n* 在Node的构造函数里,`nodeEnvironment = new NodeEnvironment(this.settings, this.environment);`完成Node环境初始化,\n* `final ThreadPool threadPool = new ThreadPool(settings);`完成线程池初始化，进入ThreadPool可以看到对于不同任务会建立不同的线程池。\n* Elasticsearch使用Guice作为依赖注入容器，这在 `ModulesBuilder modules = new ModulesBuilder();`里有所体现，这里主要关注RestModule, TransportModule,HttpServerMoudle的配置。\n* 进入RestModule.java之后进入RestActionModule.java,可以看到配置了许多RestAction,\n* 进入TransportModule.java, 可以看到NettyTransport,\n* 进入HttpServerModule.java,可以看到使用NettyHttpServerTransport.\n### Node启动\n进入INSTANCE.start(),之后进入node.start(), 可以看到得到很多实例，\n* 对于RestController, 进入之后可以看到在registerHandler函数里对不同的request method绑定了不同的handler\n* 对于TransportServer, 默认绑定到9300端口, 这个用来做集群节点间通信\n* 对于HttpServerTransport,在配置里使用NettyHttpServerTransport, 所以这里实际上是得到NettyHttpServerTransport实例, 默认绑定到9200端口, 这个用来处理http请求\n## NettyHttpServerTransport\n进入NettyHttpServerTransport, 在doStart()函数里，看到serverBoostrap是Netty的ServerBootstrap实例,看到`serverBootstrap.setPipelineFactory(configureServerChannelPipelineFactory());`, 查看configureServerChannelPipelineFactory, 知道requestHandler是HttpRequestHandler\n\n这样，差不多就完成了Elasticsearch的启动。\n","source":"_posts/Elasticsearch源码分析-启动.md","raw":"title: Elasticsearch源码分析-启动\ndate: 2016-04-15 20:06:06\ntags: \n    - Elasticsearch\ncategories:\n    - 搜索引擎\n---\n## 前言\n刚开始使用Elasticsearch时，我只需要修改Elasticsearch的_search这个查询的返回格式，使之与django-rest-framework的返回结果一致，凭着修改Solr的JSONResponseWriter返回结果的经验，在没有研究Elasticsearch源码的情况下，很快找到了org.elasticsearch.action.search.SearchResponse类，并进行修改，虽然遇到一些问题，但最终还是达到了目的。最近需要修改[top hits aggregations](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-top-hits-aggregation.html)的返回结果，于是开始看源码。\n## 准备工作\n### 修改日志\n* 修改config下的logging.yml, 将所有INFO替换为DEBUG，\n* 将`conversionPattern: \"[%d{ISO8601}][%-5p][%-25c]: %.10000m%n\"` 改为`conversionPattern: \"[%d{ISO8601}][%-5p][%l]: %.10000m%n\"`以便查看到更多的日志，这里建议生产环境中也这样设置，这个更容易查找错误\n### 查看程序入口\n查看bin目录下的启动脚本elasticsearch, 知道程序入口是org.elasticsearch.bootstrap.Elasticsearch\n## 深入代码\n* 进入Bootstrap.java的init方法,    `Environment environment = initialSettings(foreground);`加载环境配置,\n* 进入`INSTANCE.setup(true, settings, environment);`，`JarHell.checkJarHell();`完成jar hell检查, 跟踪`node = nodeBuilder.build();`，发现是这里新建Node，并完成初始化\n### Node初始化\n* 在Node的构造函数里,`nodeEnvironment = new NodeEnvironment(this.settings, this.environment);`完成Node环境初始化,\n* `final ThreadPool threadPool = new ThreadPool(settings);`完成线程池初始化，进入ThreadPool可以看到对于不同任务会建立不同的线程池。\n* Elasticsearch使用Guice作为依赖注入容器，这在 `ModulesBuilder modules = new ModulesBuilder();`里有所体现，这里主要关注RestModule, TransportModule,HttpServerMoudle的配置。\n* 进入RestModule.java之后进入RestActionModule.java,可以看到配置了许多RestAction,\n* 进入TransportModule.java, 可以看到NettyTransport,\n* 进入HttpServerModule.java,可以看到使用NettyHttpServerTransport.\n### Node启动\n进入INSTANCE.start(),之后进入node.start(), 可以看到得到很多实例，\n* 对于RestController, 进入之后可以看到在registerHandler函数里对不同的request method绑定了不同的handler\n* 对于TransportServer, 默认绑定到9300端口, 这个用来做集群节点间通信\n* 对于HttpServerTransport,在配置里使用NettyHttpServerTransport, 所以这里实际上是得到NettyHttpServerTransport实例, 默认绑定到9200端口, 这个用来处理http请求\n## NettyHttpServerTransport\n进入NettyHttpServerTransport, 在doStart()函数里，看到serverBoostrap是Netty的ServerBootstrap实例,看到`serverBootstrap.setPipelineFactory(configureServerChannelPipelineFactory());`, 查看configureServerChannelPipelineFactory, 知道requestHandler是HttpRequestHandler\n\n这样，差不多就完成了Elasticsearch的启动。\n","slug":"Elasticsearch源码分析-启动","published":1,"updated":"2016-04-15T13:17:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4ro00py26s6ps4majer"},{"title":"Elasticsearch修改版本号和日志","date":"2016-04-16T12:51:18.000Z","_content":"## 修改版本号\n在[https://github.com/elastic/elasticsearch/releases](https://github.com/elastic/elasticsearch/releases)里下载到v2.3.0的Elasticsearch, 编译后得到的是2.3.0-SNAPSHOT, 这在pom.xml文件里有体现，于是进行替换\n```\nfind . -name \"pom.xml\" | xargs sed -i '' 's/2.3.0-SNAPSHOT/2.3.0/g'\n```\n这里sed的用法是在Mac电脑上。\n\n但Elasticsearch无法启动，报错说还是2.3.0-SNAPSHOT, 打开Version.java, 将\n```\npublic static final Version V_2_3_0 = new Version(V_2_3_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_5_0);\n```\n修改为\n```\npublic static final Version V_2_3_0 = new Version(V_2_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_5_5_0);\n```\n编译后可以正常启动.\n\n## 修改日志格式\n目前Elasticsearch的日志输出无法知道是哪个类，哪个包，第几行打印的日志，所以需要修改logging.yml的配置。\n\n将\n```\nconversionPattern: \"[%d{ISO8601}][%-5p][%-25c]: %m%n\"\n```\n改为\n```\nconversionPattern: \"[%d{ISO8601}][%-5p][%l]: %m%n\"\n```\n\n## 输出query日志\n想知道用户的query日志，但Elasticsearch没有记录，在NettyHttpRequest.java里, `String uri = request.getUri();`后添加\n```\ntry {\n    logger.info(\"### query uri {}\", URLDecoder.decode(uri, \"UTF-8\"));\n} catch (java.io.UnsupportedEncodingException e) {\n    logger.info(\"### query uri {}\", uri);\n}\n```\n","source":"_posts/Elasticsearch修改版本号和日志.md","raw":"title: Elasticsearch修改版本号和日志\ndate: 2016-04-16 20:51:18\ntags: \n    - Elasticsearch\ncategories:\n    - 搜索引擎\n---\n## 修改版本号\n在[https://github.com/elastic/elasticsearch/releases](https://github.com/elastic/elasticsearch/releases)里下载到v2.3.0的Elasticsearch, 编译后得到的是2.3.0-SNAPSHOT, 这在pom.xml文件里有体现，于是进行替换\n```\nfind . -name \"pom.xml\" | xargs sed -i '' 's/2.3.0-SNAPSHOT/2.3.0/g'\n```\n这里sed的用法是在Mac电脑上。\n\n但Elasticsearch无法启动，报错说还是2.3.0-SNAPSHOT, 打开Version.java, 将\n```\npublic static final Version V_2_3_0 = new Version(V_2_3_0_ID, true, org.apache.lucene.util.Version.LUCENE_5_5_0);\n```\n修改为\n```\npublic static final Version V_2_3_0 = new Version(V_2_3_0_ID, false, org.apache.lucene.util.Version.LUCENE_5_5_0);\n```\n编译后可以正常启动.\n\n## 修改日志格式\n目前Elasticsearch的日志输出无法知道是哪个类，哪个包，第几行打印的日志，所以需要修改logging.yml的配置。\n\n将\n```\nconversionPattern: \"[%d{ISO8601}][%-5p][%-25c]: %m%n\"\n```\n改为\n```\nconversionPattern: \"[%d{ISO8601}][%-5p][%l]: %m%n\"\n```\n\n## 输出query日志\n想知道用户的query日志，但Elasticsearch没有记录，在NettyHttpRequest.java里, `String uri = request.getUri();`后添加\n```\ntry {\n    logger.info(\"### query uri {}\", URLDecoder.decode(uri, \"UTF-8\"));\n} catch (java.io.UnsupportedEncodingException e) {\n    logger.info(\"### query uri {}\", uri);\n}\n```\n","slug":"Elasticsearch修改版本号和日志","published":1,"updated":"2016-04-16T12:52:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rr00q126s6o0wlhur7"},{"title":"Elasticsearch从MySQL导数据","date":"2016-04-10T09:00:01.000Z","_content":"在Solr和Elasticsearch两个中权衡，最后还是选择了Elasticsearch。虽然之前有Solr开发经验，但是当看过Elasticsearch的配置后，还是投奔Elasticsearch,只能说Solr的配置太复杂了。\n\n依然是要从MySQL中导数据，在[http://www.jianshu.com/p/05cff717563c](http://www.jianshu.com/p/05cff717563c)中看到一些解决方案。因为对Mysql的binlog并不了解，而搜索elasticsearch-river-jdbc时，只搜到了[elasticsearch-jdbc](https://github.com/jprante/elasticsearch-jdbc),于是决定使用它。\n\n## 增量导入数据\n决定使用elasticsearch-jdbc后,使用增量导MySQL数据时发现官方文档，写的不好，而且竟然连向数据库提交的查询语句都不输出日志，出现问题时很难找错。\n\n在使用增量导数据时，一直找不到它导入时间的存储位置，于是只好看代码，发现statefile的配置很重要，于是将它加上。但还是发现需要做一次全量导入后，这个增量导入才有效。\n\n于是修改README\n```\nThere is a problem here, the first time you run the script, it can't select any data from table, it have two solutions here:\n\n1. in another script, do full-import, later you can use the incremental script to select incremental data\n2. define a statefile.json file before the first time you run the incremental script, set the lastexecutionstart to 0, so that you can select all the data from table.\n```\n\n今天发现，为何不在，开始时间设置为0，这样就可以做全亮导入了，于是提交了一个新的patch.\n## 定时导数据\n原计划是在crontab里添加定时执行任务, 所以没看elasticsearch-jdbc提供的schedule功能，但看到issue中有人提到，于是开始解决。最后发现schedule时没有重新加载statefile文件，于是提交了一个patch。这次也把向数据库提交的查询语句打印出来，方便找错。\n## 结束语\n无法删除数据确实是一个很严重的缺陷，看来还是要想办法从binlog里读取数据才行,先这样做吧，以后再优化。\n","source":"_posts/Elasticsearch从MySQL导数据.md","raw":"title: Elasticsearch从MySQL导数据\ndate: 2016-04-10 17:00:01\ntags: Elasticsearch MySQL\ncategories: 搜索引擎\n---\n在Solr和Elasticsearch两个中权衡，最后还是选择了Elasticsearch。虽然之前有Solr开发经验，但是当看过Elasticsearch的配置后，还是投奔Elasticsearch,只能说Solr的配置太复杂了。\n\n依然是要从MySQL中导数据，在[http://www.jianshu.com/p/05cff717563c](http://www.jianshu.com/p/05cff717563c)中看到一些解决方案。因为对Mysql的binlog并不了解，而搜索elasticsearch-river-jdbc时，只搜到了[elasticsearch-jdbc](https://github.com/jprante/elasticsearch-jdbc),于是决定使用它。\n\n## 增量导入数据\n决定使用elasticsearch-jdbc后,使用增量导MySQL数据时发现官方文档，写的不好，而且竟然连向数据库提交的查询语句都不输出日志，出现问题时很难找错。\n\n在使用增量导数据时，一直找不到它导入时间的存储位置，于是只好看代码，发现statefile的配置很重要，于是将它加上。但还是发现需要做一次全量导入后，这个增量导入才有效。\n\n于是修改README\n```\nThere is a problem here, the first time you run the script, it can't select any data from table, it have two solutions here:\n\n1. in another script, do full-import, later you can use the incremental script to select incremental data\n2. define a statefile.json file before the first time you run the incremental script, set the lastexecutionstart to 0, so that you can select all the data from table.\n```\n\n今天发现，为何不在，开始时间设置为0，这样就可以做全亮导入了，于是提交了一个新的patch.\n## 定时导数据\n原计划是在crontab里添加定时执行任务, 所以没看elasticsearch-jdbc提供的schedule功能，但看到issue中有人提到，于是开始解决。最后发现schedule时没有重新加载statefile文件，于是提交了一个patch。这次也把向数据库提交的查询语句打印出来，方便找错。\n## 结束语\n无法删除数据确实是一个很严重的缺陷，看来还是要想办法从binlog里读取数据才行,先这样做吧，以后再优化。\n","slug":"Elasticsearch从MySQL导数据","published":1,"updated":"2016-04-10T09:05:25.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rt00q426s6bo5y5kdf"},{"title":"Elasticsearch中ik添加同义词","date":"2016-04-06T12:13:49.000Z","_content":"参考[http://elasticsearch.cn/?/question/29](http://elasticsearch.cn/?/question/29)\n\n## 配置synonym.txt\n在config目录下analysis,在analysis目录里新建synonym.txt文件,内容如下\n```\nbeijing,北京,帝都\n上海,魔都\n```\n## 配置elasticsearch.yml\n在elasticsearch.yml里添加\n```\nindex:\n    analysis:\n        filter:\n            my_synonym:\n                type: synonym\n                synonyms_path: analysis/synonym.txt\n        analyzer:\n            ik_smart_syno:\n                type: custom\n                tokenizer: ik_smart\n                filter: [my_synonym]\n            ik_max_word_syno:\n                type: custom\n                tokenizer: ik_max_word\n                filter: [my_synonym]\n```\n\n## 测试\n新建索引`curl -XPUT 'localhost:9200/test?pretty'`,之后执行`http://localhost:9200/test/_analyze?analyzer=ik_max_word_syno&text=上海外滩`\n\n","source":"_posts/Elasticsearch中ik添加同义词.md","raw":"title: Elasticsearch中ik添加同义词\ndate: 2016-04-06 20:13:49\ntags: \n    - Elasticsearch\n    - ik\ncategories:\n    - 搜索引擎\n---\n参考[http://elasticsearch.cn/?/question/29](http://elasticsearch.cn/?/question/29)\n\n## 配置synonym.txt\n在config目录下analysis,在analysis目录里新建synonym.txt文件,内容如下\n```\nbeijing,北京,帝都\n上海,魔都\n```\n## 配置elasticsearch.yml\n在elasticsearch.yml里添加\n```\nindex:\n    analysis:\n        filter:\n            my_synonym:\n                type: synonym\n                synonyms_path: analysis/synonym.txt\n        analyzer:\n            ik_smart_syno:\n                type: custom\n                tokenizer: ik_smart\n                filter: [my_synonym]\n            ik_max_word_syno:\n                type: custom\n                tokenizer: ik_max_word\n                filter: [my_synonym]\n```\n\n## 测试\n新建索引`curl -XPUT 'localhost:9200/test?pretty'`,之后执行`http://localhost:9200/test/_analyze?analyzer=ik_max_word_syno&text=上海外滩`\n\n","slug":"Elasticsearch中ik添加同义词","published":1,"updated":"2016-04-06T12:16:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rw00q826s6exhpkyz0"},{"title":"Django生产环境静态资源配置","id":"760","date":"2014-06-21T16:17:22.000Z","_content":"\n在开发环境中，使用Django自带的server,css这些静态资源都能够找到，可是用了gunicorn后,就找不到css等静态资源了，不知道如何是好，只记得之前看到在什么地方提到开发环境和生产环境是存在一些差异的。问过志容，志容说是要配置Nginx，可是我用gunicorn,根本都没有通过nginx。\n\n今天正好看文档，正好看到，于是记下来。在[https://docs.djangoproject.com/en/dev/howto/static-files/](https://docs.djangoproject.com/en/dev/howto/static-files/) 这个页面里有说到如何设置。\n\n*   Set the STATIC_ROOT setting to the directory from which you’d like to serve these files, for example:\n```\nSTATIC_ROOT = \"/var/www/example.com/static/\"\n```\n*   Run the collectstatic management command:\n```\n$ python manage.py collectstatic\n```\n为了避免硬编码，将STATIC_ROOT设置为os.path.join(BASE_DIR, 'static')后，\n\n运行python manage.py collectstatic即可\n","source":"_posts/Django生产环境静态资源配置.md","raw":"title: Django生产环境静态资源配置\ntags:\n  - Django\n  - 静态资源\nid: 760\ncategories:\n  - Python\ndate: 2014-06-22 00:17:22\n---\n\n在开发环境中，使用Django自带的server,css这些静态资源都能够找到，可是用了gunicorn后,就找不到css等静态资源了，不知道如何是好，只记得之前看到在什么地方提到开发环境和生产环境是存在一些差异的。问过志容，志容说是要配置Nginx，可是我用gunicorn,根本都没有通过nginx。\n\n今天正好看文档，正好看到，于是记下来。在[https://docs.djangoproject.com/en/dev/howto/static-files/](https://docs.djangoproject.com/en/dev/howto/static-files/) 这个页面里有说到如何设置。\n\n*   Set the STATIC_ROOT setting to the directory from which you’d like to serve these files, for example:\n```\nSTATIC_ROOT = \"/var/www/example.com/static/\"\n```\n*   Run the collectstatic management command:\n```\n$ python manage.py collectstatic\n```\n为了避免硬编码，将STATIC_ROOT设置为os.path.join(BASE_DIR, 'static')后，\n\n运行python manage.py collectstatic即可\n","slug":"Django生产环境静态资源配置","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4rz00qd26s6dsyts4o3"},{"title":"Django添加markdown","date":"2016-02-10T13:18:52.000Z","_content":"在[Django后台添加markdown编辑器](http://program.dengshilong.org/2014/06/22/Django后台添加markdown编辑器/)中说过如何在Django后台添加markdown编辑器,后来发现这里添加的pagedown有一个问题，也就是换行问题。在markdown中，单个换行会用空格代替，但pagedown中并没有这么做。经过跟踪，发现问题是在[pagedown-extra](https://github.com/jmcmanus/pagedown-extra)中,解决的办法是在[pagedown/Markdown.Converter.js](https://github.com/jmcmanus/pagedown-extra/blob/master/pagedown/Markdown.Converter.js)的_FormParagraphs函数1168行`//if this is an HTML marker, copy it`前添加`str = str.replace(/\\n/g, \" \");`即可.\n\n如此，在后台添加markdown编辑器就完成了。之后还需要前台现实时也用markdown渲染,通过自定义filter,添加markdown渲染可以实现这个功能。\n\n* `pip install markdown`安装markdown\n\n* 按照[自定义模版标签和过滤器](https://docs.djangoproject.com/en/1.9/howto/custom-template-tags/), 在所在的app目录下新建templatetags目录，在templatetags目录里新建`__init__.py`文件，之后编写my_markdown.py文件，内容如下：\n```\nfrom django import template\nfrom markdown import markdown\nregister = template.Library()\n@register.filter(name='mark')\ndef mark(value):\n    return markdown(value, extensions=['markdown.extensions.extra', 'markdown.extensions.codehilite'])\n```\n* 在模版中使用\n```\n{% load my_markdown %}\n  <p>{{ post.content|mark|safe}}</p> \n```\n\n\n\n\n\n\n\n\n\n","source":"_posts/Django添加markdown.md","raw":"title: Django添加markdown\ndate: 2016-02-10 21:18:52\ntags:\n  - Django \n  - markdown\ncategories:\n  - Python\n---\n在[Django后台添加markdown编辑器](http://program.dengshilong.org/2014/06/22/Django后台添加markdown编辑器/)中说过如何在Django后台添加markdown编辑器,后来发现这里添加的pagedown有一个问题，也就是换行问题。在markdown中，单个换行会用空格代替，但pagedown中并没有这么做。经过跟踪，发现问题是在[pagedown-extra](https://github.com/jmcmanus/pagedown-extra)中,解决的办法是在[pagedown/Markdown.Converter.js](https://github.com/jmcmanus/pagedown-extra/blob/master/pagedown/Markdown.Converter.js)的_FormParagraphs函数1168行`//if this is an HTML marker, copy it`前添加`str = str.replace(/\\n/g, \" \");`即可.\n\n如此，在后台添加markdown编辑器就完成了。之后还需要前台现实时也用markdown渲染,通过自定义filter,添加markdown渲染可以实现这个功能。\n\n* `pip install markdown`安装markdown\n\n* 按照[自定义模版标签和过滤器](https://docs.djangoproject.com/en/1.9/howto/custom-template-tags/), 在所在的app目录下新建templatetags目录，在templatetags目录里新建`__init__.py`文件，之后编写my_markdown.py文件，内容如下：\n```\nfrom django import template\nfrom markdown import markdown\nregister = template.Library()\n@register.filter(name='mark')\ndef mark(value):\n    return markdown(value, extensions=['markdown.extensions.extra', 'markdown.extensions.codehilite'])\n```\n* 在模版中使用\n```\n{% load my_markdown %}\n  <p>{{ post.content|mark|safe}}</p> \n```\n\n\n\n\n\n\n\n\n\n","slug":"Django添加markdown","published":1,"updated":"2016-03-06T02:32:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4s200qi26s6951lo4yg"},{"title":"Django后台添加markdown编辑器","id":"765","date":"2014-06-22T08:42:36.000Z","_content":"\n在论坛和网上找了一下，发现django-pagedown可以满足需求，搜索之后，按照[https://pypi.python.org/pypi/django-pagedown/0.1.0](https://pypi.python.org/pypi/django-pagedown/0.1.0) 进行添加。\n\n首先是安装\n1. Get the code: `pip install django-pagedown`\n2. Add `pagedown` to your `INSTALLED_APPS`\n3. Make sure to collect the static files: `python manage.py collectstatic --noinput`\n\n1.首先pip install django-pagedown下载\n\n2.之后添加pagedown到项目的'INSTALLED_APPS‘中，\n\n3.执行命令python manage.py collectstatic --noinput，收集js,css等django-pagedown用到的静态文件。\n\n之后开始添加，我的博客是在blog目录下,在目录里创建forms.py,添加如下内容\n\n``` python\nfrom pagedown.widgets import AdminPagedownWidget\nfrom django import forms\nfrom blog.models import Post\n\nclass PostForm(forms.ModelForm):\n        content = forms.CharField(widget=AdminPagedownWidget())\n\n        class Meta:\n            model = Post\n```\n\n这里是将content字段设置为markdown编辑，之后在admin.py中添加如下内容：\n``` python\nfrom django.contrib import admin\nfrom blog.models import Post\nfrom blog.forms import PostForm\nclass PostAdmin(admin.ModelAdmin):\n    form = PostForm\nadmin.site.register(Post, PostAdmin)\n```\n搞定。这样之后，在编辑content时，在它的下方就会有一个markdown的解析成HTML的结果。这里，我在数据库中只保存了markdown的原始内容，显示时还需要将它解析成HTML，这个另外再说。\n","source":"_posts/Django后台添加markdown编辑器.md","raw":"title: Django后台添加markdown编辑器\ntags:\n  - Django\n  - markdown\nid: 765\ncategories:\n  - Python\ndate: 2014-06-22 16:42:36\n---\n\n在论坛和网上找了一下，发现django-pagedown可以满足需求，搜索之后，按照[https://pypi.python.org/pypi/django-pagedown/0.1.0](https://pypi.python.org/pypi/django-pagedown/0.1.0) 进行添加。\n\n首先是安装\n1. Get the code: `pip install django-pagedown`\n2. Add `pagedown` to your `INSTALLED_APPS`\n3. Make sure to collect the static files: `python manage.py collectstatic --noinput`\n\n1.首先pip install django-pagedown下载\n\n2.之后添加pagedown到项目的'INSTALLED_APPS‘中，\n\n3.执行命令python manage.py collectstatic --noinput，收集js,css等django-pagedown用到的静态文件。\n\n之后开始添加，我的博客是在blog目录下,在目录里创建forms.py,添加如下内容\n\n``` python\nfrom pagedown.widgets import AdminPagedownWidget\nfrom django import forms\nfrom blog.models import Post\n\nclass PostForm(forms.ModelForm):\n        content = forms.CharField(widget=AdminPagedownWidget())\n\n        class Meta:\n            model = Post\n```\n\n这里是将content字段设置为markdown编辑，之后在admin.py中添加如下内容：\n``` python\nfrom django.contrib import admin\nfrom blog.models import Post\nfrom blog.forms import PostForm\nclass PostAdmin(admin.ModelAdmin):\n    form = PostForm\nadmin.site.register(Post, PostAdmin)\n```\n搞定。这样之后，在编辑content时，在它的下方就会有一个markdown的解析成HTML的结果。这里，我在数据库中只保存了markdown的原始内容，显示时还需要将它解析成HTML，这个另外再说。\n","slug":"Django后台添加markdown编辑器","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4s500qn26s6weltpwop"},{"title":"Django1.9.1使用django-pagination分页","date":"2016-04-23T10:16:20.000Z","_content":"之前是用Django自带的[Paginator](https://docs.djangoproject.com/en/1.9/topics/pagination/)进行分页。在每一个需要分页的view都要添加分页处理，而使用django-pagination, 则只需要在模版里添加即可。于是开始使用django-pagination。使用的过程中发现以下问题\n\n## 'WSGIRequest' object has no attribute 'REQUEST'\n\n这是因为REQUEST对象已经在Django1.9中丢弃. 进入python的lib目录，进入lib/python2.7/site-packages／pagination, 将middleware.py里的return int(self.REQUEST['page'])改为return int(self.GET['page'])\n\n## sequence index must be integer, not 'slice'\n这是因为xrange对象不能进行slice操作，进入templatetags,将pagination_tags.py,paginate函数里的page_range = paginator.page_range改为 page_range = list(paginator.page_range)\n\n很郁闷的是，django-pagination的github仓库里的程序没有更新，而且报TOKEN_BLOCK错误，估计是这个[commit](https://github.com/ericflo/django-pagination/commit/ef5ff95059866e94e89cad912c30497f90442765)中引入的。\n\n于是只好fork出一份，自己修改。参见[product分支](https://github.com/dengshilong/django-pagination/tree/product)\n","source":"_posts/Django1-9-1使用django-pagination分页.md","raw":"title: Django1.9.1使用django-pagination分页\ndate: 2016-04-23 18:16:20\ntags: \n    - Django\ncategories:\n    - Python\n---\n之前是用Django自带的[Paginator](https://docs.djangoproject.com/en/1.9/topics/pagination/)进行分页。在每一个需要分页的view都要添加分页处理，而使用django-pagination, 则只需要在模版里添加即可。于是开始使用django-pagination。使用的过程中发现以下问题\n\n## 'WSGIRequest' object has no attribute 'REQUEST'\n\n这是因为REQUEST对象已经在Django1.9中丢弃. 进入python的lib目录，进入lib/python2.7/site-packages／pagination, 将middleware.py里的return int(self.REQUEST['page'])改为return int(self.GET['page'])\n\n## sequence index must be integer, not 'slice'\n这是因为xrange对象不能进行slice操作，进入templatetags,将pagination_tags.py,paginate函数里的page_range = paginator.page_range改为 page_range = list(paginator.page_range)\n\n很郁闷的是，django-pagination的github仓库里的程序没有更新，而且报TOKEN_BLOCK错误，估计是这个[commit](https://github.com/ericflo/django-pagination/commit/ef5ff95059866e94e89cad912c30497f90442765)中引入的。\n\n于是只好fork出一份，自己修改。参见[product分支](https://github.com/dengshilong/django-pagination/tree/product)\n","slug":"Django1-9-1使用django-pagination分页","published":1,"updated":"2016-04-23T12:04:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4s900qr26s68lahxugf"},{"title":"13球问题","id":"965","date":"2014-11-22T16:39:45.000Z","_content":"\n以前专门考虑过这个问题，只是没有记录笔记，和组里的同事说起这个问题，于是又考虑了一次，这次还是记下来为妙。\n\n13球问题说的是有12个标准球和1个不合格的球，这个球可能偏重或者偏轻了，给你一个天平，问至少称多少次可以找到这个不合格的球。\n\n考虑这个问题之前，可以先考虑高中时代，数学老师问过的8球问题。8球问题说的是一共有8个球，其中有一个球偏重了，给你一个天平，问至少称几次可以找到这个球。\n\n一个很显然的办法是，两边各4个，之后拿重的一方再对分称，之后再拿重的一方对分称，一共三次就可以称出来。但这不是最优的，记得当时大部分同学都是这么考虑的，只有一个许杨冰同学不是这样，她说称两次即可知道。方法是，左边放三个，右边放三个，如果是左边重，则球一定在这3个中，从这个三个中取两个，天平两边各放一个，如果两边一样重，则偏重的球是剩下的那一个，如果两边不一样重，则偏重的一方就是那个球。当时就觉得许同学非同一般，后来高考时她考了全班第一。\n\n大三的时候，学习了信息论，发现这个问题可以用信息论的观点来解释。考虑上面的8球问题，当只有3个球时，只称一次即可知道是哪一个球偏重了，也就是说，一次称球，可以知道3种情况，那么2此称球就可以知道9种情况。而8球问题，只有8种情况，所以只需称两次即可找到那个球。考虑上面的13球问题，这里一共有26种情况，1号球偏重，1号球偏轻，2号球偏重，2号球偏轻。。。，因为两次称球可以知道9种情况，那么三次称球可以知道27种情况，而13球一共只有26中情况，所以13球问题只需称3次就可以找到那个球，剩下的问题就是如何称了。\n\n考虑之后，给出了一种解法。为了方便，我们给球编号，1，2，3，4，，，13。\n1.首先把1，2，3，4放在左边天平，把5，6，7，8放在右边天平，\n2.如果天平一样重，则那个球在剩下的5个球中，其它8个为标准球。之后在这5个球中取3个球，放在左边，取3个标准球放在天平右边，分三种情况\nA 如果一样重，则不合格球在剩下的两个球中，对于剩下的两个球，取其中一个出来称，如果偏重或者偏轻，则找到了那个不合格球，如果一样重，则不合格球是剩下的一个(注意，这里我们不能知道它是偏重或者偏轻)。\nB 如果左边轻，之后再称一次就可以知道是哪个球偏轻。\nC 如果左边重，之后再称一次就可以知道是哪个球偏轻。\n3.如果不一样重，则那个球在这8个球中。假设是左边重了，则剩下可能的8种情况，1，2，3，4号偏重，5，6，7，8号偏轻。之后的取法可以这样，左边放三个标准球再加上8号球，右边放5，6，7和4号球。依然分三种情况\nA 如果一样重，则1 2 3号球偏重，称一次即可知道结果\nB 如果左边重，则5 6 7 号球偏轻，称一次即可知道结果\nC 如果左边轻，则8号球偏轻或者4号球偏重，称一次即可知道结果。\n\n现在再来考虑，2时，剩下5个球的情况，5个球的时候，一共有10种情况，9号偏重，9号偏轻，，，13号偏重，所以称两次是无法知道具体是哪一个球偏重或者偏轻，这也是为什么在2的A情况中，如果一样重，则不合格球是剩下的一个，但我们无法知道它是偏重或者偏轻。所幸题目只要求我们找到那个球就可以了，没有要求知道它是偏重或者偏轻。\n\n那么如果一定要找到那个球，且知道它是偏重或者偏轻呢？这样的话就不是这种方法能解决的了，需要精心设计的方法，继续考虑，等知道了再分享。","source":"_posts/13球问题.md","raw":"title: 13球问题\ntags:\n  - 13球\n  - 8球\n  - 信息论\nid: 965\ncategories:\n  - 数学\ndate: 2014-11-23 00:39:45\n---\n\n以前专门考虑过这个问题，只是没有记录笔记，和组里的同事说起这个问题，于是又考虑了一次，这次还是记下来为妙。\n\n13球问题说的是有12个标准球和1个不合格的球，这个球可能偏重或者偏轻了，给你一个天平，问至少称多少次可以找到这个不合格的球。\n\n考虑这个问题之前，可以先考虑高中时代，数学老师问过的8球问题。8球问题说的是一共有8个球，其中有一个球偏重了，给你一个天平，问至少称几次可以找到这个球。\n\n一个很显然的办法是，两边各4个，之后拿重的一方再对分称，之后再拿重的一方对分称，一共三次就可以称出来。但这不是最优的，记得当时大部分同学都是这么考虑的，只有一个许杨冰同学不是这样，她说称两次即可知道。方法是，左边放三个，右边放三个，如果是左边重，则球一定在这3个中，从这个三个中取两个，天平两边各放一个，如果两边一样重，则偏重的球是剩下的那一个，如果两边不一样重，则偏重的一方就是那个球。当时就觉得许同学非同一般，后来高考时她考了全班第一。\n\n大三的时候，学习了信息论，发现这个问题可以用信息论的观点来解释。考虑上面的8球问题，当只有3个球时，只称一次即可知道是哪一个球偏重了，也就是说，一次称球，可以知道3种情况，那么2此称球就可以知道9种情况。而8球问题，只有8种情况，所以只需称两次即可找到那个球。考虑上面的13球问题，这里一共有26种情况，1号球偏重，1号球偏轻，2号球偏重，2号球偏轻。。。，因为两次称球可以知道9种情况，那么三次称球可以知道27种情况，而13球一共只有26中情况，所以13球问题只需称3次就可以找到那个球，剩下的问题就是如何称了。\n\n考虑之后，给出了一种解法。为了方便，我们给球编号，1，2，3，4，，，13。\n1.首先把1，2，3，4放在左边天平，把5，6，7，8放在右边天平，\n2.如果天平一样重，则那个球在剩下的5个球中，其它8个为标准球。之后在这5个球中取3个球，放在左边，取3个标准球放在天平右边，分三种情况\nA 如果一样重，则不合格球在剩下的两个球中，对于剩下的两个球，取其中一个出来称，如果偏重或者偏轻，则找到了那个不合格球，如果一样重，则不合格球是剩下的一个(注意，这里我们不能知道它是偏重或者偏轻)。\nB 如果左边轻，之后再称一次就可以知道是哪个球偏轻。\nC 如果左边重，之后再称一次就可以知道是哪个球偏轻。\n3.如果不一样重，则那个球在这8个球中。假设是左边重了，则剩下可能的8种情况，1，2，3，4号偏重，5，6，7，8号偏轻。之后的取法可以这样，左边放三个标准球再加上8号球，右边放5，6，7和4号球。依然分三种情况\nA 如果一样重，则1 2 3号球偏重，称一次即可知道结果\nB 如果左边重，则5 6 7 号球偏轻，称一次即可知道结果\nC 如果左边轻，则8号球偏轻或者4号球偏重，称一次即可知道结果。\n\n现在再来考虑，2时，剩下5个球的情况，5个球的时候，一共有10种情况，9号偏重，9号偏轻，，，13号偏重，所以称两次是无法知道具体是哪一个球偏重或者偏轻，这也是为什么在2的A情况中，如果一样重，则不合格球是剩下的一个，但我们无法知道它是偏重或者偏轻。所幸题目只要求我们找到那个球就可以了，没有要求知道它是偏重或者偏轻。\n\n那么如果一定要找到那个球，且知道它是偏重或者偏轻呢？这样的话就不是这种方法能解决的了，需要精心设计的方法，继续考虑，等知道了再分享。","slug":"13球问题","published":1,"updated":"2016-01-03T00:38:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinuar4sc00qu26s65fbsh6ci"}],"PostAsset":[],"PostCategory":[{"post_id":"cinuar4a2000026s65fz5hpip","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4ab000426s6rduxc261"},{"post_id":"cinuar4ax000726s6cpantzr8","category_id":"cinuar4ay000826s6pccbpctk","_id":"cinuar4ay000b26s6i78triu4"},{"post_id":"cinuar4b0000e26s6a3e7od57","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4b1000i26s62nvztlpv"},{"post_id":"cinuar4b2000j26s6am7ue4pp","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4b3000k26s65wvsqbut"},{"post_id":"cinuar4b5000n26s6j3ggx44m","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4b7000r26s6zvfi87h2"},{"post_id":"cinuar4b8000y26s6klz9g1cs","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4bb001226s68z7qmgl3"},{"post_id":"cinuar4bd001526s6nla88zgy","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4be001926s6xxhperth"},{"post_id":"cinuar4bg001c26s6qqqin1bu","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4bh001d26s6qqi3cfh6"},{"post_id":"cinuar4bk001j26s65kzk2z4r","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4bl001k26s6cg8psues"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4bn001m26s6ekikyvuu"},{"post_id":"cinuar4br001w26s65watgidi","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4bs001x26s6xi092n4q"},{"post_id":"cinuar4bt002226s6u2ibwkgi","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4bv002326s6azkle62s"},{"post_id":"cinuar4bw002526s6ii64o8cw","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4bx002626s6bycezex3"},{"post_id":"cinuar4by002826s6ih30ml2w","category_id":"cinuar4bz002926s6j89rvr8s","_id":"cinuar4c0002c26s640koao0n"},{"post_id":"cinuar4c2002h26s6g4yf56de","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4c4002i26s6tdsdzqfu"},{"post_id":"cinuar4c7002v26s64tgl3nxi","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4c8002w26s6c2qiwhe4"},{"post_id":"cinuar4ca003126s6xvzwhfa4","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4cb003226s6xqxr5odl"},{"post_id":"cinuar4cc003526s6ngipvocs","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4cd003626s6qoyr86o1"},{"post_id":"cinuar4cf003h26s6wkk3j1wv","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4cg003i26s6n9hnb1lu"},{"post_id":"cinuar4ck003p26s6x8rlb10r","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4cl003q26s6hcxe0v14"},{"post_id":"cinuar4cm003w26s6aehx1wfu","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4cn003x26s6zb1wtgco"},{"post_id":"cinuar4cp004526s69xqem9ik","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4cs004626s6ixse2ger"},{"post_id":"cinuar4cu004b26s6nb0pgtu6","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4cw004f26s6wgkff14t"},{"post_id":"cinuar4cx004i26s6bn48o72a","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4cz004j26s64e1xwtlc"},{"post_id":"cinuar4d1004n26s68h0tmub6","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4d2004o26s6xq7g0pnh"},{"post_id":"cinuar4d4004r26s61xaz58gk","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4d6004s26s6vbd1umxq"},{"post_id":"cinuar4d8004y26s679sw1uh8","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4da004z26s6pxknosif"},{"post_id":"cinuar4dc005526s6lvgocwbg","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4dd005626s6m4zcjp3b"},{"post_id":"cinuar4df005a26s66rw44k19","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4dg005b26s6v38nru1i"},{"post_id":"cinuar4di005f26s6gbo2ugfy","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4dj005g26s6nk464q21"},{"post_id":"cinuar4dk005k26s6ufj2ypsg","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4do005l26s6abcce58l"},{"post_id":"cinuar4dp005p26s6iezvnssm","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4dq005q26s6tce3lnt4"},{"post_id":"cinuar4ds005w26s6jxfex6ca","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4du005x26s6s4bdfu2c"},{"post_id":"cinuar4dy006126s67k4pyugj","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4dz006226s61ep9dziy"},{"post_id":"cinuar4e1006626s633y0a57s","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4e3006726s6v5lwtvfz"},{"post_id":"cinuar4e4006d26s6c6hn6hfx","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4e5006e26s6k8at0qek"},{"post_id":"cinuar4e7006i26s6u9dlke5s","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4e7006j26s6mwsff11w"},{"post_id":"cinuar4ef006n26s6lu9bet63","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4eg006o26s6kgrnu0ed"},{"post_id":"cinuar4eh006s26s6uc9xvvnb","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ei006t26s6b870c769"},{"post_id":"cinuar4ej006w26s63tgrds25","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ek006x26s61dd1sm09"},{"post_id":"cinuar4el007226s6bdujs554","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4en007326s6ttcnomz8"},{"post_id":"cinuar4ep007726s64h5k3r7q","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ep007826s602p4g01f"},{"post_id":"cinuar4er007c26s6prymzb1r","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4es007d26s600tmjs9b"},{"post_id":"cinuar4eu007l26s6ayke7qyk","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ew007m26s6vazin5do"},{"post_id":"cinuar4ey007q26s6525j4i7a","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ez007r26s6jfmj34vm"},{"post_id":"cinuar4f1007x26s6o1bja2nx","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4f2007y26s6j9vvcgg4"},{"post_id":"cinuar4f4008226s66459rxr4","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4f5008326s6w7ct5u5j"},{"post_id":"cinuar4f9008826s6hunnl33a","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4fa008926s6gnszff8e"},{"post_id":"cinuar4fw008d26s6f662e8vi","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4fy008e26s68y46749u"},{"post_id":"cinuar4fz008h26s6fudq62l7","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4g0008i26s6z7b0upno"},{"post_id":"cinuar4g1008m26s6sxanpok5","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4g2008n26s6publr2c1"},{"post_id":"cinuar4g4008q26s6s67fmc31","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4g4008r26s6fhxi0mmi"},{"post_id":"cinuar4g9008v26s6dg2jd7vl","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ga008w26s6hrf3p83f"},{"post_id":"cinuar4gi009126s6mtftwk2m","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4gj009226s60taop1g8"},{"post_id":"cinuar4gl009626s6cjyxz7ur","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4gm009726s6bwq6iam0"},{"post_id":"cinuar4gn009a26s66pbv97ak","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4gp009b26s6skwe2ubs"},{"post_id":"cinuar4gq009f26s6bbioktdl","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4gr009g26s6bwww5dgo"},{"post_id":"cinuar4gy009j26s6mn40xjkg","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4gz009k26s6urc3dhvi"},{"post_id":"cinuar4h1009q26s6kf8wjiky","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4h3009r26s6h52qv8n4"},{"post_id":"cinuar4h5009v26s6uoga7x40","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4h6009w26s6kxfhpc1p"},{"post_id":"cinuar4h800a026s634xo2t7s","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4h900a126s62fh7uxsm"},{"post_id":"cinuar4hk00a426s6om17j45t","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4hl00a526s6o8un7q52"},{"post_id":"cinuar4hv00a926s6zz4csof9","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4hx00aa26s695fudjd9"},{"post_id":"cinuar4hz00af26s6f2eg27ez","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4i200ag26s6penoohzy"},{"post_id":"cinuar4i500am26s67kkp4khe","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4i600an26s673s1duqn"},{"post_id":"cinuar4i900ar26s61ege0al0","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ia00as26s674asi6pv"},{"post_id":"cinuar4id00ay26s66gll655m","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ie00az26s6o5xrec8a"},{"post_id":"cinuar4ir00b726s6q8395wqj","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4it00b826s6mf8xa1hh"},{"post_id":"cinuar4iu00bc26s6gg1tgmtp","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4iv00bd26s6wuam7kjw"},{"post_id":"cinuar4ix00bh26s6n1o0f0fx","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4iy00bi26s6tj81g6mw"},{"post_id":"cinuar4j000bl26s6wza9f2wd","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4j100bm26s60dtvf612"},{"post_id":"cinuar4j200bp26s6ebo8ys8l","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4j300bq26s6a01vavp4"},{"post_id":"cinuar4j400bw26s626in9xah","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4j500bx26s6jbqu7eph"},{"post_id":"cinuar4j700c026s6oxa92yep","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4j800c126s6bbg08iyf"},{"post_id":"cinuar4ja00c526s645twdp4k","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jb00c626s6bnbinw38"},{"post_id":"cinuar4jc00c926s62q81as1j","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jd00ca26s6cgvnnxb2"},{"post_id":"cinuar4je00ce26s6vx52rn9d","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jf00cf26s6a3ad3apd"},{"post_id":"cinuar4jh00cl26s6abrkyioj","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4ji00cm26s63a4yj4sl"},{"post_id":"cinuar4jk00cq26s63j6jad3n","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jk00cr26s6d4tctrl8"},{"post_id":"cinuar4jm00cw26s690gmu8gj","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jn00cx26s6q5xea2g6"},{"post_id":"cinuar4jo00d026s6lce0ugy9","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jq00d126s6ug4zmvyx"},{"post_id":"cinuar4jr00d526s6n6xejla8","category_id":"cinuar4cv004c26s6ct1k6k76","_id":"cinuar4jt00d626s6wvcntb02"},{"post_id":"cinuar4jv00d926s696cuza9u","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4jx00da26s656yaxve7"},{"post_id":"cinuar4jz00df26s62867e1zg","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4k100dg26s64tuungud"},{"post_id":"cinuar4k200di26s6hcio7u7b","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4k300dj26s61chun6yi"},{"post_id":"cinuar4k500dl26s6y7o2urh0","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4k600dm26s6b0ck3xny"},{"post_id":"cinuar4k800ds26s67k3viirh","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4k900dt26s6v8jglztr"},{"post_id":"cinuar4kb00dy26s6tmggl3qn","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4kc00dz26s6mqjqrer0"},{"post_id":"cinuar4ke00e226s6lwh27aps","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4kf00e326s62zknetc3"},{"post_id":"cinuar4kg00e526s698sewiuw","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4kh00e626s6v0qoblpf"},{"post_id":"cinuar4ki00ea26s6yhanz03o","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4kk00ee26s6h4i3vqyk"},{"post_id":"cinuar4kl00eh26s6rz18zjkd","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4km00ei26s6bf7bra9o"},{"post_id":"cinuar4ko00en26s6hh6t6rg4","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4kp00eo26s6t77de2w8"},{"post_id":"cinuar4kq00es26s63uu9iru2","category_id":"cinuar4ay000826s6pccbpctk","_id":"cinuar4kr00et26s648g50g51"},{"post_id":"cinuar4kt00ex26s6od49iplb","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4ku00ey26s66pdq7i7c"},{"post_id":"cinuar4kv00f026s61finrxe3","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4kw00f126s6wn1zlqzw"},{"post_id":"cinuar4kx00f526s64xc41ylq","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ky00f626s679c7o7jk"},{"post_id":"cinuar4l000f926s6f9zwmewt","category_id":"cinuar4l100fa26s6o8wp2cgr","_id":"cinuar4l200fd26s6fqcfw3yy"},{"post_id":"cinuar4l300fg26s63d6o081l","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4l400fh26s6q0rx8tkz"},{"post_id":"cinuar4l500fl26s6j00t24lc","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4l600fm26s6o3h79485"},{"post_id":"cinuar4l700fo26s6byt6m54j","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4l800fp26s6qo9xiwys"},{"post_id":"cinuar4l900fs26s6jek5a4mj","category_id":"cinuar4l100fa26s6o8wp2cgr","_id":"cinuar4la00ft26s6qihntora"},{"post_id":"cinuar4lc00fw26s6scpb2f30","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4le00g026s6sn8sqkej"},{"post_id":"cinuar4lf00g126s6nhj627g0","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4lg00g226s6bj5iiy5r"},{"post_id":"cinuar4lh00g526s6mmz324hg","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4lj00g626s61o77gw57"},{"post_id":"cinuar4ll00g926s6k4mcx722","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4ln00ga26s6oq3j81gn"},{"post_id":"cinuar4lo00gf26s69olz00pp","category_id":"cinuar4lp00gg26s6z7qll19l","_id":"cinuar4lq00gj26s68h4grlxb"},{"post_id":"cinuar4lr00gl26s6bwo3jube","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4lu00gm26s6jz26n5py"},{"post_id":"cinuar4lw00gr26s6neacr07w","category_id":"cinuar4b1000f26s6ug7ootoz","_id":"cinuar4lx00gs26s6pdrvhmv4"},{"post_id":"cinuar4m300h126s6m3eenkf1","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4m400h226s66zhrtvhh"},{"post_id":"cinuar4m600h726s68h1crgyw","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4m700h826s6m42l0443"},{"post_id":"cinuar4m900hd26s6k5j5l5zr","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ma00he26s6x7heqwhz"},{"post_id":"cinuar4mb00hi26s6avw95gn2","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4mg00hj26s6k7e7cuza"},{"post_id":"cinuar4mi00ho26s6mr0pbiqz","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4mj00hp26s66imf2ask"},{"post_id":"cinuar4mk00hr26s659xsguzc","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4mm00hs26s66aebnmqn"},{"post_id":"cinuar4mn00hu26s6f2xtdgk2","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4mo00hv26s6a573o3kf"},{"post_id":"cinuar4mp00hx26s69iih61hg","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4mq00hy26s6itsvn94f"},{"post_id":"cinuar4mq00i026s6jf6g0xug","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4ms00i126s6vdwwb3e3"},{"post_id":"cinuar4ms00i326s6qdc5ymma","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4mu00i426s6ymj3xa4n"},{"post_id":"cinuar4mv00i726s6wh9k1s5z","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4mw00i826s6q2uc56t2"},{"post_id":"cinuar4my00id26s6fhufzqkc","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4mz00ie26s6m2f88cbt"},{"post_id":"cinuar4n100ij26s6p77n7hpq","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4n200ik26s682hv8hgv"},{"post_id":"cinuar4n400iq26s6zwbowo4z","category_id":"cinuar4n500ir26s6irntv0vk","_id":"cinuar4n600iu26s6es5fca2r"},{"post_id":"cinuar4n700ix26s65ack2bj5","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4n900iy26s64ot0eoa3"},{"post_id":"cinuar4nb00j126s68v6ogdl4","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4nc00j226s6di98ocsx"},{"post_id":"cinuar4ng00j926s6qrjirv0r","category_id":"cinuar4n500ir26s6irntv0vk","_id":"cinuar4nh00ja26s633y5dame"},{"post_id":"cinuar4nk00jh26s6zz5fd8p0","category_id":"cinuar4l100fa26s6o8wp2cgr","_id":"cinuar4nl00ji26s6y14w32vq"},{"post_id":"cinuar4nm00jl26s608tmpb4g","category_id":"cinuar4l100fa26s6o8wp2cgr","_id":"cinuar4nn00jm26s6f42f6mby"},{"post_id":"cinuar4np00jt26s6pb8k5vmp","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4nr00ju26s67je3glwj"},{"post_id":"cinuar4nu00jx26s6tll8lgw9","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4nv00jy26s6l09j5cxo"},{"post_id":"cinuar4ny00k226s6z95elcyp","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4o000k326s6vmqyfvm9"},{"post_id":"cinuar4o200k626s6mia3myn6","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4o800k726s6alprgp6r"},{"post_id":"cinuar4ob00kb26s6w78742dj","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4oc00kc26s6dnniot42"},{"post_id":"cinuar4oe00kh26s6wag5x4na","category_id":"cinuar4of00ki26s67reod77g","_id":"cinuar4og00kl26s6k0709k33"},{"post_id":"cinuar4oh00ko26s6y7ra7n0m","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4oi00kp26s6art02yx5"},{"post_id":"cinuar4ok00ku26s6hp6d9hpr","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4om00kv26s6v3tisewa"},{"post_id":"cinuar4oo00l026s64chh0ujv","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4op00l126s6t8pr964y"},{"post_id":"cinuar4or00l726s63yi8qs67","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4os00l826s6l1aahu61"},{"post_id":"cinuar4ou00lf26s6dipl1s9h","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ow00lg26s6ydt4ci5t"},{"post_id":"cinuar4oy00lo26s62qr1ozgd","category_id":"cinuar4oz00lp26s64c4p8c0x","_id":"cinuar4p000ls26s6hshplph2"},{"post_id":"cinuar4p100lt26s6w64x22ch","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4p200lu26s6en6n225o"},{"post_id":"cinuar4p400lz26s680kim30c","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4p500m026s6zxps96vk"},{"post_id":"cinuar4p600m326s64bd8i4tz","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4p800m426s65t0cu7np"},{"post_id":"cinuar4pa00mc26s6bok0vbe0","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pb00md26s66bcpz0bp"},{"post_id":"cinuar4pe00mj26s67v6in4of","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pf00mk26s63cjl0b48"},{"post_id":"cinuar4pg00mn26s6vw9prq4o","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ph00mo26s666ui7vb1"},{"post_id":"cinuar4pk00mt26s6sgwto2ti","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pm00mu26s6diybn0wh"},{"post_id":"cinuar4po00mz26s6jdrymye0","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pq00n026s6ozm3h4pw"},{"post_id":"cinuar4pr00n226s64munergq","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ps00n326s6rz14ucsa"},{"post_id":"cinuar4pt00n526s6uhlgsce3","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pu00n626s6xwj73k8x"},{"post_id":"cinuar4pv00n826s698fiqabc","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4pz00n926s670m6j5sk"},{"post_id":"cinuar4q400nf26s6md0ea01o","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4q600ng26s6xk436ozm"},{"post_id":"cinuar4q800nj26s60b7ar14x","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4q900nk26s66mg2a2lu"},{"post_id":"cinuar4qb00np26s6drm10y2z","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4qd00nq26s64oil9qf4"},{"post_id":"cinuar4qf00nv26s6p13wfz6q","category_id":"cinuar4lp00gg26s6z7qll19l","_id":"cinuar4qg00nw26s67pqeumkd"},{"post_id":"cinuar4qh00nz26s65e065m7o","category_id":"cinuar4lp00gg26s6z7qll19l","_id":"cinuar4qi00o026s63o4p3c5h"},{"post_id":"cinuar4ql00o726s6fdumg49d","category_id":"cinuar4qn00o826s6kj3115ql","_id":"cinuar4qn00ob26s66vh30hy6"},{"post_id":"cinuar4qo00oc26s6kz7feo2t","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4qp00od26s6ky9119gb"},{"post_id":"cinuar4qr00of26s69p7g1dfl","category_id":"cinuar4qs00og26s6l79cdwpf","_id":"cinuar4qt00oj26s6g197ryxw"},{"post_id":"cinuar4qv00oo26s6odqra38x","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4qw00op26s6il9jtrhw"},{"post_id":"cinuar4qy00ou26s6ragxb04f","category_id":"cinuar4qz00ov26s62185ka6b","_id":"cinuar4r000oy26s6lsh0m39u"},{"post_id":"cinuar4r100oz26s6yduu1wd3","category_id":"cinuar4qz00ov26s62185ka6b","_id":"cinuar4r200p026s6c6xf7ok9"},{"post_id":"cinuar4r400p326s680etg6jd","category_id":"cinuar4qz00ov26s62185ka6b","_id":"cinuar4r500p426s65hbq8b38"},{"post_id":"cinuar4r600p626s6627ru215","category_id":"cinuar4qz00ov26s62185ka6b","_id":"cinuar4r700p726s6ahv0vc4y"},{"post_id":"cinuar4r900pb26s6maskh2ev","category_id":"cinuar4ba000z26s661xuwf2o","_id":"cinuar4rb00pc26s6qxwugupd"},{"post_id":"cinuar4rd00ph26s6aa5bhxk4","category_id":"cinuar4l100fa26s6o8wp2cgr","_id":"cinuar4re00pi26s6yplrfu28"},{"post_id":"cinuar4rg00pl26s6vqktnddf","category_id":"cinuar4ld00fx26s6jvrnkd95","_id":"cinuar4rh00pm26s6br3ka8zy"},{"post_id":"cinuar4rj00pr26s6r04w8ehd","category_id":"cinuar4a9000126s68a9ofmwp","_id":"cinuar4rk00ps26s63s6qigjo"},{"post_id":"cinuar4rm00pv26s6kzixwfho","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4rn00pw26s66jhpbu30"},{"post_id":"cinuar4ro00py26s6ps4majer","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4rq00pz26s6aopw6psf"},{"post_id":"cinuar4rr00q126s6o0wlhur7","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4rs00q226s603kennwi"},{"post_id":"cinuar4rt00q426s6bo5y5kdf","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4ru00q526s6kb5zwl3l"},{"post_id":"cinuar4rw00q826s6exhpkyz0","category_id":"cinuar4b6000o26s6ymffjcdv","_id":"cinuar4rx00q926s67seb12b5"},{"post_id":"cinuar4rz00qd26s6dsyts4o3","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4s000qe26s68s4ixz15"},{"post_id":"cinuar4s200qi26s6951lo4yg","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4s300qj26s6xuy922k8"},{"post_id":"cinuar4s500qn26s6weltpwop","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4s700qo26s6teyxds86"},{"post_id":"cinuar4s900qr26s68lahxugf","category_id":"cinuar4be001626s692sqcylh","_id":"cinuar4sb00qs26s626tqvcou"},{"post_id":"cinuar4sc00qu26s65fbsh6ci","category_id":"cinuar4kj00eb26s6ni5yxglw","_id":"cinuar4sd00qv26s6d8aoarx1"},{"post_id":"cinuar4q100nb26s6m90bmg09","category_id":"cinuar4oz00lp26s64c4p8c0x","_id":"cinuavb6l000032s630gya58b"}],"PostTag":[{"post_id":"cinuar4a2000026s65fz5hpip","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4ab000326s6jhbvx7pu"},{"post_id":"cinuar4ax000726s6cpantzr8","tag_id":"cinuar4ay000926s69rywph8s","_id":"cinuar4az000c26s6js51et6q"},{"post_id":"cinuar4ax000726s6cpantzr8","tag_id":"cinuar4ay000a26s6s12n9fl4","_id":"cinuar4az000d26s6tsx8j2tl"},{"post_id":"cinuar4b0000e26s6a3e7od57","tag_id":"cinuar4b1000g26s69ufctg7z","_id":"cinuar4b1000h26s6v8co7v4y"},{"post_id":"cinuar4b2000j26s6am7ue4pp","tag_id":"cinuar4b3000l26s6mmnmlq34","_id":"cinuar4b3000m26s6gj3t8b4f"},{"post_id":"cinuar4b5000n26s6j3ggx44m","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4b7000u26s6jhrms01r"},{"post_id":"cinuar4b5000n26s6j3ggx44m","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4b7000v26s6wrp6zchs"},{"post_id":"cinuar4b5000n26s6j3ggx44m","tag_id":"cinuar4b7000s26s6s588wk3t","_id":"cinuar4b7000w26s64y95w1vl"},{"post_id":"cinuar4b5000n26s6j3ggx44m","tag_id":"cinuar4b7000t26s6c6m11nf1","_id":"cinuar4b7000x26s6s22tccrh"},{"post_id":"cinuar4b8000y26s6klz9g1cs","tag_id":"cinuar4ba001026s6ag18kswt","_id":"cinuar4bb001326s60daf1s9k"},{"post_id":"cinuar4b8000y26s6klz9g1cs","tag_id":"cinuar4bb001126s6pz1ggtjf","_id":"cinuar4bc001426s6urkaflxd"},{"post_id":"cinuar4bd001526s6nla88zgy","tag_id":"cinuar4be001726s65linj3v3","_id":"cinuar4bf001a26s6oejf512e"},{"post_id":"cinuar4bd001526s6nla88zgy","tag_id":"cinuar4be001826s6egag66wd","_id":"cinuar4bf001b26s65c6hm5kq"},{"post_id":"cinuar4bg001c26s6qqqin1bu","tag_id":"cinuar4bh001e26s6949s0pz0","_id":"cinuar4bj001g26s6aggb48pc"},{"post_id":"cinuar4bg001c26s6qqqin1bu","tag_id":"cinuar4bi001f26s6aouq1ce5","_id":"cinuar4bj001h26s690e2rcgx"},{"post_id":"cinuar4bg001c26s6qqqin1bu","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4bj001i26s6w3x4acjr"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","tag_id":"cinuar4bn001n26s6mj74iuj2","_id":"cinuar4bo001r26s6ebnw0hej"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4bp001s26s67m4xnsye"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","tag_id":"cinuar4bo001o26s6oc9mt2p5","_id":"cinuar4bp001t26s6xlt0y910"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","tag_id":"cinuar4bo001p26s6srjae7id","_id":"cinuar4bp001u26s60g54r8a4"},{"post_id":"cinuar4bm001l26s6fn6n8xh9","tag_id":"cinuar4bo001q26s63e7obpjk","_id":"cinuar4bp001v26s6i2gsblx5"},{"post_id":"cinuar4br001w26s65watgidi","tag_id":"cinuar4bs001y26s6kapkjzi2","_id":"cinuar4bs002026s6reg3lvmj"},{"post_id":"cinuar4br001w26s65watgidi","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4bt002126s6j0gd7eva"},{"post_id":"cinuar4bt002226s6u2ibwkgi","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4bv002426s65ejsf9k5"},{"post_id":"cinuar4bw002526s6ii64o8cw","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4bx002726s6tfruqgy2"},{"post_id":"cinuar4by002826s6ih30ml2w","tag_id":"cinuar4bz002a26s6vjfwau5c","_id":"cinuar4c0002e26s6l9jyjh1o"},{"post_id":"cinuar4by002826s6ih30ml2w","tag_id":"cinuar4c0002b26s6q8jxpzip","_id":"cinuar4c0002f26s60uhvdlf8"},{"post_id":"cinuar4by002826s6ih30ml2w","tag_id":"cinuar4c0002d26s6i9xawxcg","_id":"cinuar4c1002g26s6unl984a5"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c4002j26s62go0m8vu","_id":"cinuar4c5002p26s6e7o5kp4i"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c5002k26s6xupqqp8o","_id":"cinuar4c6002q26s67b9ji2hq"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c5002l26s6tjd7qmt0","_id":"cinuar4c6002r26s6pxrlkaoi"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c5002m26s6y4yla9ql","_id":"cinuar4c6002s26s6ghnv4wtd"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c5002n26s6tuduuql8","_id":"cinuar4c6002t26s6xric1ge2"},{"post_id":"cinuar4c2002h26s6g4yf56de","tag_id":"cinuar4c5002o26s6w4bgtd5y","_id":"cinuar4c6002u26s61g4s7szx"},{"post_id":"cinuar4c7002v26s64tgl3nxi","tag_id":"cinuar4c8002x26s6iw2d7lqi","_id":"cinuar4c9002z26s68wsbrog9"},{"post_id":"cinuar4c7002v26s64tgl3nxi","tag_id":"cinuar4c9002y26s6as9ger7t","_id":"cinuar4c9003026s6m0em3wdf"},{"post_id":"cinuar4ca003126s6xvzwhfa4","tag_id":"cinuar4c8002x26s6iw2d7lqi","_id":"cinuar4cb003326s6b0z2pyt5"},{"post_id":"cinuar4ca003126s6xvzwhfa4","tag_id":"cinuar4c9002y26s6as9ger7t","_id":"cinuar4cb003426s63a3w6vja"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4cd003726s6fjr07x3t","_id":"cinuar4ce003b26s6pjl56iao"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4cd003826s6grkzvhx5","_id":"cinuar4ce003c26s6hsbi12e4"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4ce003d26s64wa7e3vg"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4ce003e26s6kd4n7g6o"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4cd003926s69zuc9138","_id":"cinuar4ce003f26s6047snn00"},{"post_id":"cinuar4cc003526s6ngipvocs","tag_id":"cinuar4cd003a26s6ph9k1q8d","_id":"cinuar4ce003g26s62dx5a8lx"},{"post_id":"cinuar4cf003h26s6wkk3j1wv","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4ch003l26s6kn449mrp"},{"post_id":"cinuar4cf003h26s6wkk3j1wv","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4ch003m26s6bdtykroo"},{"post_id":"cinuar4cf003h26s6wkk3j1wv","tag_id":"cinuar4cg003j26s6nqlj7yat","_id":"cinuar4ci003n26s6o681mxbz"},{"post_id":"cinuar4cf003h26s6wkk3j1wv","tag_id":"cinuar4ch003k26s619pcuqhs","_id":"cinuar4ci003o26s65dwbeu58"},{"post_id":"cinuar4ck003p26s6x8rlb10r","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4cm003t26s61myj5ij6"},{"post_id":"cinuar4ck003p26s6x8rlb10r","tag_id":"cinuar4cl003r26s6sfcrph38","_id":"cinuar4cm003u26s6wgmeqtmj"},{"post_id":"cinuar4ck003p26s6x8rlb10r","tag_id":"cinuar4cl003s26s6pxd84911","_id":"cinuar4cm003v26s6vvr2ns3u"},{"post_id":"cinuar4cm003w26s6aehx1wfu","tag_id":"cinuar4cn003y26s6pnuejj7f","_id":"cinuar4co004026s6m8ja29gr"},{"post_id":"cinuar4cm003w26s6aehx1wfu","tag_id":"cinuar4co003z26s61m1ac812","_id":"cinuar4co004126s6dewp2o0k"},{"post_id":"cinuar4cm003w26s6aehx1wfu","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4co004226s6sgja87zn"},{"post_id":"cinuar4cm003w26s6aehx1wfu","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4co004326s6vm3v9fc5"},{"post_id":"cinuar4cm003w26s6aehx1wfu","tag_id":"cinuar4cl003s26s6pxd84911","_id":"cinuar4co004426s6yflj5zde"},{"post_id":"cinuar4cp004526s69xqem9ik","tag_id":"cinuar4cs004726s6wveb8eed","_id":"cinuar4ct004926s680wid66f"},{"post_id":"cinuar4cp004526s69xqem9ik","tag_id":"cinuar4ct004826s61s3vpqp6","_id":"cinuar4ct004a26s6sietg0b7"},{"post_id":"cinuar4cu004b26s6nb0pgtu6","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4cw004g26s68v5s7m28"},{"post_id":"cinuar4cu004b26s6nb0pgtu6","tag_id":"cinuar4cw004e26s6rllzynja","_id":"cinuar4cw004h26s6mhs5i8s6"},{"post_id":"cinuar4cx004i26s6bn48o72a","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4d0004l26s6w3x68xfv"},{"post_id":"cinuar4cx004i26s6bn48o72a","tag_id":"cinuar4d0004k26s67ngzm6o2","_id":"cinuar4d0004m26s6zahaw5zw"},{"post_id":"cinuar4d1004n26s68h0tmub6","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4d2004p26s62zs1dy5p"},{"post_id":"cinuar4d1004n26s68h0tmub6","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4d2004q26s61j8xi74c"},{"post_id":"cinuar4d4004r26s61xaz58gk","tag_id":"cinuar4d6004t26s6a5n6upsz","_id":"cinuar4d7004v26s6rvf7mits"},{"post_id":"cinuar4d4004r26s61xaz58gk","tag_id":"cinuar4d6004u26s60fv5vlks","_id":"cinuar4d7004w26s68qm8zpoj"},{"post_id":"cinuar4d4004r26s61xaz58gk","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4d7004x26s6gfav8ngn"},{"post_id":"cinuar4d8004y26s679sw1uh8","tag_id":"cinuar4da005026s6qcnhrzmy","_id":"cinuar4db005226s6r2509ia8"},{"post_id":"cinuar4d8004y26s679sw1uh8","tag_id":"cinuar4da005126s6gklu6r0e","_id":"cinuar4db005326s6wwhff2ig"},{"post_id":"cinuar4d8004y26s679sw1uh8","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4db005426s6ia1uvgt8"},{"post_id":"cinuar4dc005526s6lvgocwbg","tag_id":"cinuar4dd005726s6033zcdhh","_id":"cinuar4de005826s6jdb4yifm"},{"post_id":"cinuar4dc005526s6lvgocwbg","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4de005926s6ux2wfvl9"},{"post_id":"cinuar4df005a26s66rw44k19","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4dg005c26s6mzt9key9"},{"post_id":"cinuar4df005a26s66rw44k19","tag_id":"cinuar4d6004t26s6a5n6upsz","_id":"cinuar4dg005d26s6l2u9wm18"},{"post_id":"cinuar4df005a26s66rw44k19","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4dg005e26s68ujutf48"},{"post_id":"cinuar4di005f26s6gbo2ugfy","tag_id":"cinuar4dj005h26s6whaud91p","_id":"cinuar4dj005i26s6vcf2hrhx"},{"post_id":"cinuar4di005f26s6gbo2ugfy","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4dj005j26s6xttdbs2a"},{"post_id":"cinuar4dk005k26s6ufj2ypsg","tag_id":"cinuar4do005m26s6l8rfe50y","_id":"cinuar4do005n26s6naxqcp44"},{"post_id":"cinuar4dk005k26s6ufj2ypsg","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4do005o26s6hetwg4e1"},{"post_id":"cinuar4dp005p26s6iezvnssm","tag_id":"cinuar4dq005r26s6vec28s6i","_id":"cinuar4dr005t26s6md17hvz6"},{"post_id":"cinuar4dp005p26s6iezvnssm","tag_id":"cinuar4dq005s26s6sl2g9yki","_id":"cinuar4dr005u26s61p7zmcc2"},{"post_id":"cinuar4dp005p26s6iezvnssm","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4dr005v26s6sywhym2g"},{"post_id":"cinuar4ds005w26s6jxfex6ca","tag_id":"cinuar4dv005y26s6zdsw5yue","_id":"cinuar4dv005z26s64otspkyw"},{"post_id":"cinuar4ds005w26s6jxfex6ca","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4dv006026s6gm4tcpjd"},{"post_id":"cinuar4dy006126s67k4pyugj","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4e0006426s6vcw95lvj"},{"post_id":"cinuar4dy006126s67k4pyugj","tag_id":"cinuar4e0006326s60hill1jd","_id":"cinuar4e0006526s6mfz0geuo"},{"post_id":"cinuar4e1006626s633y0a57s","tag_id":"cinuar4e3006826s6lel5o74n","_id":"cinuar4e3006a26s6t3qf2y9k"},{"post_id":"cinuar4e1006626s633y0a57s","tag_id":"cinuar4e3006926s6aoyilbo5","_id":"cinuar4e4006b26s6f4z5o27o"},{"post_id":"cinuar4e1006626s633y0a57s","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4e4006c26s6qtux4f5p"},{"post_id":"cinuar4e4006d26s6c6hn6hfx","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4e6006g26s6z8uf56js"},{"post_id":"cinuar4e4006d26s6c6hn6hfx","tag_id":"cinuar4e5006f26s6fn0ek248","_id":"cinuar4e6006h26s6fs07x4uk"},{"post_id":"cinuar4e7006i26s6u9dlke5s","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ee006l26s6i4stueei"},{"post_id":"cinuar4e7006i26s6u9dlke5s","tag_id":"cinuar4e8006k26s62mdsyuuv","_id":"cinuar4ee006m26s6bxcs9wi7"},{"post_id":"cinuar4ef006n26s6lu9bet63","tag_id":"cinuar4eg006p26s6keun9hkn","_id":"cinuar4eg006q26s6yiu0aa7v"},{"post_id":"cinuar4ef006n26s6lu9bet63","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4eg006r26s6pjyqh1h0"},{"post_id":"cinuar4eh006s26s6uc9xvvnb","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ei006u26s6v048d2sw"},{"post_id":"cinuar4eh006s26s6uc9xvvnb","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4ei006v26s6x7vn6re6"},{"post_id":"cinuar4ej006w26s63tgrds25","tag_id":"cinuar4ek006y26s6fbl7r459","_id":"cinuar4ek006z26s646rfezfz"},{"post_id":"cinuar4ej006w26s63tgrds25","tag_id":"cinuar4do005m26s6l8rfe50y","_id":"cinuar4ek007026s6n8dmldxq"},{"post_id":"cinuar4ej006w26s63tgrds25","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ek007126s6jj7d0fok"},{"post_id":"cinuar4el007226s6bdujs554","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4en007526s6w73qhno7"},{"post_id":"cinuar4el007226s6bdujs554","tag_id":"cinuar4en007426s6q910fhf6","_id":"cinuar4en007626s6kni3o48v"},{"post_id":"cinuar4ep007726s64h5k3r7q","tag_id":"cinuar4eq007926s6uq8gu1b7","_id":"cinuar4eq007a26s6att61gbm"},{"post_id":"cinuar4ep007726s64h5k3r7q","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4eq007b26s6rirmlgm6"},{"post_id":"cinuar4er007c26s6prymzb1r","tag_id":"cinuar4es007e26s6uo4ep8ga","_id":"cinuar4et007h26s60fyj4nbd"},{"post_id":"cinuar4er007c26s6prymzb1r","tag_id":"cinuar4et007f26s6if4edqcp","_id":"cinuar4et007i26s6hfvuytth"},{"post_id":"cinuar4er007c26s6prymzb1r","tag_id":"cinuar4et007g26s6hmo5egjr","_id":"cinuar4et007j26s6b6ya11pn"},{"post_id":"cinuar4er007c26s6prymzb1r","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4et007k26s6qca2da0x"},{"post_id":"cinuar4eu007l26s6ayke7qyk","tag_id":"cinuar4ew007n26s66chqv7dn","_id":"cinuar4ex007o26s6aasqnv21"},{"post_id":"cinuar4eu007l26s6ayke7qyk","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ex007p26s646qt46on"},{"post_id":"cinuar4ey007q26s6525j4i7a","tag_id":"cinuar4f0007s26s6idk0h80d","_id":"cinuar4f0007u26s6qhygetc5"},{"post_id":"cinuar4ey007q26s6525j4i7a","tag_id":"cinuar4f0007t26s6kqskc3a5","_id":"cinuar4f1007v26s6szaiemip"},{"post_id":"cinuar4ey007q26s6525j4i7a","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4f1007w26s66mky3zl7"},{"post_id":"cinuar4f1007x26s6o1bja2nx","tag_id":"cinuar4f3007z26s6y9w7yewp","_id":"cinuar4f3008026s6q67d5vjp"},{"post_id":"cinuar4f1007x26s6o1bja2nx","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4f3008126s645pno7xh"},{"post_id":"cinuar4f4008226s66459rxr4","tag_id":"cinuar4f5008426s6wixgxp7j","_id":"cinuar4f5008526s6c626cnbd"},{"post_id":"cinuar4f4008226s66459rxr4","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4f6008626s6d2h43sqr"},{"post_id":"cinuar4f4008226s66459rxr4","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4f6008726s6925rilln"},{"post_id":"cinuar4f9008826s6hunnl33a","tag_id":"cinuar4fa008a26s6a71m9q6n","_id":"cinuar4fa008b26s6txk755t0"},{"post_id":"cinuar4f9008826s6hunnl33a","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4fa008c26s6xygtvsk9"},{"post_id":"cinuar4fw008d26s6f662e8vi","tag_id":"cinuar4dq005s26s6sl2g9yki","_id":"cinuar4fy008f26s6anvmbw8p"},{"post_id":"cinuar4fw008d26s6f662e8vi","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4fy008g26s6pu74zuhf"},{"post_id":"cinuar4fz008h26s6fudq62l7","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4g0008k26s6ietv49e6"},{"post_id":"cinuar4fz008h26s6fudq62l7","tag_id":"cinuar4g0008j26s603j87e5e","_id":"cinuar4g0008l26s6xufcr3e9"},{"post_id":"cinuar4g1008m26s6sxanpok5","tag_id":"cinuar4f5008426s6wixgxp7j","_id":"cinuar4g2008o26s65svkzc92"},{"post_id":"cinuar4g1008m26s6sxanpok5","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4g2008p26s6mojo305p"},{"post_id":"cinuar4g4008q26s6s67fmc31","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4g5008s26s6un1qf8gh"},{"post_id":"cinuar4g4008q26s6s67fmc31","tag_id":"cinuar4bs001y26s6kapkjzi2","_id":"cinuar4g5008t26s6atacrvf0"},{"post_id":"cinuar4g4008q26s6s67fmc31","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4g5008u26s6gsykaa29"},{"post_id":"cinuar4g9008v26s6dg2jd7vl","tag_id":"cinuar4dq005s26s6sl2g9yki","_id":"cinuar4gb008y26s6o3x4gkle"},{"post_id":"cinuar4g9008v26s6dg2jd7vl","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4gd008z26s6vs0el2kb"},{"post_id":"cinuar4g9008v26s6dg2jd7vl","tag_id":"cinuar4gb008x26s6gldfmcj8","_id":"cinuar4gd009026s6ezf0hz1a"},{"post_id":"cinuar4gi009126s6mtftwk2m","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4gk009326s6w4mewcyw"},{"post_id":"cinuar4gi009126s6mtftwk2m","tag_id":"cinuar4bs001y26s6kapkjzi2","_id":"cinuar4gk009426s6brym6lp3"},{"post_id":"cinuar4gi009126s6mtftwk2m","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4gk009526s6pimiqjls"},{"post_id":"cinuar4gl009626s6cjyxz7ur","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4gm009826s6jwwhn6ev"},{"post_id":"cinuar4gl009626s6cjyxz7ur","tag_id":"cinuar4e0006326s60hill1jd","_id":"cinuar4gm009926s6e8ac20wp"},{"post_id":"cinuar4gn009a26s66pbv97ak","tag_id":"cinuar4gp009c26s6o2a7r2a9","_id":"cinuar4gp009d26s6bllutwkw"},{"post_id":"cinuar4gn009a26s66pbv97ak","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4gp009e26s6egu1yh8s"},{"post_id":"cinuar4gq009f26s6bbioktdl","tag_id":"cinuar4f5008426s6wixgxp7j","_id":"cinuar4gr009h26s6jtiqi0c6"},{"post_id":"cinuar4gq009f26s6bbioktdl","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4gs009i26s6ttn8qevo"},{"post_id":"cinuar4gy009j26s6mn40xjkg","tag_id":"cinuar4gz009l26s6k4sddmgb","_id":"cinuar4gz009n26s6pp6c3uoy"},{"post_id":"cinuar4gy009j26s6mn40xjkg","tag_id":"cinuar4gz009m26s6az7vaoj9","_id":"cinuar4h0009o26s6l1qpnbq4"},{"post_id":"cinuar4gy009j26s6mn40xjkg","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4h0009p26s6erjl0qci"},{"post_id":"cinuar4h1009q26s6kf8wjiky","tag_id":"cinuar4h3009s26s6z4x4r8by","_id":"cinuar4h3009t26s6lbo9xnjd"},{"post_id":"cinuar4h1009q26s6kf8wjiky","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4h3009u26s6v8byz47h"},{"post_id":"cinuar4h5009v26s6uoga7x40","tag_id":"cinuar4h6009x26s6iarz4qtn","_id":"cinuar4h6009y26s6laoc09ax"},{"post_id":"cinuar4h5009v26s6uoga7x40","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4h7009z26s6gtkmlpmv"},{"post_id":"cinuar4h800a026s634xo2t7s","tag_id":"cinuar4do005m26s6l8rfe50y","_id":"cinuar4h900a226s63lnowa57"},{"post_id":"cinuar4h800a026s634xo2t7s","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4h900a326s6rmq1us04"},{"post_id":"cinuar4hk00a426s6om17j45t","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4hn00a726s6lui5psj3"},{"post_id":"cinuar4hk00a426s6om17j45t","tag_id":"cinuar4hm00a626s6ow07adqh","_id":"cinuar4hn00a826s6oqa6n52u"},{"post_id":"cinuar4hv00a926s6zz4csof9","tag_id":"cinuar4hx00ab26s6awlxzb1y","_id":"cinuar4hx00ac26s6vxjchhno"},{"post_id":"cinuar4hv00a926s6zz4csof9","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4hx00ad26s6xpl6g7m0"},{"post_id":"cinuar4hv00a926s6zz4csof9","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4hx00ae26s67dkznmgi"},{"post_id":"cinuar4hz00af26s6f2eg27ez","tag_id":"cinuar4i200ah26s6d6pa2jvn","_id":"cinuar4i300aj26s68q1p0fqt"},{"post_id":"cinuar4hz00af26s6f2eg27ez","tag_id":"cinuar4i300ai26s6af9ymbnd","_id":"cinuar4i400ak26s624ftbr7p"},{"post_id":"cinuar4hz00af26s6f2eg27ez","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4i400al26s6rtukqmtn"},{"post_id":"cinuar4i500am26s67kkp4khe","tag_id":"cinuar4i600ao26s6h8rgzuwm","_id":"cinuar4i700ap26s65gsvyb4m"},{"post_id":"cinuar4i500am26s67kkp4khe","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4i700aq26s6yjs1oigg"},{"post_id":"cinuar4i900ar26s61ege0al0","tag_id":"cinuar4ia00at26s6bh2fhi3j","_id":"cinuar4ib00av26s65h67xq7q"},{"post_id":"cinuar4i900ar26s61ege0al0","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ic00aw26s65u8aqnnr"},{"post_id":"cinuar4i900ar26s61ege0al0","tag_id":"cinuar4ib00au26s6tz2u40mq","_id":"cinuar4ic00ax26s6vegjxkyk"},{"post_id":"cinuar4id00ay26s66gll655m","tag_id":"cinuar4ie00b026s6t864xgwq","_id":"cinuar4if00b326s63ndkswl2"},{"post_id":"cinuar4id00ay26s66gll655m","tag_id":"cinuar4if00b126s6ri94orel","_id":"cinuar4ig00b426s6mojx18f0"},{"post_id":"cinuar4id00ay26s66gll655m","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ig00b526s630mgy2fo"},{"post_id":"cinuar4id00ay26s66gll655m","tag_id":"cinuar4if00b226s6c5g8r5q9","_id":"cinuar4ig00b626s65xy2gqho"},{"post_id":"cinuar4ir00b726s6q8395wqj","tag_id":"cinuar4it00b926s60kvylkkl","_id":"cinuar4it00ba26s6j7780nhh"},{"post_id":"cinuar4ir00b726s6q8395wqj","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4it00bb26s6pjcv59kh"},{"post_id":"cinuar4iu00bc26s6gg1tgmtp","tag_id":"cinuar4iv00be26s6wdej6wu3","_id":"cinuar4iw00bf26s614yjtg4n"},{"post_id":"cinuar4iu00bc26s6gg1tgmtp","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4iw00bg26s6fbdkqed7"},{"post_id":"cinuar4ix00bh26s6n1o0f0fx","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4iy00bj26s6ox8rermg"},{"post_id":"cinuar4ix00bh26s6n1o0f0fx","tag_id":"cinuar4e0006326s60hill1jd","_id":"cinuar4iz00bk26s64sdo0umb"},{"post_id":"cinuar4j000bl26s6wza9f2wd","tag_id":"cinuar4i600ao26s6h8rgzuwm","_id":"cinuar4j100bn26s689y20gxi"},{"post_id":"cinuar4j000bl26s6wza9f2wd","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4j100bo26s6k90u5j7g"},{"post_id":"cinuar4j200bp26s6ebo8ys8l","tag_id":"cinuar4j300br26s6aqpvz4r2","_id":"cinuar4j300bt26s6wmm143av"},{"post_id":"cinuar4j200bp26s6ebo8ys8l","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4j400bu26s6b9qxl2w5"},{"post_id":"cinuar4j200bp26s6ebo8ys8l","tag_id":"cinuar4j300bs26s64gd96mac","_id":"cinuar4j400bv26s6nt498jkh"},{"post_id":"cinuar4j400bw26s626in9xah","tag_id":"cinuar4gz009l26s6k4sddmgb","_id":"cinuar4j600by26s6d0o512rg"},{"post_id":"cinuar4j400bw26s626in9xah","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4j600bz26s6brigw3qg"},{"post_id":"cinuar4j700c026s6oxa92yep","tag_id":"cinuar4j800c226s6fpqhkz89","_id":"cinuar4j900c326s6src4kxtf"},{"post_id":"cinuar4j700c026s6oxa92yep","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4j900c426s638wfdc69"},{"post_id":"cinuar4ja00c526s645twdp4k","tag_id":"cinuar4h3009s26s6z4x4r8by","_id":"cinuar4jb00c726s6fkp2jn2w"},{"post_id":"cinuar4ja00c526s645twdp4k","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jb00c826s6w1zp9mb9"},{"post_id":"cinuar4jc00c926s62q81as1j","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jd00cc26s6b68o2di5"},{"post_id":"cinuar4jc00c926s62q81as1j","tag_id":"cinuar4jd00cb26s6huxtr42u","_id":"cinuar4jd00cd26s6etkw73it"},{"post_id":"cinuar4je00ce26s6vx52rn9d","tag_id":"cinuar4jf00cg26s6bmsyfiri","_id":"cinuar4jg00ci26s69jclpp4n"},{"post_id":"cinuar4je00ce26s6vx52rn9d","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jg00cj26s69tprx52f"},{"post_id":"cinuar4je00ce26s6vx52rn9d","tag_id":"cinuar4jg00ch26s6hnqrjojc","_id":"cinuar4jg00ck26s6tkhi71dw"},{"post_id":"cinuar4jh00cl26s6abrkyioj","tag_id":"cinuar4ji00cn26s6bb7924kx","_id":"cinuar4jj00co26s6c2rofv9g"},{"post_id":"cinuar4jh00cl26s6abrkyioj","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jj00cp26s6d7wz28ip"},{"post_id":"cinuar4jk00cq26s63j6jad3n","tag_id":"cinuar4f3007z26s6y9w7yewp","_id":"cinuar4jl00ct26s66ns3viui"},{"post_id":"cinuar4jk00cq26s63j6jad3n","tag_id":"cinuar4jl00cs26s631cecde8","_id":"cinuar4jm00cu26s6ut2fkia0"},{"post_id":"cinuar4jk00cq26s63j6jad3n","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jm00cv26s6517v1lgo"},{"post_id":"cinuar4jm00cw26s690gmu8gj","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jn00cy26s6iwx7vbeq"},{"post_id":"cinuar4jm00cw26s690gmu8gj","tag_id":"cinuar4d0004k26s67ngzm6o2","_id":"cinuar4jo00cz26s6i7ixs7a4"},{"post_id":"cinuar4jo00d026s6lce0ugy9","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4jq00d226s67q2dkwdd"},{"post_id":"cinuar4jo00d026s6lce0ugy9","tag_id":"cinuar4bs001y26s6kapkjzi2","_id":"cinuar4jq00d326s6uge350bn"},{"post_id":"cinuar4jo00d026s6lce0ugy9","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4jq00d426s6qn7hjdkl"},{"post_id":"cinuar4jr00d526s6n6xejla8","tag_id":"cinuar4e3006826s6lel5o74n","_id":"cinuar4ju00d726s6ev4vv16l"},{"post_id":"cinuar4jr00d526s6n6xejla8","tag_id":"cinuar4cv004d26s62zjm4phg","_id":"cinuar4ju00d826s68mwxlz2b"},{"post_id":"cinuar4jv00d926s696cuza9u","tag_id":"cinuar4jx00db26s68nlmzhwg","_id":"cinuar4jy00dd26s6bti3hyd0"},{"post_id":"cinuar4jv00d926s696cuza9u","tag_id":"cinuar4jx00dc26s625njdk1a","_id":"cinuar4jy00de26s697e1973e"},{"post_id":"cinuar4jz00df26s62867e1zg","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4k100dh26s69kwa79ji"},{"post_id":"cinuar4k200di26s6hcio7u7b","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4k400dk26s6yft5aprg"},{"post_id":"cinuar4k500dl26s6y7o2urh0","tag_id":"cinuar4gz009l26s6k4sddmgb","_id":"cinuar4k700dp26s69tmwsxek"},{"post_id":"cinuar4k500dl26s6y7o2urh0","tag_id":"cinuar4k700dn26s6qmszr3df","_id":"cinuar4k700dq26s6yg98o37w"},{"post_id":"cinuar4k500dl26s6y7o2urh0","tag_id":"cinuar4k700do26s6h1benj4x","_id":"cinuar4k700dr26s6x97hpdbn"},{"post_id":"cinuar4k800ds26s67k3viirh","tag_id":"cinuar4ka00du26s65nnsb8s0","_id":"cinuar4ka00dw26s6c6v0jvgd"},{"post_id":"cinuar4k800ds26s67k3viirh","tag_id":"cinuar4ka00dv26s647frncyd","_id":"cinuar4kb00dx26s6ihsehbjx"},{"post_id":"cinuar4kb00dy26s6tmggl3qn","tag_id":"cinuar4kd00e026s6mv5lwtf5","_id":"cinuar4kd00e126s6vlik72ey"},{"post_id":"cinuar4ke00e226s6lwh27aps","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4kf00e426s6mig9wytx"},{"post_id":"cinuar4kg00e526s698sewiuw","tag_id":"cinuar4kh00e726s68iizdwgj","_id":"cinuar4ki00e826s6falivuxz"},{"post_id":"cinuar4kg00e526s698sewiuw","tag_id":"cinuar4kd00e026s6mv5lwtf5","_id":"cinuar4ki00e926s6ajd0sjt8"},{"post_id":"cinuar4ki00ea26s6yhanz03o","tag_id":"cinuar4kk00ec26s6ldbr3bgk","_id":"cinuar4kk00ef26s60aw7k14d"},{"post_id":"cinuar4ki00ea26s6yhanz03o","tag_id":"cinuar4kk00ed26s6v3fuija7","_id":"cinuar4kl00eg26s63tf4xmdu"},{"post_id":"cinuar4kl00eh26s6rz18zjkd","tag_id":"cinuar4gz009l26s6k4sddmgb","_id":"cinuar4kn00ek26s6h4p6piaz"},{"post_id":"cinuar4kl00eh26s6rz18zjkd","tag_id":"cinuar4km00ej26s6deq0sevy","_id":"cinuar4kn00el26s6ez2kkx31"},{"post_id":"cinuar4kl00eh26s6rz18zjkd","tag_id":"cinuar4k700do26s6h1benj4x","_id":"cinuar4kn00em26s6t00ecusl"},{"post_id":"cinuar4ko00en26s6hh6t6rg4","tag_id":"cinuar4f0007t26s6kqskc3a5","_id":"cinuar4kq00eq26s6xxsw06zx"},{"post_id":"cinuar4ko00en26s6hh6t6rg4","tag_id":"cinuar4kp00ep26s6zublvgys","_id":"cinuar4kq00er26s6diepr4xh"},{"post_id":"cinuar4kq00es26s63uu9iru2","tag_id":"cinuar4ks00eu26s6iyzdolwk","_id":"cinuar4ks00ev26s6sfx8v88n"},{"post_id":"cinuar4kq00es26s63uu9iru2","tag_id":"cinuar4ay000a26s6s12n9fl4","_id":"cinuar4ks00ew26s6k5ud3f93"},{"post_id":"cinuar4kt00ex26s6od49iplb","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4ku00ez26s6yl2lcwrr"},{"post_id":"cinuar4kv00f026s61finrxe3","tag_id":"cinuar4cd003726s6fjr07x3t","_id":"cinuar4kw00f226s66vkgccjc"},{"post_id":"cinuar4kv00f026s61finrxe3","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4kw00f326s6du5p9k6f"},{"post_id":"cinuar4kv00f026s61finrxe3","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4kw00f426s682clbq39"},{"post_id":"cinuar4kx00f526s64xc41ylq","tag_id":"cinuar4ky00f726s6yserjydi","_id":"cinuar4kz00f826s64miacqk5"},{"post_id":"cinuar4l000f926s6f9zwmewt","tag_id":"cinuar4l100fb26s67egwxhw8","_id":"cinuar4l200fe26s60v67ttb3"},{"post_id":"cinuar4l000f926s6f9zwmewt","tag_id":"cinuar4l100fc26s6cpluftj6","_id":"cinuar4l200ff26s6nf6ici4b"},{"post_id":"cinuar4l300fg26s63d6o081l","tag_id":"cinuar4gz009l26s6k4sddmgb","_id":"cinuar4l400fj26s6fh3fgdh1"},{"post_id":"cinuar4l300fg26s63d6o081l","tag_id":"cinuar4l400fi26s6aavilbki","_id":"cinuar4l400fk26s6rwep9jji"},{"post_id":"cinuar4l500fl26s6j00t24lc","tag_id":"cinuar4l100fb26s67egwxhw8","_id":"cinuar4l600fn26s6a7v1ryuj"},{"post_id":"cinuar4l700fo26s6byt6m54j","tag_id":"cinuar4l800fq26s6tlj2o1o7","_id":"cinuar4l900fr26s6fe7lb446"},{"post_id":"cinuar4l900fs26s6jek5a4mj","tag_id":"cinuar4la00fu26s6kimot3gu","_id":"cinuar4lb00fv26s6hz4mubey"},{"post_id":"cinuar4lc00fw26s6scpb2f30","tag_id":"cinuar4ld00fy26s66d7y0w6q","_id":"cinuar4le00fz26s6nueiyrf8"},{"post_id":"cinuar4lf00g126s6nhj627g0","tag_id":"cinuar4lg00g326s67oksn3il","_id":"cinuar4lh00g426s64ustxctb"},{"post_id":"cinuar4lh00g526s6mmz324hg","tag_id":"cinuar4d6004t26s6a5n6upsz","_id":"cinuar4lj00g726s6dn5t6mxl"},{"post_id":"cinuar4lh00g526s6mmz324hg","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4lj00g826s61zs2g2r9"},{"post_id":"cinuar4ll00g926s6k4mcx722","tag_id":"cinuar4ln00gb26s627j3awd5","_id":"cinuar4ln00gd26s6aysmculb"},{"post_id":"cinuar4ll00g926s6k4mcx722","tag_id":"cinuar4ln00gc26s6lc8qsdqg","_id":"cinuar4lo00ge26s6lh2uxjbk"},{"post_id":"cinuar4lo00gf26s69olz00pp","tag_id":"cinuar4ka00du26s65nnsb8s0","_id":"cinuar4lq00gi26s6bdxp0cir"},{"post_id":"cinuar4lo00gf26s69olz00pp","tag_id":"cinuar4lp00gh26s6a94yh43y","_id":"cinuar4lq00gk26s6e5nxhzlq"},{"post_id":"cinuar4lr00gl26s6bwo3jube","tag_id":"cinuar4lu00gn26s6rlmldmu5","_id":"cinuar4lv00gp26s6sc5llo4n"},{"post_id":"cinuar4lr00gl26s6bwo3jube","tag_id":"cinuar4lu00go26s6l7n7pglb","_id":"cinuar4lv00gq26s69l671fg4"},{"post_id":"cinuar4lw00gr26s6neacr07w","tag_id":"cinuar4lx00gt26s68pfzq0sx","_id":"cinuar4m000gx26s6e186pueo"},{"post_id":"cinuar4lw00gr26s6neacr07w","tag_id":"cinuar4ly00gu26s6uyptxon1","_id":"cinuar4m100gy26s6rh6mhxmh"},{"post_id":"cinuar4lw00gr26s6neacr07w","tag_id":"cinuar4ly00gv26s6cimzbp5m","_id":"cinuar4m100gz26s6x5k7rejs"},{"post_id":"cinuar4lw00gr26s6neacr07w","tag_id":"cinuar4ly00gw26s6yr0n77xz","_id":"cinuar4m100h026s6yotxs6ed"},{"post_id":"cinuar4m300h126s6m3eenkf1","tag_id":"cinuar4m400h326s68gv2ez79","_id":"cinuar4m500h526s6ekb18vgr"},{"post_id":"cinuar4m300h126s6m3eenkf1","tag_id":"cinuar4m400h426s6dk5ncobv","_id":"cinuar4m500h626s6c1oiczt7"},{"post_id":"cinuar4m600h726s68h1crgyw","tag_id":"cinuar4e3006926s6aoyilbo5","_id":"cinuar4m700ha26s6wz1725e1"},{"post_id":"cinuar4m600h726s68h1crgyw","tag_id":"cinuar4m700h926s6e5h4tace","_id":"cinuar4m800hb26s6s3vi5eom"},{"post_id":"cinuar4m600h726s68h1crgyw","tag_id":"cinuar4jd00cb26s6huxtr42u","_id":"cinuar4m800hc26s6gfhbhga2"},{"post_id":"cinuar4m900hd26s6k5j5l5zr","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4ma00hf26s6s6y4zd4y"},{"post_id":"cinuar4m900hd26s6k5j5l5zr","tag_id":"cinuar4cl003s26s6pxd84911","_id":"cinuar4ma00hg26s6wmiv8dt0"},{"post_id":"cinuar4m900hd26s6k5j5l5zr","tag_id":"cinuar4cd003a26s6ph9k1q8d","_id":"cinuar4ma00hh26s6sl5ondd8"},{"post_id":"cinuar4mb00hi26s6avw95gn2","tag_id":"cinuar4mg00hk26s6w70mdbhk","_id":"cinuar4mh00hm26s6npm4ei6t"},{"post_id":"cinuar4mb00hi26s6avw95gn2","tag_id":"cinuar4mh00hl26s6ph9z2wp1","_id":"cinuar4mh00hn26s6w5vffbuv"},{"post_id":"cinuar4mi00ho26s6mr0pbiqz","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4mj00hq26s6oo2oxbbs"},{"post_id":"cinuar4mk00hr26s659xsguzc","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4mm00ht26s6jbw28ibf"},{"post_id":"cinuar4mn00hu26s6f2xtdgk2","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4mo00hw26s6oudoku7v"},{"post_id":"cinuar4mp00hx26s69iih61hg","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4mq00hz26s62sx33egg"},{"post_id":"cinuar4mq00i026s6jf6g0xug","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4ms00i226s6hckv2ls4"},{"post_id":"cinuar4ms00i326s6qdc5ymma","tag_id":"cinuar4mu00i526s6fuzjoe85","_id":"cinuar4mu00i626s60rlkz1al"},{"post_id":"cinuar4mv00i726s6wh9k1s5z","tag_id":"cinuar4mw00i926s6y0ddaloj","_id":"cinuar4mx00ib26s6kn0vyyjl"},{"post_id":"cinuar4mv00i726s6wh9k1s5z","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4mx00ic26s6t9m2w8r1"},{"post_id":"cinuar4my00id26s6fhufzqkc","tag_id":"cinuar4mw00i926s6y0ddaloj","_id":"cinuar4n000ig26s67xwrfbph"},{"post_id":"cinuar4my00id26s6fhufzqkc","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4n000ih26s68upy5sun"},{"post_id":"cinuar4my00id26s6fhufzqkc","tag_id":"cinuar4mz00if26s62vbj9pcy","_id":"cinuar4n000ii26s6kfcdyfji"},{"post_id":"cinuar4n100ij26s6p77n7hpq","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4n300in26s66e5mt6oj"},{"post_id":"cinuar4n100ij26s6p77n7hpq","tag_id":"cinuar4n200il26s6i3qx281h","_id":"cinuar4n300io26s6ykddw88e"},{"post_id":"cinuar4n100ij26s6p77n7hpq","tag_id":"cinuar4n300im26s6j6ch1g77","_id":"cinuar4n300ip26s6bg13ack5"},{"post_id":"cinuar4n400iq26s6zwbowo4z","tag_id":"cinuar4n600is26s655bwck2k","_id":"cinuar4n700iv26s61zndu7ce"},{"post_id":"cinuar4n400iq26s6zwbowo4z","tag_id":"cinuar4n600it26s66uotw4qj","_id":"cinuar4n700iw26s6zp0j9l5t"},{"post_id":"cinuar4n700ix26s65ack2bj5","tag_id":"cinuar4n900iz26s6hez1dzu3","_id":"cinuar4n900j026s69gapaw2a"},{"post_id":"cinuar4nb00j126s68v6ogdl4","tag_id":"cinuar4nd00j326s670ni2fri","_id":"cinuar4ne00j626s654eqnjyc"},{"post_id":"cinuar4nb00j126s68v6ogdl4","tag_id":"cinuar4nd00j426s60npnvrym","_id":"cinuar4ne00j726s6qiqxi4vt"},{"post_id":"cinuar4nb00j126s68v6ogdl4","tag_id":"cinuar4nd00j526s6mzb5pw7y","_id":"cinuar4ne00j826s6vq1e330v"},{"post_id":"cinuar4ng00j926s6qrjirv0r","tag_id":"cinuar4nh00jb26s6dozwgtxl","_id":"cinuar4ni00je26s6z57jmjzy"},{"post_id":"cinuar4ng00j926s6qrjirv0r","tag_id":"cinuar4ni00jc26s6nolqh81a","_id":"cinuar4nj00jf26s6szngf13g"},{"post_id":"cinuar4ng00j926s6qrjirv0r","tag_id":"cinuar4ni00jd26s6w3wixnqk","_id":"cinuar4nj00jg26s6y08kpvug"},{"post_id":"cinuar4nk00jh26s6zz5fd8p0","tag_id":"cinuar4nl00jj26s6u2jtf6n7","_id":"cinuar4nl00jk26s6zh13063m"},{"post_id":"cinuar4nm00jl26s608tmpb4g","tag_id":"cinuar4nn00jn26s6jd9pd4cl","_id":"cinuar4no00jq26s6nglm39fq"},{"post_id":"cinuar4nm00jl26s608tmpb4g","tag_id":"cinuar4no00jo26s6ajkjoca2","_id":"cinuar4np00jr26s6tg0csh45"},{"post_id":"cinuar4nm00jl26s608tmpb4g","tag_id":"cinuar4no00jp26s6qsgflauq","_id":"cinuar4np00js26s6et58cdxf"},{"post_id":"cinuar4np00jt26s6pb8k5vmp","tag_id":"cinuar4nd00j326s670ni2fri","_id":"cinuar4nr00jv26s6ww85w9o6"},{"post_id":"cinuar4np00jt26s6pb8k5vmp","tag_id":"cinuar4n900iz26s6hez1dzu3","_id":"cinuar4ns00jw26s6dznfwegj"},{"post_id":"cinuar4nu00jx26s6tll8lgw9","tag_id":"cinuar4nv00jz26s66wpw6a48","_id":"cinuar4nw00k026s6q8hil46s"},{"post_id":"cinuar4nu00jx26s6tll8lgw9","tag_id":"cinuar4n900iz26s6hez1dzu3","_id":"cinuar4nw00k126s6xln4qa0c"},{"post_id":"cinuar4ny00k226s6z95elcyp","tag_id":"cinuar4o000k426s6gvijom9a","_id":"cinuar4o100k526s6q51y4qmb"},{"post_id":"cinuar4o200k626s6mia3myn6","tag_id":"cinuar4mu00i526s6fuzjoe85","_id":"cinuar4oa00k926s69nkgdnrx"},{"post_id":"cinuar4o200k626s6mia3myn6","tag_id":"cinuar4o900k826s6ltxhsb4p","_id":"cinuar4oa00ka26s6nobbbsdd"},{"post_id":"cinuar4ob00kb26s6w78742dj","tag_id":"cinuar4oc00kd26s6w3kxla2d","_id":"cinuar4od00kf26s6krwbvrzy"},{"post_id":"cinuar4ob00kb26s6w78742dj","tag_id":"cinuar4od00ke26s6or60zl5y","_id":"cinuar4od00kg26s6cbnf700l"},{"post_id":"cinuar4oe00kh26s6wag5x4na","tag_id":"cinuar4of00kj26s63geousmr","_id":"cinuar4og00km26s6w8olgczp"},{"post_id":"cinuar4oe00kh26s6wag5x4na","tag_id":"cinuar4og00kk26s6aw70c2ev","_id":"cinuar4og00kn26s6at908dgs"},{"post_id":"cinuar4oh00ko26s6y7ra7n0m","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4oj00kr26s6kdbx5aao"},{"post_id":"cinuar4oh00ko26s6y7ra7n0m","tag_id":"cinuar4cd003a26s6ph9k1q8d","_id":"cinuar4oj00ks26s6bko8qf10"},{"post_id":"cinuar4oh00ko26s6y7ra7n0m","tag_id":"cinuar4oi00kq26s6cxko2syk","_id":"cinuar4oj00kt26s6ourb3k6t"},{"post_id":"cinuar4ok00ku26s6hp6d9hpr","tag_id":"cinuar4b6000p26s674xvgczw","_id":"cinuar4om00kx26s6on5x9p47"},{"post_id":"cinuar4ok00ku26s6hp6d9hpr","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4on00ky26s632yjh37c"},{"post_id":"cinuar4ok00ku26s6hp6d9hpr","tag_id":"cinuar4om00kw26s6lzza27jw","_id":"cinuar4on00kz26s6ltla41mj"},{"post_id":"cinuar4oo00l026s64chh0ujv","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4oq00l426s6h6uwkozr"},{"post_id":"cinuar4oo00l026s64chh0ujv","tag_id":"cinuar4op00l226s60c7stedk","_id":"cinuar4oq00l526s6asvtbah4"},{"post_id":"cinuar4oo00l026s64chh0ujv","tag_id":"cinuar4op00l326s6xmhfcj52","_id":"cinuar4oq00l626s6tdpkxss8"},{"post_id":"cinuar4or00l726s63yi8qs67","tag_id":"cinuar4os00l926s60205x89p","_id":"cinuar4ot00lb26s6ae0d2hrc"},{"post_id":"cinuar4or00l726s63yi8qs67","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4ou00lc26s6k04ld7lr"},{"post_id":"cinuar4or00l726s63yi8qs67","tag_id":"cinuar4op00l226s60c7stedk","_id":"cinuar4ou00ld26s6ownmeq7u"},{"post_id":"cinuar4or00l726s63yi8qs67","tag_id":"cinuar4ot00la26s6bcv39yer","_id":"cinuar4ou00le26s6ll53mbai"},{"post_id":"cinuar4ou00lf26s6dipl1s9h","tag_id":"cinuar4b6000q26s63wmb76mp","_id":"cinuar4ox00lk26s6rzouy7g4"},{"post_id":"cinuar4ou00lf26s6dipl1s9h","tag_id":"cinuar4ow00lh26s6q6ux2opv","_id":"cinuar4ox00ll26s6ykisuxti"},{"post_id":"cinuar4ou00lf26s6dipl1s9h","tag_id":"cinuar4ow00li26s6imbwmjvr","_id":"cinuar4ox00lm26s6mcj8s201"},{"post_id":"cinuar4ou00lf26s6dipl1s9h","tag_id":"cinuar4ox00lj26s610ovig5y","_id":"cinuar4oy00ln26s662g758et"},{"post_id":"cinuar4oy00lo26s62qr1ozgd","tag_id":"cinuar4p000lq26s6tfgq4jx9","_id":"cinuar4p000lr26s6nsunj8qi"},{"post_id":"cinuar4p100lt26s6w64x22ch","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4p300lw26s607rhunbp"},{"post_id":"cinuar4p100lt26s6w64x22ch","tag_id":"cinuar4p200lv26s6son30rll","_id":"cinuar4p300lx26s69s2k4geh"},{"post_id":"cinuar4p100lt26s6w64x22ch","tag_id":"cinuar4bo001q26s63e7obpjk","_id":"cinuar4p300ly26s6jgadfv3u"},{"post_id":"cinuar4p400lz26s680kim30c","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4p500m126s68mvfw5mr"},{"post_id":"cinuar4p400lz26s680kim30c","tag_id":"cinuar4bo001q26s63e7obpjk","_id":"cinuar4p600m226s62v4gp7pn"},{"post_id":"cinuar4p600m326s64bd8i4tz","tag_id":"cinuar4p800m526s6f7lugtdw","_id":"cinuar4p900m826s6jpcnjusm"},{"post_id":"cinuar4p600m326s64bd8i4tz","tag_id":"cinuar4p800m626s68orud1zl","_id":"cinuar4p900m926s67thk5hin"},{"post_id":"cinuar4p600m326s64bd8i4tz","tag_id":"cinuar4ly00gv26s6cimzbp5m","_id":"cinuar4p900ma26s6x1rt4a5h"},{"post_id":"cinuar4p600m326s64bd8i4tz","tag_id":"cinuar4p900m726s6h0bgik0j","_id":"cinuar4p900mb26s6s4v6x7az"},{"post_id":"cinuar4pa00mc26s6bok0vbe0","tag_id":"cinuar4pc00me26s6qltf8fm4","_id":"cinuar4pd00mg26s6u8qinnia"},{"post_id":"cinuar4pa00mc26s6bok0vbe0","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4pd00mh26s66a1ar846"},{"post_id":"cinuar4pa00mc26s6bok0vbe0","tag_id":"cinuar4pc00mf26s62462japl","_id":"cinuar4pd00mi26s6cfsvxmhk"},{"post_id":"cinuar4pe00mj26s67v6in4of","tag_id":"cinuar4pc00me26s6qltf8fm4","_id":"cinuar4pf00ml26s6n2g2y3ib"},{"post_id":"cinuar4pe00mj26s67v6in4of","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4pf00mm26s66a8ql524"},{"post_id":"cinuar4pg00mn26s6vw9prq4o","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4pi00mq26s6em1k6vd6"},{"post_id":"cinuar4pg00mn26s6vw9prq4o","tag_id":"cinuar4pi00mp26s6cwt8dw1c","_id":"cinuar4pi00mr26s69fs83f76"},{"post_id":"cinuar4pg00mn26s6vw9prq4o","tag_id":"cinuar4n200il26s6i3qx281h","_id":"cinuar4pj00ms26s6rp9suklq"},{"post_id":"cinuar4pk00mt26s6sgwto2ti","tag_id":"cinuar4pm00mv26s6l7i5upr2","_id":"cinuar4pn00mw26s69ro6me2t"},{"post_id":"cinuar4pk00mt26s6sgwto2ti","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4pn00mx26s62r8lpb4z"},{"post_id":"cinuar4pk00mt26s6sgwto2ti","tag_id":"cinuar4n200il26s6i3qx281h","_id":"cinuar4pn00my26s6pphvmcdp"},{"post_id":"cinuar4po00mz26s6jdrymye0","tag_id":"cinuar4ky00f726s6yserjydi","_id":"cinuar4pq00n126s6ygxjxl3e"},{"post_id":"cinuar4pr00n226s64munergq","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4ps00n426s6uhom3dqo"},{"post_id":"cinuar4pt00n526s6uhlgsce3","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4pv00n726s6dwfy40zy"},{"post_id":"cinuar4pv00n826s698fiqabc","tag_id":"cinuar4mx00ia26s6zxhx533z","_id":"cinuar4q000na26s6dg9s6pcl"},{"post_id":"cinuar4q100nb26s6m90bmg09","tag_id":"cinuar4q200nd26s6w8ogm8vk","_id":"cinuar4q300ne26s6w537haif"},{"post_id":"cinuar4q400nf26s6md0ea01o","tag_id":"cinuar4q600nh26s6ti8wwla5","_id":"cinuar4q700ni26s6ut3p4lyq"},{"post_id":"cinuar4q800nj26s60b7ar14x","tag_id":"cinuar4qa00nl26s6krrn1bzn","_id":"cinuar4qa00nm26s6l8qt0pl4"},{"post_id":"cinuar4q800nj26s60b7ar14x","tag_id":"cinuar4bs001y26s6kapkjzi2","_id":"cinuar4qb00nn26s6vxxlq20a"},{"post_id":"cinuar4q800nj26s60b7ar14x","tag_id":"cinuar4bs001z26s6p6cfzqey","_id":"cinuar4qb00no26s6tied95ge"},{"post_id":"cinuar4qb00np26s6drm10y2z","tag_id":"cinuar4qd00nr26s639k1d3cl","_id":"cinuar4qe00nt26s66l1mrkra"},{"post_id":"cinuar4qb00np26s6drm10y2z","tag_id":"cinuar4qd00ns26s6ewkgtkrm","_id":"cinuar4qe00nu26s65agmuozy"},{"post_id":"cinuar4qf00nv26s6p13wfz6q","tag_id":"cinuar4qg00nx26s6vhfei7cw","_id":"cinuar4qg00ny26s6l0jgz4b0"},{"post_id":"cinuar4qh00nz26s65e065m7o","tag_id":"cinuar4qj00o126s6cvdvjjih","_id":"cinuar4qk00o426s6np9ouhgj"},{"post_id":"cinuar4qh00nz26s65e065m7o","tag_id":"cinuar4qj00o226s6ck5hefgd","_id":"cinuar4qk00o526s60lswesd9"},{"post_id":"cinuar4qh00nz26s65e065m7o","tag_id":"cinuar4qk00o326s6kexoipzl","_id":"cinuar4qk00o626s64jvxzyqt"},{"post_id":"cinuar4ql00o726s6fdumg49d","tag_id":"cinuar4qn00o926s6nggk0e37","_id":"cinuar4qn00oa26s62855rtoj"},{"post_id":"cinuar4qo00oc26s6kz7feo2t","tag_id":"cinuar4a9000226s68m58rh42","_id":"cinuar4qq00oe26s6dk3g5aa7"},{"post_id":"cinuar4qr00of26s69p7g1dfl","tag_id":"cinuar4qs00oh26s6tmup28y7","_id":"cinuar4qu00ol26s6embk1l22"},{"post_id":"cinuar4qr00of26s69p7g1dfl","tag_id":"cinuar4qt00oi26s69xutikdt","_id":"cinuar4qu00om26s6tkeouqny"},{"post_id":"cinuar4qr00of26s69p7g1dfl","tag_id":"cinuar4qt00ok26s6h6mne3an","_id":"cinuar4qu00on26s6znrtxrto"},{"post_id":"cinuar4qv00oo26s6odqra38x","tag_id":"cinuar4os00l926s60205x89p","_id":"cinuar4qx00or26s6zrajtip0"},{"post_id":"cinuar4qv00oo26s6odqra38x","tag_id":"cinuar4qw00oq26s6r0ncj4dz","_id":"cinuar4qx00os26s6gdsea8b8"},{"post_id":"cinuar4qv00oo26s6odqra38x","tag_id":"cinuar4op00l226s60c7stedk","_id":"cinuar4qx00ot26s6vux3z8o1"},{"post_id":"cinuar4qy00ou26s6ragxb04f","tag_id":"cinuar4r000ow26s64elnl28j","_id":"cinuar4r000ox26s6j2yk50og"},{"post_id":"cinuar4r100oz26s6yduu1wd3","tag_id":"cinuar4r000ow26s64elnl28j","_id":"cinuar4r300p126s6l8m454lv"},{"post_id":"cinuar4r100oz26s6yduu1wd3","tag_id":"cinuar4bo001q26s63e7obpjk","_id":"cinuar4r300p226s6dbcrkpcq"},{"post_id":"cinuar4r400p326s680etg6jd","tag_id":"cinuar4r000ow26s64elnl28j","_id":"cinuar4r500p526s6w8xgqv7s"},{"post_id":"cinuar4r600p626s6627ru215","tag_id":"cinuar4r800p826s6mciri9ds","_id":"cinuar4r800p926s6kq6ktcic"},{"post_id":"cinuar4r600p626s6627ru215","tag_id":"cinuar4r000ow26s64elnl28j","_id":"cinuar4r900pa26s688odii5v"},{"post_id":"cinuar4r900pb26s6maskh2ev","tag_id":"cinuar4rb00pd26s6hla060y4","_id":"cinuar4rc00pf26s6gttk988r"},{"post_id":"cinuar4r900pb26s6maskh2ev","tag_id":"cinuar4rc00pe26s65mxsaasr","_id":"cinuar4rc00pg26s62rlvjyor"},{"post_id":"cinuar4rd00ph26s6aa5bhxk4","tag_id":"cinuar4re00pj26s6raj8zdks","_id":"cinuar4rf00pk26s6869kzuqu"},{"post_id":"cinuar4rg00pl26s6vqktnddf","tag_id":"cinuar4rh00pn26s6h8bowz3q","_id":"cinuar4ri00pp26s6jrapn7e0"},{"post_id":"cinuar4rg00pl26s6vqktnddf","tag_id":"cinuar4rh00po26s62g6lzscp","_id":"cinuar4ri00pq26s6vhpwatko"},{"post_id":"cinuar4rj00pr26s6r04w8ehd","tag_id":"cinuar4rl00pt26s60xi46r0v","_id":"cinuar4rl00pu26s6wns3ch28"},{"post_id":"cinuar4rm00pv26s6kzixwfho","tag_id":"cinuar4lu00gn26s6rlmldmu5","_id":"cinuar4ro00px26s6p5eszzts"},{"post_id":"cinuar4ro00py26s6ps4majer","tag_id":"cinuar4lu00gn26s6rlmldmu5","_id":"cinuar4rq00q026s6ndqm356g"},{"post_id":"cinuar4rr00q126s6o0wlhur7","tag_id":"cinuar4lu00gn26s6rlmldmu5","_id":"cinuar4rs00q326s6g2i35c3i"},{"post_id":"cinuar4rt00q426s6bo5y5kdf","tag_id":"cinuar4ru00q626s6b52ovj8e","_id":"cinuar4rv00q726s6e4g2qwwb"},{"post_id":"cinuar4rw00q826s6exhpkyz0","tag_id":"cinuar4lu00gn26s6rlmldmu5","_id":"cinuar4ry00qb26s633q29uyy"},{"post_id":"cinuar4rw00q826s6exhpkyz0","tag_id":"cinuar4rx00qa26s6yj2bitej","_id":"cinuar4ry00qc26s6csi5fbs7"},{"post_id":"cinuar4rz00qd26s6dsyts4o3","tag_id":"cinuar4o000k426s6gvijom9a","_id":"cinuar4s100qg26s68vfhp59t"},{"post_id":"cinuar4rz00qd26s6dsyts4o3","tag_id":"cinuar4s000qf26s6w0dw3boj","_id":"cinuar4s100qh26s61umo22zy"},{"post_id":"cinuar4s200qi26s6951lo4yg","tag_id":"cinuar4o000k426s6gvijom9a","_id":"cinuar4s400ql26s60l07bqca"},{"post_id":"cinuar4s200qi26s6951lo4yg","tag_id":"cinuar4s400qk26s6g1yxjzdc","_id":"cinuar4s400qm26s6dpu0aa45"},{"post_id":"cinuar4s500qn26s6weltpwop","tag_id":"cinuar4o000k426s6gvijom9a","_id":"cinuar4s800qp26s6pju2ukuk"},{"post_id":"cinuar4s500qn26s6weltpwop","tag_id":"cinuar4s400qk26s6g1yxjzdc","_id":"cinuar4s800qq26s62q7dgjmj"},{"post_id":"cinuar4s900qr26s68lahxugf","tag_id":"cinuar4o000k426s6gvijom9a","_id":"cinuar4sb00qt26s69dnlki8f"},{"post_id":"cinuar4sc00qu26s65fbsh6ci","tag_id":"cinuar4sd00qw26s6rxkuq94e","_id":"cinuar4sf00qz26s6cs79hez6"},{"post_id":"cinuar4sc00qu26s65fbsh6ci","tag_id":"cinuar4se00qx26s6k08y768j","_id":"cinuar4sf00r026s6dh3iq769"},{"post_id":"cinuar4sc00qu26s65fbsh6ci","tag_id":"cinuar4se00qy26s6m7vyy1a8","_id":"cinuar4sf00r126s6hf4woedk"}],"Tag":[{"name":"C名题百则","_id":"cinuar4a9000226s68m58rh42"},{"name":"公开课","_id":"cinuar4ay000926s69rywph8s"},{"name":"金融学","_id":"cinuar4ay000a26s6s12n9fl4"},{"name":"manufactoria","_id":"cinuar4b1000g26s69ufctg7z"},{"name":"选择排序","_id":"cinuar4b3000l26s6mmnmlq34"},{"name":"Sphinx","_id":"cinuar4b6000p26s674xvgczw"},{"name":"Sphinx-for-chinese","_id":"cinuar4b6000q26s63wmb76mp"},{"name":"sql_query_info","_id":"cinuar4b7000s26s6s588wk3t"},{"name":"匈牙利","_id":"cinuar4b7000t26s6c6m11nf1"},{"name":"硬链接","_id":"cinuar4ba001026s6ag18kswt"},{"name":"软链接","_id":"cinuar4bb001126s6pz1ggtjf"},{"name":"defaultdict","_id":"cinuar4be001726s65linj3v3"},{"name":"简洁","_id":"cinuar4be001826s6egag66wd"},{"name":"max_matches","_id":"cinuar4bh001e26s6949s0pz0"},{"name":"SetLimits","_id":"cinuar4bi001f26s6aouq1ce5"},{"name":"flush","_id":"cinuar4bn001n26s6mj74iuj2"},{"name":"sphinxclient","_id":"cinuar4bo001o26s6oc9mt2p5"},{"name":"开源","_id":"cinuar4bo001p26s6srjae7id"},{"name":"索引","_id":"cinuar4bo001q26s63e7obpjk"},{"name":"筛法","_id":"cinuar4bs001y26s6kapkjzi2"},{"name":"素数","_id":"cinuar4bs001z26s6p6cfzqey"},{"name":"html","_id":"cinuar4bz002a26s6vjfwau5c"},{"name":"javascript","_id":"cinuar4c0002b26s6q8jxpzip"},{"name":"焦点","_id":"cinuar4c0002d26s6i9xawxcg"},{"name":"select","_id":"cinuar4c4002j26s62go0m8vu"},{"name":"SIGINT","_id":"cinuar4c5002k26s6xupqqp8o"},{"name":"sleep","_id":"cinuar4c5002l26s6tjd7qmt0"},{"name":"中断","_id":"cinuar4c5002m26s6y4yla9ql"},{"name":"定时器","_id":"cinuar4c5002n26s6tuduuql8"},{"name":"忽略","_id":"cinuar4c5002o26s6w4bgtd5y"},{"name":"epoll","_id":"cinuar4c8002x26s6iw2d7lqi"},{"name":"telnet","_id":"cinuar4c9002y26s6as9ger7t"},{"name":"Klist","_id":"cinuar4cd003726s6fjr07x3t"},{"name":"Klists","_id":"cinuar4cd003826s6grkzvhx5"},{"name":"删除","_id":"cinuar4cd003926s69zuc9138"},{"name":"更新","_id":"cinuar4cd003a26s6ph9k1q8d"},{"name":"主索引","_id":"cinuar4cg003j26s6nqlj7yat"},{"name":"速度","_id":"cinuar4ch003k26s619pcuqhs"},{"name":"临时索引","_id":"cinuar4cl003r26s6sfcrph38"},{"name":"增量索引","_id":"cinuar4cl003s26s6pxd84911"},{"name":"delta","_id":"cinuar4cn003y26s6pnuejj7f"},{"name":"main","_id":"cinuar4co003z26s61m1ac812"},{"name":"最小公倍数","_id":"cinuar4cs004726s6wveb8eed"},{"name":"质因子","_id":"cinuar4ct004826s61s3vpqp6"},{"name":"欧拉工程","_id":"cinuar4cv004d26s62zjm4phg"},{"name":"毕达哥拉斯数","_id":"cinuar4cw004e26s6rllzynja"},{"name":"连续乘积","_id":"cinuar4d0004k26s67ngzm6o2"},{"name":"米勒-拉宾","_id":"cinuar4d6004t26s6a5n6upsz"},{"name":"素数判定","_id":"cinuar4d6004u26s60fv5vlks"},{"name":"和的平方","_id":"cinuar4da005026s6qcnhrzmy"},{"name":"平方的和","_id":"cinuar4da005126s6gklu6r0e"},{"name":"异或","_id":"cinuar4dd005726s6033zcdhh"},{"name":"分数加法","_id":"cinuar4dj005h26s6whaud91p"},{"name":"幂方","_id":"cinuar4do005m26s6l8rfe50y"},{"name":"利克瑞尔数","_id":"cinuar4dq005r26s6vec28s6i"},{"name":"回文数","_id":"cinuar4dq005s26s6sl2g9yki"},{"name":"扑克牌","_id":"cinuar4dv005y26s6zdsw5yue"},{"name":"阶乘","_id":"cinuar4e0006326s60hill1jd"},{"name":"倍数","_id":"cinuar4e3006826s6lel5o74n"},{"name":"排列","_id":"cinuar4e3006926s6aoyilbo5"},{"name":"素数族","_id":"cinuar4e5006f26s6fn0ek248"},{"name":"连续素数和","_id":"cinuar4e8006k26s62mdsyuuv"},{"name":"最小乘积","_id":"cinuar4eg006p26s6keun9hkn"},{"name":"大数运算","_id":"cinuar4ek006y26s6fbl7r459"},{"name":"素数因子","_id":"cinuar4en007426s6q910fhf6"},{"name":"哥德巴赫的另一个猜想","_id":"cinuar4eq007926s6uq8gu1b7"},{"name":"三角形的","_id":"cinuar4es007e26s6uo4ep8ga"},{"name":"五边形的","_id":"cinuar4et007f26s6if4edqcp"},{"name":"六边形的","_id":"cinuar4et007g26s6hmo5egjr"},{"name":"五边形数","_id":"cinuar4ew007n26s66chqv7dn"},{"name":"推理","_id":"cinuar4f0007s26s6idk0h80d"},{"name":"枚举","_id":"cinuar4f0007t26s6kqskc3a5"},{"name":"三角数","_id":"cinuar4f3007z26s6y9w7yewp"},{"name":"全位数","_id":"cinuar4f5008426s6wixgxp7j"},{"name":"Champernowne数","_id":"cinuar4fa008a26s6a71m9q6n"},{"name":"直角三角形","_id":"cinuar4g0008j26s603j87e5e"},{"name":"进制","_id":"cinuar4gb008x26s6gldfmcj8"},{"name":"分数化简","_id":"cinuar4gp009c26s6o2a7r2a9"},{"name":"动态规划","_id":"cinuar4gz009l26s6k4sddmgb"},{"name":"多重背包","_id":"cinuar4gz009m26s6az7vaoj9"},{"name":"幂","_id":"cinuar4h3009s26s6z4x4r8by"},{"name":"最大素数因子","_id":"cinuar4h6009x26s6iarz4qtn"},{"name":"螺旋","_id":"cinuar4hm00a626s6ow07adqh"},{"name":"二项式公式","_id":"cinuar4hx00ab26s6awlxzb1y"},{"name":"单分数","_id":"cinuar4i200ah26s6d6pa2jvn"},{"name":"循环小数","_id":"cinuar4i300ai26s6af9ymbnd"},{"name":"斐波那契数列","_id":"cinuar4i600ao26s6h8rgzuwm"},{"name":"全排列","_id":"cinuar4ia00at26s6bh2fhi3j"},{"name":"非递归","_id":"cinuar4ib00au26s6tz2u40mq"},{"name":"亏数","_id":"cinuar4ie00b026s6t864xgwq"},{"name":"完美数","_id":"cinuar4if00b126s6ri94orel"},{"name":"盈数","_id":"cinuar4if00b226s6c5g8r5q9"},{"name":"字典序","_id":"cinuar4it00b926s60kvylkkl"},{"name":"亲和数","_id":"cinuar4iv00be26s6wdej6wu3"},{"name":"日期","_id":"cinuar4j300br26s6aqpvz4r2"},{"name":"闰年","_id":"cinuar4j300bs26s64gd96mac"},{"name":"数字写成单词","_id":"cinuar4j800c226s6fpqhkz89"},{"name":"组合","_id":"cinuar4jd00cb26s6huxtr42u"},{"name":"collatz","_id":"cinuar4jf00cg26s6bmsyfiri"},{"name":"考拉兹问题","_id":"cinuar4jg00ch26s6hnqrjojc"},{"name":"大整数求和","_id":"cinuar4ji00cn26s6bb7924kx"},{"name":"因子个数","_id":"cinuar4jl00cs26s631cecde8"},{"name":"lsof","_id":"cinuar4jx00db26s68nlmzhwg"},{"name":"netstat","_id":"cinuar4jx00dc26s625njdk1a"},{"name":"编辑距离","_id":"cinuar4k700dn26s6qmszr3df"},{"name":"递归","_id":"cinuar4k700do26s6h1benj4x"},{"name":"堆","_id":"cinuar4ka00du26s65nnsb8s0"},{"name":"最小的K个数","_id":"cinuar4ka00dv26s647frncyd"},{"name":"最大连续子序列","_id":"cinuar4kd00e026s6mv5lwtf5"},{"name":"最大子矩阵","_id":"cinuar4kh00e726s68iizdwgj"},{"name":"加德纳","_id":"cinuar4kk00ec26s6ldbr3bgk"},{"name":"无解的难题","_id":"cinuar4kk00ed26s6v3fuija7"},{"name":"整数划分","_id":"cinuar4km00ej26s6deq0sevy"},{"name":"漩涡","_id":"cinuar4kp00ep26s6zublvgys"},{"name":"股票","_id":"cinuar4ks00eu26s6iyzdolwk"},{"name":"Solr","_id":"cinuar4ky00f726s6yserjydi"},{"name":"正则","_id":"cinuar4l100fb26s67egwxhw8"},{"name":"点号","_id":"cinuar4l100fc26s6cpluftj6"},{"name":"扔蛋问题","_id":"cinuar4l400fi26s6aavilbki"},{"name":"C命题百则","_id":"cinuar4l800fq26s6tlj2o1o7"},{"name":"jdk","_id":"cinuar4la00fu26s6kimot3gu"},{"name":"Maven","_id":"cinuar4ld00fy26s66d7y0w6q"},{"name":"site查询","_id":"cinuar4lg00g326s67oksn3il"},{"name":"八皇后问题","_id":"cinuar4ln00gb26s627j3awd5"},{"name":"方格","_id":"cinuar4ln00gc26s6lc8qsdqg"},{"name":"堆排序","_id":"cinuar4lp00gh26s6a94yh43y"},{"name":"Elasticsearch","_id":"cinuar4lu00gn26s6rlmldmu5"},{"name":"Intellij","_id":"cinuar4lu00go26s6l7n7pglb"},{"name":"C++","_id":"cinuar4lx00gt26s68pfzq0sx"},{"name":"coredump","_id":"cinuar4ly00gu26s6uyptxon1"},{"name":"sort","_id":"cinuar4ly00gv26s6cimzbp5m"},{"name":"比较函数","_id":"cinuar4ly00gw26s6yr0n77xz"},{"name":"取石子","_id":"cinuar4m400h326s68gv2ez79"},{"name":"黄金分割比","_id":"cinuar4m400h426s6dk5ncobv"},{"name":"笔试题","_id":"cinuar4m700h926s6e5h4tace"},{"name":"virtualenvwrapper","_id":"cinuar4mg00hk26s6w70mdbhk"},{"name":"virtual","_id":"cinuar4mh00hl26s6ph9z2wp1"},{"name":"Hexo","_id":"cinuar4mu00i526s6fuzjoe85"},{"name":"fieldcache","_id":"cinuar4mw00i926s6y0ddaloj"},{"name":"solr","_id":"cinuar4mx00ia26s6zxhx533z"},{"name":"段合并","_id":"cinuar4mz00if26s62vbj9pcy"},{"name":"分布式","_id":"cinuar4n200il26s6i3qx281h"},{"name":"分页","_id":"cinuar4n300im26s6j6ch1g77"},{"name":"smarty","_id":"cinuar4n600is26s655bwck2k"},{"name":"换行","_id":"cinuar4n600it26s66uotw4qj"},{"name":"shell","_id":"cinuar4n900iz26s6hez1dzu3"},{"name":"find","_id":"cinuar4nd00j326s670ni2fri"},{"name":"sed","_id":"cinuar4nd00j426s60npnvrym"},{"name":"子目录","_id":"cinuar4nd00j526s6mzb5pw7y"},{"name":"mysqli","_id":"cinuar4nh00jb26s6dozwgtxl"},{"name":"mysqli_fetch_all","_id":"cinuar4ni00jc26s6nolqh81a"},{"name":"mysqlnd","_id":"cinuar4ni00jd26s6w3wixnqk"},{"name":"junit","_id":"cinuar4nl00jj26s6u2jtf6n7"},{"name":"byte数组","_id":"cinuar4nn00jn26s6jd9pd4cl"},{"name":"java","_id":"cinuar4no00jo26s6ajkjoca2"},{"name":"转换","_id":"cinuar4no00jp26s6qsgflauq"},{"name":"crontab","_id":"cinuar4nv00jz26s66wpw6a48"},{"name":"Django","_id":"cinuar4o000k426s6gvijom9a"},{"name":"Wordpress","_id":"cinuar4o900k826s6ltxhsb4p"},{"name":"evince","_id":"cinuar4oc00kd26s6w3kxla2d"},{"name":"pdf","_id":"cinuar4od00ke26s6or60zl5y"},{"name":"TCP","_id":"cinuar4of00kj26s63geousmr"},{"name":"三次握手","_id":"cinuar4og00kk26s6aw70c2ev"},{"name":"负值","_id":"cinuar4oi00kq26s6cxko2syk"},{"name":"一元分词","_id":"cinuar4om00kw26s6lzza27jw"},{"name":"分词","_id":"cinuar4op00l226s60c7stedk"},{"name":"细粒度","_id":"cinuar4op00l326s6xmhfcj52"},{"name":"mmseg","_id":"cinuar4os00l926s60205x89p"},{"name":"粒度","_id":"cinuar4ot00la26s6bcv39yer"},{"name":"SPH_RANK_SPH04","_id":"cinuar4ow00lh26s6q6ux2opv"},{"name":"分词粒度","_id":"cinuar4ow00li26s6imbwmjvr"},{"name":"精确匹配","_id":"cinuar4ox00lj26s610ovig5y"},{"name":"Spark","_id":"cinuar4p000lq26s6tfgq4jx9"},{"name":"升级","_id":"cinuar4p200lv26s6son30rll"},{"name":"awk","_id":"cinuar4p800m526s6f7lugtdw"},{"name":"grep","_id":"cinuar4p800m626s68orud1zl"},{"name":"uniq","_id":"cinuar4p900m726s6h0bgik0j"},{"name":"security","_id":"cinuar4pc00me26s6qltf8fm4"},{"name":"solrj","_id":"cinuar4pc00mf26s62462japl"},{"name":"stage","_id":"cinuar4pi00mp26s6cwt8dw1c"},{"name":"group查询","_id":"cinuar4pm00mv26s6l7i5upr2"},{"name":"推荐系统","_id":"cinuar4q200nd26s6w8ogm8vk"},{"name":"Screen","_id":"cinuar4q600nh26s6ti8wwla5"},{"name":"列表解析","_id":"cinuar4qa00nl26s6krrn1bzn"},{"name":"PyCharm","_id":"cinuar4qd00nr26s639k1d3cl"},{"name":"vim","_id":"cinuar4qd00ns26s6ewkgtkrm"},{"name":"并查集","_id":"cinuar4qg00nx26s6vhfei7cw"},{"name":"trie","_id":"cinuar4qj00o126s6cvdvjjih"},{"name":"前缀树","_id":"cinuar4qj00o226s6ck5hefgd"},{"name":"字典树","_id":"cinuar4qk00o326s6kexoipzl"},{"name":"octave","_id":"cinuar4qn00o926s6nggk0e37"},{"name":"MySQL","_id":"cinuar4qs00oh26s6tmup28y7"},{"name":"timestamp","_id":"cinuar4qt00oi26s69xutikdt"},{"name":"自动更新","_id":"cinuar4qt00ok26s6h6mne3an"},{"name":"Python","_id":"cinuar4qw00oq26s6r0ncj4dz"},{"name":"Lucene","_id":"cinuar4r000ow26s64elnl28j"},{"name":"codec","_id":"cinuar4r800p826s6mciri9ds"},{"name":"Linux","_id":"cinuar4rb00pd26s6hla060y4"},{"name":"U盘","_id":"cinuar4rc00pe26s65mxsaasr"},{"name":"线程","_id":"cinuar4re00pj26s6raj8zdks"},{"name":"Hadoop","_id":"cinuar4rh00pn26s6h8bowz3q"},{"name":"Yarn","_id":"cinuar4rh00po26s62g6lzscp"},{"name":"AC自动机","_id":"cinuar4rl00pt26s60xi46r0v"},{"name":"Elasticsearch MySQL","_id":"cinuar4ru00q626s6b52ovj8e"},{"name":"ik","_id":"cinuar4rx00qa26s6yj2bitej"},{"name":"静态资源","_id":"cinuar4s000qf26s6w0dw3boj"},{"name":"markdown","_id":"cinuar4s400qk26s6g1yxjzdc"},{"name":"13球","_id":"cinuar4sd00qw26s6rxkuq94e"},{"name":"8球","_id":"cinuar4se00qx26s6k08y768j"},{"name":"信息论","_id":"cinuar4se00qy26s6m7vyy1a8"}]}}